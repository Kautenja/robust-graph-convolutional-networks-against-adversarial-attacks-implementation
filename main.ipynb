{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from keras.layers import Input, Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the path of execution\n",
    "EXE_PATH = os.path.abspath(os.path.curdir)\n",
    "# the path of the vendor files\n",
    "VENDOR_PATH = os.path.join(EXE_PATH, 'vendor')\n",
    "# the vendors to include in the system path\n",
    "VENDORS = ['keras-gcn']\n",
    "# create the absolute paths for all vendors\n",
    "VENDORS = list(map(lambda x: os.path.join(VENDOR_PATH, x), VENDORS))\n",
    "# update the Python path to include necessary vendor module\n",
    "sys.path += VENDORS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kegra.utils import load_data, preprocess_adj, get_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cora dataset...\n",
      "Dataset has 2708 nodes, 5429 edges, 1433 features.\n"
     ]
    }
   ],
   "source": [
    "X, A, y = load_data('data/cora/', dataset='cora')\n",
    "X /= X.sum(1).reshape(-1, 1)\n",
    "A = preprocess_adj(A)\n",
    "y_train, y_val, y_test, idx_train, idx_val, idx_test, train_mask = get_splits(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2708x2708 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 13264 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       ...,\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 1, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0]], dtype=int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1110 14:34:26.142214 140009850488640 deprecation_wrapper.py:119] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1110 14:34:26.149286 140009850488640 deprecation_wrapper.py:119] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:515: The name tf.sparse_placeholder is deprecated. Please use tf.compat.v1.sparse_placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "support = 1\n",
    "graph = [X, A]\n",
    "G = [Input(shape=(None, None), batch_shape=(None, None), sparse=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1110 14:34:26.154808 140009850488640 deprecation_wrapper.py:119] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_in = Input(shape=(X.shape[1],))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCN (baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kegra.layers.graph import GraphConvolution\n",
    "from kegra.utils import evaluate_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1110 14:34:26.165310 140009850488640 deprecation_wrapper.py:119] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W1110 14:34:26.170295 140009850488640 deprecation.py:506] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W1110 14:34:26.179300 140009850488640 deprecation_wrapper.py:119] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define model architecture\n",
    "# NOTE: We pass arguments for graph convolutional layers as a list of tensors.\n",
    "# This is somewhat hacky, more elegant options would require rewriting the Layer base class.\n",
    "H = Dropout(0.5)(X_in)\n",
    "H = GraphConvolution(16, support, activation='relu', kernel_regularizer=l2(5e-4))([H]+G)\n",
    "H = Dropout(0.5)(H)\n",
    "Y = GraphConvolution(y.shape[1], support, activation='softmax')([H]+G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1110 14:34:26.220656 140009850488640 deprecation_wrapper.py:119] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=[X_in]+G, outputs=Y)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1110 14:34:26.290377 140009850488640 deprecation.py:323] From /home/bitcommander/.local/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 train_loss= 1.9334 train_acc= 0.4357 val_loss= 1.9348 val_acc= 0.4033 time= 1.1041\n",
      "Epoch: 0002 train_loss= 1.9210 train_acc= 0.4214 val_loss= 1.9239 val_acc= 0.4033 time= 0.0235\n",
      "Epoch: 0003 train_loss= 1.9068 train_acc= 0.4643 val_loss= 1.9121 val_acc= 0.4200 time= 0.0268\n",
      "Epoch: 0004 train_loss= 1.8922 train_acc= 0.4857 val_loss= 1.9005 val_acc= 0.4633 time= 0.0184\n",
      "Epoch: 0005 train_loss= 1.8779 train_acc= 0.4857 val_loss= 1.8891 val_acc= 0.4633 time= 0.0194\n",
      "Epoch: 0006 train_loss= 1.8630 train_acc= 0.4857 val_loss= 1.8769 val_acc= 0.4633 time= 0.0187\n",
      "Epoch: 0007 train_loss= 1.8477 train_acc= 0.4857 val_loss= 1.8642 val_acc= 0.4800 time= 0.0235\n",
      "Epoch: 0008 train_loss= 1.8321 train_acc= 0.4786 val_loss= 1.8514 val_acc= 0.4800 time= 0.0198\n",
      "Epoch: 0009 train_loss= 1.8169 train_acc= 0.4786 val_loss= 1.8388 val_acc= 0.4767 time= 0.0194\n",
      "Epoch: 0010 train_loss= 1.8021 train_acc= 0.4786 val_loss= 1.8268 val_acc= 0.4733 time= 0.0238\n",
      "Epoch: 0011 train_loss= 1.7872 train_acc= 0.4786 val_loss= 1.8152 val_acc= 0.4800 time= 0.0195\n",
      "Epoch: 0012 train_loss= 1.7727 train_acc= 0.4786 val_loss= 1.8043 val_acc= 0.4800 time= 0.0190\n",
      "Epoch: 0013 train_loss= 1.7588 train_acc= 0.4786 val_loss= 1.7941 val_acc= 0.4800 time= 0.0273\n",
      "Epoch: 0014 train_loss= 1.7459 train_acc= 0.4786 val_loss= 1.7848 val_acc= 0.4800 time= 0.0186\n",
      "Epoch: 0015 train_loss= 1.7337 train_acc= 0.4786 val_loss= 1.7761 val_acc= 0.4800 time= 0.0192\n",
      "Epoch: 0016 train_loss= 1.7222 train_acc= 0.4786 val_loss= 1.7678 val_acc= 0.4800 time= 0.0196\n",
      "Epoch: 0017 train_loss= 1.7113 train_acc= 0.4714 val_loss= 1.7599 val_acc= 0.4700 time= 0.0187\n",
      "Epoch: 0018 train_loss= 1.7008 train_acc= 0.4714 val_loss= 1.7523 val_acc= 0.4533 time= 0.0237\n",
      "Epoch: 0019 train_loss= 1.6908 train_acc= 0.4571 val_loss= 1.7449 val_acc= 0.4333 time= 0.0234\n",
      "Epoch: 0020 train_loss= 1.6809 train_acc= 0.4571 val_loss= 1.7378 val_acc= 0.4233 time= 0.0214\n",
      "Epoch: 0021 train_loss= 1.6711 train_acc= 0.4571 val_loss= 1.7308 val_acc= 0.4167 time= 0.0193\n",
      "Epoch: 0022 train_loss= 1.6611 train_acc= 0.4429 val_loss= 1.7238 val_acc= 0.4133 time= 0.0193\n",
      "Epoch: 0023 train_loss= 1.6511 train_acc= 0.4429 val_loss= 1.7168 val_acc= 0.4100 time= 0.0206\n",
      "Epoch: 0024 train_loss= 1.6409 train_acc= 0.4357 val_loss= 1.7097 val_acc= 0.4033 time= 0.0237\n",
      "Epoch: 0025 train_loss= 1.6305 train_acc= 0.4357 val_loss= 1.7026 val_acc= 0.4033 time= 0.0254\n",
      "Epoch: 0026 train_loss= 1.6198 train_acc= 0.4357 val_loss= 1.6955 val_acc= 0.4033 time= 0.0273\n",
      "Epoch: 0027 train_loss= 1.6091 train_acc= 0.4357 val_loss= 1.6883 val_acc= 0.4033 time= 0.0182\n",
      "Epoch: 0028 train_loss= 1.5983 train_acc= 0.4429 val_loss= 1.6816 val_acc= 0.4133 time= 0.0248\n",
      "Epoch: 0029 train_loss= 1.5876 train_acc= 0.4500 val_loss= 1.6749 val_acc= 0.4133 time= 0.0238\n",
      "Epoch: 0030 train_loss= 1.5769 train_acc= 0.4643 val_loss= 1.6682 val_acc= 0.4200 time= 0.0185\n",
      "Epoch: 0031 train_loss= 1.5661 train_acc= 0.4786 val_loss= 1.6614 val_acc= 0.4300 time= 0.0203\n",
      "Epoch: 0032 train_loss= 1.5553 train_acc= 0.4929 val_loss= 1.6546 val_acc= 0.4367 time= 0.0250\n",
      "Epoch: 0033 train_loss= 1.5444 train_acc= 0.4929 val_loss= 1.6476 val_acc= 0.4433 time= 0.0241\n",
      "Epoch: 0034 train_loss= 1.5335 train_acc= 0.4929 val_loss= 1.6405 val_acc= 0.4767 time= 0.0232\n",
      "Epoch: 0035 train_loss= 1.5225 train_acc= 0.5071 val_loss= 1.6333 val_acc= 0.4800 time= 0.0240\n",
      "Epoch: 0036 train_loss= 1.5116 train_acc= 0.5214 val_loss= 1.6258 val_acc= 0.4967 time= 0.0228\n",
      "Epoch: 0037 train_loss= 1.5006 train_acc= 0.5214 val_loss= 1.6180 val_acc= 0.5000 time= 0.0193\n",
      "Epoch: 0038 train_loss= 1.4898 train_acc= 0.5214 val_loss= 1.6099 val_acc= 0.5033 time= 0.0233\n",
      "Epoch: 0039 train_loss= 1.4789 train_acc= 0.5214 val_loss= 1.6018 val_acc= 0.5033 time= 0.0232\n",
      "Epoch: 0040 train_loss= 1.4680 train_acc= 0.5286 val_loss= 1.5940 val_acc= 0.5067 time= 0.0204\n",
      "Epoch: 0041 train_loss= 1.4570 train_acc= 0.5357 val_loss= 1.5863 val_acc= 0.5100 time= 0.0234\n",
      "Epoch: 0042 train_loss= 1.4461 train_acc= 0.5357 val_loss= 1.5786 val_acc= 0.5133 time= 0.0189\n",
      "Epoch: 0043 train_loss= 1.4352 train_acc= 0.5500 val_loss= 1.5710 val_acc= 0.5200 time= 0.0202\n",
      "Epoch: 0044 train_loss= 1.4244 train_acc= 0.5571 val_loss= 1.5634 val_acc= 0.5233 time= 0.0229\n",
      "Epoch: 0045 train_loss= 1.4137 train_acc= 0.5571 val_loss= 1.5560 val_acc= 0.5300 time= 0.0225\n",
      "Epoch: 0046 train_loss= 1.4032 train_acc= 0.5786 val_loss= 1.5487 val_acc= 0.5333 time= 0.0196\n",
      "Epoch: 0047 train_loss= 1.3927 train_acc= 0.5929 val_loss= 1.5413 val_acc= 0.5333 time= 0.0247\n",
      "Epoch: 0048 train_loss= 1.3823 train_acc= 0.6000 val_loss= 1.5339 val_acc= 0.5367 time= 0.0222\n",
      "Epoch: 0049 train_loss= 1.3720 train_acc= 0.6286 val_loss= 1.5265 val_acc= 0.5467 time= 0.0185\n",
      "Epoch: 0050 train_loss= 1.3618 train_acc= 0.6357 val_loss= 1.5192 val_acc= 0.5533 time= 0.0198\n",
      "Epoch: 0051 train_loss= 1.3517 train_acc= 0.6357 val_loss= 1.5119 val_acc= 0.5567 time= 0.0244\n",
      "Epoch: 0052 train_loss= 1.3416 train_acc= 0.6429 val_loss= 1.5046 val_acc= 0.5567 time= 0.0310\n",
      "Epoch: 0053 train_loss= 1.3317 train_acc= 0.6643 val_loss= 1.4974 val_acc= 0.5567 time= 0.0189\n",
      "Epoch: 0054 train_loss= 1.3217 train_acc= 0.6714 val_loss= 1.4903 val_acc= 0.5600 time= 0.0238\n",
      "Epoch: 0055 train_loss= 1.3117 train_acc= 0.6714 val_loss= 1.4828 val_acc= 0.5600 time= 0.0242\n",
      "Epoch: 0056 train_loss= 1.3017 train_acc= 0.6714 val_loss= 1.4752 val_acc= 0.5667 time= 0.0201\n",
      "Epoch: 0057 train_loss= 1.2918 train_acc= 0.6714 val_loss= 1.4677 val_acc= 0.5667 time= 0.0229\n",
      "Epoch: 0058 train_loss= 1.2821 train_acc= 0.6786 val_loss= 1.4605 val_acc= 0.5733 time= 0.0230\n",
      "Epoch: 0059 train_loss= 1.2725 train_acc= 0.6786 val_loss= 1.4534 val_acc= 0.5767 time= 0.0228\n",
      "Epoch: 0060 train_loss= 1.2627 train_acc= 0.6786 val_loss= 1.4459 val_acc= 0.5833 time= 0.0206\n",
      "Epoch: 0061 train_loss= 1.2530 train_acc= 0.6857 val_loss= 1.4384 val_acc= 0.5867 time= 0.0238\n",
      "Epoch: 0062 train_loss= 1.2434 train_acc= 0.6929 val_loss= 1.4309 val_acc= 0.5867 time= 0.0291\n",
      "Epoch: 0063 train_loss= 1.2338 train_acc= 0.6929 val_loss= 1.4237 val_acc= 0.5867 time= 0.0234\n",
      "Epoch: 0064 train_loss= 1.2243 train_acc= 0.6929 val_loss= 1.4163 val_acc= 0.5900 time= 0.0189\n",
      "Epoch: 0065 train_loss= 1.2148 train_acc= 0.6929 val_loss= 1.4090 val_acc= 0.5900 time= 0.0212\n",
      "Epoch: 0066 train_loss= 1.2053 train_acc= 0.7000 val_loss= 1.4015 val_acc= 0.5900 time= 0.0242\n",
      "Epoch: 0067 train_loss= 1.1960 train_acc= 0.7071 val_loss= 1.3942 val_acc= 0.5967 time= 0.0247\n",
      "Epoch: 0068 train_loss= 1.1868 train_acc= 0.7143 val_loss= 1.3869 val_acc= 0.6033 time= 0.0202\n",
      "Epoch: 0069 train_loss= 1.1780 train_acc= 0.7214 val_loss= 1.3801 val_acc= 0.6100 time= 0.0236\n",
      "Epoch: 0070 train_loss= 1.1690 train_acc= 0.7214 val_loss= 1.3735 val_acc= 0.6100 time= 0.0216\n",
      "Epoch: 0071 train_loss= 1.1603 train_acc= 0.7214 val_loss= 1.3669 val_acc= 0.6233 time= 0.0248\n",
      "Epoch: 0072 train_loss= 1.1513 train_acc= 0.7214 val_loss= 1.3605 val_acc= 0.6233 time= 0.0243\n",
      "Epoch: 0073 train_loss= 1.1425 train_acc= 0.7214 val_loss= 1.3544 val_acc= 0.6400 time= 0.0233\n",
      "Epoch: 0074 train_loss= 1.1334 train_acc= 0.7214 val_loss= 1.3482 val_acc= 0.6433 time= 0.0185\n",
      "Epoch: 0075 train_loss= 1.1241 train_acc= 0.7214 val_loss= 1.3407 val_acc= 0.6400 time= 0.0233\n",
      "Epoch: 0076 train_loss= 1.1151 train_acc= 0.7214 val_loss= 1.3333 val_acc= 0.6333 time= 0.0247\n",
      "Epoch: 0077 train_loss= 1.1066 train_acc= 0.7214 val_loss= 1.3263 val_acc= 0.6267 time= 0.0198\n",
      "Epoch: 0078 train_loss= 1.0985 train_acc= 0.7214 val_loss= 1.3196 val_acc= 0.6200 time= 0.0233\n",
      "Epoch: 0079 train_loss= 1.0904 train_acc= 0.7214 val_loss= 1.3126 val_acc= 0.6200 time= 0.0191\n",
      "Epoch: 0080 train_loss= 1.0824 train_acc= 0.7214 val_loss= 1.3057 val_acc= 0.6233 time= 0.0203\n",
      "Epoch: 0081 train_loss= 1.0746 train_acc= 0.7286 val_loss= 1.2991 val_acc= 0.6333 time= 0.0266\n",
      "Epoch: 0082 train_loss= 1.0668 train_acc= 0.7286 val_loss= 1.2929 val_acc= 0.6400 time= 0.0229\n",
      "Epoch: 0083 train_loss= 1.0591 train_acc= 0.7286 val_loss= 1.2867 val_acc= 0.6500 time= 0.0227\n",
      "Epoch: 0084 train_loss= 1.0514 train_acc= 0.7429 val_loss= 1.2806 val_acc= 0.6633 time= 0.0201\n",
      "Epoch: 0085 train_loss= 1.0434 train_acc= 0.7500 val_loss= 1.2745 val_acc= 0.6700 time= 0.0184\n",
      "Epoch: 0086 train_loss= 1.0350 train_acc= 0.7643 val_loss= 1.2684 val_acc= 0.6767 time= 0.0250\n",
      "Epoch: 0087 train_loss= 1.0265 train_acc= 0.7643 val_loss= 1.2626 val_acc= 0.6967 time= 0.0232\n",
      "Epoch: 0088 train_loss= 1.0179 train_acc= 0.7786 val_loss= 1.2563 val_acc= 0.7033 time= 0.0183\n",
      "Epoch: 0089 train_loss= 1.0096 train_acc= 0.7786 val_loss= 1.2501 val_acc= 0.7100 time= 0.0177\n",
      "Epoch: 0090 train_loss= 1.0018 train_acc= 0.7929 val_loss= 1.2442 val_acc= 0.7033 time= 0.0193\n",
      "Epoch: 0091 train_loss= 0.9943 train_acc= 0.7929 val_loss= 1.2382 val_acc= 0.6967 time= 0.0233\n",
      "Epoch: 0092 train_loss= 0.9869 train_acc= 0.7929 val_loss= 1.2321 val_acc= 0.6967 time= 0.0179\n",
      "Epoch: 0093 train_loss= 0.9797 train_acc= 0.7929 val_loss= 1.2259 val_acc= 0.7000 time= 0.0196\n",
      "Epoch: 0094 train_loss= 0.9726 train_acc= 0.8000 val_loss= 1.2197 val_acc= 0.7000 time= 0.0266\n",
      "Epoch: 0095 train_loss= 0.9653 train_acc= 0.8071 val_loss= 1.2139 val_acc= 0.7067 time= 0.0189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0096 train_loss= 0.9579 train_acc= 0.8071 val_loss= 1.2083 val_acc= 0.7133 time= 0.0222\n",
      "Epoch: 0097 train_loss= 0.9505 train_acc= 0.8143 val_loss= 1.2026 val_acc= 0.7200 time= 0.0238\n",
      "Epoch: 0098 train_loss= 0.9432 train_acc= 0.8357 val_loss= 1.1968 val_acc= 0.7233 time= 0.0183\n",
      "Epoch: 0099 train_loss= 0.9360 train_acc= 0.8429 val_loss= 1.1911 val_acc= 0.7233 time= 0.0224\n",
      "Epoch: 0100 train_loss= 0.9287 train_acc= 0.8500 val_loss= 1.1854 val_acc= 0.7233 time= 0.0223\n",
      "Epoch: 0101 train_loss= 0.9214 train_acc= 0.8500 val_loss= 1.1797 val_acc= 0.7233 time= 0.0199\n",
      "Epoch: 0102 train_loss= 0.9141 train_acc= 0.8500 val_loss= 1.1740 val_acc= 0.7233 time= 0.0222\n",
      "Epoch: 0103 train_loss= 0.9072 train_acc= 0.8500 val_loss= 1.1681 val_acc= 0.7267 time= 0.0226\n",
      "Epoch: 0104 train_loss= 0.9006 train_acc= 0.8500 val_loss= 1.1620 val_acc= 0.7267 time= 0.0182\n",
      "Epoch: 0105 train_loss= 0.8944 train_acc= 0.8571 val_loss= 1.1565 val_acc= 0.7300 time= 0.0181\n",
      "Epoch: 0106 train_loss= 0.8880 train_acc= 0.8643 val_loss= 1.1516 val_acc= 0.7300 time= 0.0224\n",
      "Epoch: 0107 train_loss= 0.8814 train_acc= 0.8643 val_loss= 1.1471 val_acc= 0.7333 time= 0.0246\n",
      "Epoch: 0108 train_loss= 0.8749 train_acc= 0.8643 val_loss= 1.1428 val_acc= 0.7400 time= 0.0239\n",
      "Epoch: 0109 train_loss= 0.8682 train_acc= 0.8643 val_loss= 1.1387 val_acc= 0.7433 time= 0.0236\n",
      "Epoch: 0110 train_loss= 0.8616 train_acc= 0.8714 val_loss= 1.1350 val_acc= 0.7500 time= 0.0179\n",
      "Epoch: 0111 train_loss= 0.8549 train_acc= 0.8714 val_loss= 1.1309 val_acc= 0.7500 time= 0.0228\n",
      "Epoch: 0112 train_loss= 0.8486 train_acc= 0.8643 val_loss= 1.1271 val_acc= 0.7500 time= 0.0198\n",
      "Epoch: 0113 train_loss= 0.8419 train_acc= 0.8643 val_loss= 1.1217 val_acc= 0.7500 time= 0.0231\n",
      "Epoch: 0114 train_loss= 0.8350 train_acc= 0.8714 val_loss= 1.1142 val_acc= 0.7433 time= 0.0229\n",
      "Epoch: 0115 train_loss= 0.8292 train_acc= 0.8643 val_loss= 1.1074 val_acc= 0.7400 time= 0.0183\n",
      "Epoch: 0116 train_loss= 0.8236 train_acc= 0.8643 val_loss= 1.1017 val_acc= 0.7400 time= 0.0234\n",
      "Epoch: 0117 train_loss= 0.8180 train_acc= 0.8643 val_loss= 1.0964 val_acc= 0.7467 time= 0.0207\n",
      "Epoch: 0118 train_loss= 0.8119 train_acc= 0.8714 val_loss= 1.0912 val_acc= 0.7533 time= 0.0208\n",
      "Epoch: 0119 train_loss= 0.8057 train_acc= 0.8786 val_loss= 1.0875 val_acc= 0.7533 time= 0.0240\n",
      "Epoch: 0120 train_loss= 0.8002 train_acc= 0.8714 val_loss= 1.0841 val_acc= 0.7633 time= 0.0235\n",
      "Epoch: 0121 train_loss= 0.7948 train_acc= 0.8714 val_loss= 1.0811 val_acc= 0.7600 time= 0.0184\n",
      "Epoch: 0122 train_loss= 0.7898 train_acc= 0.8786 val_loss= 1.0778 val_acc= 0.7600 time= 0.0186\n",
      "Epoch: 0123 train_loss= 0.7845 train_acc= 0.8929 val_loss= 1.0736 val_acc= 0.7600 time= 0.0191\n",
      "Epoch: 0124 train_loss= 0.7789 train_acc= 0.8929 val_loss= 1.0690 val_acc= 0.7633 time= 0.0283\n",
      "Epoch: 0125 train_loss= 0.7733 train_acc= 0.9071 val_loss= 1.0635 val_acc= 0.7700 time= 0.0183\n",
      "Epoch: 0126 train_loss= 0.7680 train_acc= 0.9071 val_loss= 1.0582 val_acc= 0.7800 time= 0.0230\n",
      "Epoch: 0127 train_loss= 0.7630 train_acc= 0.9071 val_loss= 1.0532 val_acc= 0.7833 time= 0.0194\n",
      "Epoch: 0128 train_loss= 0.7585 train_acc= 0.9071 val_loss= 1.0498 val_acc= 0.7800 time= 0.0228\n",
      "Epoch: 0129 train_loss= 0.7536 train_acc= 0.9071 val_loss= 1.0464 val_acc= 0.7800 time= 0.0184\n",
      "Epoch: 0130 train_loss= 0.7483 train_acc= 0.9071 val_loss= 1.0437 val_acc= 0.7733 time= 0.0197\n",
      "Epoch: 0131 train_loss= 0.7431 train_acc= 0.9071 val_loss= 1.0407 val_acc= 0.7800 time= 0.0272\n",
      "Epoch: 0132 train_loss= 0.7376 train_acc= 0.9071 val_loss= 1.0361 val_acc= 0.7800 time= 0.0185\n",
      "Epoch: 0133 train_loss= 0.7322 train_acc= 0.9071 val_loss= 1.0309 val_acc= 0.7767 time= 0.0186\n",
      "Epoch: 0134 train_loss= 0.7273 train_acc= 0.9071 val_loss= 1.0263 val_acc= 0.7700 time= 0.0189\n",
      "Epoch: 0135 train_loss= 0.7225 train_acc= 0.9071 val_loss= 1.0220 val_acc= 0.7733 time= 0.0247\n",
      "Epoch: 0136 train_loss= 0.7182 train_acc= 0.9071 val_loss= 1.0184 val_acc= 0.7700 time= 0.0183\n",
      "Epoch: 0137 train_loss= 0.7142 train_acc= 0.9143 val_loss= 1.0152 val_acc= 0.7700 time= 0.0230\n",
      "Epoch: 0138 train_loss= 0.7099 train_acc= 0.9214 val_loss= 1.0127 val_acc= 0.7767 time= 0.0190\n",
      "Epoch: 0139 train_loss= 0.7054 train_acc= 0.9214 val_loss= 1.0096 val_acc= 0.7800 time= 0.0187\n",
      "Epoch: 0140 train_loss= 0.7010 train_acc= 0.9143 val_loss= 1.0063 val_acc= 0.7767 time= 0.0221\n",
      "Epoch: 0141 train_loss= 0.6969 train_acc= 0.9071 val_loss= 1.0036 val_acc= 0.7767 time= 0.0224\n",
      "Epoch: 0142 train_loss= 0.6930 train_acc= 0.9071 val_loss= 1.0000 val_acc= 0.7767 time= 0.0198\n",
      "Epoch: 0143 train_loss= 0.6894 train_acc= 0.9071 val_loss= 0.9972 val_acc= 0.7767 time= 0.0189\n",
      "Epoch: 0144 train_loss= 0.6860 train_acc= 0.9071 val_loss= 0.9951 val_acc= 0.7767 time= 0.0226\n",
      "Epoch: 0145 train_loss= 0.6826 train_acc= 0.9071 val_loss= 0.9926 val_acc= 0.7833 time= 0.0246\n",
      "Epoch: 0146 train_loss= 0.6792 train_acc= 0.9071 val_loss= 0.9898 val_acc= 0.7833 time= 0.0235\n",
      "Epoch: 0147 train_loss= 0.6757 train_acc= 0.9071 val_loss= 0.9868 val_acc= 0.7833 time= 0.0263\n",
      "Epoch: 0148 train_loss= 0.6721 train_acc= 0.9071 val_loss= 0.9845 val_acc= 0.7833 time= 0.0237\n",
      "Epoch: 0149 train_loss= 0.6687 train_acc= 0.9071 val_loss= 0.9824 val_acc= 0.7833 time= 0.0187\n",
      "Epoch: 0150 train_loss= 0.6654 train_acc= 0.9071 val_loss= 0.9801 val_acc= 0.7833 time= 0.0184\n",
      "Epoch: 0151 train_loss= 0.6630 train_acc= 0.9071 val_loss= 0.9796 val_acc= 0.7867 time= 0.0249\n",
      "Epoch: 0152 train_loss= 0.6609 train_acc= 0.9071 val_loss= 0.9793 val_acc= 0.7900 time= 0.0243\n",
      "Epoch: 0153 train_loss= 0.6580 train_acc= 0.9071 val_loss= 0.9783 val_acc= 0.7900 time= 0.0184\n",
      "Epoch: 0154 train_loss= 0.6536 train_acc= 0.9071 val_loss= 0.9747 val_acc= 0.7867 time= 0.0231\n",
      "Epoch: 0155 train_loss= 0.6487 train_acc= 0.9071 val_loss= 0.9700 val_acc= 0.7867 time= 0.0205\n",
      "Epoch: 0156 train_loss= 0.6437 train_acc= 0.9071 val_loss= 0.9640 val_acc= 0.7867 time= 0.0242\n",
      "Epoch: 0157 train_loss= 0.6394 train_acc= 0.9071 val_loss= 0.9587 val_acc= 0.7867 time= 0.0276\n",
      "Epoch: 0158 train_loss= 0.6355 train_acc= 0.9071 val_loss= 0.9551 val_acc= 0.7900 time= 0.0185\n",
      "Epoch: 0159 train_loss= 0.6315 train_acc= 0.9071 val_loss= 0.9523 val_acc= 0.7967 time= 0.0186\n",
      "Epoch: 0160 train_loss= 0.6282 train_acc= 0.9071 val_loss= 0.9497 val_acc= 0.7967 time= 0.0242\n",
      "Epoch: 0161 train_loss= 0.6244 train_acc= 0.9071 val_loss= 0.9473 val_acc= 0.7967 time= 0.0199\n",
      "Epoch: 0162 train_loss= 0.6207 train_acc= 0.9071 val_loss= 0.9451 val_acc= 0.7900 time= 0.0185\n",
      "Epoch: 0163 train_loss= 0.6171 train_acc= 0.9071 val_loss= 0.9435 val_acc= 0.7900 time= 0.0188\n",
      "Epoch: 0164 train_loss= 0.6138 train_acc= 0.9143 val_loss= 0.9427 val_acc= 0.7867 time= 0.0190\n",
      "Epoch: 0165 train_loss= 0.6110 train_acc= 0.9214 val_loss= 0.9424 val_acc= 0.7900 time= 0.0227\n",
      "Epoch: 0166 train_loss= 0.6084 train_acc= 0.9214 val_loss= 0.9412 val_acc= 0.7900 time= 0.0206\n",
      "Epoch: 0167 train_loss= 0.6059 train_acc= 0.9214 val_loss= 0.9397 val_acc= 0.7933 time= 0.0280\n",
      "Epoch: 0168 train_loss= 0.6034 train_acc= 0.9214 val_loss= 0.9378 val_acc= 0.7967 time= 0.0185\n",
      "Epoch: 0169 train_loss= 0.6004 train_acc= 0.9214 val_loss= 0.9338 val_acc= 0.7933 time= 0.0188\n",
      "Epoch: 0170 train_loss= 0.5968 train_acc= 0.9214 val_loss= 0.9283 val_acc= 0.7933 time= 0.0194\n",
      "Epoch: 0171 train_loss= 0.5938 train_acc= 0.9286 val_loss= 0.9236 val_acc= 0.7933 time= 0.0194\n",
      "Epoch: 0172 train_loss= 0.5908 train_acc= 0.9286 val_loss= 0.9199 val_acc= 0.7967 time= 0.0210\n",
      "Epoch: 0173 train_loss= 0.5876 train_acc= 0.9286 val_loss= 0.9177 val_acc= 0.8000 time= 0.0281\n",
      "Epoch: 0174 train_loss= 0.5847 train_acc= 0.9214 val_loss= 0.9157 val_acc= 0.7933 time= 0.0231\n",
      "Epoch: 0175 train_loss= 0.5817 train_acc= 0.9214 val_loss= 0.9146 val_acc= 0.7933 time= 0.0226\n",
      "Epoch: 0176 train_loss= 0.5788 train_acc= 0.9214 val_loss= 0.9133 val_acc= 0.7933 time= 0.0188\n",
      "Epoch: 0177 train_loss= 0.5758 train_acc= 0.9143 val_loss= 0.9124 val_acc= 0.7933 time= 0.0244\n",
      "Epoch: 0178 train_loss= 0.5731 train_acc= 0.9143 val_loss= 0.9121 val_acc= 0.7933 time= 0.0191\n",
      "Epoch: 0179 train_loss= 0.5707 train_acc= 0.9214 val_loss= 0.9124 val_acc= 0.8000 time= 0.0247\n",
      "Epoch: 0180 train_loss= 0.5683 train_acc= 0.9143 val_loss= 0.9126 val_acc= 0.8033 time= 0.0208\n",
      "Epoch: 0181 train_loss= 0.5654 train_acc= 0.9214 val_loss= 0.9100 val_acc= 0.7967 time= 0.0235\n",
      "Epoch: 0182 train_loss= 0.5623 train_acc= 0.9214 val_loss= 0.9060 val_acc= 0.8000 time= 0.0189\n",
      "Epoch: 0183 train_loss= 0.5595 train_acc= 0.9286 val_loss= 0.9012 val_acc= 0.7967 time= 0.0274\n",
      "Epoch: 0184 train_loss= 0.5576 train_acc= 0.9429 val_loss= 0.8971 val_acc= 0.7967 time= 0.0196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0185 train_loss= 0.5563 train_acc= 0.9429 val_loss= 0.8949 val_acc= 0.7967 time= 0.0227\n",
      "Epoch: 0186 train_loss= 0.5548 train_acc= 0.9429 val_loss= 0.8935 val_acc= 0.7900 time= 0.0233\n",
      "Epoch: 0187 train_loss= 0.5531 train_acc= 0.9429 val_loss= 0.8915 val_acc= 0.7900 time= 0.0184\n",
      "Epoch: 0188 train_loss= 0.5504 train_acc= 0.9429 val_loss= 0.8898 val_acc= 0.7967 time= 0.0206\n",
      "Epoch: 0189 train_loss= 0.5478 train_acc= 0.9357 val_loss= 0.8888 val_acc= 0.7967 time= 0.0232\n",
      "Epoch: 0190 train_loss= 0.5457 train_acc= 0.9357 val_loss= 0.8877 val_acc= 0.7967 time= 0.0240\n",
      "Epoch: 0191 train_loss= 0.5439 train_acc= 0.9286 val_loss= 0.8879 val_acc= 0.7933 time= 0.0187\n",
      "Epoch: 0192 train_loss= 0.5422 train_acc= 0.9214 val_loss= 0.8885 val_acc= 0.8000 time= 0.0182\n",
      "Epoch: 0193 train_loss= 0.5397 train_acc= 0.9214 val_loss= 0.8884 val_acc= 0.7967 time= 0.0186\n",
      "Epoch: 0194 train_loss= 0.5364 train_acc= 0.9286 val_loss= 0.8870 val_acc= 0.8000 time= 0.0217\n",
      "Epoch: 0195 train_loss= 0.5325 train_acc= 0.9286 val_loss= 0.8845 val_acc= 0.7967 time= 0.0237\n",
      "Epoch: 0196 train_loss= 0.5293 train_acc= 0.9357 val_loss= 0.8831 val_acc= 0.7933 time= 0.0234\n",
      "Epoch: 0197 train_loss= 0.5269 train_acc= 0.9429 val_loss= 0.8819 val_acc= 0.7933 time= 0.0254\n",
      "Epoch: 0198 train_loss= 0.5248 train_acc= 0.9429 val_loss= 0.8813 val_acc= 0.7933 time= 0.0185\n",
      "Epoch: 0199 train_loss= 0.5236 train_acc= 0.9429 val_loss= 0.8817 val_acc= 0.7900 time= 0.0185\n",
      "Epoch: 0200 train_loss= 0.5212 train_acc= 0.9429 val_loss= 0.8793 val_acc= 0.7867 time= 0.0194\n"
     ]
    }
   ],
   "source": [
    "NB_EPOCH = 200\n",
    "PATIENCE = 10  # early stopping patience\n",
    "# Helper variables for main training loop\n",
    "wait = 0\n",
    "preds = None\n",
    "best_val_loss = 99999\n",
    "\n",
    "# Fit\n",
    "for epoch in range(1, NB_EPOCH+1):\n",
    "\n",
    "    # Log wall-clock time\n",
    "    t = time.time()\n",
    "\n",
    "    # Single training iteration (we mask nodes without labels for loss calculation)\n",
    "    model.fit(graph, y_train, sample_weight=train_mask,\n",
    "              batch_size=A.shape[0], epochs=1, shuffle=False, verbose=0)\n",
    "\n",
    "    # Predict on full dataset\n",
    "    preds = model.predict(graph, batch_size=A.shape[0])\n",
    "\n",
    "    # Train / validation scores\n",
    "    train_val_loss, train_val_acc = evaluate_preds(preds, [y_train, y_val],\n",
    "                                                   [idx_train, idx_val])\n",
    "    print(\"Epoch: {:04d}\".format(epoch),\n",
    "          \"train_loss= {:.4f}\".format(train_val_loss[0]),\n",
    "          \"train_acc= {:.4f}\".format(train_val_acc[0]),\n",
    "          \"val_loss= {:.4f}\".format(train_val_loss[1]),\n",
    "          \"val_acc= {:.4f}\".format(train_val_acc[1]),\n",
    "          \"time= {:.4f}\".format(time.time() - t))\n",
    "\n",
    "    # Early stopping\n",
    "    if train_val_loss[1] < best_val_loss:\n",
    "        best_val_loss = train_val_loss[1]\n",
    "        wait = 0\n",
    "    else:\n",
    "        if wait >= PATIENCE:\n",
    "            print('Epoch {}: early stopping'.format(epoch))\n",
    "            break\n",
    "        wait += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.9388\n",
      "accuracy = 0.7650\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate_preds(preds, [y_test], [idx_test])\n",
    "print(f\"\"\"\n",
    "loss = {test_loss[0]:.4f}\n",
    "accuracy = {test_acc[0]:.4f}\n",
    "\"\"\".strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Graph Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from ggcn import GaussianGraphConvolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = Dropout(0.5)(X_in)\n",
    "H = GaussianGraphConvolution(16, support, activation='relu', kernel_regularizer=l2(5e-4))([H]+G)\n",
    "H = Dropout(0.5)(H)\n",
    "Y = GaussianGraphConvolution(y.shape[1], support, activation='softmax')([H]+G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[X_in]+G, outputs=Y)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 train_loss= 1.9327 train_acc= 0.3571 val_loss= 1.9338 val_acc= 0.3700 time= 0.4164\n",
      "Epoch: 0002 train_loss= 1.9192 train_acc= 0.3643 val_loss= 1.9217 val_acc= 0.3633 time= 0.0231\n",
      "Epoch: 0003 train_loss= 1.9051 train_acc= 0.3857 val_loss= 1.9096 val_acc= 0.3667 time= 0.0192\n",
      "Epoch: 0004 train_loss= 1.8907 train_acc= 0.3929 val_loss= 1.8974 val_acc= 0.3733 time= 0.0228\n",
      "Epoch: 0005 train_loss= 1.8762 train_acc= 0.4000 val_loss= 1.8851 val_acc= 0.3767 time= 0.0196\n",
      "Epoch: 0006 train_loss= 1.8614 train_acc= 0.4071 val_loss= 1.8726 val_acc= 0.3767 time= 0.0233\n",
      "Epoch: 0007 train_loss= 1.8465 train_acc= 0.4071 val_loss= 1.8599 val_acc= 0.3767 time= 0.0281\n",
      "Epoch: 0008 train_loss= 1.8313 train_acc= 0.4071 val_loss= 1.8470 val_acc= 0.3733 time= 0.0224\n",
      "Epoch: 0009 train_loss= 1.8161 train_acc= 0.4071 val_loss= 1.8339 val_acc= 0.3733 time= 0.0186\n",
      "Epoch: 0010 train_loss= 1.8013 train_acc= 0.4000 val_loss= 1.8215 val_acc= 0.3733 time= 0.0300\n",
      "Epoch: 0011 train_loss= 1.7868 train_acc= 0.4000 val_loss= 1.8097 val_acc= 0.3733 time= 0.0201\n",
      "Epoch: 0012 train_loss= 1.7726 train_acc= 0.4143 val_loss= 1.7985 val_acc= 0.3733 time= 0.0210\n",
      "Epoch: 0013 train_loss= 1.7589 train_acc= 0.4143 val_loss= 1.7878 val_acc= 0.3733 time= 0.0238\n",
      "Epoch: 0014 train_loss= 1.7457 train_acc= 0.4143 val_loss= 1.7777 val_acc= 0.3733 time= 0.0238\n",
      "Epoch: 0015 train_loss= 1.7330 train_acc= 0.4143 val_loss= 1.7683 val_acc= 0.3833 time= 0.0229\n",
      "Epoch: 0016 train_loss= 1.7207 train_acc= 0.4143 val_loss= 1.7594 val_acc= 0.3867 time= 0.0233\n",
      "Epoch: 0017 train_loss= 1.7089 train_acc= 0.4286 val_loss= 1.7509 val_acc= 0.3867 time= 0.0199\n",
      "Epoch: 0018 train_loss= 1.6977 train_acc= 0.4286 val_loss= 1.7430 val_acc= 0.3900 time= 0.0230\n",
      "Epoch: 0019 train_loss= 1.6869 train_acc= 0.4286 val_loss= 1.7358 val_acc= 0.3967 time= 0.0240\n",
      "Epoch: 0020 train_loss= 1.6763 train_acc= 0.4286 val_loss= 1.7292 val_acc= 0.4067 time= 0.0196\n",
      "Epoch: 0021 train_loss= 1.6658 train_acc= 0.4286 val_loss= 1.7228 val_acc= 0.4100 time= 0.0203\n",
      "Epoch: 0022 train_loss= 1.6554 train_acc= 0.4429 val_loss= 1.7166 val_acc= 0.4133 time= 0.0191\n",
      "Epoch: 0023 train_loss= 1.6450 train_acc= 0.4571 val_loss= 1.7104 val_acc= 0.4200 time= 0.0212\n",
      "Epoch: 0024 train_loss= 1.6344 train_acc= 0.4643 val_loss= 1.7039 val_acc= 0.4300 time= 0.0237\n",
      "Epoch: 0025 train_loss= 1.6235 train_acc= 0.4643 val_loss= 1.6967 val_acc= 0.4367 time= 0.0189\n",
      "Epoch: 0026 train_loss= 1.6125 train_acc= 0.4643 val_loss= 1.6891 val_acc= 0.4333 time= 0.0254\n",
      "Epoch: 0027 train_loss= 1.6013 train_acc= 0.4643 val_loss= 1.6814 val_acc= 0.4367 time= 0.0232\n",
      "Epoch: 0028 train_loss= 1.5897 train_acc= 0.4714 val_loss= 1.6737 val_acc= 0.4400 time= 0.0245\n",
      "Epoch: 0029 train_loss= 1.5776 train_acc= 0.4714 val_loss= 1.6655 val_acc= 0.4467 time= 0.0248\n",
      "Epoch: 0030 train_loss= 1.5653 train_acc= 0.4714 val_loss= 1.6569 val_acc= 0.4500 time= 0.0242\n",
      "Epoch: 0031 train_loss= 1.5528 train_acc= 0.4714 val_loss= 1.6481 val_acc= 0.4500 time= 0.0184\n",
      "Epoch: 0032 train_loss= 1.5401 train_acc= 0.4857 val_loss= 1.6392 val_acc= 0.4467 time= 0.0227\n",
      "Epoch: 0033 train_loss= 1.5273 train_acc= 0.4929 val_loss= 1.6302 val_acc= 0.4467 time= 0.0228\n",
      "Epoch: 0034 train_loss= 1.5143 train_acc= 0.5000 val_loss= 1.6214 val_acc= 0.4533 time= 0.0246\n",
      "Epoch: 0035 train_loss= 1.5014 train_acc= 0.5071 val_loss= 1.6125 val_acc= 0.4600 time= 0.0236\n",
      "Epoch: 0036 train_loss= 1.4883 train_acc= 0.5143 val_loss= 1.6036 val_acc= 0.4800 time= 0.0188\n",
      "Epoch: 0037 train_loss= 1.4752 train_acc= 0.5214 val_loss= 1.5950 val_acc= 0.4933 time= 0.0187\n",
      "Epoch: 0038 train_loss= 1.4619 train_acc= 0.5500 val_loss= 1.5866 val_acc= 0.5300 time= 0.0230\n",
      "Epoch: 0039 train_loss= 1.4485 train_acc= 0.5571 val_loss= 1.5779 val_acc= 0.5333 time= 0.0204\n",
      "Epoch: 0040 train_loss= 1.4351 train_acc= 0.5929 val_loss= 1.5690 val_acc= 0.5400 time= 0.0287\n",
      "Epoch: 0041 train_loss= 1.4216 train_acc= 0.6143 val_loss= 1.5601 val_acc= 0.5500 time= 0.0188\n",
      "Epoch: 0042 train_loss= 1.4083 train_acc= 0.6286 val_loss= 1.5507 val_acc= 0.5500 time= 0.0185\n",
      "Epoch: 0043 train_loss= 1.3948 train_acc= 0.6429 val_loss= 1.5412 val_acc= 0.5533 time= 0.0198\n",
      "Epoch: 0044 train_loss= 1.3814 train_acc= 0.6429 val_loss= 1.5313 val_acc= 0.5533 time= 0.0239\n",
      "Epoch: 0045 train_loss= 1.3678 train_acc= 0.6429 val_loss= 1.5209 val_acc= 0.5567 time= 0.0228\n",
      "Epoch: 0046 train_loss= 1.3540 train_acc= 0.6357 val_loss= 1.5101 val_acc= 0.5567 time= 0.0190\n",
      "Epoch: 0047 train_loss= 1.3406 train_acc= 0.6357 val_loss= 1.4994 val_acc= 0.5567 time= 0.0240\n",
      "Epoch: 0048 train_loss= 1.3271 train_acc= 0.6357 val_loss= 1.4887 val_acc= 0.5567 time= 0.0231\n",
      "Epoch: 0049 train_loss= 1.3137 train_acc= 0.6357 val_loss= 1.4784 val_acc= 0.5567 time= 0.0219\n",
      "Epoch: 0050 train_loss= 1.3004 train_acc= 0.6429 val_loss= 1.4683 val_acc= 0.5600 time= 0.0192\n",
      "Epoch: 0051 train_loss= 1.2872 train_acc= 0.6500 val_loss= 1.4586 val_acc= 0.5633 time= 0.0191\n",
      "Epoch: 0052 train_loss= 1.2742 train_acc= 0.6571 val_loss= 1.4489 val_acc= 0.5667 time= 0.0281\n",
      "Epoch: 0053 train_loss= 1.2614 train_acc= 0.6643 val_loss= 1.4395 val_acc= 0.5800 time= 0.0236\n",
      "Epoch: 0054 train_loss= 1.2487 train_acc= 0.6714 val_loss= 1.4301 val_acc= 0.5933 time= 0.0179\n",
      "Epoch: 0055 train_loss= 1.2361 train_acc= 0.6786 val_loss= 1.4206 val_acc= 0.5967 time= 0.0225\n",
      "Epoch: 0056 train_loss= 1.2234 train_acc= 0.6786 val_loss= 1.4111 val_acc= 0.6000 time= 0.0233\n",
      "Epoch: 0057 train_loss= 1.2107 train_acc= 0.6857 val_loss= 1.4015 val_acc= 0.6067 time= 0.0193\n",
      "Epoch: 0058 train_loss= 1.1983 train_acc= 0.6929 val_loss= 1.3918 val_acc= 0.6067 time= 0.0247\n",
      "Epoch: 0059 train_loss= 1.1862 train_acc= 0.6857 val_loss= 1.3821 val_acc= 0.6133 time= 0.0304\n",
      "Epoch: 0060 train_loss= 1.1741 train_acc= 0.6929 val_loss= 1.3723 val_acc= 0.6133 time= 0.0192\n",
      "Epoch: 0061 train_loss= 1.1620 train_acc= 0.6929 val_loss= 1.3628 val_acc= 0.6167 time= 0.0197\n",
      "Epoch: 0062 train_loss= 1.1500 train_acc= 0.7071 val_loss= 1.3530 val_acc= 0.6200 time= 0.0236\n",
      "Epoch: 0063 train_loss= 1.1380 train_acc= 0.7357 val_loss= 1.3438 val_acc= 0.6233 time= 0.0284\n",
      "Epoch: 0064 train_loss= 1.1261 train_acc= 0.7357 val_loss= 1.3341 val_acc= 0.6233 time= 0.0187\n",
      "Epoch: 0065 train_loss= 1.1144 train_acc= 0.7500 val_loss= 1.3244 val_acc= 0.6267 time= 0.0237\n",
      "Epoch: 0066 train_loss= 1.1029 train_acc= 0.7500 val_loss= 1.3151 val_acc= 0.6433 time= 0.0187\n",
      "Epoch: 0067 train_loss= 1.0915 train_acc= 0.7571 val_loss= 1.3065 val_acc= 0.6500 time= 0.0235\n",
      "Epoch: 0068 train_loss= 1.0801 train_acc= 0.7571 val_loss= 1.2978 val_acc= 0.6733 time= 0.0179\n",
      "Epoch: 0069 train_loss= 1.0687 train_acc= 0.7714 val_loss= 1.2891 val_acc= 0.6767 time= 0.0192\n",
      "Epoch: 0070 train_loss= 1.0572 train_acc= 0.7714 val_loss= 1.2805 val_acc= 0.6767 time= 0.0193\n",
      "Epoch: 0071 train_loss= 1.0461 train_acc= 0.7857 val_loss= 1.2721 val_acc= 0.6800 time= 0.0214\n",
      "Epoch: 0072 train_loss= 1.0351 train_acc= 0.8000 val_loss= 1.2643 val_acc= 0.6967 time= 0.0204\n",
      "Epoch: 0073 train_loss= 1.0245 train_acc= 0.8071 val_loss= 1.2571 val_acc= 0.7000 time= 0.0197\n",
      "Epoch: 0074 train_loss= 1.0142 train_acc= 0.8071 val_loss= 1.2498 val_acc= 0.7033 time= 0.0191\n",
      "Epoch: 0075 train_loss= 1.0039 train_acc= 0.8143 val_loss= 1.2416 val_acc= 0.7067 time= 0.0194\n",
      "Epoch: 0076 train_loss= 0.9935 train_acc= 0.8143 val_loss= 1.2321 val_acc= 0.7033 time= 0.0185\n",
      "Epoch: 0077 train_loss= 0.9835 train_acc= 0.8143 val_loss= 1.2225 val_acc= 0.7033 time= 0.0192\n",
      "Epoch: 0078 train_loss= 0.9739 train_acc= 0.8143 val_loss= 1.2132 val_acc= 0.6967 time= 0.0232\n",
      "Epoch: 0079 train_loss= 0.9643 train_acc= 0.8143 val_loss= 1.2048 val_acc= 0.7000 time= 0.0235\n",
      "Epoch: 0080 train_loss= 0.9550 train_acc= 0.8143 val_loss= 1.1970 val_acc= 0.7033 time= 0.0248\n",
      "Epoch: 0081 train_loss= 0.9454 train_acc= 0.8214 val_loss= 1.1903 val_acc= 0.7133 time= 0.0230\n",
      "Epoch: 0082 train_loss= 0.9361 train_acc= 0.8214 val_loss= 1.1846 val_acc= 0.7233 time= 0.0189\n",
      "Epoch: 0083 train_loss= 0.9272 train_acc= 0.8357 val_loss= 1.1786 val_acc= 0.7233 time= 0.0193\n",
      "Epoch: 0084 train_loss= 0.9192 train_acc= 0.8286 val_loss= 1.1730 val_acc= 0.7300 time= 0.0228\n",
      "Epoch: 0085 train_loss= 0.9116 train_acc= 0.8214 val_loss= 1.1672 val_acc= 0.7400 time= 0.0221\n",
      "Epoch: 0086 train_loss= 0.9044 train_acc= 0.8214 val_loss= 1.1612 val_acc= 0.7400 time= 0.0183\n",
      "Epoch: 0087 train_loss= 0.8967 train_acc= 0.8214 val_loss= 1.1547 val_acc= 0.7400 time= 0.0184\n",
      "Epoch: 0088 train_loss= 0.8889 train_acc= 0.8286 val_loss= 1.1466 val_acc= 0.7400 time= 0.0190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0089 train_loss= 0.8813 train_acc= 0.8286 val_loss= 1.1388 val_acc= 0.7433 time= 0.0203\n",
      "Epoch: 0090 train_loss= 0.8740 train_acc= 0.8429 val_loss= 1.1313 val_acc= 0.7433 time= 0.0259\n",
      "Epoch: 0091 train_loss= 0.8669 train_acc= 0.8429 val_loss= 1.1242 val_acc= 0.7433 time= 0.0208\n",
      "Epoch: 0092 train_loss= 0.8598 train_acc= 0.8429 val_loss= 1.1176 val_acc= 0.7467 time= 0.0236\n",
      "Epoch: 0093 train_loss= 0.8527 train_acc= 0.8429 val_loss= 1.1115 val_acc= 0.7467 time= 0.0241\n",
      "Epoch: 0094 train_loss= 0.8453 train_acc= 0.8500 val_loss= 1.1055 val_acc= 0.7533 time= 0.0206\n",
      "Epoch: 0095 train_loss= 0.8378 train_acc= 0.8500 val_loss= 1.1003 val_acc= 0.7433 time= 0.0194\n",
      "Epoch: 0096 train_loss= 0.8303 train_acc= 0.8571 val_loss= 1.0960 val_acc= 0.7533 time= 0.0190\n",
      "Epoch: 0097 train_loss= 0.8232 train_acc= 0.8571 val_loss= 1.0919 val_acc= 0.7600 time= 0.0214\n",
      "Epoch: 0098 train_loss= 0.8161 train_acc= 0.8571 val_loss= 1.0868 val_acc= 0.7633 time= 0.0210\n",
      "Epoch: 0099 train_loss= 0.8090 train_acc= 0.8643 val_loss= 1.0810 val_acc= 0.7633 time= 0.0242\n",
      "Epoch: 0100 train_loss= 0.8019 train_acc= 0.8643 val_loss= 1.0753 val_acc= 0.7600 time= 0.0186\n",
      "Epoch: 0101 train_loss= 0.7951 train_acc= 0.8714 val_loss= 1.0693 val_acc= 0.7667 time= 0.0194\n",
      "Epoch: 0102 train_loss= 0.7885 train_acc= 0.8786 val_loss= 1.0637 val_acc= 0.7667 time= 0.0194\n",
      "Epoch: 0103 train_loss= 0.7822 train_acc= 0.8857 val_loss= 1.0580 val_acc= 0.7667 time= 0.0192\n",
      "Epoch: 0104 train_loss= 0.7762 train_acc= 0.8857 val_loss= 1.0519 val_acc= 0.7733 time= 0.0194\n",
      "Epoch: 0105 train_loss= 0.7705 train_acc= 0.8857 val_loss= 1.0466 val_acc= 0.7733 time= 0.0252\n",
      "Epoch: 0106 train_loss= 0.7646 train_acc= 0.8929 val_loss= 1.0423 val_acc= 0.7800 time= 0.0188\n",
      "Epoch: 0107 train_loss= 0.7591 train_acc= 0.9000 val_loss= 1.0379 val_acc= 0.7800 time= 0.0233\n",
      "Epoch: 0108 train_loss= 0.7536 train_acc= 0.9000 val_loss= 1.0340 val_acc= 0.7833 time= 0.0227\n",
      "Epoch: 0109 train_loss= 0.7482 train_acc= 0.9000 val_loss= 1.0312 val_acc= 0.7800 time= 0.0180\n",
      "Epoch: 0110 train_loss= 0.7433 train_acc= 0.9000 val_loss= 1.0282 val_acc= 0.7800 time= 0.0240\n",
      "Epoch: 0111 train_loss= 0.7386 train_acc= 0.9000 val_loss= 1.0234 val_acc= 0.7767 time= 0.0203\n",
      "Epoch: 0112 train_loss= 0.7341 train_acc= 0.9000 val_loss= 1.0198 val_acc= 0.7800 time= 0.0236\n",
      "Epoch: 0113 train_loss= 0.7298 train_acc= 0.9000 val_loss= 1.0166 val_acc= 0.7833 time= 0.0241\n",
      "Epoch: 0114 train_loss= 0.7251 train_acc= 0.9000 val_loss= 1.0141 val_acc= 0.7833 time= 0.0188\n",
      "Epoch: 0115 train_loss= 0.7201 train_acc= 0.9000 val_loss= 1.0116 val_acc= 0.7833 time= 0.0195\n",
      "Epoch: 0116 train_loss= 0.7151 train_acc= 0.9000 val_loss= 1.0084 val_acc= 0.7833 time= 0.0185\n",
      "Epoch: 0117 train_loss= 0.7097 train_acc= 0.9000 val_loss= 1.0040 val_acc= 0.7800 time= 0.0237\n",
      "Epoch: 0118 train_loss= 0.7040 train_acc= 0.9000 val_loss= 0.9990 val_acc= 0.7800 time= 0.0195\n",
      "Epoch: 0119 train_loss= 0.6985 train_acc= 0.9000 val_loss= 0.9933 val_acc= 0.7800 time= 0.0198\n",
      "Epoch: 0120 train_loss= 0.6939 train_acc= 0.9000 val_loss= 0.9890 val_acc= 0.7800 time= 0.0188\n",
      "Epoch: 0121 train_loss= 0.6894 train_acc= 0.9000 val_loss= 0.9854 val_acc= 0.7800 time= 0.0188\n",
      "Epoch: 0122 train_loss= 0.6850 train_acc= 0.9000 val_loss= 0.9817 val_acc= 0.7767 time= 0.0189\n",
      "Epoch: 0123 train_loss= 0.6804 train_acc= 0.9071 val_loss= 0.9781 val_acc= 0.7800 time= 0.0227\n",
      "Epoch: 0124 train_loss= 0.6761 train_acc= 0.9071 val_loss= 0.9760 val_acc= 0.7833 time= 0.0187\n",
      "Epoch: 0125 train_loss= 0.6722 train_acc= 0.9071 val_loss= 0.9740 val_acc= 0.7833 time= 0.0190\n",
      "Epoch: 0126 train_loss= 0.6679 train_acc= 0.9000 val_loss= 0.9710 val_acc= 0.7833 time= 0.0199\n",
      "Epoch: 0127 train_loss= 0.6636 train_acc= 0.9000 val_loss= 0.9672 val_acc= 0.7867 time= 0.0231\n",
      "Epoch: 0128 train_loss= 0.6594 train_acc= 0.9000 val_loss= 0.9618 val_acc= 0.7933 time= 0.0233\n",
      "Epoch: 0129 train_loss= 0.6558 train_acc= 0.9000 val_loss= 0.9564 val_acc= 0.7967 time= 0.0189\n",
      "Epoch: 0130 train_loss= 0.6526 train_acc= 0.9071 val_loss= 0.9518 val_acc= 0.8000 time= 0.0182\n",
      "Epoch: 0131 train_loss= 0.6492 train_acc= 0.9143 val_loss= 0.9487 val_acc= 0.7967 time= 0.0197\n",
      "Epoch: 0132 train_loss= 0.6452 train_acc= 0.9214 val_loss= 0.9460 val_acc= 0.7967 time= 0.0190\n",
      "Epoch: 0133 train_loss= 0.6403 train_acc= 0.9286 val_loss= 0.9438 val_acc= 0.7967 time= 0.0186\n",
      "Epoch: 0134 train_loss= 0.6356 train_acc= 0.9286 val_loss= 0.9421 val_acc= 0.8000 time= 0.0229\n",
      "Epoch: 0135 train_loss= 0.6313 train_acc= 0.9286 val_loss= 0.9408 val_acc= 0.8067 time= 0.0200\n",
      "Epoch: 0136 train_loss= 0.6276 train_acc= 0.9357 val_loss= 0.9394 val_acc= 0.8100 time= 0.0230\n",
      "Epoch: 0137 train_loss= 0.6241 train_acc= 0.9214 val_loss= 0.9382 val_acc= 0.8033 time= 0.0191\n",
      "Epoch: 0138 train_loss= 0.6198 train_acc= 0.9214 val_loss= 0.9351 val_acc= 0.8000 time= 0.0276\n",
      "Epoch: 0139 train_loss= 0.6151 train_acc= 0.9214 val_loss= 0.9305 val_acc= 0.7933 time= 0.0195\n",
      "Epoch: 0140 train_loss= 0.6108 train_acc= 0.9214 val_loss= 0.9265 val_acc= 0.8067 time= 0.0230\n",
      "Epoch: 0141 train_loss= 0.6069 train_acc= 0.9143 val_loss= 0.9226 val_acc= 0.8067 time= 0.0186\n",
      "Epoch: 0142 train_loss= 0.6038 train_acc= 0.9286 val_loss= 0.9191 val_acc= 0.8067 time= 0.0232\n",
      "Epoch: 0143 train_loss= 0.6010 train_acc= 0.9214 val_loss= 0.9155 val_acc= 0.8067 time= 0.0233\n",
      "Epoch: 0144 train_loss= 0.5988 train_acc= 0.9214 val_loss= 0.9116 val_acc= 0.8100 time= 0.0227\n",
      "Epoch: 0145 train_loss= 0.5957 train_acc= 0.9214 val_loss= 0.9084 val_acc= 0.8100 time= 0.0200\n",
      "Epoch: 0146 train_loss= 0.5922 train_acc= 0.9357 val_loss= 0.9053 val_acc= 0.8133 time= 0.0234\n",
      "Epoch: 0147 train_loss= 0.5882 train_acc= 0.9357 val_loss= 0.9033 val_acc= 0.8100 time= 0.0195\n",
      "Epoch: 0148 train_loss= 0.5849 train_acc= 0.9357 val_loss= 0.9021 val_acc= 0.8067 time= 0.0181\n",
      "Epoch: 0149 train_loss= 0.5824 train_acc= 0.9500 val_loss= 0.9009 val_acc= 0.8067 time= 0.0241\n",
      "Epoch: 0150 train_loss= 0.5799 train_acc= 0.9500 val_loss= 0.8993 val_acc= 0.8033 time= 0.0188\n",
      "Epoch: 0151 train_loss= 0.5770 train_acc= 0.9500 val_loss= 0.8963 val_acc= 0.8067 time= 0.0233\n",
      "Epoch: 0152 train_loss= 0.5732 train_acc= 0.9429 val_loss= 0.8928 val_acc= 0.8133 time= 0.0243\n",
      "Epoch: 0153 train_loss= 0.5694 train_acc= 0.9429 val_loss= 0.8889 val_acc= 0.8100 time= 0.0190\n",
      "Epoch: 0154 train_loss= 0.5662 train_acc= 0.9429 val_loss= 0.8855 val_acc= 0.8100 time= 0.0190\n",
      "Epoch: 0155 train_loss= 0.5635 train_acc= 0.9500 val_loss= 0.8819 val_acc= 0.8133 time= 0.0189\n",
      "Epoch: 0156 train_loss= 0.5612 train_acc= 0.9500 val_loss= 0.8795 val_acc= 0.8200 time= 0.0192\n",
      "Epoch: 0157 train_loss= 0.5585 train_acc= 0.9500 val_loss= 0.8774 val_acc= 0.8233 time= 0.0196\n",
      "Epoch: 0158 train_loss= 0.5550 train_acc= 0.9500 val_loss= 0.8751 val_acc= 0.8233 time= 0.0185\n",
      "Epoch: 0159 train_loss= 0.5506 train_acc= 0.9500 val_loss= 0.8731 val_acc= 0.8267 time= 0.0227\n",
      "Epoch: 0160 train_loss= 0.5465 train_acc= 0.9500 val_loss= 0.8712 val_acc= 0.8267 time= 0.0194\n",
      "Epoch: 0161 train_loss= 0.5431 train_acc= 0.9571 val_loss= 0.8697 val_acc= 0.8167 time= 0.0246\n",
      "Epoch: 0162 train_loss= 0.5402 train_acc= 0.9571 val_loss= 0.8680 val_acc= 0.8167 time= 0.0190\n",
      "Epoch: 0163 train_loss= 0.5381 train_acc= 0.9643 val_loss= 0.8682 val_acc= 0.8067 time= 0.0209\n",
      "Epoch: 0164 train_loss= 0.5358 train_acc= 0.9643 val_loss= 0.8672 val_acc= 0.7967 time= 0.0185\n",
      "Epoch: 0165 train_loss= 0.5333 train_acc= 0.9643 val_loss= 0.8657 val_acc= 0.7967 time= 0.0192\n",
      "Epoch: 0166 train_loss= 0.5303 train_acc= 0.9643 val_loss= 0.8618 val_acc= 0.8033 time= 0.0187\n",
      "Epoch: 0167 train_loss= 0.5278 train_acc= 0.9643 val_loss= 0.8588 val_acc= 0.8100 time= 0.0182\n",
      "Epoch: 0168 train_loss= 0.5257 train_acc= 0.9643 val_loss= 0.8564 val_acc= 0.8100 time= 0.0189\n",
      "Epoch: 0169 train_loss= 0.5236 train_acc= 0.9643 val_loss= 0.8535 val_acc= 0.8133 time= 0.0239\n",
      "Epoch: 0170 train_loss= 0.5211 train_acc= 0.9643 val_loss= 0.8505 val_acc= 0.8200 time= 0.0191\n",
      "Epoch: 0171 train_loss= 0.5191 train_acc= 0.9643 val_loss= 0.8482 val_acc= 0.8200 time= 0.0229\n",
      "Epoch: 0172 train_loss= 0.5170 train_acc= 0.9571 val_loss= 0.8464 val_acc= 0.8200 time= 0.0189\n",
      "Epoch: 0173 train_loss= 0.5149 train_acc= 0.9571 val_loss= 0.8441 val_acc= 0.8200 time= 0.0243\n",
      "Epoch: 0174 train_loss= 0.5135 train_acc= 0.9571 val_loss= 0.8421 val_acc= 0.8167 time= 0.0184\n",
      "Epoch: 0175 train_loss= 0.5121 train_acc= 0.9643 val_loss= 0.8403 val_acc= 0.8200 time= 0.0182\n",
      "Epoch: 0176 train_loss= 0.5102 train_acc= 0.9643 val_loss= 0.8388 val_acc= 0.8200 time= 0.0235\n",
      "Epoch: 0177 train_loss= 0.5082 train_acc= 0.9643 val_loss= 0.8366 val_acc= 0.8200 time= 0.0233\n",
      "Epoch: 0178 train_loss= 0.5058 train_acc= 0.9714 val_loss= 0.8348 val_acc= 0.8233 time= 0.0231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0179 train_loss= 0.5038 train_acc= 0.9714 val_loss= 0.8325 val_acc= 0.8200 time= 0.0202\n",
      "Epoch: 0180 train_loss= 0.5013 train_acc= 0.9714 val_loss= 0.8301 val_acc= 0.8233 time= 0.0246\n",
      "Epoch: 0181 train_loss= 0.4981 train_acc= 0.9714 val_loss= 0.8285 val_acc= 0.8233 time= 0.0183\n",
      "Epoch: 0182 train_loss= 0.4948 train_acc= 0.9643 val_loss= 0.8276 val_acc= 0.8233 time= 0.0195\n",
      "Epoch: 0183 train_loss= 0.4917 train_acc= 0.9643 val_loss= 0.8271 val_acc= 0.8200 time= 0.0238\n",
      "Epoch: 0184 train_loss= 0.4888 train_acc= 0.9643 val_loss= 0.8260 val_acc= 0.8100 time= 0.0201\n",
      "Epoch: 0185 train_loss= 0.4855 train_acc= 0.9643 val_loss= 0.8219 val_acc= 0.8133 time= 0.0229\n",
      "Epoch: 0186 train_loss= 0.4826 train_acc= 0.9643 val_loss= 0.8182 val_acc= 0.8133 time= 0.0192\n",
      "Epoch: 0187 train_loss= 0.4798 train_acc= 0.9643 val_loss= 0.8165 val_acc= 0.8067 time= 0.0188\n",
      "Epoch: 0188 train_loss= 0.4772 train_acc= 0.9643 val_loss= 0.8158 val_acc= 0.8233 time= 0.0185\n",
      "Epoch: 0189 train_loss= 0.4755 train_acc= 0.9643 val_loss= 0.8139 val_acc= 0.8233 time= 0.0192\n",
      "Epoch: 0190 train_loss= 0.4740 train_acc= 0.9643 val_loss= 0.8120 val_acc= 0.8200 time= 0.0190\n",
      "Epoch: 0191 train_loss= 0.4725 train_acc= 0.9643 val_loss= 0.8109 val_acc= 0.8233 time= 0.0183\n",
      "Epoch: 0192 train_loss= 0.4704 train_acc= 0.9643 val_loss= 0.8095 val_acc= 0.8233 time= 0.0192\n",
      "Epoch: 0193 train_loss= 0.4679 train_acc= 0.9643 val_loss= 0.8091 val_acc= 0.8167 time= 0.0178\n",
      "Epoch: 0194 train_loss= 0.4662 train_acc= 0.9643 val_loss= 0.8099 val_acc= 0.8133 time= 0.0194\n",
      "Epoch: 0195 train_loss= 0.4654 train_acc= 0.9643 val_loss= 0.8104 val_acc= 0.8067 time= 0.0231\n",
      "Epoch: 0196 train_loss= 0.4650 train_acc= 0.9643 val_loss= 0.8110 val_acc= 0.8100 time= 0.0178\n",
      "Epoch: 0197 train_loss= 0.4638 train_acc= 0.9643 val_loss= 0.8089 val_acc= 0.8100 time= 0.0235\n",
      "Epoch: 0198 train_loss= 0.4621 train_acc= 0.9643 val_loss= 0.8054 val_acc= 0.8133 time= 0.0233\n",
      "Epoch: 0199 train_loss= 0.4608 train_acc= 0.9643 val_loss= 0.8014 val_acc= 0.8233 time= 0.0188\n",
      "Epoch: 0200 train_loss= 0.4612 train_acc= 0.9714 val_loss= 0.7994 val_acc= 0.8300 time= 0.0242\n"
     ]
    }
   ],
   "source": [
    "NB_EPOCH = 200\n",
    "PATIENCE = 10  # early stopping patience\n",
    "# Helper variables for main training loop\n",
    "wait = 0\n",
    "preds = None\n",
    "best_val_loss = 99999\n",
    "\n",
    "# Fit\n",
    "for epoch in range(1, NB_EPOCH+1):\n",
    "\n",
    "    # Log wall-clock time\n",
    "    t = time.time()\n",
    "\n",
    "    # Single training iteration (we mask nodes without labels for loss calculation)\n",
    "    model.fit(graph, y_train, sample_weight=train_mask,\n",
    "              batch_size=A.shape[0], epochs=1, shuffle=False, verbose=0)\n",
    "\n",
    "    # Predict on full dataset\n",
    "    preds = model.predict(graph, batch_size=A.shape[0])\n",
    "\n",
    "    # Train / validation scores\n",
    "    train_val_loss, train_val_acc = evaluate_preds(preds, [y_train, y_val],\n",
    "                                                   [idx_train, idx_val])\n",
    "    print(\"Epoch: {:04d}\".format(epoch),\n",
    "          \"train_loss= {:.4f}\".format(train_val_loss[0]),\n",
    "          \"train_acc= {:.4f}\".format(train_val_acc[0]),\n",
    "          \"val_loss= {:.4f}\".format(train_val_loss[1]),\n",
    "          \"val_acc= {:.4f}\".format(train_val_acc[1]),\n",
    "          \"time= {:.4f}\".format(time.time() - t))\n",
    "\n",
    "    # Early stopping\n",
    "    if train_val_loss[1] < best_val_loss:\n",
    "        best_val_loss = train_val_loss[1]\n",
    "        wait = 0\n",
    "    else:\n",
    "        if wait >= PATIENCE:\n",
    "            print('Epoch {}: early stopping'.format(epoch))\n",
    "            break\n",
    "        wait += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.8679\n",
      "accuracy = 0.7920\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate_preds(preds, [y_test], [idx_test])\n",
    "print(f\"\"\"\n",
    "loss = {test_loss[0]:.4f}\n",
    "accuracy = {test_acc[0]:.4f}\n",
    "\"\"\".strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
