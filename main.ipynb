{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from keras.layers import Input, Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the path of execution\n",
    "EXE_PATH = os.path.abspath(os.path.curdir)\n",
    "# the path of the vendor files\n",
    "VENDOR_PATH = os.path.join(EXE_PATH, 'vendor')\n",
    "# the vendors to include in the system path\n",
    "VENDORS = ['keras-gcn']\n",
    "# create the absolute paths for all vendors\n",
    "VENDORS = list(map(lambda x: os.path.join(VENDOR_PATH, x), VENDORS))\n",
    "# update the Python path to include necessary vendor module\n",
    "sys.path += VENDORS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kegra.utils import load_data, preprocess_adj, get_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cora dataset...\n",
      "Dataset has 2708 nodes, 5429 edges, 1433 features.\n"
     ]
    }
   ],
   "source": [
    "X, A, y = load_data('data/cora/', dataset='cora')\n",
    "X /= X.sum(1).reshape(-1, 1)\n",
    "A = preprocess_adj(A)\n",
    "y_train, y_val, y_test, idx_train, idx_val, idx_test, train_mask = get_splits(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2708x2708 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 13264 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 1, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1110 13:31:45.978815 139757527222080 deprecation_wrapper.py:119] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1110 13:31:45.986023 139757527222080 deprecation_wrapper.py:119] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:515: The name tf.sparse_placeholder is deprecated. Please use tf.compat.v1.sparse_placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "support = 1\n",
    "graph = [X, A]\n",
    "G = [Input(shape=(None, None), batch_shape=(None, None), sparse=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1110 13:31:45.990471 139757527222080 deprecation_wrapper.py:119] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_in = Input(shape=(X.shape[1],))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCN (baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kegra.layers.graph import GraphConvolution\n",
    "from kegra.utils import evaluate_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1110 13:31:46.000496 139757527222080 deprecation_wrapper.py:119] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W1110 13:31:46.004836 139757527222080 deprecation.py:506] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W1110 13:31:46.012698 139757527222080 deprecation_wrapper.py:119] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define model architecture\n",
    "# NOTE: We pass arguments for graph convolutional layers as a list of tensors.\n",
    "# This is somewhat hacky, more elegant options would require rewriting the Layer base class.\n",
    "H = Dropout(0.5)(X_in)\n",
    "H = GraphConvolution(16, support, activation='relu', kernel_regularizer=l2(5e-4))([H]+G)\n",
    "H = Dropout(0.5)(H)\n",
    "Y = GraphConvolution(y.shape[1], support, activation='softmax')([H]+G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1110 13:31:46.052633 139757527222080 deprecation_wrapper.py:119] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=[X_in]+G, outputs=Y)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1110 13:31:46.119970 139757527222080 deprecation.py:323] From /home/bitcommander/.local/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 train_loss= 1.9344 train_acc= 0.3214 val_loss= 1.9347 val_acc= 0.3600 time= 1.0685\n",
      "Epoch: 0002 train_loss= 1.9216 train_acc= 0.3000 val_loss= 1.9231 val_acc= 0.3500 time= 0.0235\n",
      "Epoch: 0003 train_loss= 1.9072 train_acc= 0.2929 val_loss= 1.9105 val_acc= 0.3500 time= 0.0223\n",
      "Epoch: 0004 train_loss= 1.8915 train_acc= 0.2929 val_loss= 1.8966 val_acc= 0.3500 time= 0.0229\n",
      "Epoch: 0005 train_loss= 1.8746 train_acc= 0.3143 val_loss= 1.8815 val_acc= 0.3533 time= 0.0189\n",
      "Epoch: 0006 train_loss= 1.8581 train_acc= 0.3000 val_loss= 1.8666 val_acc= 0.3533 time= 0.0182\n",
      "Epoch: 0007 train_loss= 1.8415 train_acc= 0.2929 val_loss= 1.8518 val_acc= 0.3533 time= 0.0224\n",
      "Epoch: 0008 train_loss= 1.8248 train_acc= 0.2929 val_loss= 1.8367 val_acc= 0.3500 time= 0.0192\n",
      "Epoch: 0009 train_loss= 1.8083 train_acc= 0.2929 val_loss= 1.8219 val_acc= 0.3500 time= 0.0184\n",
      "Epoch: 0010 train_loss= 1.7922 train_acc= 0.2929 val_loss= 1.8077 val_acc= 0.3500 time= 0.0201\n",
      "Epoch: 0011 train_loss= 1.7766 train_acc= 0.2929 val_loss= 1.7941 val_acc= 0.3500 time= 0.0242\n",
      "Epoch: 0012 train_loss= 1.7617 train_acc= 0.2929 val_loss= 1.7816 val_acc= 0.3500 time= 0.0194\n",
      "Epoch: 0013 train_loss= 1.7476 train_acc= 0.2929 val_loss= 1.7703 val_acc= 0.3500 time= 0.0242\n",
      "Epoch: 0014 train_loss= 1.7342 train_acc= 0.2929 val_loss= 1.7601 val_acc= 0.3500 time= 0.0228\n",
      "Epoch: 0015 train_loss= 1.7214 train_acc= 0.3071 val_loss= 1.7509 val_acc= 0.3533 time= 0.0183\n",
      "Epoch: 0016 train_loss= 1.7093 train_acc= 0.3214 val_loss= 1.7426 val_acc= 0.3567 time= 0.0226\n",
      "Epoch: 0017 train_loss= 1.6973 train_acc= 0.3429 val_loss= 1.7351 val_acc= 0.3600 time= 0.0235\n",
      "Epoch: 0018 train_loss= 1.6855 train_acc= 0.3714 val_loss= 1.7282 val_acc= 0.3667 time= 0.0226\n",
      "Epoch: 0019 train_loss= 1.6738 train_acc= 0.4071 val_loss= 1.7216 val_acc= 0.3667 time= 0.0228\n",
      "Epoch: 0020 train_loss= 1.6622 train_acc= 0.4143 val_loss= 1.7152 val_acc= 0.3800 time= 0.0236\n",
      "Epoch: 0021 train_loss= 1.6508 train_acc= 0.4286 val_loss= 1.7090 val_acc= 0.4067 time= 0.0195\n",
      "Epoch: 0022 train_loss= 1.6394 train_acc= 0.4643 val_loss= 1.7026 val_acc= 0.4133 time= 0.0185\n",
      "Epoch: 0023 train_loss= 1.6280 train_acc= 0.4643 val_loss= 1.6960 val_acc= 0.4333 time= 0.0193\n",
      "Epoch: 0024 train_loss= 1.6163 train_acc= 0.4714 val_loss= 1.6888 val_acc= 0.4600 time= 0.0203\n",
      "Epoch: 0025 train_loss= 1.6043 train_acc= 0.4786 val_loss= 1.6813 val_acc= 0.4667 time= 0.0180\n",
      "Epoch: 0026 train_loss= 1.5922 train_acc= 0.4786 val_loss= 1.6734 val_acc= 0.4700 time= 0.0225\n",
      "Epoch: 0027 train_loss= 1.5799 train_acc= 0.4786 val_loss= 1.6649 val_acc= 0.4700 time= 0.0194\n",
      "Epoch: 0028 train_loss= 1.5674 train_acc= 0.4786 val_loss= 1.6562 val_acc= 0.4700 time= 0.0225\n",
      "Epoch: 0029 train_loss= 1.5549 train_acc= 0.4929 val_loss= 1.6473 val_acc= 0.4767 time= 0.0227\n",
      "Epoch: 0030 train_loss= 1.5423 train_acc= 0.4929 val_loss= 1.6383 val_acc= 0.4800 time= 0.0186\n",
      "Epoch: 0031 train_loss= 1.5297 train_acc= 0.4929 val_loss= 1.6291 val_acc= 0.4800 time= 0.0215\n",
      "Epoch: 0032 train_loss= 1.5172 train_acc= 0.4929 val_loss= 1.6197 val_acc= 0.4767 time= 0.0248\n",
      "Epoch: 0033 train_loss= 1.5047 train_acc= 0.4929 val_loss= 1.6103 val_acc= 0.4800 time= 0.0218\n",
      "Epoch: 0034 train_loss= 1.4923 train_acc= 0.4929 val_loss= 1.6012 val_acc= 0.4800 time= 0.0234\n",
      "Epoch: 0035 train_loss= 1.4796 train_acc= 0.5071 val_loss= 1.5922 val_acc= 0.4800 time= 0.0205\n",
      "Epoch: 0036 train_loss= 1.4670 train_acc= 0.5214 val_loss= 1.5832 val_acc= 0.4800 time= 0.0239\n",
      "Epoch: 0037 train_loss= 1.4542 train_acc= 0.5357 val_loss= 1.5741 val_acc= 0.4800 time= 0.0210\n",
      "Epoch: 0038 train_loss= 1.4413 train_acc= 0.5357 val_loss= 1.5650 val_acc= 0.4800 time= 0.0278\n",
      "Epoch: 0039 train_loss= 1.4281 train_acc= 0.5429 val_loss= 1.5556 val_acc= 0.4833 time= 0.0187\n",
      "Epoch: 0040 train_loss= 1.4147 train_acc= 0.5429 val_loss= 1.5462 val_acc= 0.4833 time= 0.0239\n",
      "Epoch: 0041 train_loss= 1.4013 train_acc= 0.5571 val_loss= 1.5366 val_acc= 0.4867 time= 0.0183\n",
      "Epoch: 0042 train_loss= 1.3877 train_acc= 0.5571 val_loss= 1.5267 val_acc= 0.4900 time= 0.0235\n",
      "Epoch: 0043 train_loss= 1.3743 train_acc= 0.5643 val_loss= 1.5171 val_acc= 0.4967 time= 0.0193\n",
      "Epoch: 0044 train_loss= 1.3611 train_acc= 0.5786 val_loss= 1.5074 val_acc= 0.4967 time= 0.0226\n",
      "Epoch: 0045 train_loss= 1.3480 train_acc= 0.5857 val_loss= 1.4984 val_acc= 0.5167 time= 0.0228\n",
      "Epoch: 0046 train_loss= 1.3351 train_acc= 0.5857 val_loss= 1.4890 val_acc= 0.5267 time= 0.0237\n",
      "Epoch: 0047 train_loss= 1.3224 train_acc= 0.5929 val_loss= 1.4799 val_acc= 0.5333 time= 0.0193\n",
      "Epoch: 0048 train_loss= 1.3097 train_acc= 0.5929 val_loss= 1.4706 val_acc= 0.5300 time= 0.0191\n",
      "Epoch: 0049 train_loss= 1.2971 train_acc= 0.6000 val_loss= 1.4613 val_acc= 0.5400 time= 0.0234\n",
      "Epoch: 0050 train_loss= 1.2848 train_acc= 0.6214 val_loss= 1.4523 val_acc= 0.5433 time= 0.0196\n",
      "Epoch: 0051 train_loss= 1.2725 train_acc= 0.6286 val_loss= 1.4432 val_acc= 0.5567 time= 0.0186\n",
      "Epoch: 0052 train_loss= 1.2603 train_acc= 0.6357 val_loss= 1.4340 val_acc= 0.5733 time= 0.0179\n",
      "Epoch: 0053 train_loss= 1.2481 train_acc= 0.6571 val_loss= 1.4245 val_acc= 0.5833 time= 0.0225\n",
      "Epoch: 0054 train_loss= 1.2361 train_acc= 0.6714 val_loss= 1.4150 val_acc= 0.5900 time= 0.0222\n",
      "Epoch: 0055 train_loss= 1.2240 train_acc= 0.6786 val_loss= 1.4057 val_acc= 0.5967 time= 0.0183\n",
      "Epoch: 0056 train_loss= 1.2118 train_acc= 0.6786 val_loss= 1.3967 val_acc= 0.6000 time= 0.0228\n",
      "Epoch: 0057 train_loss= 1.1999 train_acc= 0.6857 val_loss= 1.3878 val_acc= 0.6000 time= 0.0196\n",
      "Epoch: 0058 train_loss= 1.1881 train_acc= 0.6929 val_loss= 1.3793 val_acc= 0.6067 time= 0.0223\n",
      "Epoch: 0059 train_loss= 1.1765 train_acc= 0.7000 val_loss= 1.3711 val_acc= 0.6033 time= 0.0226\n",
      "Epoch: 0060 train_loss= 1.1650 train_acc= 0.7286 val_loss= 1.3629 val_acc= 0.6267 time= 0.0217\n",
      "Epoch: 0061 train_loss= 1.1538 train_acc= 0.7286 val_loss= 1.3548 val_acc= 0.6367 time= 0.0225\n",
      "Epoch: 0062 train_loss= 1.1428 train_acc= 0.7500 val_loss= 1.3467 val_acc= 0.6400 time= 0.0185\n",
      "Epoch: 0063 train_loss= 1.1319 train_acc= 0.7643 val_loss= 1.3386 val_acc= 0.6467 time= 0.0233\n",
      "Epoch: 0064 train_loss= 1.1214 train_acc= 0.7643 val_loss= 1.3307 val_acc= 0.6533 time= 0.0234\n",
      "Epoch: 0065 train_loss= 1.1110 train_acc= 0.7714 val_loss= 1.3228 val_acc= 0.6533 time= 0.0233\n",
      "Epoch: 0066 train_loss= 1.1006 train_acc= 0.7714 val_loss= 1.3151 val_acc= 0.6633 time= 0.0190\n",
      "Epoch: 0067 train_loss= 1.0900 train_acc= 0.7857 val_loss= 1.3073 val_acc= 0.6700 time= 0.0233\n",
      "Epoch: 0068 train_loss= 1.0796 train_acc= 0.7929 val_loss= 1.2995 val_acc= 0.6800 time= 0.0196\n",
      "Epoch: 0069 train_loss= 1.0694 train_acc= 0.8071 val_loss= 1.2920 val_acc= 0.6900 time= 0.0187\n",
      "Epoch: 0070 train_loss= 1.0592 train_acc= 0.8071 val_loss= 1.2842 val_acc= 0.6900 time= 0.0193\n",
      "Epoch: 0071 train_loss= 1.0494 train_acc= 0.8214 val_loss= 1.2770 val_acc= 0.7000 time= 0.0194\n",
      "Epoch: 0072 train_loss= 1.0393 train_acc= 0.8429 val_loss= 1.2686 val_acc= 0.7033 time= 0.0227\n",
      "Epoch: 0073 train_loss= 1.0294 train_acc= 0.8357 val_loss= 1.2596 val_acc= 0.7133 time= 0.0191\n",
      "Epoch: 0074 train_loss= 1.0202 train_acc= 0.8071 val_loss= 1.2505 val_acc= 0.7133 time= 0.0191\n",
      "Epoch: 0075 train_loss= 1.0114 train_acc= 0.8143 val_loss= 1.2427 val_acc= 0.7067 time= 0.0234\n",
      "Epoch: 0076 train_loss= 1.0024 train_acc= 0.8143 val_loss= 1.2352 val_acc= 0.7033 time= 0.0233\n",
      "Epoch: 0077 train_loss= 0.9933 train_acc= 0.8071 val_loss= 1.2281 val_acc= 0.7067 time= 0.0236\n",
      "Epoch: 0078 train_loss= 0.9845 train_acc= 0.8000 val_loss= 1.2211 val_acc= 0.7067 time= 0.0230\n",
      "Epoch: 0079 train_loss= 0.9752 train_acc= 0.8214 val_loss= 1.2143 val_acc= 0.7100 time= 0.0249\n",
      "Epoch: 0080 train_loss= 0.9660 train_acc= 0.8357 val_loss= 1.2079 val_acc= 0.7133 time= 0.0230\n",
      "Epoch: 0081 train_loss= 0.9572 train_acc= 0.8429 val_loss= 1.2017 val_acc= 0.7133 time= 0.0189\n",
      "Epoch: 0082 train_loss= 0.9482 train_acc= 0.8500 val_loss= 1.1954 val_acc= 0.7267 time= 0.0199\n",
      "Epoch: 0083 train_loss= 0.9394 train_acc= 0.8571 val_loss= 1.1890 val_acc= 0.7300 time= 0.0226\n",
      "Epoch: 0084 train_loss= 0.9311 train_acc= 0.8643 val_loss= 1.1829 val_acc= 0.7333 time= 0.0182\n",
      "Epoch: 0085 train_loss= 0.9225 train_acc= 0.8714 val_loss= 1.1761 val_acc= 0.7367 time= 0.0188\n",
      "Epoch: 0086 train_loss= 0.9140 train_acc= 0.8786 val_loss= 1.1691 val_acc= 0.7367 time= 0.0242\n",
      "Epoch: 0087 train_loss= 0.9059 train_acc= 0.8786 val_loss= 1.1624 val_acc= 0.7467 time= 0.0225\n",
      "Epoch: 0088 train_loss= 0.8981 train_acc= 0.8786 val_loss= 1.1563 val_acc= 0.7467 time= 0.0236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0089 train_loss= 0.8906 train_acc= 0.8857 val_loss= 1.1510 val_acc= 0.7500 time= 0.0188\n",
      "Epoch: 0090 train_loss= 0.8834 train_acc= 0.8857 val_loss= 1.1456 val_acc= 0.7500 time= 0.0211\n",
      "Epoch: 0091 train_loss= 0.8764 train_acc= 0.8857 val_loss= 1.1407 val_acc= 0.7500 time= 0.0186\n",
      "Epoch: 0092 train_loss= 0.8697 train_acc= 0.8857 val_loss= 1.1362 val_acc= 0.7500 time= 0.0183\n",
      "Epoch: 0093 train_loss= 0.8626 train_acc= 0.8857 val_loss= 1.1305 val_acc= 0.7500 time= 0.0186\n",
      "Epoch: 0094 train_loss= 0.8554 train_acc= 0.8857 val_loss= 1.1243 val_acc= 0.7533 time= 0.0238\n",
      "Epoch: 0095 train_loss= 0.8485 train_acc= 0.8857 val_loss= 1.1186 val_acc= 0.7533 time= 0.0186\n",
      "Epoch: 0096 train_loss= 0.8417 train_acc= 0.8857 val_loss= 1.1133 val_acc= 0.7600 time= 0.0189\n",
      "Epoch: 0097 train_loss= 0.8350 train_acc= 0.8857 val_loss= 1.1076 val_acc= 0.7600 time= 0.0177\n",
      "Epoch: 0098 train_loss= 0.8286 train_acc= 0.8857 val_loss= 1.1025 val_acc= 0.7667 time= 0.0230\n",
      "Epoch: 0099 train_loss= 0.8218 train_acc= 0.8857 val_loss= 1.0968 val_acc= 0.7667 time= 0.0181\n",
      "Epoch: 0100 train_loss= 0.8146 train_acc= 0.8857 val_loss= 1.0918 val_acc= 0.7633 time= 0.0250\n",
      "Epoch: 0101 train_loss= 0.8081 train_acc= 0.8857 val_loss= 1.0873 val_acc= 0.7633 time= 0.0185\n",
      "Epoch: 0102 train_loss= 0.8019 train_acc= 0.8857 val_loss= 1.0836 val_acc= 0.7633 time= 0.0231\n",
      "Epoch: 0103 train_loss= 0.7963 train_acc= 0.8857 val_loss= 1.0806 val_acc= 0.7600 time= 0.0234\n",
      "Epoch: 0104 train_loss= 0.7904 train_acc= 0.8857 val_loss= 1.0764 val_acc= 0.7600 time= 0.0179\n",
      "Epoch: 0105 train_loss= 0.7843 train_acc= 0.8857 val_loss= 1.0711 val_acc= 0.7600 time= 0.0181\n",
      "Epoch: 0106 train_loss= 0.7781 train_acc= 0.8857 val_loss= 1.0657 val_acc= 0.7600 time= 0.0182\n",
      "Epoch: 0107 train_loss= 0.7723 train_acc= 0.8857 val_loss= 1.0603 val_acc= 0.7567 time= 0.0189\n",
      "Epoch: 0108 train_loss= 0.7667 train_acc= 0.8857 val_loss= 1.0553 val_acc= 0.7567 time= 0.0190\n",
      "Epoch: 0109 train_loss= 0.7611 train_acc= 0.8857 val_loss= 1.0506 val_acc= 0.7633 time= 0.0184\n",
      "Epoch: 0110 train_loss= 0.7558 train_acc= 0.8857 val_loss= 1.0461 val_acc= 0.7633 time= 0.0189\n",
      "Epoch: 0111 train_loss= 0.7504 train_acc= 0.8857 val_loss= 1.0418 val_acc= 0.7700 time= 0.0193\n",
      "Epoch: 0112 train_loss= 0.7455 train_acc= 0.8857 val_loss= 1.0383 val_acc= 0.7733 time= 0.0182\n",
      "Epoch: 0113 train_loss= 0.7401 train_acc= 0.8857 val_loss= 1.0352 val_acc= 0.7733 time= 0.0192\n",
      "Epoch: 0114 train_loss= 0.7350 train_acc= 0.8857 val_loss= 1.0313 val_acc= 0.7767 time= 0.0275\n",
      "Epoch: 0115 train_loss= 0.7294 train_acc= 0.8929 val_loss= 1.0267 val_acc= 0.7767 time= 0.0194\n",
      "Epoch: 0116 train_loss= 0.7240 train_acc= 0.8929 val_loss= 1.0222 val_acc= 0.7767 time= 0.0182\n",
      "Epoch: 0117 train_loss= 0.7189 train_acc= 0.9000 val_loss= 1.0174 val_acc= 0.7733 time= 0.0237\n",
      "Epoch: 0118 train_loss= 0.7145 train_acc= 0.9000 val_loss= 1.0131 val_acc= 0.7700 time= 0.0188\n",
      "Epoch: 0119 train_loss= 0.7104 train_acc= 0.8929 val_loss= 1.0092 val_acc= 0.7700 time= 0.0192\n",
      "Epoch: 0120 train_loss= 0.7062 train_acc= 0.8929 val_loss= 1.0061 val_acc= 0.7700 time= 0.0226\n",
      "Epoch: 0121 train_loss= 0.7015 train_acc= 0.8929 val_loss= 1.0024 val_acc= 0.7700 time= 0.0186\n",
      "Epoch: 0122 train_loss= 0.6969 train_acc= 0.8929 val_loss= 0.9981 val_acc= 0.7700 time= 0.0229\n",
      "Epoch: 0123 train_loss= 0.6924 train_acc= 0.8929 val_loss= 0.9945 val_acc= 0.7667 time= 0.0223\n",
      "Epoch: 0124 train_loss= 0.6875 train_acc= 0.8929 val_loss= 0.9915 val_acc= 0.7700 time= 0.0192\n",
      "Epoch: 0125 train_loss= 0.6826 train_acc= 0.8929 val_loss= 0.9893 val_acc= 0.7767 time= 0.0229\n",
      "Epoch: 0126 train_loss= 0.6782 train_acc= 0.8929 val_loss= 0.9880 val_acc= 0.7867 time= 0.0193\n",
      "Epoch: 0127 train_loss= 0.6747 train_acc= 0.9000 val_loss= 0.9881 val_acc= 0.7933 time= 0.0227\n",
      "Epoch: 0128 train_loss= 0.6705 train_acc= 0.9000 val_loss= 0.9857 val_acc= 0.7867 time= 0.0185\n",
      "Epoch: 0129 train_loss= 0.6659 train_acc= 0.9071 val_loss= 0.9823 val_acc= 0.7900 time= 0.0188\n",
      "Epoch: 0130 train_loss= 0.6606 train_acc= 0.9071 val_loss= 0.9768 val_acc= 0.7967 time= 0.0186\n",
      "Epoch: 0131 train_loss= 0.6557 train_acc= 0.9071 val_loss= 0.9708 val_acc= 0.7933 time= 0.0234\n",
      "Epoch: 0132 train_loss= 0.6511 train_acc= 0.9071 val_loss= 0.9648 val_acc= 0.7900 time= 0.0196\n",
      "Epoch: 0133 train_loss= 0.6473 train_acc= 0.9071 val_loss= 0.9592 val_acc= 0.7867 time= 0.0248\n",
      "Epoch: 0134 train_loss= 0.6442 train_acc= 0.9071 val_loss= 0.9550 val_acc= 0.7867 time= 0.0233\n",
      "Epoch: 0135 train_loss= 0.6400 train_acc= 0.9071 val_loss= 0.9512 val_acc= 0.7833 time= 0.0227\n",
      "Epoch: 0136 train_loss= 0.6351 train_acc= 0.9143 val_loss= 0.9487 val_acc= 0.7833 time= 0.0187\n",
      "Epoch: 0137 train_loss= 0.6309 train_acc= 0.9214 val_loss= 0.9481 val_acc= 0.7833 time= 0.0240\n",
      "Epoch: 0138 train_loss= 0.6280 train_acc= 0.9214 val_loss= 0.9486 val_acc= 0.7800 time= 0.0234\n",
      "Epoch: 0139 train_loss= 0.6250 train_acc= 0.9286 val_loss= 0.9478 val_acc= 0.7800 time= 0.0199\n",
      "Epoch: 0140 train_loss= 0.6206 train_acc= 0.9286 val_loss= 0.9434 val_acc= 0.7833 time= 0.0242\n",
      "Epoch: 0141 train_loss= 0.6160 train_acc= 0.9286 val_loss= 0.9377 val_acc= 0.7900 time= 0.0193\n",
      "Epoch: 0142 train_loss= 0.6139 train_acc= 0.9214 val_loss= 0.9342 val_acc= 0.7867 time= 0.0185\n",
      "Epoch: 0143 train_loss= 0.6134 train_acc= 0.9286 val_loss= 0.9329 val_acc= 0.7867 time= 0.0239\n",
      "Epoch: 0144 train_loss= 0.6121 train_acc= 0.9214 val_loss= 0.9315 val_acc= 0.7867 time= 0.0276\n",
      "Epoch: 0145 train_loss= 0.6080 train_acc= 0.9214 val_loss= 0.9290 val_acc= 0.7867 time= 0.0180\n",
      "Epoch: 0146 train_loss= 0.6033 train_acc= 0.9286 val_loss= 0.9261 val_acc= 0.7933 time= 0.0193\n",
      "Epoch: 0147 train_loss= 0.5989 train_acc= 0.9429 val_loss= 0.9240 val_acc= 0.7967 time= 0.0178\n",
      "Epoch: 0148 train_loss= 0.5950 train_acc= 0.9429 val_loss= 0.9226 val_acc= 0.7900 time= 0.0233\n",
      "Epoch: 0149 train_loss= 0.5915 train_acc= 0.9429 val_loss= 0.9205 val_acc= 0.7900 time= 0.0225\n",
      "Epoch: 0150 train_loss= 0.5875 train_acc= 0.9429 val_loss= 0.9163 val_acc= 0.7933 time= 0.0182\n",
      "Epoch: 0151 train_loss= 0.5838 train_acc= 0.9429 val_loss= 0.9122 val_acc= 0.7900 time= 0.0237\n",
      "Epoch: 0152 train_loss= 0.5802 train_acc= 0.9429 val_loss= 0.9070 val_acc= 0.7933 time= 0.0182\n",
      "Epoch: 0153 train_loss= 0.5773 train_acc= 0.9429 val_loss= 0.9033 val_acc= 0.7833 time= 0.0183\n",
      "Epoch: 0154 train_loss= 0.5753 train_acc= 0.9429 val_loss= 0.9011 val_acc= 0.7800 time= 0.0188\n",
      "Epoch: 0155 train_loss= 0.5731 train_acc= 0.9429 val_loss= 0.8997 val_acc= 0.7800 time= 0.0182\n",
      "Epoch: 0156 train_loss= 0.5702 train_acc= 0.9429 val_loss= 0.8987 val_acc= 0.7800 time= 0.0238\n",
      "Epoch: 0157 train_loss= 0.5675 train_acc= 0.9429 val_loss= 0.8976 val_acc= 0.7800 time= 0.0194\n",
      "Epoch: 0158 train_loss= 0.5640 train_acc= 0.9429 val_loss= 0.8960 val_acc= 0.7800 time= 0.0182\n",
      "Epoch: 0159 train_loss= 0.5604 train_acc= 0.9429 val_loss= 0.8948 val_acc= 0.7900 time= 0.0236\n",
      "Epoch: 0160 train_loss= 0.5573 train_acc= 0.9429 val_loss= 0.8945 val_acc= 0.7933 time= 0.0228\n",
      "Epoch: 0161 train_loss= 0.5548 train_acc= 0.9429 val_loss= 0.8945 val_acc= 0.7933 time= 0.0195\n",
      "Epoch: 0162 train_loss= 0.5524 train_acc= 0.9429 val_loss= 0.8947 val_acc= 0.7900 time= 0.0223\n",
      "Epoch: 0163 train_loss= 0.5491 train_acc= 0.9429 val_loss= 0.8927 val_acc= 0.7900 time= 0.0230\n",
      "Epoch: 0164 train_loss= 0.5451 train_acc= 0.9429 val_loss= 0.8887 val_acc= 0.7933 time= 0.0186\n",
      "Epoch: 0165 train_loss= 0.5412 train_acc= 0.9429 val_loss= 0.8842 val_acc= 0.7933 time= 0.0234\n",
      "Epoch: 0166 train_loss= 0.5374 train_acc= 0.9429 val_loss= 0.8787 val_acc= 0.7933 time= 0.0195\n",
      "Epoch: 0167 train_loss= 0.5339 train_acc= 0.9429 val_loss= 0.8751 val_acc= 0.7933 time= 0.0234\n",
      "Epoch: 0168 train_loss= 0.5311 train_acc= 0.9429 val_loss= 0.8722 val_acc= 0.7900 time= 0.0186\n",
      "Epoch: 0169 train_loss= 0.5285 train_acc= 0.9500 val_loss= 0.8697 val_acc= 0.7967 time= 0.0237\n",
      "Epoch: 0170 train_loss= 0.5262 train_acc= 0.9500 val_loss= 0.8682 val_acc= 0.7933 time= 0.0233\n",
      "Epoch: 0171 train_loss= 0.5238 train_acc= 0.9500 val_loss= 0.8671 val_acc= 0.7933 time= 0.0182\n",
      "Epoch: 0172 train_loss= 0.5213 train_acc= 0.9500 val_loss= 0.8652 val_acc= 0.7967 time= 0.0183\n",
      "Epoch: 0173 train_loss= 0.5187 train_acc= 0.9500 val_loss= 0.8628 val_acc= 0.7967 time= 0.0224\n",
      "Epoch: 0174 train_loss= 0.5163 train_acc= 0.9500 val_loss= 0.8605 val_acc= 0.7967 time= 0.0228\n",
      "Epoch: 0175 train_loss= 0.5144 train_acc= 0.9429 val_loss= 0.8583 val_acc= 0.8000 time= 0.0191\n",
      "Epoch: 0176 train_loss= 0.5126 train_acc= 0.9429 val_loss= 0.8567 val_acc= 0.7967 time= 0.0184\n",
      "Epoch: 0177 train_loss= 0.5103 train_acc= 0.9429 val_loss= 0.8548 val_acc= 0.7967 time= 0.0191\n",
      "Epoch: 0178 train_loss= 0.5077 train_acc= 0.9500 val_loss= 0.8528 val_acc= 0.8000 time= 0.0235\n",
      "Epoch: 0179 train_loss= 0.5050 train_acc= 0.9500 val_loss= 0.8522 val_acc= 0.7967 time= 0.0229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0180 train_loss= 0.5027 train_acc= 0.9500 val_loss= 0.8510 val_acc= 0.7933 time= 0.0201\n",
      "Epoch: 0181 train_loss= 0.5005 train_acc= 0.9500 val_loss= 0.8483 val_acc= 0.7933 time= 0.0243\n",
      "Epoch: 0182 train_loss= 0.4986 train_acc= 0.9500 val_loss= 0.8462 val_acc= 0.7967 time= 0.0233\n",
      "Epoch: 0183 train_loss= 0.4967 train_acc= 0.9500 val_loss= 0.8445 val_acc= 0.7967 time= 0.0189\n",
      "Epoch: 0184 train_loss= 0.4946 train_acc= 0.9500 val_loss= 0.8422 val_acc= 0.8000 time= 0.0238\n",
      "Epoch: 0185 train_loss= 0.4916 train_acc= 0.9500 val_loss= 0.8397 val_acc= 0.8000 time= 0.0237\n",
      "Epoch: 0186 train_loss= 0.4888 train_acc= 0.9500 val_loss= 0.8375 val_acc= 0.8000 time= 0.0201\n",
      "Epoch: 0187 train_loss= 0.4861 train_acc= 0.9571 val_loss= 0.8355 val_acc= 0.7967 time= 0.0273\n",
      "Epoch: 0188 train_loss= 0.4836 train_acc= 0.9571 val_loss= 0.8336 val_acc= 0.7867 time= 0.0188\n",
      "Epoch: 0189 train_loss= 0.4815 train_acc= 0.9571 val_loss= 0.8320 val_acc= 0.7900 time= 0.0187\n",
      "Epoch: 0190 train_loss= 0.4794 train_acc= 0.9571 val_loss= 0.8302 val_acc= 0.7900 time= 0.0249\n",
      "Epoch: 0191 train_loss= 0.4773 train_acc= 0.9571 val_loss= 0.8287 val_acc= 0.7900 time= 0.0273\n",
      "Epoch: 0192 train_loss= 0.4753 train_acc= 0.9571 val_loss= 0.8274 val_acc= 0.7867 time= 0.0187\n",
      "Epoch: 0193 train_loss= 0.4737 train_acc= 0.9571 val_loss= 0.8266 val_acc= 0.7900 time= 0.0269\n",
      "Epoch: 0194 train_loss= 0.4726 train_acc= 0.9500 val_loss= 0.8264 val_acc= 0.8000 time= 0.0179\n",
      "Epoch: 0195 train_loss= 0.4717 train_acc= 0.9429 val_loss= 0.8272 val_acc= 0.8000 time= 0.0232\n",
      "Epoch: 0196 train_loss= 0.4700 train_acc= 0.9429 val_loss= 0.8280 val_acc= 0.7967 time= 0.0221\n",
      "Epoch: 0197 train_loss= 0.4679 train_acc= 0.9500 val_loss= 0.8287 val_acc= 0.7967 time= 0.0187\n",
      "Epoch: 0198 train_loss= 0.4659 train_acc= 0.9571 val_loss= 0.8296 val_acc= 0.7933 time= 0.0187\n",
      "Epoch: 0199 train_loss= 0.4645 train_acc= 0.9643 val_loss= 0.8298 val_acc= 0.7967 time= 0.0180\n",
      "Epoch: 0200 train_loss= 0.4622 train_acc= 0.9571 val_loss= 0.8273 val_acc= 0.7933 time= 0.0192\n"
     ]
    }
   ],
   "source": [
    "NB_EPOCH = 200\n",
    "PATIENCE = 10  # early stopping patience\n",
    "# Helper variables for main training loop\n",
    "wait = 0\n",
    "preds = None\n",
    "best_val_loss = 99999\n",
    "\n",
    "# Fit\n",
    "for epoch in range(1, NB_EPOCH+1):\n",
    "\n",
    "    # Log wall-clock time\n",
    "    t = time.time()\n",
    "\n",
    "    # Single training iteration (we mask nodes without labels for loss calculation)\n",
    "    model.fit(graph, y_train, sample_weight=train_mask,\n",
    "              batch_size=A.shape[0], epochs=1, shuffle=False, verbose=0)\n",
    "\n",
    "    # Predict on full dataset\n",
    "    preds = model.predict(graph, batch_size=A.shape[0])\n",
    "\n",
    "    # Train / validation scores\n",
    "    train_val_loss, train_val_acc = evaluate_preds(preds, [y_train, y_val],\n",
    "                                                   [idx_train, idx_val])\n",
    "    print(\"Epoch: {:04d}\".format(epoch),\n",
    "          \"train_loss= {:.4f}\".format(train_val_loss[0]),\n",
    "          \"train_acc= {:.4f}\".format(train_val_acc[0]),\n",
    "          \"val_loss= {:.4f}\".format(train_val_loss[1]),\n",
    "          \"val_acc= {:.4f}\".format(train_val_acc[1]),\n",
    "          \"time= {:.4f}\".format(time.time() - t))\n",
    "\n",
    "    # Early stopping\n",
    "    if train_val_loss[1] < best_val_loss:\n",
    "        best_val_loss = train_val_loss[1]\n",
    "        wait = 0\n",
    "    else:\n",
    "        if wait >= PATIENCE:\n",
    "            print('Epoch {}: early stopping'.format(epoch))\n",
    "            break\n",
    "        wait += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.8976\n",
      "accuracy = 0.8000\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate_preds(preds, [y_test], [idx_test])\n",
    "print(f\"\"\"\n",
    "loss = {test_loss[0]:.4f}\n",
    "accuracy = {test_acc[0]:.4f}\n",
    "\"\"\".strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Graph Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gaussian_graph_convolution import GaussianGraphConvolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = Dropout(0.5)(X_in)\n",
    "H = GaussianGraphConvolution(16, support, activation='relu', kernel_regularizer=l2(5e-4))([H]+G)\n",
    "H = Dropout(0.5)(H)\n",
    "Y = GaussianGraphConvolution(y.shape[1], support, activation='softmax')([H]+G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[X_in]+G, outputs=Y)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 train_loss= 1.9371 train_acc= 0.4429 val_loss= 1.9378 val_acc= 0.3867 time= 0.4000\n",
      "Epoch: 0002 train_loss= 1.9280 train_acc= 0.4143 val_loss= 1.9294 val_acc= 0.3733 time= 0.0222\n",
      "Epoch: 0003 train_loss= 1.9183 train_acc= 0.3857 val_loss= 1.9209 val_acc= 0.3700 time= 0.0179\n",
      "Epoch: 0004 train_loss= 1.9083 train_acc= 0.4286 val_loss= 1.9124 val_acc= 0.3933 time= 0.0180\n",
      "Epoch: 0005 train_loss= 1.8977 train_acc= 0.4429 val_loss= 1.9036 val_acc= 0.4100 time= 0.0179\n",
      "Epoch: 0006 train_loss= 1.8869 train_acc= 0.4643 val_loss= 1.8950 val_acc= 0.4433 time= 0.0231\n",
      "Epoch: 0007 train_loss= 1.8764 train_acc= 0.4714 val_loss= 1.8866 val_acc= 0.4533 time= 0.0223\n",
      "Epoch: 0008 train_loss= 1.8658 train_acc= 0.4714 val_loss= 1.8781 val_acc= 0.4633 time= 0.0181\n",
      "Epoch: 0009 train_loss= 1.8550 train_acc= 0.4714 val_loss= 1.8693 val_acc= 0.4633 time= 0.0182\n",
      "Epoch: 0010 train_loss= 1.8440 train_acc= 0.4714 val_loss= 1.8603 val_acc= 0.4633 time= 0.0227\n",
      "Epoch: 0011 train_loss= 1.8330 train_acc= 0.4714 val_loss= 1.8514 val_acc= 0.4300 time= 0.0177\n",
      "Epoch: 0012 train_loss= 1.8221 train_acc= 0.4714 val_loss= 1.8429 val_acc= 0.4200 time= 0.0187\n",
      "Epoch: 0013 train_loss= 1.8114 train_acc= 0.4500 val_loss= 1.8345 val_acc= 0.4200 time= 0.0181\n",
      "Epoch: 0014 train_loss= 1.8005 train_acc= 0.4500 val_loss= 1.8264 val_acc= 0.4200 time= 0.0223\n",
      "Epoch: 0015 train_loss= 1.7893 train_acc= 0.4643 val_loss= 1.8183 val_acc= 0.4233 time= 0.0180\n",
      "Epoch: 0016 train_loss= 1.7781 train_acc= 0.4714 val_loss= 1.8106 val_acc= 0.4467 time= 0.0180\n",
      "Epoch: 0017 train_loss= 1.7667 train_acc= 0.4714 val_loss= 1.8027 val_acc= 0.4667 time= 0.0233\n",
      "Epoch: 0018 train_loss= 1.7555 train_acc= 0.4714 val_loss= 1.7951 val_acc= 0.4700 time= 0.0223\n",
      "Epoch: 0019 train_loss= 1.7443 train_acc= 0.4786 val_loss= 1.7876 val_acc= 0.4767 time= 0.0180\n",
      "Epoch: 0020 train_loss= 1.7329 train_acc= 0.4786 val_loss= 1.7798 val_acc= 0.4800 time= 0.0182\n",
      "Epoch: 0021 train_loss= 1.7215 train_acc= 0.4786 val_loss= 1.7719 val_acc= 0.4733 time= 0.0187\n",
      "Epoch: 0022 train_loss= 1.7098 train_acc= 0.4786 val_loss= 1.7637 val_acc= 0.4700 time= 0.0209\n",
      "Epoch: 0023 train_loss= 1.6980 train_acc= 0.4786 val_loss= 1.7555 val_acc= 0.4700 time= 0.0189\n",
      "Epoch: 0024 train_loss= 1.6862 train_acc= 0.4857 val_loss= 1.7473 val_acc= 0.4700 time= 0.0189\n",
      "Epoch: 0025 train_loss= 1.6742 train_acc= 0.4929 val_loss= 1.7388 val_acc= 0.4700 time= 0.0192\n",
      "Epoch: 0026 train_loss= 1.6620 train_acc= 0.4857 val_loss= 1.7301 val_acc= 0.4700 time= 0.0188\n",
      "Epoch: 0027 train_loss= 1.6498 train_acc= 0.4857 val_loss= 1.7214 val_acc= 0.4700 time= 0.0187\n",
      "Epoch: 0028 train_loss= 1.6376 train_acc= 0.4857 val_loss= 1.7129 val_acc= 0.4700 time= 0.0190\n",
      "Epoch: 0029 train_loss= 1.6255 train_acc= 0.4857 val_loss= 1.7043 val_acc= 0.4700 time= 0.0190\n",
      "Epoch: 0030 train_loss= 1.6132 train_acc= 0.4857 val_loss= 1.6954 val_acc= 0.4733 time= 0.0193\n",
      "Epoch: 0031 train_loss= 1.6009 train_acc= 0.4857 val_loss= 1.6865 val_acc= 0.4833 time= 0.0197\n",
      "Epoch: 0032 train_loss= 1.5885 train_acc= 0.4857 val_loss= 1.6778 val_acc= 0.4833 time= 0.0197\n",
      "Epoch: 0033 train_loss= 1.5760 train_acc= 0.4929 val_loss= 1.6693 val_acc= 0.4800 time= 0.0243\n",
      "Epoch: 0034 train_loss= 1.5635 train_acc= 0.4929 val_loss= 1.6606 val_acc= 0.4800 time= 0.0197\n",
      "Epoch: 0035 train_loss= 1.5509 train_acc= 0.4929 val_loss= 1.6518 val_acc= 0.4800 time= 0.0194\n",
      "Epoch: 0036 train_loss= 1.5383 train_acc= 0.4929 val_loss= 1.6427 val_acc= 0.4800 time= 0.0197\n",
      "Epoch: 0037 train_loss= 1.5256 train_acc= 0.4929 val_loss= 1.6340 val_acc= 0.4800 time= 0.0194\n",
      "Epoch: 0038 train_loss= 1.5129 train_acc= 0.4929 val_loss= 1.6251 val_acc= 0.4800 time= 0.0199\n",
      "Epoch: 0039 train_loss= 1.5001 train_acc= 0.5000 val_loss= 1.6162 val_acc= 0.4800 time= 0.0192\n",
      "Epoch: 0040 train_loss= 1.4874 train_acc= 0.5071 val_loss= 1.6074 val_acc= 0.4833 time= 0.0195\n",
      "Epoch: 0041 train_loss= 1.4746 train_acc= 0.5214 val_loss= 1.5983 val_acc= 0.4833 time= 0.0196\n",
      "Epoch: 0042 train_loss= 1.4618 train_acc= 0.5357 val_loss= 1.5891 val_acc= 0.4900 time= 0.0198\n",
      "Epoch: 0043 train_loss= 1.4487 train_acc= 0.5429 val_loss= 1.5798 val_acc= 0.4900 time= 0.0206\n",
      "Epoch: 0044 train_loss= 1.4358 train_acc= 0.5571 val_loss= 1.5703 val_acc= 0.4933 time= 0.0218\n",
      "Epoch: 0045 train_loss= 1.4229 train_acc= 0.5571 val_loss= 1.5610 val_acc= 0.4967 time= 0.0212\n",
      "Epoch: 0046 train_loss= 1.4097 train_acc= 0.5571 val_loss= 1.5513 val_acc= 0.5000 time= 0.0209\n",
      "Epoch: 0047 train_loss= 1.3964 train_acc= 0.5786 val_loss= 1.5423 val_acc= 0.4967 time= 0.0204\n",
      "Epoch: 0048 train_loss= 1.3833 train_acc= 0.6214 val_loss= 1.5331 val_acc= 0.5100 time= 0.0193\n",
      "Epoch: 0049 train_loss= 1.3703 train_acc= 0.6286 val_loss= 1.5239 val_acc= 0.5267 time= 0.0188\n",
      "Epoch: 0050 train_loss= 1.3573 train_acc= 0.6357 val_loss= 1.5141 val_acc= 0.5400 time= 0.0185\n",
      "Epoch: 0051 train_loss= 1.3443 train_acc= 0.6500 val_loss= 1.5043 val_acc= 0.5467 time= 0.0183\n",
      "Epoch: 0052 train_loss= 1.3312 train_acc= 0.6500 val_loss= 1.4947 val_acc= 0.5533 time= 0.0211\n",
      "Epoch: 0053 train_loss= 1.3182 train_acc= 0.6500 val_loss= 1.4848 val_acc= 0.5600 time= 0.0179\n",
      "Epoch: 0054 train_loss= 1.3052 train_acc= 0.6571 val_loss= 1.4751 val_acc= 0.5700 time= 0.0191\n",
      "Epoch: 0055 train_loss= 1.2923 train_acc= 0.6643 val_loss= 1.4654 val_acc= 0.5767 time= 0.0192\n",
      "Epoch: 0056 train_loss= 1.2796 train_acc= 0.6643 val_loss= 1.4557 val_acc= 0.5867 time= 0.0193\n",
      "Epoch: 0057 train_loss= 1.2671 train_acc= 0.6857 val_loss= 1.4465 val_acc= 0.5900 time= 0.0227\n",
      "Epoch: 0058 train_loss= 1.2546 train_acc= 0.7000 val_loss= 1.4372 val_acc= 0.5900 time= 0.0183\n",
      "Epoch: 0059 train_loss= 1.2424 train_acc= 0.7000 val_loss= 1.4279 val_acc= 0.5933 time= 0.0179\n",
      "Epoch: 0060 train_loss= 1.2303 train_acc= 0.7000 val_loss= 1.4186 val_acc= 0.5933 time= 0.0182\n",
      "Epoch: 0061 train_loss= 1.2182 train_acc= 0.7000 val_loss= 1.4094 val_acc= 0.6000 time= 0.0226\n",
      "Epoch: 0062 train_loss= 1.2060 train_acc= 0.7143 val_loss= 1.4001 val_acc= 0.6000 time= 0.0180\n",
      "Epoch: 0063 train_loss= 1.1938 train_acc= 0.7357 val_loss= 1.3912 val_acc= 0.6033 time= 0.0190\n",
      "Epoch: 0064 train_loss= 1.1819 train_acc= 0.7357 val_loss= 1.3824 val_acc= 0.6167 time= 0.0181\n",
      "Epoch: 0065 train_loss= 1.1700 train_acc= 0.7429 val_loss= 1.3737 val_acc= 0.6300 time= 0.0182\n",
      "Epoch: 0066 train_loss= 1.1582 train_acc= 0.7571 val_loss= 1.3650 val_acc= 0.6367 time= 0.0179\n",
      "Epoch: 0067 train_loss= 1.1469 train_acc= 0.7643 val_loss= 1.3565 val_acc= 0.6500 time= 0.0209\n",
      "Epoch: 0068 train_loss= 1.1356 train_acc= 0.7643 val_loss= 1.3479 val_acc= 0.6567 time= 0.0194\n",
      "Epoch: 0069 train_loss= 1.1245 train_acc= 0.7714 val_loss= 1.3394 val_acc= 0.6567 time= 0.0179\n",
      "Epoch: 0070 train_loss= 1.1134 train_acc= 0.7786 val_loss= 1.3309 val_acc= 0.6633 time= 0.0181\n",
      "Epoch: 0071 train_loss= 1.1026 train_acc= 0.7786 val_loss= 1.3224 val_acc= 0.6667 time= 0.0179\n",
      "Epoch: 0072 train_loss= 1.0918 train_acc= 0.7786 val_loss= 1.3134 val_acc= 0.6633 time= 0.0223\n",
      "Epoch: 0073 train_loss= 1.0811 train_acc= 0.7786 val_loss= 1.3045 val_acc= 0.6633 time= 0.0183\n",
      "Epoch: 0074 train_loss= 1.0707 train_acc= 0.7786 val_loss= 1.2956 val_acc= 0.6567 time= 0.0183\n",
      "Epoch: 0075 train_loss= 1.0604 train_acc= 0.7714 val_loss= 1.2873 val_acc= 0.6600 time= 0.0230\n",
      "Epoch: 0076 train_loss= 1.0502 train_acc= 0.7857 val_loss= 1.2792 val_acc= 0.6700 time= 0.0182\n",
      "Epoch: 0077 train_loss= 1.0403 train_acc= 0.7857 val_loss= 1.2712 val_acc= 0.6767 time= 0.0197\n",
      "Epoch: 0078 train_loss= 1.0303 train_acc= 0.7857 val_loss= 1.2632 val_acc= 0.6800 time= 0.0226\n",
      "Epoch: 0079 train_loss= 1.0201 train_acc= 0.7857 val_loss= 1.2558 val_acc= 0.6833 time= 0.0181\n",
      "Epoch: 0080 train_loss= 1.0099 train_acc= 0.8000 val_loss= 1.2483 val_acc= 0.6900 time= 0.0179\n",
      "Epoch: 0081 train_loss= 0.9998 train_acc= 0.8143 val_loss= 1.2410 val_acc= 0.6933 time= 0.0224\n",
      "Epoch: 0082 train_loss= 0.9898 train_acc= 0.8214 val_loss= 1.2333 val_acc= 0.7033 time= 0.0179\n",
      "Epoch: 0083 train_loss= 0.9801 train_acc= 0.8286 val_loss= 1.2260 val_acc= 0.7067 time= 0.0180\n",
      "Epoch: 0084 train_loss= 0.9709 train_acc= 0.8429 val_loss= 1.2198 val_acc= 0.7200 time= 0.0243\n",
      "Epoch: 0085 train_loss= 0.9620 train_acc= 0.8429 val_loss= 1.2135 val_acc= 0.7267 time= 0.0188\n",
      "Epoch: 0086 train_loss= 0.9532 train_acc= 0.8500 val_loss= 1.2077 val_acc= 0.7267 time= 0.0251\n",
      "Epoch: 0087 train_loss= 0.9443 train_acc= 0.8500 val_loss= 1.2013 val_acc= 0.7333 time= 0.0298\n",
      "Epoch: 0088 train_loss= 0.9355 train_acc= 0.8643 val_loss= 1.1944 val_acc= 0.7367 time= 0.0192\n",
      "Epoch: 0089 train_loss= 0.9269 train_acc= 0.8643 val_loss= 1.1877 val_acc= 0.7367 time= 0.0208\n",
      "Epoch: 0090 train_loss= 0.9185 train_acc= 0.8714 val_loss= 1.1806 val_acc= 0.7300 time= 0.0293\n",
      "Epoch: 0091 train_loss= 0.9105 train_acc= 0.8714 val_loss= 1.1735 val_acc= 0.7367 time= 0.0189\n",
      "Epoch: 0092 train_loss= 0.9027 train_acc= 0.8643 val_loss= 1.1664 val_acc= 0.7367 time= 0.0187\n",
      "Epoch: 0093 train_loss= 0.8950 train_acc= 0.8643 val_loss= 1.1598 val_acc= 0.7367 time= 0.0189\n",
      "Epoch: 0094 train_loss= 0.8871 train_acc= 0.8714 val_loss= 1.1540 val_acc= 0.7400 time= 0.0244\n",
      "Epoch: 0095 train_loss= 0.8795 train_acc= 0.8857 val_loss= 1.1484 val_acc= 0.7433 time= 0.0248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0096 train_loss= 0.8718 train_acc= 0.8857 val_loss= 1.1429 val_acc= 0.7500 time= 0.0244\n",
      "Epoch: 0097 train_loss= 0.8641 train_acc= 0.8857 val_loss= 1.1374 val_acc= 0.7500 time= 0.0217\n",
      "Epoch: 0098 train_loss= 0.8566 train_acc= 0.8857 val_loss= 1.1319 val_acc= 0.7567 time= 0.0194\n",
      "Epoch: 0099 train_loss= 0.8493 train_acc= 0.8857 val_loss= 1.1262 val_acc= 0.7533 time= 0.0185\n",
      "Epoch: 0100 train_loss= 0.8423 train_acc= 0.8857 val_loss= 1.1206 val_acc= 0.7533 time= 0.0241\n",
      "Epoch: 0101 train_loss= 0.8354 train_acc= 0.8857 val_loss= 1.1150 val_acc= 0.7500 time= 0.0187\n",
      "Epoch: 0102 train_loss= 0.8284 train_acc= 0.8857 val_loss= 1.1089 val_acc= 0.7567 time= 0.0189\n",
      "Epoch: 0103 train_loss= 0.8213 train_acc= 0.8857 val_loss= 1.1022 val_acc= 0.7533 time= 0.0240\n",
      "Epoch: 0104 train_loss= 0.8147 train_acc= 0.9000 val_loss= 1.0962 val_acc= 0.7633 time= 0.0198\n",
      "Epoch: 0105 train_loss= 0.8084 train_acc= 0.9000 val_loss= 1.0906 val_acc= 0.7667 time= 0.0251\n",
      "Epoch: 0106 train_loss= 0.8023 train_acc= 0.9000 val_loss= 1.0855 val_acc= 0.7700 time= 0.0191\n",
      "Epoch: 0107 train_loss= 0.7956 train_acc= 0.9071 val_loss= 1.0806 val_acc= 0.7700 time= 0.0242\n",
      "Epoch: 0108 train_loss= 0.7888 train_acc= 0.9071 val_loss= 1.0764 val_acc= 0.7700 time= 0.0257\n",
      "Epoch: 0109 train_loss= 0.7822 train_acc= 0.8929 val_loss= 1.0729 val_acc= 0.7767 time= 0.0188\n",
      "Epoch: 0110 train_loss= 0.7760 train_acc= 0.8929 val_loss= 1.0696 val_acc= 0.7800 time= 0.0179\n",
      "Epoch: 0111 train_loss= 0.7702 train_acc= 0.9000 val_loss= 1.0664 val_acc= 0.7800 time= 0.0223\n",
      "Epoch: 0112 train_loss= 0.7641 train_acc= 0.9000 val_loss= 1.0612 val_acc= 0.7800 time= 0.0180\n",
      "Epoch: 0113 train_loss= 0.7579 train_acc= 0.8929 val_loss= 1.0553 val_acc= 0.7800 time= 0.0230\n",
      "Epoch: 0114 train_loss= 0.7520 train_acc= 0.8929 val_loss= 1.0499 val_acc= 0.7800 time= 0.0181\n",
      "Epoch: 0115 train_loss= 0.7464 train_acc= 0.9071 val_loss= 1.0443 val_acc= 0.7800 time= 0.0181\n",
      "Epoch: 0116 train_loss= 0.7408 train_acc= 0.9071 val_loss= 1.0384 val_acc= 0.7767 time= 0.0188\n",
      "Epoch: 0117 train_loss= 0.7354 train_acc= 0.9071 val_loss= 1.0330 val_acc= 0.7733 time= 0.0268\n",
      "Epoch: 0118 train_loss= 0.7298 train_acc= 0.9071 val_loss= 1.0279 val_acc= 0.7800 time= 0.0183\n",
      "Epoch: 0119 train_loss= 0.7242 train_acc= 0.9071 val_loss= 1.0236 val_acc= 0.7767 time= 0.0179\n",
      "Epoch: 0120 train_loss= 0.7184 train_acc= 0.9071 val_loss= 1.0204 val_acc= 0.7800 time= 0.0226\n",
      "Epoch: 0121 train_loss= 0.7135 train_acc= 0.9071 val_loss= 1.0174 val_acc= 0.7800 time= 0.0180\n",
      "Epoch: 0122 train_loss= 0.7085 train_acc= 0.9143 val_loss= 1.0150 val_acc= 0.7833 time= 0.0190\n",
      "Epoch: 0123 train_loss= 0.7039 train_acc= 0.9143 val_loss= 1.0124 val_acc= 0.7833 time= 0.0284\n",
      "Epoch: 0124 train_loss= 0.6992 train_acc= 0.9143 val_loss= 1.0088 val_acc= 0.7800 time= 0.0184\n",
      "Epoch: 0125 train_loss= 0.6949 train_acc= 0.9143 val_loss= 1.0053 val_acc= 0.7800 time= 0.0182\n",
      "Epoch: 0126 train_loss= 0.6907 train_acc= 0.9143 val_loss= 1.0017 val_acc= 0.7800 time= 0.0185\n",
      "Epoch: 0127 train_loss= 0.6866 train_acc= 0.9143 val_loss= 0.9982 val_acc= 0.7800 time= 0.0183\n",
      "Epoch: 0128 train_loss= 0.6825 train_acc= 0.9143 val_loss= 0.9935 val_acc= 0.7767 time= 0.0204\n",
      "Epoch: 0129 train_loss= 0.6785 train_acc= 0.9143 val_loss= 0.9887 val_acc= 0.7733 time= 0.0235\n",
      "Epoch: 0130 train_loss= 0.6748 train_acc= 0.9143 val_loss= 0.9841 val_acc= 0.7700 time= 0.0184\n",
      "Epoch: 0131 train_loss= 0.6700 train_acc= 0.9143 val_loss= 0.9796 val_acc= 0.7733 time= 0.0193\n",
      "Epoch: 0132 train_loss= 0.6644 train_acc= 0.9143 val_loss= 0.9755 val_acc= 0.7767 time= 0.0237\n",
      "Epoch: 0133 train_loss= 0.6587 train_acc= 0.9143 val_loss= 0.9727 val_acc= 0.7800 time= 0.0183\n",
      "Epoch: 0134 train_loss= 0.6538 train_acc= 0.9143 val_loss= 0.9699 val_acc= 0.7800 time= 0.0185\n",
      "Epoch: 0135 train_loss= 0.6492 train_acc= 0.9143 val_loss= 0.9676 val_acc= 0.7767 time= 0.0193\n",
      "Epoch: 0136 train_loss= 0.6448 train_acc= 0.9143 val_loss= 0.9644 val_acc= 0.7800 time= 0.0279\n",
      "Epoch: 0137 train_loss= 0.6403 train_acc= 0.9143 val_loss= 0.9610 val_acc= 0.7800 time= 0.0227\n",
      "Epoch: 0138 train_loss= 0.6357 train_acc= 0.9143 val_loss= 0.9574 val_acc= 0.7833 time= 0.0240\n",
      "Epoch: 0139 train_loss= 0.6317 train_acc= 0.9143 val_loss= 0.9534 val_acc= 0.7833 time= 0.0282\n",
      "Epoch: 0140 train_loss= 0.6282 train_acc= 0.9143 val_loss= 0.9502 val_acc= 0.7833 time= 0.0179\n",
      "Epoch: 0141 train_loss= 0.6250 train_acc= 0.9143 val_loss= 0.9464 val_acc= 0.7833 time= 0.0184\n",
      "Epoch: 0142 train_loss= 0.6217 train_acc= 0.9143 val_loss= 0.9431 val_acc= 0.7800 time= 0.0184\n",
      "Epoch: 0143 train_loss= 0.6180 train_acc= 0.9143 val_loss= 0.9396 val_acc= 0.7767 time= 0.0181\n",
      "Epoch: 0144 train_loss= 0.6140 train_acc= 0.9143 val_loss= 0.9366 val_acc= 0.7767 time= 0.0180\n",
      "Epoch: 0145 train_loss= 0.6101 train_acc= 0.9143 val_loss= 0.9341 val_acc= 0.7833 time= 0.0227\n",
      "Epoch: 0146 train_loss= 0.6061 train_acc= 0.9143 val_loss= 0.9327 val_acc= 0.7833 time= 0.0185\n",
      "Epoch: 0147 train_loss= 0.6028 train_acc= 0.9143 val_loss= 0.9319 val_acc= 0.7833 time= 0.0191\n",
      "Epoch: 0148 train_loss= 0.5999 train_acc= 0.9214 val_loss= 0.9310 val_acc= 0.7800 time= 0.0194\n",
      "Epoch: 0149 train_loss= 0.5962 train_acc= 0.9214 val_loss= 0.9280 val_acc= 0.7767 time= 0.0197\n",
      "Epoch: 0150 train_loss= 0.5919 train_acc= 0.9214 val_loss= 0.9231 val_acc= 0.7800 time= 0.0198\n",
      "Epoch: 0151 train_loss= 0.5885 train_acc= 0.9214 val_loss= 0.9194 val_acc= 0.7833 time= 0.0195\n",
      "Epoch: 0152 train_loss= 0.5853 train_acc= 0.9214 val_loss= 0.9160 val_acc= 0.7867 time= 0.0192\n",
      "Epoch: 0153 train_loss= 0.5821 train_acc= 0.9214 val_loss= 0.9134 val_acc= 0.7867 time= 0.0197\n",
      "Epoch: 0154 train_loss= 0.5787 train_acc= 0.9214 val_loss= 0.9118 val_acc= 0.7933 time= 0.0199\n",
      "Epoch: 0155 train_loss= 0.5750 train_acc= 0.9214 val_loss= 0.9086 val_acc= 0.7933 time= 0.0192\n",
      "Epoch: 0156 train_loss= 0.5710 train_acc= 0.9214 val_loss= 0.9053 val_acc= 0.7933 time= 0.0202\n",
      "Epoch: 0157 train_loss= 0.5672 train_acc= 0.9286 val_loss= 0.9010 val_acc= 0.7933 time= 0.0203\n",
      "Epoch: 0158 train_loss= 0.5636 train_acc= 0.9286 val_loss= 0.8972 val_acc= 0.8000 time= 0.0203\n",
      "Epoch: 0159 train_loss= 0.5605 train_acc= 0.9286 val_loss= 0.8939 val_acc= 0.7967 time= 0.0275\n",
      "Epoch: 0160 train_loss= 0.5578 train_acc= 0.9286 val_loss= 0.8906 val_acc= 0.7967 time= 0.0210\n",
      "Epoch: 0161 train_loss= 0.5553 train_acc= 0.9286 val_loss= 0.8879 val_acc= 0.7933 time= 0.0262\n",
      "Epoch: 0162 train_loss= 0.5519 train_acc= 0.9286 val_loss= 0.8861 val_acc= 0.7967 time= 0.0199\n",
      "Epoch: 0163 train_loss= 0.5487 train_acc= 0.9286 val_loss= 0.8846 val_acc= 0.7967 time= 0.0203\n",
      "Epoch: 0164 train_loss= 0.5454 train_acc= 0.9286 val_loss= 0.8834 val_acc= 0.7933 time= 0.0257\n",
      "Epoch: 0165 train_loss= 0.5426 train_acc= 0.9286 val_loss= 0.8828 val_acc= 0.7933 time= 0.0208\n",
      "Epoch: 0166 train_loss= 0.5401 train_acc= 0.9286 val_loss= 0.8819 val_acc= 0.7900 time= 0.0246\n",
      "Epoch: 0167 train_loss= 0.5380 train_acc= 0.9286 val_loss= 0.8796 val_acc= 0.7933 time= 0.0243\n",
      "Epoch: 0168 train_loss= 0.5364 train_acc= 0.9286 val_loss= 0.8776 val_acc= 0.7900 time= 0.0199\n",
      "Epoch: 0169 train_loss= 0.5351 train_acc= 0.9286 val_loss= 0.8762 val_acc= 0.7933 time= 0.0246\n",
      "Epoch: 0170 train_loss= 0.5333 train_acc= 0.9286 val_loss= 0.8754 val_acc= 0.7933 time= 0.0193\n",
      "Epoch: 0171 train_loss= 0.5311 train_acc= 0.9286 val_loss= 0.8735 val_acc= 0.7967 time= 0.0246\n",
      "Epoch: 0172 train_loss= 0.5287 train_acc= 0.9286 val_loss= 0.8717 val_acc= 0.7967 time= 0.0248\n",
      "Epoch: 0173 train_loss= 0.5263 train_acc= 0.9286 val_loss= 0.8705 val_acc= 0.7967 time= 0.0267\n",
      "Epoch: 0174 train_loss= 0.5241 train_acc= 0.9286 val_loss= 0.8696 val_acc= 0.7967 time= 0.0248\n",
      "Epoch: 0175 train_loss= 0.5218 train_acc= 0.9357 val_loss= 0.8672 val_acc= 0.7967 time= 0.0191\n",
      "Epoch: 0176 train_loss= 0.5193 train_acc= 0.9357 val_loss= 0.8638 val_acc= 0.8000 time= 0.0254\n",
      "Epoch: 0177 train_loss= 0.5164 train_acc= 0.9357 val_loss= 0.8606 val_acc= 0.8000 time= 0.0250\n",
      "Epoch: 0178 train_loss= 0.5129 train_acc= 0.9357 val_loss= 0.8577 val_acc= 0.8000 time= 0.0247\n",
      "Epoch: 0179 train_loss= 0.5095 train_acc= 0.9286 val_loss= 0.8557 val_acc= 0.7967 time= 0.0253\n",
      "Epoch: 0180 train_loss= 0.5066 train_acc= 0.9357 val_loss= 0.8545 val_acc= 0.7933 time= 0.0232\n",
      "Epoch: 0181 train_loss= 0.5040 train_acc= 0.9357 val_loss= 0.8537 val_acc= 0.7900 time= 0.0228\n",
      "Epoch: 0182 train_loss= 0.5018 train_acc= 0.9357 val_loss= 0.8521 val_acc= 0.7900 time= 0.0227\n",
      "Epoch: 0183 train_loss= 0.4998 train_acc= 0.9286 val_loss= 0.8503 val_acc= 0.7933 time= 0.0182\n",
      "Epoch: 0184 train_loss= 0.4982 train_acc= 0.9286 val_loss= 0.8477 val_acc= 0.7933 time= 0.0183\n",
      "Epoch: 0185 train_loss= 0.4969 train_acc= 0.9286 val_loss= 0.8458 val_acc= 0.7933 time= 0.0232\n",
      "Epoch: 0186 train_loss= 0.4953 train_acc= 0.9286 val_loss= 0.8439 val_acc= 0.7900 time= 0.0186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0187 train_loss= 0.4934 train_acc= 0.9357 val_loss= 0.8420 val_acc= 0.7900 time= 0.0192\n",
      "Epoch: 0188 train_loss= 0.4913 train_acc= 0.9429 val_loss= 0.8401 val_acc= 0.7933 time= 0.0193\n",
      "Epoch: 0189 train_loss= 0.4891 train_acc= 0.9429 val_loss= 0.8383 val_acc= 0.8000 time= 0.0231\n",
      "Epoch: 0190 train_loss= 0.4868 train_acc= 0.9429 val_loss= 0.8365 val_acc= 0.8000 time= 0.0192\n",
      "Epoch: 0191 train_loss= 0.4849 train_acc= 0.9429 val_loss= 0.8354 val_acc= 0.8000 time= 0.0184\n",
      "Epoch: 0192 train_loss= 0.4832 train_acc= 0.9429 val_loss= 0.8351 val_acc= 0.7967 time= 0.0211\n",
      "Epoch: 0193 train_loss= 0.4820 train_acc= 0.9429 val_loss= 0.8353 val_acc= 0.7933 time= 0.0210\n",
      "Epoch: 0194 train_loss= 0.4807 train_acc= 0.9429 val_loss= 0.8365 val_acc= 0.7867 time= 0.0221\n",
      "Epoch: 0195 train_loss= 0.4799 train_acc= 0.9429 val_loss= 0.8380 val_acc= 0.7900 time= 0.0266\n",
      "Epoch: 0196 train_loss= 0.4785 train_acc= 0.9429 val_loss= 0.8383 val_acc= 0.7867 time= 0.0264\n",
      "Epoch: 0197 train_loss= 0.4770 train_acc= 0.9429 val_loss= 0.8381 val_acc= 0.7933 time= 0.0233\n",
      "Epoch: 0198 train_loss= 0.4750 train_acc= 0.9429 val_loss= 0.8371 val_acc= 0.7967 time= 0.0284\n",
      "Epoch: 0199 train_loss= 0.4725 train_acc= 0.9429 val_loss= 0.8344 val_acc= 0.7933 time= 0.0231\n",
      "Epoch: 0200 train_loss= 0.4700 train_acc= 0.9429 val_loss= 0.8317 val_acc= 0.7933 time= 0.0197\n"
     ]
    }
   ],
   "source": [
    "NB_EPOCH = 200\n",
    "PATIENCE = 10  # early stopping patience\n",
    "# Helper variables for main training loop\n",
    "wait = 0\n",
    "preds = None\n",
    "best_val_loss = 99999\n",
    "\n",
    "# Fit\n",
    "for epoch in range(1, NB_EPOCH+1):\n",
    "\n",
    "    # Log wall-clock time\n",
    "    t = time.time()\n",
    "\n",
    "    # Single training iteration (we mask nodes without labels for loss calculation)\n",
    "    model.fit(graph, y_train, sample_weight=train_mask,\n",
    "              batch_size=A.shape[0], epochs=1, shuffle=False, verbose=0)\n",
    "\n",
    "    # Predict on full dataset\n",
    "    preds = model.predict(graph, batch_size=A.shape[0])\n",
    "\n",
    "    # Train / validation scores\n",
    "    train_val_loss, train_val_acc = evaluate_preds(preds, [y_train, y_val],\n",
    "                                                   [idx_train, idx_val])\n",
    "    print(\"Epoch: {:04d}\".format(epoch),\n",
    "          \"train_loss= {:.4f}\".format(train_val_loss[0]),\n",
    "          \"train_acc= {:.4f}\".format(train_val_acc[0]),\n",
    "          \"val_loss= {:.4f}\".format(train_val_loss[1]),\n",
    "          \"val_acc= {:.4f}\".format(train_val_acc[1]),\n",
    "          \"time= {:.4f}\".format(time.time() - t))\n",
    "\n",
    "    # Early stopping\n",
    "    if train_val_loss[1] < best_val_loss:\n",
    "        best_val_loss = train_val_loss[1]\n",
    "        wait = 0\n",
    "    else:\n",
    "        if wait >= PATIENCE:\n",
    "            print('Epoch {}: early stopping'.format(epoch))\n",
    "            break\n",
    "        wait += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.8890\n",
      "accuracy = 0.7770\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate_preds(preds, [y_test], [idx_test])\n",
    "print(f\"\"\"\n",
    "loss = {test_loss[0]:.4f}\n",
    "accuracy = {test_acc[0]:.4f}\n",
    "\"\"\".strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
