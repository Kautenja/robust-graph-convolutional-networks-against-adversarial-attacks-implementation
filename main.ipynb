{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from keras.layers import Input, Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the path of execution\n",
    "EXE_PATH = os.path.abspath(os.path.curdir)\n",
    "# the path of the vendor files\n",
    "VENDOR_PATH = os.path.join(EXE_PATH, 'vendor')\n",
    "# the vendors to include in the system path\n",
    "VENDORS = ['keras-gcn']\n",
    "# create the absolute paths for all vendors\n",
    "VENDORS = list(map(lambda x: os.path.join(VENDOR_PATH, x), VENDORS))\n",
    "# update the Python path to include necessary vendor module\n",
    "sys.path += VENDORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kegra.layers.graph import GraphConvolution\n",
    "from kegra.utils import load_data, preprocess_adj, get_splits, evaluate_preds\n",
    "from ggcn import GaussianGraphConvolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cora dataset...\n",
      "Dataset has 2708 nodes, 5429 edges, 1433 features.\n"
     ]
    }
   ],
   "source": [
    "X, A, y = load_data('data/cora/', dataset='cora')\n",
    "X /= X.sum(1).reshape(-1, 1)\n",
    "A = preprocess_adj(A)\n",
    "y_train, y_val, y_test, idx_train, idx_val, idx_test, train_mask = get_splits(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2708x2708 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 13264 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 1, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 1, 0]], dtype=int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1110 15:29:28.199064 140340509591360 deprecation_wrapper.py:119] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1110 15:29:28.206780 140340509591360 deprecation_wrapper.py:119] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:515: The name tf.sparse_placeholder is deprecated. Please use tf.compat.v1.sparse_placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "support = 1\n",
    "graph = [X, A]\n",
    "G = [Input(shape=(None, None), batch_shape=(None, None), sparse=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1110 15:29:28.213454 140340509591360 deprecation_wrapper.py:119] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_in = Input(shape=(X.shape[1],))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCN (baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1110 15:29:28.221709 140340509591360 deprecation_wrapper.py:119] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W1110 15:29:28.227010 140340509591360 deprecation.py:506] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W1110 15:29:28.235213 140340509591360 deprecation_wrapper.py:119] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define model architecture\n",
    "# NOTE: We pass arguments for graph convolutional layers as a list of tensors.\n",
    "# This is somewhat hacky, more elegant options would require rewriting the Layer base class.\n",
    "H = Dropout(0.5)(X_in)\n",
    "H = GraphConvolution(16, support, activation='relu', kernel_regularizer=l2(5e-4))([H]+G)\n",
    "H = Dropout(0.5)(H)\n",
    "Y = GraphConvolution(y.shape[1], support, activation='softmax')([H]+G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1110 15:29:28.279044 140340509591360 deprecation_wrapper.py:119] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=[X_in]+G, outputs=Y)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1110 15:29:28.351851 140340509591360 deprecation.py:323] From /home/bitcommander/.local/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 train_loss= 1.9349 train_acc= 0.2929 val_loss= 1.9348 val_acc= 0.3500 time= 1.0828\n",
      "Epoch: 0002 train_loss= 1.9233 train_acc= 0.2929 val_loss= 1.9237 val_acc= 0.3500 time= 0.0226\n",
      "Epoch: 0003 train_loss= 1.9112 train_acc= 0.2929 val_loss= 1.9121 val_acc= 0.3500 time= 0.0180\n",
      "Epoch: 0004 train_loss= 1.8980 train_acc= 0.2929 val_loss= 1.8996 val_acc= 0.3500 time= 0.0230\n",
      "Epoch: 0005 train_loss= 1.8844 train_acc= 0.2929 val_loss= 1.8870 val_acc= 0.3500 time= 0.0227\n",
      "Epoch: 0006 train_loss= 1.8707 train_acc= 0.2929 val_loss= 1.8742 val_acc= 0.3500 time= 0.0236\n",
      "Epoch: 0007 train_loss= 1.8567 train_acc= 0.2929 val_loss= 1.8614 val_acc= 0.3500 time= 0.0190\n",
      "Epoch: 0008 train_loss= 1.8428 train_acc= 0.2929 val_loss= 1.8485 val_acc= 0.3500 time= 0.0227\n",
      "Epoch: 0009 train_loss= 1.8289 train_acc= 0.2929 val_loss= 1.8360 val_acc= 0.3500 time= 0.0222\n",
      "Epoch: 0010 train_loss= 1.8152 train_acc= 0.2929 val_loss= 1.8238 val_acc= 0.3500 time= 0.0250\n",
      "Epoch: 0011 train_loss= 1.8020 train_acc= 0.2929 val_loss= 1.8122 val_acc= 0.3500 time= 0.0235\n",
      "Epoch: 0012 train_loss= 1.7893 train_acc= 0.2929 val_loss= 1.8012 val_acc= 0.3500 time= 0.0192\n",
      "Epoch: 0013 train_loss= 1.7770 train_acc= 0.2929 val_loss= 1.7907 val_acc= 0.3500 time= 0.0248\n",
      "Epoch: 0014 train_loss= 1.7657 train_acc= 0.2929 val_loss= 1.7816 val_acc= 0.3500 time= 0.0229\n",
      "Epoch: 0015 train_loss= 1.7552 train_acc= 0.2929 val_loss= 1.7737 val_acc= 0.3500 time= 0.0247\n",
      "Epoch: 0016 train_loss= 1.7454 train_acc= 0.2929 val_loss= 1.7667 val_acc= 0.3500 time= 0.0238\n",
      "Epoch: 0017 train_loss= 1.7360 train_acc= 0.2929 val_loss= 1.7606 val_acc= 0.3500 time= 0.0237\n",
      "Epoch: 0018 train_loss= 1.7270 train_acc= 0.2929 val_loss= 1.7551 val_acc= 0.3500 time= 0.0239\n",
      "Epoch: 0019 train_loss= 1.7183 train_acc= 0.2929 val_loss= 1.7501 val_acc= 0.3500 time= 0.0189\n",
      "Epoch: 0020 train_loss= 1.7097 train_acc= 0.3000 val_loss= 1.7451 val_acc= 0.3500 time= 0.0239\n",
      "Epoch: 0021 train_loss= 1.7008 train_acc= 0.3357 val_loss= 1.7402 val_acc= 0.3600 time= 0.0202\n",
      "Epoch: 0022 train_loss= 1.6917 train_acc= 0.3714 val_loss= 1.7352 val_acc= 0.3633 time= 0.0230\n",
      "Epoch: 0023 train_loss= 1.6823 train_acc= 0.3857 val_loss= 1.7299 val_acc= 0.3633 time= 0.0240\n",
      "Epoch: 0024 train_loss= 1.6727 train_acc= 0.4000 val_loss= 1.7246 val_acc= 0.3667 time= 0.0186\n",
      "Epoch: 0025 train_loss= 1.6628 train_acc= 0.4143 val_loss= 1.7190 val_acc= 0.3767 time= 0.0225\n",
      "Epoch: 0026 train_loss= 1.6527 train_acc= 0.4214 val_loss= 1.7133 val_acc= 0.3900 time= 0.0180\n",
      "Epoch: 0027 train_loss= 1.6427 train_acc= 0.4286 val_loss= 1.7074 val_acc= 0.3933 time= 0.0187\n",
      "Epoch: 0028 train_loss= 1.6324 train_acc= 0.4357 val_loss= 1.7011 val_acc= 0.4100 time= 0.0189\n",
      "Epoch: 0029 train_loss= 1.6218 train_acc= 0.4429 val_loss= 1.6946 val_acc= 0.4100 time= 0.0233\n",
      "Epoch: 0030 train_loss= 1.6111 train_acc= 0.4500 val_loss= 1.6878 val_acc= 0.4133 time= 0.0184\n",
      "Epoch: 0031 train_loss= 1.6001 train_acc= 0.4571 val_loss= 1.6807 val_acc= 0.4200 time= 0.0231\n",
      "Epoch: 0032 train_loss= 1.5890 train_acc= 0.4571 val_loss= 1.6736 val_acc= 0.4300 time= 0.0222\n",
      "Epoch: 0033 train_loss= 1.5778 train_acc= 0.4643 val_loss= 1.6663 val_acc= 0.4500 time= 0.0182\n",
      "Epoch: 0034 train_loss= 1.5665 train_acc= 0.4643 val_loss= 1.6588 val_acc= 0.4600 time= 0.0204\n",
      "Epoch: 0035 train_loss= 1.5552 train_acc= 0.4643 val_loss= 1.6512 val_acc= 0.4633 time= 0.0243\n",
      "Epoch: 0036 train_loss= 1.5437 train_acc= 0.4643 val_loss= 1.6433 val_acc= 0.4633 time= 0.0237\n",
      "Epoch: 0037 train_loss= 1.5322 train_acc= 0.4643 val_loss= 1.6351 val_acc= 0.4633 time= 0.0184\n",
      "Epoch: 0038 train_loss= 1.5204 train_acc= 0.4643 val_loss= 1.6266 val_acc= 0.4667 time= 0.0184\n",
      "Epoch: 0039 train_loss= 1.5086 train_acc= 0.4643 val_loss= 1.6181 val_acc= 0.4667 time= 0.0183\n",
      "Epoch: 0040 train_loss= 1.4966 train_acc= 0.4643 val_loss= 1.6093 val_acc= 0.4633 time= 0.0285\n",
      "Epoch: 0041 train_loss= 1.4845 train_acc= 0.4643 val_loss= 1.6005 val_acc= 0.4633 time= 0.0189\n",
      "Epoch: 0042 train_loss= 1.4722 train_acc= 0.4643 val_loss= 1.5916 val_acc= 0.4633 time= 0.0248\n",
      "Epoch: 0043 train_loss= 1.4598 train_acc= 0.4643 val_loss= 1.5827 val_acc= 0.4600 time= 0.0236\n",
      "Epoch: 0044 train_loss= 1.4472 train_acc= 0.4643 val_loss= 1.5738 val_acc= 0.4633 time= 0.0279\n",
      "Epoch: 0045 train_loss= 1.4347 train_acc= 0.4714 val_loss= 1.5650 val_acc= 0.4567 time= 0.0230\n",
      "Epoch: 0046 train_loss= 1.4221 train_acc= 0.4714 val_loss= 1.5564 val_acc= 0.4600 time= 0.0191\n",
      "Epoch: 0047 train_loss= 1.4096 train_acc= 0.4929 val_loss= 1.5481 val_acc= 0.4667 time= 0.0183\n",
      "Epoch: 0048 train_loss= 1.3971 train_acc= 0.4929 val_loss= 1.5397 val_acc= 0.4733 time= 0.0185\n",
      "Epoch: 0049 train_loss= 1.3844 train_acc= 0.4929 val_loss= 1.5311 val_acc= 0.4733 time= 0.0235\n",
      "Epoch: 0050 train_loss= 1.3718 train_acc= 0.5143 val_loss= 1.5225 val_acc= 0.4767 time= 0.0192\n",
      "Epoch: 0051 train_loss= 1.3593 train_acc= 0.5214 val_loss= 1.5138 val_acc= 0.4833 time= 0.0287\n",
      "Epoch: 0052 train_loss= 1.3468 train_acc= 0.5214 val_loss= 1.5049 val_acc= 0.4867 time= 0.0224\n",
      "Epoch: 0053 train_loss= 1.3343 train_acc= 0.5214 val_loss= 1.4956 val_acc= 0.4900 time= 0.0222\n",
      "Epoch: 0054 train_loss= 1.3220 train_acc= 0.5214 val_loss= 1.4863 val_acc= 0.4967 time= 0.0233\n",
      "Epoch: 0055 train_loss= 1.3099 train_acc= 0.5357 val_loss= 1.4768 val_acc= 0.4967 time= 0.0228\n",
      "Epoch: 0056 train_loss= 1.2978 train_acc= 0.5357 val_loss= 1.4673 val_acc= 0.5000 time= 0.0244\n",
      "Epoch: 0057 train_loss= 1.2860 train_acc= 0.5357 val_loss= 1.4578 val_acc= 0.5033 time= 0.0227\n",
      "Epoch: 0058 train_loss= 1.2743 train_acc= 0.5357 val_loss= 1.4485 val_acc= 0.5033 time= 0.0246\n",
      "Epoch: 0059 train_loss= 1.2623 train_acc= 0.5571 val_loss= 1.4394 val_acc= 0.5100 time= 0.0258\n",
      "Epoch: 0060 train_loss= 1.2501 train_acc= 0.5571 val_loss= 1.4305 val_acc= 0.5167 time= 0.0233\n",
      "Epoch: 0061 train_loss= 1.2381 train_acc= 0.5786 val_loss= 1.4219 val_acc= 0.5300 time= 0.0196\n",
      "Epoch: 0062 train_loss= 1.2263 train_acc= 0.6214 val_loss= 1.4140 val_acc= 0.5600 time= 0.0187\n",
      "Epoch: 0063 train_loss= 1.2153 train_acc= 0.6429 val_loss= 1.4064 val_acc= 0.5667 time= 0.0193\n",
      "Epoch: 0064 train_loss= 1.2043 train_acc= 0.6429 val_loss= 1.3986 val_acc= 0.5700 time= 0.0185\n",
      "Epoch: 0065 train_loss= 1.1932 train_acc= 0.6500 val_loss= 1.3902 val_acc= 0.5700 time= 0.0242\n",
      "Epoch: 0066 train_loss= 1.1821 train_acc= 0.6500 val_loss= 1.3813 val_acc= 0.5700 time= 0.0180\n",
      "Epoch: 0067 train_loss= 1.1711 train_acc= 0.6571 val_loss= 1.3725 val_acc= 0.5700 time= 0.0189\n",
      "Epoch: 0068 train_loss= 1.1604 train_acc= 0.6571 val_loss= 1.3637 val_acc= 0.5700 time= 0.0247\n",
      "Epoch: 0069 train_loss= 1.1500 train_acc= 0.6571 val_loss= 1.3551 val_acc= 0.5767 time= 0.0236\n",
      "Epoch: 0070 train_loss= 1.1401 train_acc= 0.6786 val_loss= 1.3470 val_acc= 0.5733 time= 0.0187\n",
      "Epoch: 0071 train_loss= 1.1303 train_acc= 0.7000 val_loss= 1.3397 val_acc= 0.5833 time= 0.0228\n",
      "Epoch: 0072 train_loss= 1.1202 train_acc= 0.7286 val_loss= 1.3325 val_acc= 0.5967 time= 0.0205\n",
      "Epoch: 0073 train_loss= 1.1102 train_acc= 0.7286 val_loss= 1.3254 val_acc= 0.6100 time= 0.0203\n",
      "Epoch: 0074 train_loss= 1.1005 train_acc= 0.7429 val_loss= 1.3189 val_acc= 0.6100 time= 0.0228\n",
      "Epoch: 0075 train_loss= 1.0912 train_acc= 0.7643 val_loss= 1.3125 val_acc= 0.6233 time= 0.0240\n",
      "Epoch: 0076 train_loss= 1.0817 train_acc= 0.7929 val_loss= 1.3062 val_acc= 0.6367 time= 0.0250\n",
      "Epoch: 0077 train_loss= 1.0722 train_acc= 0.8000 val_loss= 1.2994 val_acc= 0.6400 time= 0.0227\n",
      "Epoch: 0078 train_loss= 1.0625 train_acc= 0.8071 val_loss= 1.2920 val_acc= 0.6533 time= 0.0243\n",
      "Epoch: 0079 train_loss= 1.0531 train_acc= 0.8071 val_loss= 1.2849 val_acc= 0.6600 time= 0.0185\n",
      "Epoch: 0080 train_loss= 1.0438 train_acc= 0.8143 val_loss= 1.2774 val_acc= 0.6600 time= 0.0184\n",
      "Epoch: 0081 train_loss= 1.0348 train_acc= 0.8143 val_loss= 1.2702 val_acc= 0.6600 time= 0.0234\n",
      "Epoch: 0082 train_loss= 1.0261 train_acc= 0.8143 val_loss= 1.2631 val_acc= 0.6733 time= 0.0188\n",
      "Epoch: 0083 train_loss= 1.0174 train_acc= 0.8143 val_loss= 1.2561 val_acc= 0.6833 time= 0.0181\n",
      "Epoch: 0084 train_loss= 1.0086 train_acc= 0.8214 val_loss= 1.2491 val_acc= 0.6967 time= 0.0231\n",
      "Epoch: 0085 train_loss= 0.9997 train_acc= 0.8214 val_loss= 1.2419 val_acc= 0.6967 time= 0.0187\n",
      "Epoch: 0086 train_loss= 0.9908 train_acc= 0.8214 val_loss= 1.2347 val_acc= 0.6933 time= 0.0197\n",
      "Epoch: 0087 train_loss= 0.9820 train_acc= 0.8286 val_loss= 1.2274 val_acc= 0.6933 time= 0.0232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0088 train_loss= 0.9733 train_acc= 0.8357 val_loss= 1.2206 val_acc= 0.6933 time= 0.0189\n",
      "Epoch: 0089 train_loss= 0.9648 train_acc= 0.8429 val_loss= 1.2138 val_acc= 0.7033 time= 0.0212\n",
      "Epoch: 0090 train_loss= 0.9567 train_acc= 0.8500 val_loss= 1.2076 val_acc= 0.7100 time= 0.0226\n",
      "Epoch: 0091 train_loss= 0.9492 train_acc= 0.8500 val_loss= 1.2014 val_acc= 0.7167 time= 0.0244\n",
      "Epoch: 0092 train_loss= 0.9420 train_acc= 0.8500 val_loss= 1.1949 val_acc= 0.7267 time= 0.0249\n",
      "Epoch: 0093 train_loss= 0.9346 train_acc= 0.8500 val_loss= 1.1885 val_acc= 0.7267 time= 0.0182\n",
      "Epoch: 0094 train_loss= 0.9267 train_acc= 0.8571 val_loss= 1.1818 val_acc= 0.7333 time= 0.0228\n",
      "Epoch: 0095 train_loss= 0.9186 train_acc= 0.8643 val_loss= 1.1752 val_acc= 0.7333 time= 0.0185\n",
      "Epoch: 0096 train_loss= 0.9102 train_acc= 0.8643 val_loss= 1.1690 val_acc= 0.7367 time= 0.0183\n",
      "Epoch: 0097 train_loss= 0.9018 train_acc= 0.8643 val_loss= 1.1632 val_acc= 0.7500 time= 0.0207\n",
      "Epoch: 0098 train_loss= 0.8937 train_acc= 0.8714 val_loss= 1.1575 val_acc= 0.7500 time= 0.0238\n",
      "Epoch: 0099 train_loss= 0.8860 train_acc= 0.8786 val_loss= 1.1515 val_acc= 0.7500 time= 0.0221\n",
      "Epoch: 0100 train_loss= 0.8785 train_acc= 0.8786 val_loss= 1.1458 val_acc= 0.7533 time= 0.0182\n",
      "Epoch: 0101 train_loss= 0.8714 train_acc= 0.8786 val_loss= 1.1406 val_acc= 0.7533 time= 0.0238\n",
      "Epoch: 0102 train_loss= 0.8645 train_acc= 0.8786 val_loss= 1.1352 val_acc= 0.7567 time= 0.0241\n",
      "Epoch: 0103 train_loss= 0.8576 train_acc= 0.8786 val_loss= 1.1301 val_acc= 0.7600 time= 0.0222\n",
      "Epoch: 0104 train_loss= 0.8508 train_acc= 0.8786 val_loss= 1.1249 val_acc= 0.7600 time= 0.0197\n",
      "Epoch: 0105 train_loss= 0.8442 train_acc= 0.8786 val_loss= 1.1205 val_acc= 0.7600 time= 0.0189\n",
      "Epoch: 0106 train_loss= 0.8378 train_acc= 0.8786 val_loss= 1.1165 val_acc= 0.7600 time= 0.0186\n",
      "Epoch: 0107 train_loss= 0.8319 train_acc= 0.8786 val_loss= 1.1130 val_acc= 0.7567 time= 0.0235\n",
      "Epoch: 0108 train_loss= 0.8262 train_acc= 0.8857 val_loss= 1.1092 val_acc= 0.7600 time= 0.0194\n",
      "Epoch: 0109 train_loss= 0.8192 train_acc= 0.8857 val_loss= 1.1026 val_acc= 0.7633 time= 0.0244\n",
      "Epoch: 0110 train_loss= 0.8121 train_acc= 0.8857 val_loss= 1.0958 val_acc= 0.7633 time= 0.0280\n",
      "Epoch: 0111 train_loss= 0.8053 train_acc= 0.8857 val_loss= 1.0893 val_acc= 0.7667 time= 0.0190\n",
      "Epoch: 0112 train_loss= 0.7990 train_acc= 0.8857 val_loss= 1.0831 val_acc= 0.7667 time= 0.0300\n",
      "Epoch: 0113 train_loss= 0.7932 train_acc= 0.8857 val_loss= 1.0767 val_acc= 0.7600 time= 0.0188\n",
      "Epoch: 0114 train_loss= 0.7875 train_acc= 0.8857 val_loss= 1.0710 val_acc= 0.7667 time= 0.0229\n",
      "Epoch: 0115 train_loss= 0.7820 train_acc= 0.8857 val_loss= 1.0654 val_acc= 0.7633 time= 0.0191\n",
      "Epoch: 0116 train_loss= 0.7759 train_acc= 0.8857 val_loss= 1.0604 val_acc= 0.7633 time= 0.0180\n",
      "Epoch: 0117 train_loss= 0.7695 train_acc= 0.8857 val_loss= 1.0560 val_acc= 0.7667 time= 0.0190\n",
      "Epoch: 0118 train_loss= 0.7637 train_acc= 0.8929 val_loss= 1.0522 val_acc= 0.7667 time= 0.0238\n",
      "Epoch: 0119 train_loss= 0.7587 train_acc= 0.9000 val_loss= 1.0487 val_acc= 0.7700 time= 0.0234\n",
      "Epoch: 0120 train_loss= 0.7540 train_acc= 0.9000 val_loss= 1.0461 val_acc= 0.7700 time= 0.0230\n",
      "Epoch: 0121 train_loss= 0.7503 train_acc= 0.9143 val_loss= 1.0443 val_acc= 0.7733 time= 0.0190\n",
      "Epoch: 0122 train_loss= 0.7468 train_acc= 0.9143 val_loss= 1.0428 val_acc= 0.7733 time= 0.0236\n",
      "Epoch: 0123 train_loss= 0.7425 train_acc= 0.9143 val_loss= 1.0391 val_acc= 0.7733 time= 0.0182\n",
      "Epoch: 0124 train_loss= 0.7376 train_acc= 0.9143 val_loss= 1.0348 val_acc= 0.7733 time= 0.0186\n",
      "Epoch: 0125 train_loss= 0.7318 train_acc= 0.9143 val_loss= 1.0298 val_acc= 0.7733 time= 0.0190\n",
      "Epoch: 0126 train_loss= 0.7258 train_acc= 0.9143 val_loss= 1.0252 val_acc= 0.7833 time= 0.0226\n",
      "Epoch: 0127 train_loss= 0.7200 train_acc= 0.9214 val_loss= 1.0194 val_acc= 0.7767 time= 0.0199\n",
      "Epoch: 0128 train_loss= 0.7147 train_acc= 0.9214 val_loss= 1.0133 val_acc= 0.7767 time= 0.0271\n",
      "Epoch: 0129 train_loss= 0.7097 train_acc= 0.9286 val_loss= 1.0081 val_acc= 0.7767 time= 0.0234\n",
      "Epoch: 0130 train_loss= 0.7049 train_acc= 0.9286 val_loss= 1.0039 val_acc= 0.7733 time= 0.0196\n",
      "Epoch: 0131 train_loss= 0.6996 train_acc= 0.9286 val_loss= 1.0003 val_acc= 0.7767 time= 0.0192\n",
      "Epoch: 0132 train_loss= 0.6944 train_acc= 0.9286 val_loss= 0.9974 val_acc= 0.7733 time= 0.0196\n",
      "Epoch: 0133 train_loss= 0.6891 train_acc= 0.9357 val_loss= 0.9950 val_acc= 0.7767 time= 0.0234\n",
      "Epoch: 0134 train_loss= 0.6845 train_acc= 0.9357 val_loss= 0.9932 val_acc= 0.7767 time= 0.0287\n",
      "Epoch: 0135 train_loss= 0.6798 train_acc= 0.9357 val_loss= 0.9902 val_acc= 0.7867 time= 0.0190\n",
      "Epoch: 0136 train_loss= 0.6750 train_acc= 0.9357 val_loss= 0.9862 val_acc= 0.7867 time= 0.0238\n",
      "Epoch: 0137 train_loss= 0.6707 train_acc= 0.9357 val_loss= 0.9814 val_acc= 0.7800 time= 0.0246\n",
      "Epoch: 0138 train_loss= 0.6664 train_acc= 0.9357 val_loss= 0.9765 val_acc= 0.7800 time= 0.0237\n",
      "Epoch: 0139 train_loss= 0.6620 train_acc= 0.9357 val_loss= 0.9716 val_acc= 0.7800 time= 0.0235\n",
      "Epoch: 0140 train_loss= 0.6569 train_acc= 0.9357 val_loss= 0.9675 val_acc= 0.7800 time= 0.0240\n",
      "Epoch: 0141 train_loss= 0.6523 train_acc= 0.9357 val_loss= 0.9637 val_acc= 0.7733 time= 0.0235\n",
      "Epoch: 0142 train_loss= 0.6473 train_acc= 0.9357 val_loss= 0.9607 val_acc= 0.7800 time= 0.0229\n",
      "Epoch: 0143 train_loss= 0.6426 train_acc= 0.9357 val_loss= 0.9586 val_acc= 0.7767 time= 0.0236\n",
      "Epoch: 0144 train_loss= 0.6380 train_acc= 0.9357 val_loss= 0.9565 val_acc= 0.7833 time= 0.0220\n",
      "Epoch: 0145 train_loss= 0.6338 train_acc= 0.9357 val_loss= 0.9547 val_acc= 0.7867 time= 0.0222\n",
      "Epoch: 0146 train_loss= 0.6300 train_acc= 0.9357 val_loss= 0.9529 val_acc= 0.7867 time= 0.0235\n",
      "Epoch: 0147 train_loss= 0.6258 train_acc= 0.9357 val_loss= 0.9500 val_acc= 0.7867 time= 0.0239\n",
      "Epoch: 0148 train_loss= 0.6215 train_acc= 0.9357 val_loss= 0.9461 val_acc= 0.7867 time= 0.0283\n",
      "Epoch: 0149 train_loss= 0.6175 train_acc= 0.9357 val_loss= 0.9425 val_acc= 0.7867 time= 0.0227\n",
      "Epoch: 0150 train_loss= 0.6138 train_acc= 0.9357 val_loss= 0.9392 val_acc= 0.7833 time= 0.0248\n",
      "Epoch: 0151 train_loss= 0.6104 train_acc= 0.9357 val_loss= 0.9360 val_acc= 0.7800 time= 0.0236\n",
      "Epoch: 0152 train_loss= 0.6074 train_acc= 0.9357 val_loss= 0.9338 val_acc= 0.7833 time= 0.0227\n",
      "Epoch: 0153 train_loss= 0.6042 train_acc= 0.9357 val_loss= 0.9310 val_acc= 0.7833 time= 0.0195\n",
      "Epoch: 0154 train_loss= 0.6009 train_acc= 0.9357 val_loss= 0.9275 val_acc= 0.7867 time= 0.0235\n",
      "Epoch: 0155 train_loss= 0.5971 train_acc= 0.9357 val_loss= 0.9245 val_acc= 0.7867 time= 0.0242\n",
      "Epoch: 0156 train_loss= 0.5935 train_acc= 0.9357 val_loss= 0.9214 val_acc= 0.7833 time= 0.0234\n",
      "Epoch: 0157 train_loss= 0.5899 train_acc= 0.9357 val_loss= 0.9179 val_acc= 0.7833 time= 0.0242\n",
      "Epoch: 0158 train_loss= 0.5858 train_acc= 0.9357 val_loss= 0.9159 val_acc= 0.7867 time= 0.0190\n",
      "Epoch: 0159 train_loss= 0.5821 train_acc= 0.9357 val_loss= 0.9142 val_acc= 0.7933 time= 0.0231\n",
      "Epoch: 0160 train_loss= 0.5792 train_acc= 0.9429 val_loss= 0.9134 val_acc= 0.7900 time= 0.0278\n",
      "Epoch: 0161 train_loss= 0.5769 train_acc= 0.9429 val_loss= 0.9117 val_acc= 0.7867 time= 0.0193\n",
      "Epoch: 0162 train_loss= 0.5729 train_acc= 0.9429 val_loss= 0.9079 val_acc= 0.7900 time= 0.0296\n",
      "Epoch: 0163 train_loss= 0.5687 train_acc= 0.9357 val_loss= 0.9029 val_acc= 0.7900 time= 0.0238\n",
      "Epoch: 0164 train_loss= 0.5668 train_acc= 0.9357 val_loss= 0.9007 val_acc= 0.7833 time= 0.0224\n",
      "Epoch: 0165 train_loss= 0.5662 train_acc= 0.9357 val_loss= 0.8996 val_acc= 0.7867 time= 0.0237\n",
      "Epoch: 0166 train_loss= 0.5649 train_acc= 0.9286 val_loss= 0.8983 val_acc= 0.7800 time= 0.0186\n",
      "Epoch: 0167 train_loss= 0.5607 train_acc= 0.9286 val_loss= 0.8956 val_acc= 0.7900 time= 0.0241\n",
      "Epoch: 0168 train_loss= 0.5553 train_acc= 0.9357 val_loss= 0.8915 val_acc= 0.7867 time= 0.0191\n",
      "Epoch: 0169 train_loss= 0.5501 train_acc= 0.9357 val_loss= 0.8892 val_acc= 0.7900 time= 0.0194\n",
      "Epoch: 0170 train_loss= 0.5476 train_acc= 0.9429 val_loss= 0.8889 val_acc= 0.7900 time= 0.0187\n",
      "Epoch: 0171 train_loss= 0.5459 train_acc= 0.9500 val_loss= 0.8888 val_acc= 0.7933 time= 0.0254\n",
      "Epoch: 0172 train_loss= 0.5435 train_acc= 0.9500 val_loss= 0.8868 val_acc= 0.7900 time= 0.0275\n",
      "Epoch: 0173 train_loss= 0.5390 train_acc= 0.9571 val_loss= 0.8812 val_acc= 0.7900 time= 0.0235\n",
      "Epoch: 0174 train_loss= 0.5345 train_acc= 0.9571 val_loss= 0.8754 val_acc= 0.7967 time= 0.0184\n",
      "Epoch: 0175 train_loss= 0.5312 train_acc= 0.9571 val_loss= 0.8716 val_acc= 0.8000 time= 0.0282\n",
      "Epoch: 0176 train_loss= 0.5292 train_acc= 0.9571 val_loss= 0.8695 val_acc= 0.8000 time= 0.0187\n",
      "Epoch: 0177 train_loss= 0.5279 train_acc= 0.9571 val_loss= 0.8693 val_acc= 0.7967 time= 0.0232\n",
      "Epoch: 0178 train_loss= 0.5260 train_acc= 0.9500 val_loss= 0.8687 val_acc= 0.7933 time= 0.0191\n",
      "Epoch: 0179 train_loss= 0.5227 train_acc= 0.9429 val_loss= 0.8678 val_acc= 0.7933 time= 0.0227\n",
      "Epoch: 0180 train_loss= 0.5199 train_acc= 0.9357 val_loss= 0.8666 val_acc= 0.7933 time= 0.0286\n",
      "Epoch: 0181 train_loss= 0.5168 train_acc= 0.9357 val_loss= 0.8653 val_acc= 0.7933 time= 0.0189\n",
      "Epoch: 0182 train_loss= 0.5132 train_acc= 0.9429 val_loss= 0.8642 val_acc= 0.8000 time= 0.0230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0183 train_loss= 0.5100 train_acc= 0.9429 val_loss= 0.8622 val_acc= 0.7967 time= 0.0230\n",
      "Epoch: 0184 train_loss= 0.5069 train_acc= 0.9429 val_loss= 0.8596 val_acc= 0.7967 time= 0.0231\n",
      "Epoch: 0185 train_loss= 0.5043 train_acc= 0.9500 val_loss= 0.8560 val_acc= 0.7967 time= 0.0182\n",
      "Epoch: 0186 train_loss= 0.5017 train_acc= 0.9571 val_loss= 0.8515 val_acc= 0.7933 time= 0.0184\n",
      "Epoch: 0187 train_loss= 0.4996 train_acc= 0.9571 val_loss= 0.8474 val_acc= 0.7967 time= 0.0182\n",
      "Epoch: 0188 train_loss= 0.4978 train_acc= 0.9571 val_loss= 0.8444 val_acc= 0.7900 time= 0.0180\n",
      "Epoch: 0189 train_loss= 0.4956 train_acc= 0.9571 val_loss= 0.8421 val_acc= 0.7900 time= 0.0180\n",
      "Epoch: 0190 train_loss= 0.4931 train_acc= 0.9571 val_loss= 0.8405 val_acc= 0.7967 time= 0.0178\n",
      "Epoch: 0191 train_loss= 0.4903 train_acc= 0.9571 val_loss= 0.8404 val_acc= 0.8033 time= 0.0181\n",
      "Epoch: 0192 train_loss= 0.4884 train_acc= 0.9571 val_loss= 0.8419 val_acc= 0.8167 time= 0.0194\n",
      "Epoch: 0193 train_loss= 0.4865 train_acc= 0.9571 val_loss= 0.8428 val_acc= 0.8167 time= 0.0189\n",
      "Epoch: 0194 train_loss= 0.4845 train_acc= 0.9571 val_loss= 0.8436 val_acc= 0.8067 time= 0.0186\n",
      "Epoch: 0195 train_loss= 0.4817 train_acc= 0.9571 val_loss= 0.8423 val_acc= 0.8067 time= 0.0204\n",
      "Epoch: 0196 train_loss= 0.4783 train_acc= 0.9571 val_loss= 0.8388 val_acc= 0.8000 time= 0.0229\n",
      "Epoch: 0197 train_loss= 0.4752 train_acc= 0.9571 val_loss= 0.8343 val_acc= 0.7967 time= 0.0244\n",
      "Epoch: 0198 train_loss= 0.4728 train_acc= 0.9571 val_loss= 0.8304 val_acc= 0.7933 time= 0.0237\n",
      "Epoch: 0199 train_loss= 0.4710 train_acc= 0.9571 val_loss= 0.8276 val_acc= 0.7967 time= 0.0183\n",
      "Epoch: 0200 train_loss= 0.4694 train_acc= 0.9571 val_loss= 0.8253 val_acc= 0.7900 time= 0.0247\n"
     ]
    }
   ],
   "source": [
    "NB_EPOCH = 200\n",
    "PATIENCE = 10  # early stopping patience\n",
    "# Helper variables for main training loop\n",
    "wait = 0\n",
    "preds = None\n",
    "best_val_loss = 99999\n",
    "\n",
    "# Fit\n",
    "for epoch in range(1, NB_EPOCH+1):\n",
    "\n",
    "    # Log wall-clock time\n",
    "    t = time.time()\n",
    "\n",
    "    # Single training iteration (we mask nodes without labels for loss calculation)\n",
    "    model.fit(graph, y_train, sample_weight=train_mask,\n",
    "              batch_size=A.shape[0], epochs=1, shuffle=False, verbose=0)\n",
    "\n",
    "    # Predict on full dataset\n",
    "    preds = model.predict(graph, batch_size=A.shape[0])\n",
    "\n",
    "    # Train / validation scores\n",
    "    train_val_loss, train_val_acc = evaluate_preds(preds, [y_train, y_val],\n",
    "                                                   [idx_train, idx_val])\n",
    "    print(\"Epoch: {:04d}\".format(epoch),\n",
    "          \"train_loss= {:.4f}\".format(train_val_loss[0]),\n",
    "          \"train_acc= {:.4f}\".format(train_val_acc[0]),\n",
    "          \"val_loss= {:.4f}\".format(train_val_loss[1]),\n",
    "          \"val_acc= {:.4f}\".format(train_val_acc[1]),\n",
    "          \"time= {:.4f}\".format(time.time() - t))\n",
    "\n",
    "    # Early stopping\n",
    "    if train_val_loss[1] < best_val_loss:\n",
    "        best_val_loss = train_val_loss[1]\n",
    "        wait = 0\n",
    "    else:\n",
    "        if wait >= PATIENCE:\n",
    "            print('Epoch {}: early stopping'.format(epoch))\n",
    "            break\n",
    "        wait += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.8801\n",
      "accuracy = 0.7990\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate_preds(preds, [y_test], [idx_test])\n",
    "print(f\"\"\"\n",
    "loss = {test_loss[0]:.4f}\n",
    "accuracy = {test_acc[0]:.4f}\n",
    "\"\"\".strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Graph Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = Dropout(0.5)(X_in)\n",
    "H = GaussianGraphConvolution(16, A.shape[0], True, activation='relu', kernel_regularizer=l2(5e-4))([H]+G)\n",
    "H = Dropout(0.5)(H)\n",
    "Y = GaussianGraphConvolution(y.shape[1], A.shape[0], False, activation='softmax')([H]+G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[X_in]+G, outputs=Y)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 train_loss= 1.9402 train_acc= 0.2857 val_loss= 1.9424 val_acc= 0.1733 time= 0.3353\n",
      "Epoch: 0002 train_loss= 1.9337 train_acc= 0.4000 val_loss= 1.9376 val_acc= 0.2567 time= 0.0192\n",
      "Epoch: 0003 train_loss= 1.9261 train_acc= 0.4643 val_loss= 1.9318 val_acc= 0.3333 time= 0.0184\n",
      "Epoch: 0004 train_loss= 1.9175 train_acc= 0.4786 val_loss= 1.9253 val_acc= 0.3733 time= 0.0236\n",
      "Epoch: 0005 train_loss= 1.9080 train_acc= 0.4786 val_loss= 1.9182 val_acc= 0.3867 time= 0.0227\n",
      "Epoch: 0006 train_loss= 1.8978 train_acc= 0.4714 val_loss= 1.9106 val_acc= 0.3767 time= 0.0238\n",
      "Epoch: 0007 train_loss= 1.8869 train_acc= 0.4714 val_loss= 1.9025 val_acc= 0.3767 time= 0.0185\n",
      "Epoch: 0008 train_loss= 1.8755 train_acc= 0.4714 val_loss= 1.8941 val_acc= 0.3800 time= 0.0236\n",
      "Epoch: 0009 train_loss= 1.8637 train_acc= 0.4857 val_loss= 1.8854 val_acc= 0.3767 time= 0.0188\n",
      "Epoch: 0010 train_loss= 1.8515 train_acc= 0.4857 val_loss= 1.8765 val_acc= 0.3733 time= 0.0184\n",
      "Epoch: 0011 train_loss= 1.8389 train_acc= 0.4857 val_loss= 1.8672 val_acc= 0.3733 time= 0.0192\n",
      "Epoch: 0012 train_loss= 1.8258 train_acc= 0.4786 val_loss= 1.8576 val_acc= 0.3733 time= 0.0200\n",
      "Epoch: 0013 train_loss= 1.8123 train_acc= 0.4786 val_loss= 1.8477 val_acc= 0.3700 time= 0.0184\n",
      "Epoch: 0014 train_loss= 1.7986 train_acc= 0.4714 val_loss= 1.8375 val_acc= 0.3733 time= 0.0192\n",
      "Epoch: 0015 train_loss= 1.7847 train_acc= 0.4643 val_loss= 1.8272 val_acc= 0.3700 time= 0.0279\n",
      "Epoch: 0016 train_loss= 1.7705 train_acc= 0.4643 val_loss= 1.8168 val_acc= 0.3733 time= 0.0183\n",
      "Epoch: 0017 train_loss= 1.7562 train_acc= 0.4643 val_loss= 1.8063 val_acc= 0.3700 time= 0.0280\n",
      "Epoch: 0018 train_loss= 1.7417 train_acc= 0.4643 val_loss= 1.7956 val_acc= 0.3733 time= 0.0236\n",
      "Epoch: 0019 train_loss= 1.7270 train_acc= 0.4643 val_loss= 1.7847 val_acc= 0.3733 time= 0.0282\n",
      "Epoch: 0020 train_loss= 1.7122 train_acc= 0.4714 val_loss= 1.7739 val_acc= 0.3767 time= 0.0230\n",
      "Epoch: 0021 train_loss= 1.6974 train_acc= 0.4714 val_loss= 1.7630 val_acc= 0.3700 time= 0.0254\n",
      "Epoch: 0022 train_loss= 1.6825 train_acc= 0.4714 val_loss= 1.7521 val_acc= 0.3767 time= 0.0190\n",
      "Epoch: 0023 train_loss= 1.6676 train_acc= 0.5000 val_loss= 1.7413 val_acc= 0.3800 time= 0.0232\n",
      "Epoch: 0024 train_loss= 1.6529 train_acc= 0.5071 val_loss= 1.7304 val_acc= 0.3900 time= 0.0221\n",
      "Epoch: 0025 train_loss= 1.6382 train_acc= 0.5143 val_loss= 1.7197 val_acc= 0.4033 time= 0.0190\n",
      "Epoch: 0026 train_loss= 1.6236 train_acc= 0.5143 val_loss= 1.7090 val_acc= 0.4100 time= 0.0225\n",
      "Epoch: 0027 train_loss= 1.6090 train_acc= 0.5286 val_loss= 1.6982 val_acc= 0.4100 time= 0.0186\n",
      "Epoch: 0028 train_loss= 1.5945 train_acc= 0.5429 val_loss= 1.6874 val_acc= 0.4233 time= 0.0237\n",
      "Epoch: 0029 train_loss= 1.5801 train_acc= 0.5571 val_loss= 1.6767 val_acc= 0.4300 time= 0.0222\n",
      "Epoch: 0030 train_loss= 1.5660 train_acc= 0.5786 val_loss= 1.6661 val_acc= 0.4367 time= 0.0299\n",
      "Epoch: 0031 train_loss= 1.5520 train_acc= 0.5929 val_loss= 1.6556 val_acc= 0.4433 time= 0.0278\n",
      "Epoch: 0032 train_loss= 1.5383 train_acc= 0.6000 val_loss= 1.6452 val_acc= 0.4500 time= 0.0268\n",
      "Epoch: 0033 train_loss= 1.5247 train_acc= 0.6214 val_loss= 1.6350 val_acc= 0.4867 time= 0.0177\n",
      "Epoch: 0034 train_loss= 1.5114 train_acc= 0.6500 val_loss= 1.6250 val_acc= 0.5000 time= 0.0227\n",
      "Epoch: 0035 train_loss= 1.4982 train_acc= 0.6786 val_loss= 1.6152 val_acc= 0.5167 time= 0.0177\n",
      "Epoch: 0036 train_loss= 1.4852 train_acc= 0.6786 val_loss= 1.6055 val_acc= 0.5367 time= 0.0178\n",
      "Epoch: 0037 train_loss= 1.4725 train_acc= 0.6857 val_loss= 1.5960 val_acc= 0.5567 time= 0.0278\n",
      "Epoch: 0038 train_loss= 1.4600 train_acc= 0.7286 val_loss= 1.5868 val_acc= 0.5567 time= 0.0231\n",
      "Epoch: 0039 train_loss= 1.4477 train_acc= 0.7357 val_loss= 1.5776 val_acc= 0.5700 time= 0.0233\n",
      "Epoch: 0040 train_loss= 1.4356 train_acc= 0.7429 val_loss= 1.5685 val_acc= 0.5733 time= 0.0255\n",
      "Epoch: 0041 train_loss= 1.4235 train_acc= 0.7643 val_loss= 1.5595 val_acc= 0.6000 time= 0.0263\n",
      "Epoch: 0042 train_loss= 1.4117 train_acc= 0.7786 val_loss= 1.5505 val_acc= 0.6200 time= 0.0196\n",
      "Epoch: 0043 train_loss= 1.4001 train_acc= 0.7857 val_loss= 1.5417 val_acc= 0.6267 time= 0.0216\n",
      "Epoch: 0044 train_loss= 1.3886 train_acc= 0.8000 val_loss= 1.5329 val_acc= 0.6433 time= 0.0238\n",
      "Epoch: 0045 train_loss= 1.3772 train_acc= 0.8071 val_loss= 1.5240 val_acc= 0.6533 time= 0.0236\n",
      "Epoch: 0046 train_loss= 1.3658 train_acc= 0.8071 val_loss= 1.5151 val_acc= 0.6633 time= 0.0232\n",
      "Epoch: 0047 train_loss= 1.3545 train_acc= 0.8071 val_loss= 1.5063 val_acc= 0.6633 time= 0.0286\n",
      "Epoch: 0048 train_loss= 1.3432 train_acc= 0.8214 val_loss= 1.4976 val_acc= 0.6667 time= 0.0207\n",
      "Epoch: 0049 train_loss= 1.3320 train_acc= 0.8143 val_loss= 1.4889 val_acc= 0.6767 time= 0.0232\n",
      "Epoch: 0050 train_loss= 1.3210 train_acc= 0.8214 val_loss= 1.4803 val_acc= 0.6800 time= 0.0186\n",
      "Epoch: 0051 train_loss= 1.3102 train_acc= 0.8214 val_loss= 1.4716 val_acc= 0.6833 time= 0.0282\n",
      "Epoch: 0052 train_loss= 1.2994 train_acc= 0.8429 val_loss= 1.4630 val_acc= 0.6833 time= 0.0182\n",
      "Epoch: 0053 train_loss= 1.2887 train_acc= 0.8429 val_loss= 1.4545 val_acc= 0.6900 time= 0.0193\n",
      "Epoch: 0054 train_loss= 1.2781 train_acc= 0.8429 val_loss= 1.4461 val_acc= 0.6933 time= 0.0273\n",
      "Epoch: 0055 train_loss= 1.2676 train_acc= 0.8500 val_loss= 1.4376 val_acc= 0.7000 time= 0.0187\n",
      "Epoch: 0056 train_loss= 1.2572 train_acc= 0.8571 val_loss= 1.4293 val_acc= 0.7067 time= 0.0187\n",
      "Epoch: 0057 train_loss= 1.2468 train_acc= 0.8571 val_loss= 1.4209 val_acc= 0.7133 time= 0.0232\n",
      "Epoch: 0058 train_loss= 1.2365 train_acc= 0.8571 val_loss= 1.4125 val_acc= 0.7167 time= 0.0184\n",
      "Epoch: 0059 train_loss= 1.2262 train_acc= 0.8571 val_loss= 1.4043 val_acc= 0.7167 time= 0.0190\n",
      "Epoch: 0060 train_loss= 1.2159 train_acc= 0.8571 val_loss= 1.3960 val_acc= 0.7200 time= 0.0191\n",
      "Epoch: 0061 train_loss= 1.2058 train_acc= 0.8571 val_loss= 1.3879 val_acc= 0.7233 time= 0.0271\n",
      "Epoch: 0062 train_loss= 1.1957 train_acc= 0.8500 val_loss= 1.3800 val_acc= 0.7300 time= 0.0242\n",
      "Epoch: 0063 train_loss= 1.1857 train_acc= 0.8500 val_loss= 1.3722 val_acc= 0.7300 time= 0.0181\n",
      "Epoch: 0064 train_loss= 1.1757 train_acc= 0.8500 val_loss= 1.3644 val_acc= 0.7367 time= 0.0183\n",
      "Epoch: 0065 train_loss= 1.1657 train_acc= 0.8429 val_loss= 1.3564 val_acc= 0.7367 time= 0.0189\n",
      "Epoch: 0066 train_loss= 1.1558 train_acc= 0.8429 val_loss= 1.3486 val_acc= 0.7367 time= 0.0276\n",
      "Epoch: 0067 train_loss= 1.1461 train_acc= 0.8429 val_loss= 1.3411 val_acc= 0.7367 time= 0.0270\n",
      "Epoch: 0068 train_loss= 1.1364 train_acc= 0.8429 val_loss= 1.3337 val_acc= 0.7367 time= 0.0212\n",
      "Epoch: 0069 train_loss= 1.1269 train_acc= 0.8429 val_loss= 1.3263 val_acc= 0.7400 time= 0.0242\n",
      "Epoch: 0070 train_loss= 1.1175 train_acc= 0.8429 val_loss= 1.3190 val_acc= 0.7400 time= 0.0233\n",
      "Epoch: 0071 train_loss= 1.1081 train_acc= 0.8500 val_loss= 1.3118 val_acc= 0.7500 time= 0.0183\n",
      "Epoch: 0072 train_loss= 1.0986 train_acc= 0.8500 val_loss= 1.3044 val_acc= 0.7500 time= 0.0232\n",
      "Epoch: 0073 train_loss= 1.0892 train_acc= 0.8500 val_loss= 1.2970 val_acc= 0.7500 time= 0.0226\n",
      "Epoch: 0074 train_loss= 1.0799 train_acc= 0.8500 val_loss= 1.2898 val_acc= 0.7500 time= 0.0183\n",
      "Epoch: 0075 train_loss= 1.0707 train_acc= 0.8571 val_loss= 1.2827 val_acc= 0.7533 time= 0.0182\n",
      "Epoch: 0076 train_loss= 1.0616 train_acc= 0.8643 val_loss= 1.2761 val_acc= 0.7567 time= 0.0182\n",
      "Epoch: 0077 train_loss= 1.0528 train_acc= 0.8643 val_loss= 1.2697 val_acc= 0.7567 time= 0.0185\n",
      "Epoch: 0078 train_loss= 1.0441 train_acc= 0.8643 val_loss= 1.2634 val_acc= 0.7567 time= 0.0248\n",
      "Epoch: 0079 train_loss= 1.0354 train_acc= 0.8643 val_loss= 1.2568 val_acc= 0.7600 time= 0.0233\n",
      "Epoch: 0080 train_loss= 1.0267 train_acc= 0.8643 val_loss= 1.2504 val_acc= 0.7600 time= 0.0243\n",
      "Epoch: 0081 train_loss= 1.0181 train_acc= 0.8643 val_loss= 1.2438 val_acc= 0.7633 time= 0.0200\n",
      "Epoch: 0082 train_loss= 1.0096 train_acc= 0.8643 val_loss= 1.2373 val_acc= 0.7633 time= 0.0287\n",
      "Epoch: 0083 train_loss= 1.0011 train_acc= 0.8643 val_loss= 1.2306 val_acc= 0.7633 time= 0.0187\n",
      "Epoch: 0084 train_loss= 0.9928 train_acc= 0.8643 val_loss= 1.2241 val_acc= 0.7600 time= 0.0186\n",
      "Epoch: 0085 train_loss= 0.9845 train_acc= 0.8643 val_loss= 1.2176 val_acc= 0.7600 time= 0.0181\n",
      "Epoch: 0086 train_loss= 0.9763 train_acc= 0.8643 val_loss= 1.2108 val_acc= 0.7600 time= 0.0236\n",
      "Epoch: 0087 train_loss= 0.9680 train_acc= 0.8643 val_loss= 1.2039 val_acc= 0.7633 time= 0.0214\n",
      "Epoch: 0088 train_loss= 0.9598 train_acc= 0.8786 val_loss= 1.1972 val_acc= 0.7633 time= 0.0229\n",
      "Epoch: 0089 train_loss= 0.9519 train_acc= 0.8786 val_loss= 1.1906 val_acc= 0.7633 time= 0.0227\n",
      "Epoch: 0090 train_loss= 0.9439 train_acc= 0.8786 val_loss= 1.1840 val_acc= 0.7667 time= 0.0240\n",
      "Epoch: 0091 train_loss= 0.9358 train_acc= 0.8786 val_loss= 1.1775 val_acc= 0.7700 time= 0.0247\n",
      "Epoch: 0092 train_loss= 0.9280 train_acc= 0.8786 val_loss= 1.1711 val_acc= 0.7700 time= 0.0237\n",
      "Epoch: 0093 train_loss= 0.9202 train_acc= 0.8786 val_loss= 1.1647 val_acc= 0.7733 time= 0.0201\n",
      "Epoch: 0094 train_loss= 0.9125 train_acc= 0.8786 val_loss= 1.1584 val_acc= 0.7733 time= 0.0284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0095 train_loss= 0.9048 train_acc= 0.8786 val_loss= 1.1521 val_acc= 0.7733 time= 0.0198\n",
      "Epoch: 0096 train_loss= 0.8973 train_acc= 0.8786 val_loss= 1.1460 val_acc= 0.7733 time= 0.0226\n",
      "Epoch: 0097 train_loss= 0.8898 train_acc= 0.8786 val_loss= 1.1396 val_acc= 0.7767 time= 0.0199\n",
      "Epoch: 0098 train_loss= 0.8824 train_acc= 0.8786 val_loss= 1.1333 val_acc= 0.7767 time= 0.0229\n",
      "Epoch: 0099 train_loss= 0.8751 train_acc= 0.8857 val_loss= 1.1272 val_acc= 0.7767 time= 0.0184\n",
      "Epoch: 0100 train_loss= 0.8678 train_acc= 0.8857 val_loss= 1.1212 val_acc= 0.7767 time= 0.0195\n",
      "Epoch: 0101 train_loss= 0.8605 train_acc= 0.8857 val_loss= 1.1155 val_acc= 0.7800 time= 0.0227\n",
      "Epoch: 0102 train_loss= 0.8532 train_acc= 0.8786 val_loss= 1.1098 val_acc= 0.7800 time= 0.0189\n",
      "Epoch: 0103 train_loss= 0.8461 train_acc= 0.8786 val_loss= 1.1041 val_acc= 0.7800 time= 0.0191\n",
      "Epoch: 0104 train_loss= 0.8390 train_acc= 0.8786 val_loss= 1.0984 val_acc= 0.7800 time= 0.0242\n",
      "Epoch: 0105 train_loss= 0.8321 train_acc= 0.8786 val_loss= 1.0928 val_acc= 0.7800 time= 0.0229\n",
      "Epoch: 0106 train_loss= 0.8252 train_acc= 0.8786 val_loss= 1.0873 val_acc= 0.7767 time= 0.0226\n",
      "Epoch: 0107 train_loss= 0.8184 train_acc= 0.8786 val_loss= 1.0820 val_acc= 0.7800 time= 0.0197\n",
      "Epoch: 0108 train_loss= 0.8116 train_acc= 0.8786 val_loss= 1.0770 val_acc= 0.7800 time= 0.0270\n",
      "Epoch: 0109 train_loss= 0.8050 train_acc= 0.8857 val_loss= 1.0722 val_acc= 0.7833 time= 0.0234\n",
      "Epoch: 0110 train_loss= 0.7984 train_acc= 0.8857 val_loss= 1.0674 val_acc= 0.7833 time= 0.0228\n",
      "Epoch: 0111 train_loss= 0.7918 train_acc= 0.8929 val_loss= 1.0627 val_acc= 0.7800 time= 0.0177\n",
      "Epoch: 0112 train_loss= 0.7854 train_acc= 0.8857 val_loss= 1.0584 val_acc= 0.7767 time= 0.0191\n",
      "Epoch: 0113 train_loss= 0.7791 train_acc= 0.9000 val_loss= 1.0544 val_acc= 0.7800 time= 0.0269\n",
      "Epoch: 0114 train_loss= 0.7731 train_acc= 0.9000 val_loss= 1.0506 val_acc= 0.7767 time= 0.0187\n",
      "Epoch: 0115 train_loss= 0.7672 train_acc= 0.9000 val_loss= 1.0465 val_acc= 0.7767 time= 0.0199\n",
      "Epoch: 0116 train_loss= 0.7613 train_acc= 0.9071 val_loss= 1.0419 val_acc= 0.7767 time= 0.0288\n",
      "Epoch: 0117 train_loss= 0.7555 train_acc= 0.9071 val_loss= 1.0371 val_acc= 0.7800 time= 0.0231\n",
      "Epoch: 0118 train_loss= 0.7497 train_acc= 0.9071 val_loss= 1.0323 val_acc= 0.7800 time= 0.0230\n",
      "Epoch: 0119 train_loss= 0.7439 train_acc= 0.9071 val_loss= 1.0270 val_acc= 0.7800 time= 0.0184\n",
      "Epoch: 0120 train_loss= 0.7379 train_acc= 0.9071 val_loss= 1.0213 val_acc= 0.7833 time= 0.0239\n",
      "Epoch: 0121 train_loss= 0.7322 train_acc= 0.9071 val_loss= 1.0157 val_acc= 0.7867 time= 0.0222\n",
      "Epoch: 0122 train_loss= 0.7266 train_acc= 0.9143 val_loss= 1.0104 val_acc= 0.7867 time= 0.0279\n",
      "Epoch: 0123 train_loss= 0.7211 train_acc= 0.9143 val_loss= 1.0054 val_acc= 0.7900 time= 0.0226\n",
      "Epoch: 0124 train_loss= 0.7156 train_acc= 0.9214 val_loss= 1.0004 val_acc= 0.7900 time= 0.0244\n",
      "Epoch: 0125 train_loss= 0.7102 train_acc= 0.9214 val_loss= 0.9956 val_acc= 0.7900 time= 0.0229\n",
      "Epoch: 0126 train_loss= 0.7050 train_acc= 0.9214 val_loss= 0.9909 val_acc= 0.7900 time= 0.0186\n",
      "Epoch: 0127 train_loss= 0.6999 train_acc= 0.9214 val_loss= 0.9864 val_acc= 0.7900 time= 0.0229\n",
      "Epoch: 0128 train_loss= 0.6947 train_acc= 0.9214 val_loss= 0.9821 val_acc= 0.7900 time= 0.0239\n",
      "Epoch: 0129 train_loss= 0.6895 train_acc= 0.9214 val_loss= 0.9781 val_acc= 0.7900 time= 0.0244\n",
      "Epoch: 0130 train_loss= 0.6844 train_acc= 0.9214 val_loss= 0.9739 val_acc= 0.7900 time= 0.0228\n",
      "Epoch: 0131 train_loss= 0.6795 train_acc= 0.9214 val_loss= 0.9700 val_acc= 0.7900 time= 0.0182\n",
      "Epoch: 0132 train_loss= 0.6745 train_acc= 0.9214 val_loss= 0.9663 val_acc= 0.7900 time= 0.0191\n",
      "Epoch: 0133 train_loss= 0.6697 train_acc= 0.9214 val_loss= 0.9627 val_acc= 0.7900 time= 0.0191\n",
      "Epoch: 0134 train_loss= 0.6648 train_acc= 0.9214 val_loss= 0.9594 val_acc= 0.7867 time= 0.0188\n",
      "Epoch: 0135 train_loss= 0.6602 train_acc= 0.9214 val_loss= 0.9564 val_acc= 0.7867 time= 0.0232\n",
      "Epoch: 0136 train_loss= 0.6556 train_acc= 0.9214 val_loss= 0.9529 val_acc= 0.7867 time= 0.0183\n",
      "Epoch: 0137 train_loss= 0.6510 train_acc= 0.9214 val_loss= 0.9497 val_acc= 0.7867 time= 0.0180\n",
      "Epoch: 0138 train_loss= 0.6465 train_acc= 0.9214 val_loss= 0.9469 val_acc= 0.7867 time= 0.0248\n",
      "Epoch: 0139 train_loss= 0.6421 train_acc= 0.9214 val_loss= 0.9443 val_acc= 0.7867 time= 0.0278\n",
      "Epoch: 0140 train_loss= 0.6379 train_acc= 0.9214 val_loss= 0.9414 val_acc= 0.7867 time= 0.0187\n",
      "Epoch: 0141 train_loss= 0.6337 train_acc= 0.9214 val_loss= 0.9382 val_acc= 0.7867 time= 0.0196\n",
      "Epoch: 0142 train_loss= 0.6297 train_acc= 0.9214 val_loss= 0.9350 val_acc= 0.7867 time= 0.0195\n",
      "Epoch: 0143 train_loss= 0.6257 train_acc= 0.9214 val_loss= 0.9316 val_acc= 0.7867 time= 0.0188\n",
      "Epoch: 0144 train_loss= 0.6218 train_acc= 0.9214 val_loss= 0.9283 val_acc= 0.7867 time= 0.0228\n",
      "Epoch: 0145 train_loss= 0.6179 train_acc= 0.9214 val_loss= 0.9247 val_acc= 0.7867 time= 0.0190\n",
      "Epoch: 0146 train_loss= 0.6140 train_acc= 0.9214 val_loss= 0.9213 val_acc= 0.7833 time= 0.0191\n",
      "Epoch: 0147 train_loss= 0.6102 train_acc= 0.9214 val_loss= 0.9182 val_acc= 0.7833 time= 0.0234\n",
      "Epoch: 0148 train_loss= 0.6063 train_acc= 0.9214 val_loss= 0.9150 val_acc= 0.7867 time= 0.0244\n",
      "Epoch: 0149 train_loss= 0.6025 train_acc= 0.9214 val_loss= 0.9115 val_acc= 0.7900 time= 0.0229\n",
      "Epoch: 0150 train_loss= 0.5988 train_acc= 0.9214 val_loss= 0.9081 val_acc= 0.7900 time= 0.0184\n",
      "Epoch: 0151 train_loss= 0.5953 train_acc= 0.9214 val_loss= 0.9048 val_acc= 0.7900 time= 0.0233\n",
      "Epoch: 0152 train_loss= 0.5918 train_acc= 0.9214 val_loss= 0.9018 val_acc= 0.7900 time= 0.0191\n",
      "Epoch: 0153 train_loss= 0.5883 train_acc= 0.9214 val_loss= 0.8991 val_acc= 0.7900 time= 0.0192\n",
      "Epoch: 0154 train_loss= 0.5847 train_acc= 0.9214 val_loss= 0.8965 val_acc= 0.7900 time= 0.0229\n",
      "Epoch: 0155 train_loss= 0.5813 train_acc= 0.9214 val_loss= 0.8939 val_acc= 0.7900 time= 0.0202\n",
      "Epoch: 0156 train_loss= 0.5778 train_acc= 0.9214 val_loss= 0.8916 val_acc= 0.7900 time= 0.0192\n",
      "Epoch: 0157 train_loss= 0.5744 train_acc= 0.9214 val_loss= 0.8899 val_acc= 0.7900 time= 0.0185\n",
      "Epoch: 0158 train_loss= 0.5712 train_acc= 0.9214 val_loss= 0.8886 val_acc= 0.7867 time= 0.0190\n",
      "Epoch: 0159 train_loss= 0.5681 train_acc= 0.9214 val_loss= 0.8872 val_acc= 0.7867 time= 0.0243\n",
      "Epoch: 0160 train_loss= 0.5650 train_acc= 0.9214 val_loss= 0.8853 val_acc= 0.7867 time= 0.0201\n",
      "Epoch: 0161 train_loss= 0.5619 train_acc= 0.9214 val_loss= 0.8836 val_acc= 0.7833 time= 0.0245\n",
      "Epoch: 0162 train_loss= 0.5589 train_acc= 0.9214 val_loss= 0.8818 val_acc= 0.7833 time= 0.0229\n",
      "Epoch: 0163 train_loss= 0.5560 train_acc= 0.9214 val_loss= 0.8794 val_acc= 0.7833 time= 0.0228\n",
      "Epoch: 0164 train_loss= 0.5531 train_acc= 0.9214 val_loss= 0.8771 val_acc= 0.7833 time= 0.0185\n",
      "Epoch: 0165 train_loss= 0.5502 train_acc= 0.9214 val_loss= 0.8744 val_acc= 0.7833 time= 0.0227\n",
      "Epoch: 0166 train_loss= 0.5473 train_acc= 0.9214 val_loss= 0.8717 val_acc= 0.7900 time= 0.0182\n",
      "Epoch: 0167 train_loss= 0.5443 train_acc= 0.9286 val_loss= 0.8688 val_acc= 0.7900 time= 0.0249\n",
      "Epoch: 0168 train_loss= 0.5414 train_acc= 0.9286 val_loss= 0.8660 val_acc= 0.7933 time= 0.0192\n",
      "Epoch: 0169 train_loss= 0.5385 train_acc= 0.9286 val_loss= 0.8632 val_acc= 0.7933 time= 0.0200\n",
      "Epoch: 0170 train_loss= 0.5358 train_acc= 0.9286 val_loss= 0.8603 val_acc= 0.7933 time= 0.0411\n",
      "Epoch: 0171 train_loss= 0.5331 train_acc= 0.9286 val_loss= 0.8576 val_acc= 0.7933 time= 0.0230\n",
      "Epoch: 0172 train_loss= 0.5304 train_acc= 0.9286 val_loss= 0.8550 val_acc= 0.7933 time= 0.0256\n",
      "Epoch: 0173 train_loss= 0.5276 train_acc= 0.9286 val_loss= 0.8528 val_acc= 0.7933 time= 0.0197\n",
      "Epoch: 0174 train_loss= 0.5248 train_acc= 0.9357 val_loss= 0.8509 val_acc= 0.7933 time= 0.0183\n",
      "Epoch: 0175 train_loss= 0.5219 train_acc= 0.9357 val_loss= 0.8493 val_acc= 0.7933 time= 0.0188\n",
      "Epoch: 0176 train_loss= 0.5190 train_acc= 0.9357 val_loss= 0.8477 val_acc= 0.7933 time= 0.0194\n",
      "Epoch: 0177 train_loss= 0.5161 train_acc= 0.9357 val_loss= 0.8462 val_acc= 0.7933 time= 0.0227\n",
      "Epoch: 0178 train_loss= 0.5133 train_acc= 0.9357 val_loss= 0.8453 val_acc= 0.7933 time= 0.0234\n",
      "Epoch: 0179 train_loss= 0.5105 train_acc= 0.9357 val_loss= 0.8444 val_acc= 0.7900 time= 0.0185\n",
      "Epoch: 0180 train_loss= 0.5081 train_acc= 0.9357 val_loss= 0.8442 val_acc= 0.7833 time= 0.0184\n",
      "Epoch: 0181 train_loss= 0.5057 train_acc= 0.9357 val_loss= 0.8437 val_acc= 0.7833 time= 0.0232\n",
      "Epoch: 0182 train_loss= 0.5033 train_acc= 0.9357 val_loss= 0.8427 val_acc= 0.7833 time= 0.0196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0183 train_loss= 0.5010 train_acc= 0.9357 val_loss= 0.8416 val_acc= 0.7800 time= 0.0231\n",
      "Epoch: 0184 train_loss= 0.4987 train_acc= 0.9357 val_loss= 0.8404 val_acc= 0.7800 time= 0.0194\n",
      "Epoch: 0185 train_loss= 0.4963 train_acc= 0.9357 val_loss= 0.8387 val_acc= 0.7800 time= 0.0200\n",
      "Epoch: 0186 train_loss= 0.4938 train_acc= 0.9357 val_loss= 0.8366 val_acc= 0.7800 time= 0.0280\n",
      "Epoch: 0187 train_loss= 0.4912 train_acc= 0.9357 val_loss= 0.8341 val_acc= 0.7833 time= 0.0193\n",
      "Epoch: 0188 train_loss= 0.4886 train_acc= 0.9429 val_loss= 0.8315 val_acc= 0.7833 time= 0.0188\n",
      "Epoch: 0189 train_loss= 0.4861 train_acc= 0.9429 val_loss= 0.8291 val_acc= 0.7867 time= 0.0185\n",
      "Epoch: 0190 train_loss= 0.4836 train_acc= 0.9429 val_loss= 0.8264 val_acc= 0.7867 time= 0.0189\n",
      "Epoch: 0191 train_loss= 0.4812 train_acc= 0.9429 val_loss= 0.8235 val_acc= 0.7867 time= 0.0246\n",
      "Epoch: 0192 train_loss= 0.4788 train_acc= 0.9429 val_loss= 0.8211 val_acc= 0.7867 time= 0.0226\n",
      "Epoch: 0193 train_loss= 0.4766 train_acc= 0.9429 val_loss= 0.8186 val_acc= 0.7867 time= 0.0195\n",
      "Epoch: 0194 train_loss= 0.4745 train_acc= 0.9429 val_loss= 0.8163 val_acc= 0.7867 time= 0.0194\n",
      "Epoch: 0195 train_loss= 0.4724 train_acc= 0.9429 val_loss= 0.8141 val_acc= 0.7900 time= 0.0184\n",
      "Epoch: 0196 train_loss= 0.4704 train_acc= 0.9429 val_loss= 0.8126 val_acc= 0.7900 time= 0.0191\n",
      "Epoch: 0197 train_loss= 0.4683 train_acc= 0.9429 val_loss= 0.8109 val_acc= 0.7900 time= 0.0205\n",
      "Epoch: 0198 train_loss= 0.4664 train_acc= 0.9429 val_loss= 0.8093 val_acc= 0.7900 time= 0.0194\n",
      "Epoch: 0199 train_loss= 0.4645 train_acc= 0.9429 val_loss= 0.8081 val_acc= 0.7900 time= 0.0231\n",
      "Epoch: 0200 train_loss= 0.4627 train_acc= 0.9429 val_loss= 0.8072 val_acc= 0.7900 time= 0.0231\n"
     ]
    }
   ],
   "source": [
    "NB_EPOCH = 200\n",
    "PATIENCE = 10  # early stopping patience\n",
    "# Helper variables for main training loop\n",
    "wait = 0\n",
    "preds = None\n",
    "best_val_loss = 99999\n",
    "\n",
    "# Fit\n",
    "for epoch in range(1, NB_EPOCH+1):\n",
    "\n",
    "    # Log wall-clock time\n",
    "    t = time.time()\n",
    "\n",
    "    # Single training iteration (we mask nodes without labels for loss calculation)\n",
    "    model.fit(graph, y_train, sample_weight=train_mask,\n",
    "              batch_size=A.shape[0], epochs=1, shuffle=False, verbose=0)\n",
    "\n",
    "    # Predict on full dataset\n",
    "    preds = model.predict(graph, batch_size=A.shape[0])\n",
    "\n",
    "    # Train / validation scores\n",
    "    train_val_loss, train_val_acc = evaluate_preds(preds, [y_train, y_val],\n",
    "                                                   [idx_train, idx_val])\n",
    "    print(\"Epoch: {:04d}\".format(epoch),\n",
    "          \"train_loss= {:.4f}\".format(train_val_loss[0]),\n",
    "          \"train_acc= {:.4f}\".format(train_val_acc[0]),\n",
    "          \"val_loss= {:.4f}\".format(train_val_loss[1]),\n",
    "          \"val_acc= {:.4f}\".format(train_val_acc[1]),\n",
    "          \"time= {:.4f}\".format(time.time() - t))\n",
    "\n",
    "    # Early stopping\n",
    "    if train_val_loss[1] < best_val_loss:\n",
    "        best_val_loss = train_val_loss[1]\n",
    "        wait = 0\n",
    "    else:\n",
    "        if wait >= PATIENCE:\n",
    "            print('Epoch {}: early stopping'.format(epoch))\n",
    "            break\n",
    "        wait += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.8607\n",
      "accuracy = 0.7970\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate_preds(preds, [y_test], [idx_test])\n",
    "print(f\"\"\"\n",
    "loss = {test_loss[0]:.4f}\n",
    "accuracy = {test_acc[0]:.4f}\n",
    "\"\"\".strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
