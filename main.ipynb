{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from keras.layers import Input, Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the path of execution\n",
    "EXE_PATH = os.path.abspath(os.path.curdir)\n",
    "# the path of the vendor files\n",
    "VENDOR_PATH = os.path.join(EXE_PATH, 'vendor')\n",
    "# the vendors to include in the system path\n",
    "VENDORS = ['keras-gcn']\n",
    "# create the absolute paths for all vendors\n",
    "VENDORS = list(map(lambda x: os.path.join(VENDOR_PATH, x), VENDORS))\n",
    "# update the Python path to include necessary vendor module\n",
    "sys.path += VENDORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kegra.layers.graph import GraphConvolution\n",
    "from kegra.utils import load_data, preprocess_adj, get_splits, evaluate_preds\n",
    "from ggcn import GaussianGraphConvolution, kl_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cora dataset...\n",
      "Dataset has 2708 nodes, 5429 edges, 1433 features.\n"
     ]
    }
   ],
   "source": [
    "X, A, y = load_data('data/cora/', dataset='cora')\n",
    "X /= X.sum(1).reshape(-1, 1)\n",
    "A = preprocess_adj(A)\n",
    "y_train, y_val, y_test, idx_train, idx_val, idx_test, train_mask = get_splits(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2708x2708 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 13264 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 1, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 1]], dtype=int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1110 17:47:07.775446 140443612604224 deprecation_wrapper.py:119] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1110 17:47:07.782476 140443612604224 deprecation_wrapper.py:119] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:515: The name tf.sparse_placeholder is deprecated. Please use tf.compat.v1.sparse_placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "support = 1\n",
    "graph = [X, A]\n",
    "G = [Input(shape=(None, None), batch_shape=(None, None), sparse=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1110 17:47:07.788238 140443612604224 deprecation_wrapper.py:119] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_in = Input(shape=(X.shape[1],))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCN (baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1110 17:47:07.794351 140443612604224 deprecation_wrapper.py:119] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W1110 17:47:07.800366 140443612604224 deprecation.py:506] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W1110 17:47:07.808301 140443612604224 deprecation_wrapper.py:119] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define model architecture\n",
    "# NOTE: We pass arguments for graph convolutional layers as a list of tensors.\n",
    "# This is somewhat hacky, more elegant options would require rewriting the Layer base class.\n",
    "H = Dropout(0.5)(X_in)\n",
    "H = GraphConvolution(32, support, activation='relu', kernel_regularizer=l2(5e-4))([H]+G)\n",
    "H = Dropout(0.5)(H)\n",
    "Y = GraphConvolution(y.shape[1], support, activation='softmax')([H]+G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1110 17:47:07.851291 140443612604224 deprecation_wrapper.py:119] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=[X_in]+G, outputs=Y)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 1433)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1433)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "graph_convolution_1 (GraphConvo (None, 32)           45888       dropout_1[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 32)           0           graph_convolution_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "graph_convolution_2 (GraphConvo (None, 7)            231         dropout_2[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 46,119\n",
      "Trainable params: 46,119\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1110 17:47:07.925924 140443612604224 deprecation.py:323] From /home/bitcommander/.local/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 train_loss= 1.9280 train_acc= 0.3929 val_loss= 1.9307 val_acc= 0.3933 time= 1.0971\n",
      "Epoch: 0002 train_loss= 1.9095 train_acc= 0.4143 val_loss= 1.9149 val_acc= 0.4000 time= 0.0227\n",
      "Epoch: 0003 train_loss= 1.8894 train_acc= 0.4357 val_loss= 1.8982 val_acc= 0.4133 time= 0.0192\n",
      "Epoch: 0004 train_loss= 1.8687 train_acc= 0.4357 val_loss= 1.8807 val_acc= 0.4133 time= 0.0234\n",
      "Epoch: 0005 train_loss= 1.8475 train_acc= 0.4286 val_loss= 1.8627 val_acc= 0.4067 time= 0.0190\n",
      "Epoch: 0006 train_loss= 1.8257 train_acc= 0.4143 val_loss= 1.8441 val_acc= 0.4000 time= 0.0188\n",
      "Epoch: 0007 train_loss= 1.8043 train_acc= 0.4143 val_loss= 1.8262 val_acc= 0.3767 time= 0.0179\n",
      "Epoch: 0008 train_loss= 1.7841 train_acc= 0.4071 val_loss= 1.8093 val_acc= 0.3733 time= 0.0178\n",
      "Epoch: 0009 train_loss= 1.7655 train_acc= 0.4071 val_loss= 1.7940 val_acc= 0.3700 time= 0.0242\n",
      "Epoch: 0010 train_loss= 1.7486 train_acc= 0.4071 val_loss= 1.7808 val_acc= 0.3700 time= 0.0229\n",
      "Epoch: 0011 train_loss= 1.7335 train_acc= 0.4071 val_loss= 1.7694 val_acc= 0.3700 time= 0.0178\n",
      "Epoch: 0012 train_loss= 1.7201 train_acc= 0.4071 val_loss= 1.7601 val_acc= 0.3733 time= 0.0183\n",
      "Epoch: 0013 train_loss= 1.7081 train_acc= 0.4071 val_loss= 1.7524 val_acc= 0.3733 time= 0.0196\n",
      "Epoch: 0014 train_loss= 1.6969 train_acc= 0.4071 val_loss= 1.7455 val_acc= 0.3733 time= 0.0189\n",
      "Epoch: 0015 train_loss= 1.6856 train_acc= 0.4214 val_loss= 1.7385 val_acc= 0.3867 time= 0.0194\n",
      "Epoch: 0016 train_loss= 1.6739 train_acc= 0.4286 val_loss= 1.7313 val_acc= 0.3967 time= 0.0234\n",
      "Epoch: 0017 train_loss= 1.6612 train_acc= 0.4286 val_loss= 1.7229 val_acc= 0.4033 time= 0.0205\n",
      "Epoch: 0018 train_loss= 1.6474 train_acc= 0.4357 val_loss= 1.7134 val_acc= 0.4133 time= 0.0193\n",
      "Epoch: 0019 train_loss= 1.6328 train_acc= 0.4357 val_loss= 1.7034 val_acc= 0.4133 time= 0.0226\n",
      "Epoch: 0020 train_loss= 1.6173 train_acc= 0.4500 val_loss= 1.6925 val_acc= 0.4200 time= 0.0192\n",
      "Epoch: 0021 train_loss= 1.6015 train_acc= 0.4571 val_loss= 1.6814 val_acc= 0.4200 time= 0.0238\n",
      "Epoch: 0022 train_loss= 1.5857 train_acc= 0.4571 val_loss= 1.6701 val_acc= 0.4300 time= 0.0230\n",
      "Epoch: 0023 train_loss= 1.5699 train_acc= 0.4643 val_loss= 1.6589 val_acc= 0.4400 time= 0.0252\n",
      "Epoch: 0024 train_loss= 1.5541 train_acc= 0.4643 val_loss= 1.6479 val_acc= 0.4467 time= 0.0241\n",
      "Epoch: 0025 train_loss= 1.5386 train_acc= 0.4643 val_loss= 1.6374 val_acc= 0.4567 time= 0.0228\n",
      "Epoch: 0026 train_loss= 1.5236 train_acc= 0.4786 val_loss= 1.6273 val_acc= 0.4633 time= 0.0249\n",
      "Epoch: 0027 train_loss= 1.5088 train_acc= 0.4786 val_loss= 1.6173 val_acc= 0.4667 time= 0.0190\n",
      "Epoch: 0028 train_loss= 1.4941 train_acc= 0.5000 val_loss= 1.6073 val_acc= 0.4700 time= 0.0197\n",
      "Epoch: 0029 train_loss= 1.4792 train_acc= 0.5000 val_loss= 1.5970 val_acc= 0.4767 time= 0.0232\n",
      "Epoch: 0030 train_loss= 1.4640 train_acc= 0.5000 val_loss= 1.5864 val_acc= 0.4800 time= 0.0232\n",
      "Epoch: 0031 train_loss= 1.4482 train_acc= 0.5000 val_loss= 1.5751 val_acc= 0.4833 time= 0.0235\n",
      "Epoch: 0032 train_loss= 1.4319 train_acc= 0.5143 val_loss= 1.5635 val_acc= 0.4833 time= 0.0201\n",
      "Epoch: 0033 train_loss= 1.4154 train_acc= 0.5143 val_loss= 1.5519 val_acc= 0.4800 time= 0.0232\n",
      "Epoch: 0034 train_loss= 1.3990 train_acc= 0.5143 val_loss= 1.5403 val_acc= 0.4800 time= 0.0184\n",
      "Epoch: 0035 train_loss= 1.3831 train_acc= 0.5143 val_loss= 1.5288 val_acc= 0.4833 time= 0.0232\n",
      "Epoch: 0036 train_loss= 1.3675 train_acc= 0.5214 val_loss= 1.5176 val_acc= 0.4867 time= 0.0182\n",
      "Epoch: 0037 train_loss= 1.3520 train_acc= 0.5357 val_loss= 1.5063 val_acc= 0.4967 time= 0.0237\n",
      "Epoch: 0038 train_loss= 1.3367 train_acc= 0.5357 val_loss= 1.4951 val_acc= 0.5000 time= 0.0256\n",
      "Epoch: 0039 train_loss= 1.3211 train_acc= 0.5500 val_loss= 1.4835 val_acc= 0.5100 time= 0.0242\n",
      "Epoch: 0040 train_loss= 1.3052 train_acc= 0.5714 val_loss= 1.4717 val_acc= 0.5133 time= 0.0257\n",
      "Epoch: 0041 train_loss= 1.2893 train_acc= 0.5714 val_loss= 1.4596 val_acc= 0.5200 time= 0.0246\n",
      "Epoch: 0042 train_loss= 1.2733 train_acc= 0.5643 val_loss= 1.4471 val_acc= 0.5267 time= 0.0245\n",
      "Epoch: 0043 train_loss= 1.2574 train_acc= 0.5714 val_loss= 1.4343 val_acc= 0.5367 time= 0.0241\n",
      "Epoch: 0044 train_loss= 1.2415 train_acc= 0.5786 val_loss= 1.4218 val_acc= 0.5400 time= 0.0235\n",
      "Epoch: 0045 train_loss= 1.2257 train_acc= 0.6071 val_loss= 1.4096 val_acc= 0.5467 time= 0.0236\n",
      "Epoch: 0046 train_loss= 1.2099 train_acc= 0.6214 val_loss= 1.3972 val_acc= 0.5533 time= 0.0186\n",
      "Epoch: 0047 train_loss= 1.1945 train_acc= 0.6357 val_loss= 1.3853 val_acc= 0.5600 time= 0.0182\n",
      "Epoch: 0048 train_loss= 1.1791 train_acc= 0.6500 val_loss= 1.3741 val_acc= 0.5767 time= 0.0248\n",
      "Epoch: 0049 train_loss= 1.1637 train_acc= 0.6786 val_loss= 1.3628 val_acc= 0.5867 time= 0.0186\n",
      "Epoch: 0050 train_loss= 1.1484 train_acc= 0.7214 val_loss= 1.3521 val_acc= 0.6100 time= 0.0229\n",
      "Epoch: 0051 train_loss= 1.1333 train_acc= 0.7786 val_loss= 1.3415 val_acc= 0.6167 time= 0.0185\n",
      "Epoch: 0052 train_loss= 1.1186 train_acc= 0.8000 val_loss= 1.3302 val_acc= 0.6367 time= 0.0231\n",
      "Epoch: 0053 train_loss= 1.1038 train_acc= 0.8071 val_loss= 1.3186 val_acc= 0.6500 time= 0.0224\n",
      "Epoch: 0054 train_loss= 1.0894 train_acc= 0.8071 val_loss= 1.3072 val_acc= 0.6567 time= 0.0283\n",
      "Epoch: 0055 train_loss= 1.0752 train_acc= 0.8071 val_loss= 1.2958 val_acc= 0.6633 time= 0.0188\n",
      "Epoch: 0056 train_loss= 1.0611 train_acc= 0.8143 val_loss= 1.2849 val_acc= 0.6733 time= 0.0181\n",
      "Epoch: 0057 train_loss= 1.0474 train_acc= 0.8214 val_loss= 1.2746 val_acc= 0.6800 time= 0.0182\n",
      "Epoch: 0058 train_loss= 1.0339 train_acc= 0.8214 val_loss= 1.2637 val_acc= 0.6800 time= 0.0264\n",
      "Epoch: 0059 train_loss= 1.0204 train_acc= 0.8214 val_loss= 1.2528 val_acc= 0.6933 time= 0.0188\n",
      "Epoch: 0060 train_loss= 1.0069 train_acc= 0.8429 val_loss= 1.2421 val_acc= 0.6933 time= 0.0233\n",
      "Epoch: 0061 train_loss= 0.9934 train_acc= 0.8500 val_loss= 1.2311 val_acc= 0.7133 time= 0.0231\n",
      "Epoch: 0062 train_loss= 0.9801 train_acc= 0.8571 val_loss= 1.2201 val_acc= 0.7133 time= 0.0249\n",
      "Epoch: 0063 train_loss= 0.9671 train_acc= 0.8571 val_loss= 1.2093 val_acc= 0.7100 time= 0.0238\n",
      "Epoch: 0064 train_loss= 0.9542 train_acc= 0.8571 val_loss= 1.1986 val_acc= 0.7200 time= 0.0248\n",
      "Epoch: 0065 train_loss= 0.9417 train_acc= 0.8643 val_loss= 1.1881 val_acc= 0.7267 time= 0.0238\n",
      "Epoch: 0066 train_loss= 0.9298 train_acc= 0.8500 val_loss= 1.1784 val_acc= 0.7267 time= 0.0240\n",
      "Epoch: 0067 train_loss= 0.9177 train_acc= 0.8714 val_loss= 1.1694 val_acc= 0.7267 time= 0.0197\n",
      "Epoch: 0068 train_loss= 0.9061 train_acc= 0.8714 val_loss= 1.1612 val_acc= 0.7433 time= 0.0194\n",
      "Epoch: 0069 train_loss= 0.8947 train_acc= 0.8786 val_loss= 1.1529 val_acc= 0.7467 time= 0.0197\n",
      "Epoch: 0070 train_loss= 0.8833 train_acc= 0.8786 val_loss= 1.1442 val_acc= 0.7500 time= 0.0229\n",
      "Epoch: 0071 train_loss= 0.8720 train_acc= 0.8857 val_loss= 1.1360 val_acc= 0.7533 time= 0.0234\n",
      "Epoch: 0072 train_loss= 0.8609 train_acc= 0.8857 val_loss= 1.1271 val_acc= 0.7533 time= 0.0190\n",
      "Epoch: 0073 train_loss= 0.8502 train_acc= 0.8857 val_loss= 1.1184 val_acc= 0.7500 time= 0.0198\n",
      "Epoch: 0074 train_loss= 0.8400 train_acc= 0.8857 val_loss= 1.1102 val_acc= 0.7533 time= 0.0203\n",
      "Epoch: 0075 train_loss= 0.8300 train_acc= 0.8857 val_loss= 1.1019 val_acc= 0.7533 time= 0.0227\n",
      "Epoch: 0076 train_loss= 0.8200 train_acc= 0.8857 val_loss= 1.0938 val_acc= 0.7567 time= 0.0289\n",
      "Epoch: 0077 train_loss= 0.8104 train_acc= 0.8929 val_loss= 1.0860 val_acc= 0.7633 time= 0.0241\n",
      "Epoch: 0078 train_loss= 0.8010 train_acc= 0.8929 val_loss= 1.0791 val_acc= 0.7633 time= 0.0207\n",
      "Epoch: 0079 train_loss= 0.7916 train_acc= 0.8929 val_loss= 1.0717 val_acc= 0.7700 time= 0.0247\n",
      "Epoch: 0080 train_loss= 0.7826 train_acc= 0.9071 val_loss= 1.0644 val_acc= 0.7733 time= 0.0184\n",
      "Epoch: 0081 train_loss= 0.7736 train_acc= 0.9071 val_loss= 1.0563 val_acc= 0.7767 time= 0.0189\n",
      "Epoch: 0082 train_loss= 0.7647 train_acc= 0.9071 val_loss= 1.0487 val_acc= 0.7767 time= 0.0252\n",
      "Epoch: 0083 train_loss= 0.7563 train_acc= 0.9071 val_loss= 1.0413 val_acc= 0.7767 time= 0.0231\n",
      "Epoch: 0084 train_loss= 0.7482 train_acc= 0.9000 val_loss= 1.0343 val_acc= 0.7767 time= 0.0199\n",
      "Epoch: 0085 train_loss= 0.7402 train_acc= 0.9000 val_loss= 1.0276 val_acc= 0.7767 time= 0.0236\n",
      "Epoch: 0086 train_loss= 0.7321 train_acc= 0.9071 val_loss= 1.0204 val_acc= 0.7733 time= 0.0190\n",
      "Epoch: 0087 train_loss= 0.7232 train_acc= 0.9143 val_loss= 1.0133 val_acc= 0.7767 time= 0.0194\n",
      "Epoch: 0088 train_loss= 0.7147 train_acc= 0.9143 val_loss= 1.0063 val_acc= 0.7833 time= 0.0233\n",
      "Epoch: 0089 train_loss= 0.7059 train_acc= 0.9143 val_loss= 1.0003 val_acc= 0.7800 time= 0.0189\n",
      "Epoch: 0090 train_loss= 0.6980 train_acc= 0.9143 val_loss= 0.9948 val_acc= 0.7800 time= 0.0201\n",
      "Epoch: 0091 train_loss= 0.6911 train_acc= 0.9143 val_loss= 0.9909 val_acc= 0.7933 time= 0.0233\n",
      "Epoch: 0092 train_loss= 0.6842 train_acc= 0.9214 val_loss= 0.9865 val_acc= 0.7933 time= 0.0187\n",
      "Epoch: 0093 train_loss= 0.6771 train_acc= 0.9214 val_loss= 0.9800 val_acc= 0.7900 time= 0.0236\n",
      "Epoch: 0094 train_loss= 0.6696 train_acc= 0.9143 val_loss= 0.9715 val_acc= 0.7867 time= 0.0239\n",
      "Epoch: 0095 train_loss= 0.6629 train_acc= 0.9143 val_loss= 0.9638 val_acc= 0.7833 time= 0.0178\n",
      "Epoch: 0096 train_loss= 0.6565 train_acc= 0.9143 val_loss= 0.9577 val_acc= 0.7867 time= 0.0237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0097 train_loss= 0.6498 train_acc= 0.9214 val_loss= 0.9528 val_acc= 0.7833 time= 0.0182\n",
      "Epoch: 0098 train_loss= 0.6434 train_acc= 0.9214 val_loss= 0.9488 val_acc= 0.7833 time= 0.0179\n",
      "Epoch: 0099 train_loss= 0.6370 train_acc= 0.9214 val_loss= 0.9465 val_acc= 0.7867 time= 0.0228\n",
      "Epoch: 0100 train_loss= 0.6312 train_acc= 0.9214 val_loss= 0.9444 val_acc= 0.7900 time= 0.0191\n",
      "Epoch: 0101 train_loss= 0.6253 train_acc= 0.9214 val_loss= 0.9409 val_acc= 0.7933 time= 0.0231\n",
      "Epoch: 0102 train_loss= 0.6188 train_acc= 0.9214 val_loss= 0.9359 val_acc= 0.7967 time= 0.0179\n",
      "Epoch: 0103 train_loss= 0.6119 train_acc= 0.9286 val_loss= 0.9279 val_acc= 0.7933 time= 0.0189\n",
      "Epoch: 0104 train_loss= 0.6057 train_acc= 0.9286 val_loss= 0.9212 val_acc= 0.7933 time= 0.0196\n",
      "Epoch: 0105 train_loss= 0.6003 train_acc= 0.9286 val_loss= 0.9163 val_acc= 0.7900 time= 0.0189\n",
      "Epoch: 0106 train_loss= 0.5954 train_acc= 0.9357 val_loss= 0.9123 val_acc= 0.7900 time= 0.0187\n",
      "Epoch: 0107 train_loss= 0.5904 train_acc= 0.9500 val_loss= 0.9084 val_acc= 0.7900 time= 0.0194\n",
      "Epoch: 0108 train_loss= 0.5854 train_acc= 0.9500 val_loss= 0.9040 val_acc= 0.7900 time= 0.0230\n",
      "Epoch: 0109 train_loss= 0.5796 train_acc= 0.9357 val_loss= 0.8996 val_acc= 0.7900 time= 0.0192\n",
      "Epoch: 0110 train_loss= 0.5741 train_acc= 0.9286 val_loss= 0.8963 val_acc= 0.7900 time= 0.0189\n",
      "Epoch: 0111 train_loss= 0.5692 train_acc= 0.9286 val_loss= 0.8934 val_acc= 0.7900 time= 0.0197\n",
      "Epoch: 0112 train_loss= 0.5650 train_acc= 0.9357 val_loss= 0.8905 val_acc= 0.7900 time= 0.0206\n",
      "Epoch: 0113 train_loss= 0.5610 train_acc= 0.9429 val_loss= 0.8882 val_acc= 0.7933 time= 0.0238\n",
      "Epoch: 0114 train_loss= 0.5566 train_acc= 0.9429 val_loss= 0.8846 val_acc= 0.7967 time= 0.0235\n",
      "Epoch: 0115 train_loss= 0.5511 train_acc= 0.9429 val_loss= 0.8797 val_acc= 0.8000 time= 0.0188\n",
      "Epoch: 0116 train_loss= 0.5452 train_acc= 0.9429 val_loss= 0.8745 val_acc= 0.8033 time= 0.0237\n",
      "Epoch: 0117 train_loss= 0.5391 train_acc= 0.9500 val_loss= 0.8704 val_acc= 0.8000 time= 0.0246\n",
      "Epoch: 0118 train_loss= 0.5340 train_acc= 0.9429 val_loss= 0.8676 val_acc= 0.8100 time= 0.0234\n",
      "Epoch: 0119 train_loss= 0.5303 train_acc= 0.9429 val_loss= 0.8669 val_acc= 0.8100 time= 0.0218\n",
      "Epoch: 0120 train_loss= 0.5270 train_acc= 0.9500 val_loss= 0.8660 val_acc= 0.7933 time= 0.0235\n",
      "Epoch: 0121 train_loss= 0.5239 train_acc= 0.9571 val_loss= 0.8644 val_acc= 0.7900 time= 0.0195\n",
      "Epoch: 0122 train_loss= 0.5203 train_acc= 0.9571 val_loss= 0.8613 val_acc= 0.7900 time= 0.0201\n",
      "Epoch: 0123 train_loss= 0.5160 train_acc= 0.9571 val_loss= 0.8560 val_acc= 0.8000 time= 0.0192\n",
      "Epoch: 0124 train_loss= 0.5116 train_acc= 0.9643 val_loss= 0.8515 val_acc= 0.8033 time= 0.0283\n",
      "Epoch: 0125 train_loss= 0.5073 train_acc= 0.9500 val_loss= 0.8462 val_acc= 0.8100 time= 0.0208\n",
      "Epoch: 0126 train_loss= 0.5038 train_acc= 0.9500 val_loss= 0.8422 val_acc= 0.8067 time= 0.0246\n",
      "Epoch: 0127 train_loss= 0.5008 train_acc= 0.9500 val_loss= 0.8395 val_acc= 0.8000 time= 0.0254\n",
      "Epoch: 0128 train_loss= 0.4980 train_acc= 0.9500 val_loss= 0.8382 val_acc= 0.8100 time= 0.0234\n",
      "Epoch: 0129 train_loss= 0.4950 train_acc= 0.9500 val_loss= 0.8379 val_acc= 0.8133 time= 0.0197\n",
      "Epoch: 0130 train_loss= 0.4918 train_acc= 0.9500 val_loss= 0.8399 val_acc= 0.8067 time= 0.0240\n",
      "Epoch: 0131 train_loss= 0.4896 train_acc= 0.9429 val_loss= 0.8432 val_acc= 0.8000 time= 0.0246\n",
      "Epoch: 0132 train_loss= 0.4870 train_acc= 0.9429 val_loss= 0.8433 val_acc= 0.8033 time= 0.0261\n",
      "Epoch: 0133 train_loss= 0.4833 train_acc= 0.9429 val_loss= 0.8397 val_acc= 0.8000 time= 0.0254\n",
      "Epoch: 0134 train_loss= 0.4793 train_acc= 0.9429 val_loss= 0.8344 val_acc= 0.7967 time= 0.0234\n",
      "Epoch: 0135 train_loss= 0.4758 train_acc= 0.9500 val_loss= 0.8281 val_acc= 0.8000 time= 0.0233\n",
      "Epoch: 0136 train_loss= 0.4734 train_acc= 0.9571 val_loss= 0.8232 val_acc= 0.8067 time= 0.0234\n",
      "Epoch: 0137 train_loss= 0.4716 train_acc= 0.9571 val_loss= 0.8201 val_acc= 0.8033 time= 0.0191\n",
      "Epoch: 0138 train_loss= 0.4694 train_acc= 0.9571 val_loss= 0.8185 val_acc= 0.8033 time= 0.0184\n",
      "Epoch: 0139 train_loss= 0.4665 train_acc= 0.9643 val_loss= 0.8178 val_acc= 0.7967 time= 0.0191\n",
      "Epoch: 0140 train_loss= 0.4631 train_acc= 0.9643 val_loss= 0.8177 val_acc= 0.8033 time= 0.0187\n",
      "Epoch: 0141 train_loss= 0.4600 train_acc= 0.9643 val_loss= 0.8171 val_acc= 0.8000 time= 0.0226\n",
      "Epoch: 0142 train_loss= 0.4573 train_acc= 0.9643 val_loss= 0.8166 val_acc= 0.8033 time= 0.0207\n",
      "Epoch: 0143 train_loss= 0.4547 train_acc= 0.9643 val_loss= 0.8162 val_acc= 0.8067 time= 0.0180\n",
      "Epoch: 0144 train_loss= 0.4518 train_acc= 0.9643 val_loss= 0.8154 val_acc= 0.8067 time= 0.0182\n",
      "Epoch: 0145 train_loss= 0.4491 train_acc= 0.9714 val_loss= 0.8151 val_acc= 0.8033 time= 0.0229\n",
      "Epoch: 0146 train_loss= 0.4458 train_acc= 0.9714 val_loss= 0.8123 val_acc= 0.8033 time= 0.0238\n",
      "Epoch: 0147 train_loss= 0.4428 train_acc= 0.9643 val_loss= 0.8091 val_acc= 0.8067 time= 0.0198\n",
      "Epoch: 0148 train_loss= 0.4402 train_acc= 0.9643 val_loss= 0.8062 val_acc= 0.8133 time= 0.0182\n",
      "Epoch: 0149 train_loss= 0.4379 train_acc= 0.9643 val_loss= 0.8021 val_acc= 0.8100 time= 0.0231\n",
      "Epoch: 0150 train_loss= 0.4361 train_acc= 0.9714 val_loss= 0.7993 val_acc= 0.8033 time= 0.0195\n",
      "Epoch: 0151 train_loss= 0.4345 train_acc= 0.9714 val_loss= 0.7974 val_acc= 0.8100 time= 0.0189\n",
      "Epoch: 0152 train_loss= 0.4318 train_acc= 0.9714 val_loss= 0.7965 val_acc= 0.8033 time= 0.0189\n",
      "Epoch: 0153 train_loss= 0.4290 train_acc= 0.9714 val_loss= 0.7957 val_acc= 0.8067 time= 0.0187\n",
      "Epoch: 0154 train_loss= 0.4266 train_acc= 0.9714 val_loss= 0.7935 val_acc= 0.8067 time= 0.0182\n",
      "Epoch: 0155 train_loss= 0.4239 train_acc= 0.9643 val_loss= 0.7910 val_acc= 0.8067 time= 0.0185\n",
      "Epoch: 0156 train_loss= 0.4213 train_acc= 0.9643 val_loss= 0.7886 val_acc= 0.8200 time= 0.0188\n",
      "Epoch: 0157 train_loss= 0.4187 train_acc= 0.9643 val_loss= 0.7861 val_acc= 0.8200 time= 0.0265\n",
      "Epoch: 0158 train_loss= 0.4154 train_acc= 0.9714 val_loss= 0.7845 val_acc= 0.8200 time= 0.0236\n",
      "Epoch: 0159 train_loss= 0.4117 train_acc= 0.9714 val_loss= 0.7833 val_acc= 0.8167 time= 0.0202\n",
      "Epoch: 0160 train_loss= 0.4089 train_acc= 0.9714 val_loss= 0.7822 val_acc= 0.8100 time= 0.0186\n",
      "Epoch: 0161 train_loss= 0.4066 train_acc= 0.9714 val_loss= 0.7807 val_acc= 0.8100 time= 0.0237\n",
      "Epoch: 0162 train_loss= 0.4046 train_acc= 0.9714 val_loss= 0.7800 val_acc= 0.8067 time= 0.0232\n",
      "Epoch: 0163 train_loss= 0.4028 train_acc= 0.9714 val_loss= 0.7787 val_acc= 0.8033 time= 0.0248\n",
      "Epoch: 0164 train_loss= 0.4011 train_acc= 0.9714 val_loss= 0.7771 val_acc= 0.8033 time= 0.0232\n",
      "Epoch: 0165 train_loss= 0.3992 train_acc= 0.9714 val_loss= 0.7748 val_acc= 0.8000 time= 0.0234\n",
      "Epoch: 0166 train_loss= 0.3972 train_acc= 0.9714 val_loss= 0.7725 val_acc= 0.8000 time= 0.0244\n",
      "Epoch: 0167 train_loss= 0.3949 train_acc= 0.9714 val_loss= 0.7702 val_acc= 0.8067 time= 0.0248\n",
      "Epoch: 0168 train_loss= 0.3923 train_acc= 0.9714 val_loss= 0.7674 val_acc= 0.8033 time= 0.0255\n",
      "Epoch: 0169 train_loss= 0.3899 train_acc= 0.9714 val_loss= 0.7662 val_acc= 0.8133 time= 0.0232\n",
      "Epoch: 0170 train_loss= 0.3887 train_acc= 0.9643 val_loss= 0.7665 val_acc= 0.8133 time= 0.0229\n",
      "Epoch: 0171 train_loss= 0.3882 train_acc= 0.9714 val_loss= 0.7687 val_acc= 0.8233 time= 0.0197\n",
      "Epoch: 0172 train_loss= 0.3868 train_acc= 0.9786 val_loss= 0.7685 val_acc= 0.8233 time= 0.0248\n",
      "Epoch: 0173 train_loss= 0.3838 train_acc= 0.9786 val_loss= 0.7659 val_acc= 0.8233 time= 0.0243\n",
      "Epoch: 0174 train_loss= 0.3801 train_acc= 0.9714 val_loss= 0.7614 val_acc= 0.8233 time= 0.0239\n",
      "Epoch: 0175 train_loss= 0.3774 train_acc= 0.9714 val_loss= 0.7564 val_acc= 0.8133 time= 0.0192\n",
      "Epoch: 0176 train_loss= 0.3765 train_acc= 0.9714 val_loss= 0.7532 val_acc= 0.8167 time= 0.0231\n",
      "Epoch: 0177 train_loss= 0.3749 train_acc= 0.9714 val_loss= 0.7505 val_acc= 0.8133 time= 0.0255\n",
      "Epoch: 0178 train_loss= 0.3725 train_acc= 0.9714 val_loss= 0.7487 val_acc= 0.8100 time= 0.0246\n",
      "Epoch: 0179 train_loss= 0.3698 train_acc= 0.9714 val_loss= 0.7483 val_acc= 0.8133 time= 0.0232\n",
      "Epoch: 0180 train_loss= 0.3675 train_acc= 0.9786 val_loss= 0.7490 val_acc= 0.8100 time= 0.0189\n",
      "Epoch: 0181 train_loss= 0.3664 train_acc= 0.9786 val_loss= 0.7528 val_acc= 0.8100 time= 0.0231\n",
      "Epoch: 0182 train_loss= 0.3652 train_acc= 0.9786 val_loss= 0.7544 val_acc= 0.8033 time= 0.0187\n",
      "Epoch: 0183 train_loss= 0.3632 train_acc= 0.9786 val_loss= 0.7537 val_acc= 0.8033 time= 0.0202\n",
      "Epoch: 0184 train_loss= 0.3614 train_acc= 0.9786 val_loss= 0.7535 val_acc= 0.8133 time= 0.0189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0185 train_loss= 0.3593 train_acc= 0.9786 val_loss= 0.7508 val_acc= 0.8233 time= 0.0189\n",
      "Epoch: 0186 train_loss= 0.3575 train_acc= 0.9786 val_loss= 0.7471 val_acc= 0.8233 time= 0.0244\n",
      "Epoch: 0187 train_loss= 0.3562 train_acc= 0.9714 val_loss= 0.7440 val_acc= 0.8300 time= 0.0237\n",
      "Epoch: 0188 train_loss= 0.3552 train_acc= 0.9714 val_loss= 0.7434 val_acc= 0.8267 time= 0.0228\n",
      "Epoch: 0189 train_loss= 0.3547 train_acc= 0.9714 val_loss= 0.7432 val_acc= 0.8167 time= 0.0227\n",
      "Epoch: 0190 train_loss= 0.3519 train_acc= 0.9714 val_loss= 0.7416 val_acc= 0.8100 time= 0.0229\n",
      "Epoch: 0191 train_loss= 0.3494 train_acc= 0.9786 val_loss= 0.7406 val_acc= 0.8133 time= 0.0224\n",
      "Epoch: 0192 train_loss= 0.3482 train_acc= 0.9786 val_loss= 0.7415 val_acc= 0.8133 time= 0.0189\n",
      "Epoch: 0193 train_loss= 0.3474 train_acc= 0.9786 val_loss= 0.7420 val_acc= 0.8133 time= 0.0236\n",
      "Epoch: 0194 train_loss= 0.3462 train_acc= 0.9786 val_loss= 0.7422 val_acc= 0.8100 time= 0.0241\n",
      "Epoch: 0195 train_loss= 0.3447 train_acc= 0.9786 val_loss= 0.7405 val_acc= 0.8033 time= 0.0227\n",
      "Epoch: 0196 train_loss= 0.3433 train_acc= 0.9786 val_loss= 0.7391 val_acc= 0.8033 time= 0.0234\n",
      "Epoch: 0197 train_loss= 0.3421 train_acc= 0.9786 val_loss= 0.7377 val_acc= 0.8033 time= 0.0245\n",
      "Epoch: 0198 train_loss= 0.3411 train_acc= 0.9786 val_loss= 0.7357 val_acc= 0.8033 time= 0.0248\n",
      "Epoch: 0199 train_loss= 0.3400 train_acc= 0.9786 val_loss= 0.7341 val_acc= 0.8067 time= 0.0246\n",
      "Epoch: 0200 train_loss= 0.3388 train_acc= 0.9714 val_loss= 0.7327 val_acc= 0.8067 time= 0.0239\n"
     ]
    }
   ],
   "source": [
    "NB_EPOCH = 200\n",
    "PATIENCE = 10  # early stopping patience\n",
    "# Helper variables for main training loop\n",
    "wait = 0\n",
    "preds = None\n",
    "best_val_loss = 99999\n",
    "\n",
    "# Fit\n",
    "for epoch in range(1, NB_EPOCH+1):\n",
    "\n",
    "    # Log wall-clock time\n",
    "    t = time.time()\n",
    "\n",
    "    # Single training iteration (we mask nodes without labels for loss calculation)\n",
    "    model.fit(graph, y_train, sample_weight=train_mask,\n",
    "              batch_size=A.shape[0], epochs=1, shuffle=False, verbose=0)\n",
    "\n",
    "    # Predict on full dataset\n",
    "    preds = model.predict(graph, batch_size=A.shape[0])\n",
    "\n",
    "    # Train / validation scores\n",
    "    train_val_loss, train_val_acc = evaluate_preds(preds, [y_train, y_val],\n",
    "                                                   [idx_train, idx_val])\n",
    "    print(\"Epoch: {:04d}\".format(epoch),\n",
    "          \"train_loss= {:.4f}\".format(train_val_loss[0]),\n",
    "          \"train_acc= {:.4f}\".format(train_val_acc[0]),\n",
    "          \"val_loss= {:.4f}\".format(train_val_loss[1]),\n",
    "          \"val_acc= {:.4f}\".format(train_val_acc[1]),\n",
    "          \"time= {:.4f}\".format(time.time() - t))\n",
    "\n",
    "    # Early stopping\n",
    "    if train_val_loss[1] < best_val_loss:\n",
    "        best_val_loss = train_val_loss[1]\n",
    "        wait = 0\n",
    "    else:\n",
    "        if wait >= PATIENCE:\n",
    "            print('Epoch {}: early stopping'.format(epoch))\n",
    "            break\n",
    "        wait += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.7709\n",
      "accuracy = 0.8200\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate_preds(preds, [y_test], [idx_test])\n",
    "print(f\"\"\"\n",
    "loss = {test_loss[0]:.4f}\n",
    "accuracy = {test_acc[0]:.4f}\n",
    "\"\"\".strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Graph Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1110 17:47:13.396539 140443612604224 deprecation.py:323] From /home/bitcommander/Desktop/robust-graph-convolutional-networks-against-adversarial-attacks-implementation/ggcn/ggcl.py:28: Normal.__init__ (from tensorflow.python.ops.distributions.normal) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
      "W1110 17:47:13.398080 140443612604224 deprecation.py:323] From /home/bitcommander/.local/lib/python3.7/site-packages/tensorflow/python/ops/distributions/normal.py:160: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n"
     ]
    }
   ],
   "source": [
    "H = Dropout(0.5)(X_in)\n",
    "H1 = GaussianGraphConvolution(16,\n",
    "    is_first=True,\n",
    "    activation='relu',\n",
    "    mean_regularizer=l2(5e-4),\n",
    "    variance_regularizer=l2(5e-4),\n",
    ")([H]+G)\n",
    "Y = GaussianGraphConvolution(y.shape[1],\n",
    "    is_last=True,\n",
    "    activation='softmax',\n",
    ")(H1+G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1110 17:47:13.435772 140443612604224 deprecation.py:323] From /home/bitcommander/Desktop/robust-graph-convolutional-networks-against-adversarial-attacks-implementation/ggcn/losses.py:27: kl_divergence (from tensorflow.python.ops.distributions.kullback_leibler) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=[X_in]+G, outputs=Y)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.01))\n",
    "model.add_loss(kl_reg(*H1), H1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 1433)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 1433)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_graph_convolution_1 (G [(None, 16), (None,  45856       dropout_3[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_graph_convolution_2 (G (None, 7)            224         gaussian_graph_convolution_1[0][0\n",
      "                                                                 gaussian_graph_convolution_1[0][1\n",
      "                                                                 input_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 46,080\n",
      "Trainable params: 46,080\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 train_loss= 1.9415 train_acc= 0.4429 val_loss= 1.9434 val_acc= 0.3533 time= 0.4335\n",
      "Epoch: 0002 train_loss= 1.9366 train_acc= 0.5714 val_loss= 1.9393 val_acc= 0.4700 time= 0.0192\n",
      "Epoch: 0003 train_loss= 1.9295 train_acc= 0.6357 val_loss= 1.9347 val_acc= 0.5567 time= 0.0236\n",
      "Epoch: 0004 train_loss= 1.9210 train_acc= 0.7357 val_loss= 1.9296 val_acc= 0.5533 time= 0.0201\n",
      "Epoch: 0005 train_loss= 1.9112 train_acc= 0.7214 val_loss= 1.9241 val_acc= 0.5567 time= 0.0236\n",
      "Epoch: 0006 train_loss= 1.9022 train_acc= 0.7143 val_loss= 1.9175 val_acc= 0.5900 time= 0.0185\n",
      "Epoch: 0007 train_loss= 1.8912 train_acc= 0.7857 val_loss= 1.9114 val_acc= 0.5600 time= 0.0239\n",
      "Epoch: 0008 train_loss= 1.8808 train_acc= 0.7500 val_loss= 1.9046 val_acc= 0.5933 time= 0.0189\n",
      "Epoch: 0009 train_loss= 1.8720 train_acc= 0.7214 val_loss= 1.8965 val_acc= 0.5733 time= 0.0201\n",
      "Epoch: 0010 train_loss= 1.8582 train_acc= 0.7429 val_loss= 1.8899 val_acc= 0.5567 time= 0.0190\n",
      "Epoch: 0011 train_loss= 1.8458 train_acc= 0.7286 val_loss= 1.8787 val_acc= 0.5933 time= 0.0188\n",
      "Epoch: 0012 train_loss= 1.8304 train_acc= 0.7714 val_loss= 1.8713 val_acc= 0.5567 time= 0.0194\n",
      "Epoch: 0013 train_loss= 1.8161 train_acc= 0.7357 val_loss= 1.8623 val_acc= 0.5733 time= 0.0190\n",
      "Epoch: 0014 train_loss= 1.8014 train_acc= 0.7714 val_loss= 1.8514 val_acc= 0.6067 time= 0.0199\n",
      "Epoch: 0015 train_loss= 1.7829 train_acc= 0.7643 val_loss= 1.8400 val_acc= 0.5833 time= 0.0196\n",
      "Epoch: 0016 train_loss= 1.7672 train_acc= 0.7714 val_loss= 1.8274 val_acc= 0.6033 time= 0.0192\n",
      "Epoch: 0017 train_loss= 1.7514 train_acc= 0.7643 val_loss= 1.8191 val_acc= 0.5900 time= 0.0280\n",
      "Epoch: 0018 train_loss= 1.7337 train_acc= 0.7429 val_loss= 1.8090 val_acc= 0.5800 time= 0.0191\n",
      "Epoch: 0019 train_loss= 1.7159 train_acc= 0.7429 val_loss= 1.7918 val_acc= 0.6133 time= 0.0234\n",
      "Epoch: 0020 train_loss= 1.6929 train_acc= 0.7786 val_loss= 1.7813 val_acc= 0.5867 time= 0.0208\n",
      "Epoch: 0021 train_loss= 1.6723 train_acc= 0.7500 val_loss= 1.7674 val_acc= 0.6067 time= 0.0187\n",
      "Epoch: 0022 train_loss= 1.6539 train_acc= 0.7143 val_loss= 1.7501 val_acc= 0.5867 time= 0.0241\n",
      "Epoch: 0023 train_loss= 1.6292 train_acc= 0.7571 val_loss= 1.7361 val_acc= 0.5967 time= 0.0240\n",
      "Epoch: 0024 train_loss= 1.6102 train_acc= 0.7500 val_loss= 1.7192 val_acc= 0.5967 time= 0.0231\n",
      "Epoch: 0025 train_loss= 1.5867 train_acc= 0.7571 val_loss= 1.7068 val_acc= 0.6033 time= 0.0248\n",
      "Epoch: 0026 train_loss= 1.5592 train_acc= 0.7571 val_loss= 1.6886 val_acc= 0.6133 time= 0.0192\n",
      "Epoch: 0027 train_loss= 1.5397 train_acc= 0.7643 val_loss= 1.6727 val_acc= 0.6067 time= 0.0204\n",
      "Epoch: 0028 train_loss= 1.5141 train_acc= 0.7643 val_loss= 1.6544 val_acc= 0.6233 time= 0.0285\n",
      "Epoch: 0029 train_loss= 1.4893 train_acc= 0.7500 val_loss= 1.6385 val_acc= 0.6300 time= 0.0233\n",
      "Epoch: 0030 train_loss= 1.4637 train_acc= 0.7714 val_loss= 1.6203 val_acc= 0.6133 time= 0.0244\n",
      "Epoch: 0031 train_loss= 1.4342 train_acc= 0.7714 val_loss= 1.6018 val_acc= 0.6233 time= 0.0193\n",
      "Epoch: 0032 train_loss= 1.4128 train_acc= 0.7714 val_loss= 1.5857 val_acc= 0.6167 time= 0.0258\n",
      "Epoch: 0033 train_loss= 1.3839 train_acc= 0.7857 val_loss= 1.5665 val_acc= 0.6267 time= 0.0300\n",
      "Epoch: 0034 train_loss= 1.3593 train_acc= 0.7857 val_loss= 1.5465 val_acc= 0.6300 time= 0.0234\n",
      "Epoch: 0035 train_loss= 1.3318 train_acc= 0.7929 val_loss= 1.5270 val_acc= 0.6267 time= 0.0201\n",
      "Epoch: 0036 train_loss= 1.3052 train_acc= 0.7857 val_loss= 1.5070 val_acc= 0.6333 time= 0.0194\n",
      "Epoch: 0037 train_loss= 1.2810 train_acc= 0.7929 val_loss= 1.4864 val_acc= 0.6400 time= 0.0207\n",
      "Epoch: 0038 train_loss= 1.2525 train_acc= 0.7929 val_loss= 1.4650 val_acc= 0.6567 time= 0.0194\n",
      "Epoch: 0039 train_loss= 1.2261 train_acc= 0.8000 val_loss= 1.4480 val_acc= 0.6433 time= 0.0201\n",
      "Epoch: 0040 train_loss= 1.1957 train_acc= 0.7929 val_loss= 1.4257 val_acc= 0.6500 time= 0.0242\n",
      "Epoch: 0041 train_loss= 1.1734 train_acc= 0.8000 val_loss= 1.4046 val_acc= 0.6533 time= 0.0204\n",
      "Epoch: 0042 train_loss= 1.1456 train_acc= 0.8286 val_loss= 1.3855 val_acc= 0.6500 time= 0.0189\n",
      "Epoch: 0043 train_loss= 1.1200 train_acc= 0.8143 val_loss= 1.3644 val_acc= 0.6600 time= 0.0233\n",
      "Epoch: 0044 train_loss= 1.0917 train_acc= 0.8214 val_loss= 1.3441 val_acc= 0.6700 time= 0.0195\n",
      "Epoch: 0045 train_loss= 1.0664 train_acc= 0.8429 val_loss= 1.3246 val_acc= 0.6700 time= 0.0192\n",
      "Epoch: 0046 train_loss= 1.0388 train_acc= 0.8429 val_loss= 1.3011 val_acc= 0.6833 time= 0.0195\n",
      "Epoch: 0047 train_loss= 1.0144 train_acc= 0.8429 val_loss= 1.2834 val_acc= 0.6900 time= 0.0250\n",
      "Epoch: 0048 train_loss= 0.9885 train_acc= 0.8571 val_loss= 1.2622 val_acc= 0.7100 time= 0.0193\n",
      "Epoch: 0049 train_loss= 0.9638 train_acc= 0.8643 val_loss= 1.2417 val_acc= 0.7100 time= 0.0288\n",
      "Epoch: 0050 train_loss= 0.9389 train_acc= 0.8643 val_loss= 1.2208 val_acc= 0.7200 time= 0.0264\n",
      "Epoch: 0051 train_loss= 0.9127 train_acc= 0.8786 val_loss= 1.2029 val_acc= 0.7267 time= 0.0246\n",
      "Epoch: 0052 train_loss= 0.8893 train_acc= 0.8786 val_loss= 1.1823 val_acc= 0.7300 time= 0.0212\n",
      "Epoch: 0053 train_loss= 0.8641 train_acc= 0.8929 val_loss= 1.1620 val_acc= 0.7300 time= 0.0200\n",
      "Epoch: 0054 train_loss= 0.8397 train_acc= 0.9071 val_loss= 1.1423 val_acc= 0.7400 time= 0.0203\n",
      "Epoch: 0055 train_loss= 0.8163 train_acc= 0.9071 val_loss= 1.1238 val_acc= 0.7467 time= 0.0295\n",
      "Epoch: 0056 train_loss= 0.7916 train_acc= 0.9143 val_loss= 1.1058 val_acc= 0.7433 time= 0.0232\n",
      "Epoch: 0057 train_loss= 0.7729 train_acc= 0.9143 val_loss= 1.0882 val_acc= 0.7500 time= 0.0228\n",
      "Epoch: 0058 train_loss= 0.7479 train_acc= 0.9214 val_loss= 1.0676 val_acc= 0.7567 time= 0.0239\n",
      "Epoch: 0059 train_loss= 0.7242 train_acc= 0.9214 val_loss= 1.0502 val_acc= 0.7633 time= 0.0258\n",
      "Epoch: 0060 train_loss= 0.7053 train_acc= 0.9429 val_loss= 1.0348 val_acc= 0.7633 time= 0.0239\n",
      "Epoch: 0061 train_loss= 0.6826 train_acc= 0.9429 val_loss= 1.0157 val_acc= 0.7633 time= 0.0200\n",
      "Epoch: 0062 train_loss= 0.6601 train_acc= 0.9429 val_loss= 0.9999 val_acc= 0.7633 time= 0.0188\n",
      "Epoch: 0063 train_loss= 0.6407 train_acc= 0.9429 val_loss= 0.9834 val_acc= 0.7633 time= 0.0195\n",
      "Epoch: 0064 train_loss= 0.6211 train_acc= 0.9429 val_loss= 0.9656 val_acc= 0.7600 time= 0.0233\n",
      "Epoch: 0065 train_loss= 0.6027 train_acc= 0.9571 val_loss= 0.9482 val_acc= 0.7600 time= 0.0201\n",
      "Epoch: 0066 train_loss= 0.5841 train_acc= 0.9571 val_loss= 0.9349 val_acc= 0.7567 time= 0.0243\n",
      "Epoch: 0067 train_loss= 0.5646 train_acc= 0.9643 val_loss= 0.9210 val_acc= 0.7667 time= 0.0286\n",
      "Epoch: 0068 train_loss= 0.5477 train_acc= 0.9643 val_loss= 0.9061 val_acc= 0.7733 time= 0.0205\n",
      "Epoch: 0069 train_loss= 0.5285 train_acc= 0.9643 val_loss= 0.8915 val_acc= 0.7767 time= 0.0216\n",
      "Epoch: 0070 train_loss= 0.5114 train_acc= 0.9643 val_loss= 0.8793 val_acc= 0.7867 time= 0.0238\n",
      "Epoch: 0071 train_loss= 0.4970 train_acc= 0.9643 val_loss= 0.8677 val_acc= 0.7933 time= 0.0193\n",
      "Epoch: 0072 train_loss= 0.4835 train_acc= 0.9643 val_loss= 0.8515 val_acc= 0.8033 time= 0.0205\n",
      "Epoch: 0073 train_loss= 0.4644 train_acc= 0.9643 val_loss= 0.8403 val_acc= 0.7967 time= 0.0243\n",
      "Epoch: 0074 train_loss= 0.4523 train_acc= 0.9643 val_loss= 0.8278 val_acc= 0.8033 time= 0.0191\n",
      "Epoch: 0075 train_loss= 0.4348 train_acc= 0.9643 val_loss= 0.8160 val_acc= 0.7967 time= 0.0194\n",
      "Epoch: 0076 train_loss= 0.4247 train_acc= 0.9643 val_loss= 0.8054 val_acc= 0.8000 time= 0.0191\n",
      "Epoch: 0077 train_loss= 0.4095 train_acc= 0.9643 val_loss= 0.7950 val_acc= 0.8033 time= 0.0196\n",
      "Epoch: 0078 train_loss= 0.3966 train_acc= 0.9643 val_loss= 0.7850 val_acc= 0.8067 time= 0.0194\n",
      "Epoch: 0079 train_loss= 0.3829 train_acc= 0.9643 val_loss= 0.7757 val_acc= 0.8067 time= 0.0237\n",
      "Epoch: 0080 train_loss= 0.3711 train_acc= 0.9714 val_loss= 0.7638 val_acc= 0.8100 time= 0.0209\n",
      "Epoch: 0081 train_loss= 0.3587 train_acc= 0.9786 val_loss= 0.7548 val_acc= 0.8100 time= 0.0185\n",
      "Epoch: 0082 train_loss= 0.3484 train_acc= 0.9786 val_loss= 0.7455 val_acc= 0.8167 time= 0.0190\n",
      "Epoch: 0083 train_loss= 0.3368 train_acc= 0.9857 val_loss= 0.7375 val_acc= 0.8133 time= 0.0188\n",
      "Epoch: 0084 train_loss= 0.3247 train_acc= 0.9857 val_loss= 0.7307 val_acc= 0.8133 time= 0.0193\n",
      "Epoch: 0085 train_loss= 0.3164 train_acc= 0.9857 val_loss= 0.7225 val_acc= 0.8133 time= 0.0193\n",
      "Epoch: 0086 train_loss= 0.3070 train_acc= 0.9857 val_loss= 0.7146 val_acc= 0.8133 time= 0.0181\n",
      "Epoch: 0087 train_loss= 0.2974 train_acc= 0.9857 val_loss= 0.7075 val_acc= 0.8133 time= 0.0191\n",
      "Epoch: 0088 train_loss= 0.2879 train_acc= 0.9857 val_loss= 0.7007 val_acc= 0.8100 time= 0.0188\n",
      "Epoch: 0089 train_loss= 0.2783 train_acc= 0.9857 val_loss= 0.6942 val_acc= 0.8133 time= 0.0188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0090 train_loss= 0.2704 train_acc= 0.9857 val_loss= 0.6881 val_acc= 0.8167 time= 0.0191\n",
      "Epoch: 0091 train_loss= 0.2619 train_acc= 0.9857 val_loss= 0.6816 val_acc= 0.8167 time= 0.0192\n",
      "Epoch: 0092 train_loss= 0.2534 train_acc= 0.9857 val_loss= 0.6757 val_acc= 0.8133 time= 0.0195\n",
      "Epoch: 0093 train_loss= 0.2468 train_acc= 0.9857 val_loss= 0.6684 val_acc= 0.8133 time= 0.0191\n",
      "Epoch: 0094 train_loss= 0.2396 train_acc= 0.9857 val_loss= 0.6646 val_acc= 0.8167 time= 0.0185\n",
      "Epoch: 0095 train_loss= 0.2324 train_acc= 0.9857 val_loss= 0.6591 val_acc= 0.8167 time= 0.0185\n",
      "Epoch: 0096 train_loss= 0.2256 train_acc= 0.9857 val_loss= 0.6569 val_acc= 0.8200 time= 0.0190\n",
      "Epoch: 0097 train_loss= 0.2193 train_acc= 0.9857 val_loss= 0.6503 val_acc= 0.8200 time= 0.0192\n",
      "Epoch: 0098 train_loss= 0.2131 train_acc= 0.9857 val_loss= 0.6472 val_acc= 0.8200 time= 0.0187\n",
      "Epoch: 0099 train_loss= 0.2064 train_acc= 0.9857 val_loss= 0.6449 val_acc= 0.8200 time= 0.0192\n",
      "Epoch: 0100 train_loss= 0.2011 train_acc= 0.9857 val_loss= 0.6409 val_acc= 0.8200 time= 0.0184\n",
      "Epoch: 0101 train_loss= 0.1961 train_acc= 0.9857 val_loss= 0.6383 val_acc= 0.8200 time= 0.0190\n",
      "Epoch: 0102 train_loss= 0.1908 train_acc= 0.9857 val_loss= 0.6356 val_acc= 0.8200 time= 0.0195\n",
      "Epoch: 0103 train_loss= 0.1835 train_acc= 0.9857 val_loss= 0.6341 val_acc= 0.8200 time= 0.0195\n",
      "Epoch: 0104 train_loss= 0.1799 train_acc= 0.9857 val_loss= 0.6287 val_acc= 0.8200 time= 0.0187\n",
      "Epoch: 0105 train_loss= 0.1753 train_acc= 0.9857 val_loss= 0.6260 val_acc= 0.8233 time= 0.0184\n",
      "Epoch: 0106 train_loss= 0.1698 train_acc= 0.9857 val_loss= 0.6223 val_acc= 0.8233 time= 0.0184\n",
      "Epoch: 0107 train_loss= 0.1656 train_acc= 0.9857 val_loss= 0.6216 val_acc= 0.8233 time= 0.0185\n",
      "Epoch: 0108 train_loss= 0.1619 train_acc= 0.9857 val_loss= 0.6190 val_acc= 0.8233 time= 0.0189\n",
      "Epoch: 0109 train_loss= 0.1573 train_acc= 0.9857 val_loss= 0.6151 val_acc= 0.8233 time= 0.0184\n",
      "Epoch: 0110 train_loss= 0.1535 train_acc= 0.9857 val_loss= 0.6129 val_acc= 0.8233 time= 0.0189\n",
      "Epoch: 0111 train_loss= 0.1493 train_acc= 0.9857 val_loss= 0.6108 val_acc= 0.8233 time= 0.0188\n",
      "Epoch: 0112 train_loss= 0.1460 train_acc= 0.9857 val_loss= 0.6090 val_acc= 0.8233 time= 0.0195\n",
      "Epoch: 0113 train_loss= 0.1421 train_acc= 0.9857 val_loss= 0.6063 val_acc= 0.8233 time= 0.0197\n",
      "Epoch: 0114 train_loss= 0.1385 train_acc= 0.9857 val_loss= 0.6045 val_acc= 0.8233 time= 0.0206\n",
      "Epoch: 0115 train_loss= 0.1352 train_acc= 0.9857 val_loss= 0.6029 val_acc= 0.8267 time= 0.0202\n",
      "Epoch: 0116 train_loss= 0.1330 train_acc= 0.9857 val_loss= 0.6010 val_acc= 0.8267 time= 0.0200\n",
      "Epoch: 0117 train_loss= 0.1290 train_acc= 0.9857 val_loss= 0.5986 val_acc= 0.8267 time= 0.0191\n",
      "Epoch: 0118 train_loss= 0.1260 train_acc= 0.9929 val_loss= 0.5975 val_acc= 0.8267 time= 0.0190\n",
      "Epoch: 0119 train_loss= 0.1227 train_acc= 0.9929 val_loss= 0.5979 val_acc= 0.8233 time= 0.0190\n",
      "Epoch: 0120 train_loss= 0.1203 train_acc= 0.9929 val_loss= 0.5957 val_acc= 0.8267 time= 0.0253\n",
      "Epoch: 0121 train_loss= 0.1176 train_acc= 0.9929 val_loss= 0.5940 val_acc= 0.8267 time= 0.0188\n",
      "Epoch: 0122 train_loss= 0.1145 train_acc= 0.9929 val_loss= 0.5947 val_acc= 0.8267 time= 0.0233\n",
      "Epoch: 0123 train_loss= 0.1122 train_acc= 0.9929 val_loss= 0.5926 val_acc= 0.8267 time= 0.0244\n",
      "Epoch: 0124 train_loss= 0.1098 train_acc= 0.9929 val_loss= 0.5932 val_acc= 0.8233 time= 0.0241\n",
      "Epoch: 0125 train_loss= 0.1080 train_acc= 0.9929 val_loss= 0.5922 val_acc= 0.8267 time= 0.0239\n",
      "Epoch: 0126 train_loss= 0.1050 train_acc= 0.9929 val_loss= 0.5908 val_acc= 0.8233 time= 0.0245\n",
      "Epoch: 0127 train_loss= 0.1023 train_acc= 0.9929 val_loss= 0.5905 val_acc= 0.8233 time= 0.0199\n",
      "Epoch: 0128 train_loss= 0.1008 train_acc= 0.9929 val_loss= 0.5892 val_acc= 0.8233 time= 0.0183\n",
      "Epoch: 0129 train_loss= 0.0977 train_acc= 0.9929 val_loss= 0.5895 val_acc= 0.8233 time= 0.0198\n",
      "Epoch: 0130 train_loss= 0.0962 train_acc= 0.9929 val_loss= 0.5889 val_acc= 0.8233 time= 0.0286\n",
      "Epoch: 0131 train_loss= 0.0945 train_acc= 0.9929 val_loss= 0.5880 val_acc= 0.8267 time= 0.0191\n",
      "Epoch: 0132 train_loss= 0.0922 train_acc= 0.9929 val_loss= 0.5883 val_acc= 0.8267 time= 0.0203\n",
      "Epoch: 0133 train_loss= 0.0905 train_acc= 0.9929 val_loss= 0.5890 val_acc= 0.8267 time= 0.0191\n",
      "Epoch: 0134 train_loss= 0.0884 train_acc= 0.9929 val_loss= 0.5877 val_acc= 0.8267 time= 0.0203\n",
      "Epoch: 0135 train_loss= 0.0865 train_acc= 0.9929 val_loss= 0.5867 val_acc= 0.8267 time= 0.0237\n",
      "Epoch: 0136 train_loss= 0.0850 train_acc= 0.9929 val_loss= 0.5882 val_acc= 0.8267 time= 0.0272\n",
      "Epoch: 0137 train_loss= 0.0834 train_acc= 0.9929 val_loss= 0.5857 val_acc= 0.8267 time= 0.0303\n",
      "Epoch: 0138 train_loss= 0.0817 train_acc= 0.9929 val_loss= 0.5856 val_acc= 0.8267 time= 0.0257\n",
      "Epoch: 0139 train_loss= 0.0803 train_acc= 0.9929 val_loss= 0.5865 val_acc= 0.8267 time= 0.0239\n",
      "Epoch: 0140 train_loss= 0.0784 train_acc= 0.9929 val_loss= 0.5851 val_acc= 0.8267 time= 0.0269\n",
      "Epoch: 0141 train_loss= 0.0768 train_acc= 0.9929 val_loss= 0.5846 val_acc= 0.8267 time= 0.0201\n",
      "Epoch: 0142 train_loss= 0.0757 train_acc= 0.9929 val_loss= 0.5835 val_acc= 0.8267 time= 0.0237\n",
      "Epoch: 0143 train_loss= 0.0741 train_acc= 0.9929 val_loss= 0.5843 val_acc= 0.8267 time= 0.0264\n",
      "Epoch: 0144 train_loss= 0.0732 train_acc= 0.9929 val_loss= 0.5840 val_acc= 0.8267 time= 0.0239\n",
      "Epoch: 0145 train_loss= 0.0718 train_acc= 1.0000 val_loss= 0.5842 val_acc= 0.8267 time= 0.0242\n",
      "Epoch: 0146 train_loss= 0.0701 train_acc= 1.0000 val_loss= 0.5842 val_acc= 0.8267 time= 0.0237\n",
      "Epoch: 0147 train_loss= 0.0682 train_acc= 1.0000 val_loss= 0.5857 val_acc= 0.8267 time= 0.0186\n",
      "Epoch: 0148 train_loss= 0.0674 train_acc= 1.0000 val_loss= 0.5824 val_acc= 0.8267 time= 0.0189\n",
      "Epoch: 0149 train_loss= 0.0668 train_acc= 0.9929 val_loss= 0.5844 val_acc= 0.8267 time= 0.0199\n",
      "Epoch: 0150 train_loss= 0.0657 train_acc= 1.0000 val_loss= 0.5832 val_acc= 0.8267 time= 0.0191\n",
      "Epoch: 0151 train_loss= 0.0636 train_acc= 1.0000 val_loss= 0.5832 val_acc= 0.8233 time= 0.0294\n",
      "Epoch: 0152 train_loss= 0.0627 train_acc= 1.0000 val_loss= 0.5831 val_acc= 0.8267 time= 0.0251\n",
      "Epoch: 0153 train_loss= 0.0620 train_acc= 1.0000 val_loss= 0.5826 val_acc= 0.8267 time= 0.0234\n",
      "Epoch: 0154 train_loss= 0.0609 train_acc= 1.0000 val_loss= 0.5830 val_acc= 0.8267 time= 0.0232\n",
      "Epoch: 0155 train_loss= 0.0602 train_acc= 1.0000 val_loss= 0.5825 val_acc= 0.8233 time= 0.0204\n",
      "Epoch: 0156 train_loss= 0.0589 train_acc= 1.0000 val_loss= 0.5829 val_acc= 0.8233 time= 0.0290\n",
      "Epoch: 0157 train_loss= 0.0579 train_acc= 1.0000 val_loss= 0.5833 val_acc= 0.8233 time= 0.0242\n",
      "Epoch: 0158 train_loss= 0.0573 train_acc= 1.0000 val_loss= 0.5833 val_acc= 0.8233 time= 0.0240\n",
      "Epoch: 0159 train_loss= 0.0559 train_acc= 1.0000 val_loss= 0.5834 val_acc= 0.8233 time= 0.0195\n",
      "Epoch 159: early stopping\n"
     ]
    }
   ],
   "source": [
    "NB_EPOCH = 200\n",
    "PATIENCE = 10  # early stopping patience\n",
    "# Helper variables for main training loop\n",
    "wait = 0\n",
    "preds = None\n",
    "best_val_loss = 99999\n",
    "\n",
    "# Fit\n",
    "for epoch in range(1, NB_EPOCH+1):\n",
    "\n",
    "    # Log wall-clock time\n",
    "    t = time.time()\n",
    "\n",
    "    # Single training iteration (we mask nodes without labels for loss calculation)\n",
    "    model.fit(graph, y_train, sample_weight=train_mask,\n",
    "              batch_size=A.shape[0], epochs=1, shuffle=False, verbose=0)\n",
    "\n",
    "    # Predict on full dataset\n",
    "    preds = model.predict(graph, batch_size=A.shape[0])\n",
    "\n",
    "    # Train / validation scores\n",
    "    train_val_loss, train_val_acc = evaluate_preds(preds, [y_train, y_val],\n",
    "                                                   [idx_train, idx_val])\n",
    "    print(\"Epoch: {:04d}\".format(epoch),\n",
    "          \"train_loss= {:.4f}\".format(train_val_loss[0]),\n",
    "          \"train_acc= {:.4f}\".format(train_val_acc[0]),\n",
    "          \"val_loss= {:.4f}\".format(train_val_loss[1]),\n",
    "          \"val_acc= {:.4f}\".format(train_val_acc[1]),\n",
    "          \"time= {:.4f}\".format(time.time() - t))\n",
    "\n",
    "    # Early stopping\n",
    "    if train_val_loss[1] < best_val_loss:\n",
    "        best_val_loss = train_val_loss[1]\n",
    "        wait = 0\n",
    "    else:\n",
    "        if wait >= PATIENCE:\n",
    "            print('Epoch {}: early stopping'.format(epoch))\n",
    "            break\n",
    "        wait += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.6061\n",
      "accuracy = 0.8090\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate_preds(preds, [y_test], [idx_test])\n",
    "print(f\"\"\"\n",
    "loss = {test_loss[0]:.4f}\n",
    "accuracy = {test_acc[0]:.4f}\n",
    "\"\"\".strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
