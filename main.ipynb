{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from keras.layers import Input, Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the path of execution\n",
    "EXE_PATH = os.path.abspath(os.path.curdir)\n",
    "# the path of the vendor files\n",
    "VENDOR_PATH = os.path.join(EXE_PATH, 'vendor')\n",
    "# the vendors to include in the system path\n",
    "VENDORS = ['keras-gcn']\n",
    "# create the absolute paths for all vendors\n",
    "VENDORS = list(map(lambda x: os.path.join(VENDOR_PATH, x), VENDORS))\n",
    "# update the Python path to include necessary vendor module\n",
    "sys.path += VENDORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kegra.layers.graph import GraphConvolution\n",
    "from kegra.utils import load_data, preprocess_adj, get_splits, evaluate_preds\n",
    "from ggcn import GaussianGraphConvolution, kl_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cora dataset...\n",
      "Dataset has 2708 nodes, 5429 edges, 1433 features.\n"
     ]
    }
   ],
   "source": [
    "X, A, y = load_data('data/cora/', dataset='cora')\n",
    "X /= X.sum(1).reshape(-1, 1)\n",
    "A = preprocess_adj(A)\n",
    "y_train, y_val, y_test, idx_train, idx_val, idx_test, train_mask = get_splits(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2708x2708 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 13264 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 1, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 1, 0]], dtype=int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1110 18:01:24.696360 139652427728704 deprecation_wrapper.py:119] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1110 18:01:24.703412 139652427728704 deprecation_wrapper.py:119] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:515: The name tf.sparse_placeholder is deprecated. Please use tf.compat.v1.sparse_placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "support = 1\n",
    "graph = [X, A]\n",
    "G = [Input(shape=(None, None), batch_shape=(None, None), sparse=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1110 18:01:24.708506 139652427728704 deprecation_wrapper.py:119] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_in = Input(shape=(X.shape[1],))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCN (baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1110 18:01:24.714673 139652427728704 deprecation_wrapper.py:119] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W1110 18:01:24.720474 139652427728704 deprecation.py:506] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W1110 18:01:24.728435 139652427728704 deprecation_wrapper.py:119] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define model architecture\n",
    "# NOTE: We pass arguments for graph convolutional layers as a list of tensors.\n",
    "# This is somewhat hacky, more elegant options would require rewriting the Layer base class.\n",
    "H = Dropout(0.5)(X_in)\n",
    "H = GraphConvolution(32, support, activation='relu', kernel_regularizer=l2(5e-4))([H]+G)\n",
    "H = Dropout(0.5)(H)\n",
    "Y = GraphConvolution(y.shape[1], support, activation='softmax')([H]+G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1110 18:01:24.769569 139652427728704 deprecation_wrapper.py:119] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=[X_in]+G, outputs=Y)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 1433)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1433)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "graph_convolution_1 (GraphConvo (None, 32)           45888       dropout_1[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 32)           0           graph_convolution_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "graph_convolution_2 (GraphConvo (None, 7)            231         dropout_2[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 46,119\n",
      "Trainable params: 46,119\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1110 18:01:24.843519 139652427728704 deprecation.py:323] From /home/bitcommander/.local/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 train_loss= 1.9283 train_acc= 0.3286 val_loss= 1.9319 val_acc= 0.2833 time= 1.0792\n",
      "Epoch: 0002 train_loss= 1.9100 train_acc= 0.3857 val_loss= 1.9168 val_acc= 0.3400 time= 0.0171\n",
      "Epoch: 0003 train_loss= 1.8907 train_acc= 0.4143 val_loss= 1.9011 val_acc= 0.3800 time= 0.0167\n",
      "Epoch: 0004 train_loss= 1.8702 train_acc= 0.4643 val_loss= 1.8844 val_acc= 0.4200 time= 0.0163\n",
      "Epoch: 0005 train_loss= 1.8497 train_acc= 0.4786 val_loss= 1.8677 val_acc= 0.4433 time= 0.0173\n",
      "Epoch: 0006 train_loss= 1.8292 train_acc= 0.4929 val_loss= 1.8509 val_acc= 0.4667 time= 0.0169\n",
      "Epoch: 0007 train_loss= 1.8087 train_acc= 0.4786 val_loss= 1.8344 val_acc= 0.4633 time= 0.0165\n",
      "Epoch: 0008 train_loss= 1.7891 train_acc= 0.4714 val_loss= 1.8187 val_acc= 0.4733 time= 0.0173\n",
      "Epoch: 0009 train_loss= 1.7704 train_acc= 0.4643 val_loss= 1.8039 val_acc= 0.4633 time= 0.0165\n",
      "Epoch: 0010 train_loss= 1.7528 train_acc= 0.4571 val_loss= 1.7902 val_acc= 0.4467 time= 0.0166\n",
      "Epoch: 0011 train_loss= 1.7365 train_acc= 0.4500 val_loss= 1.7779 val_acc= 0.4200 time= 0.0173\n",
      "Epoch: 0012 train_loss= 1.7217 train_acc= 0.4500 val_loss= 1.7669 val_acc= 0.4133 time= 0.0169\n",
      "Epoch: 0013 train_loss= 1.7082 train_acc= 0.4429 val_loss= 1.7571 val_acc= 0.4133 time= 0.0165\n",
      "Epoch: 0014 train_loss= 1.6956 train_acc= 0.4286 val_loss= 1.7479 val_acc= 0.4067 time= 0.0171\n",
      "Epoch: 0015 train_loss= 1.6835 train_acc= 0.4286 val_loss= 1.7392 val_acc= 0.3900 time= 0.0177\n",
      "Epoch: 0016 train_loss= 1.6715 train_acc= 0.4214 val_loss= 1.7307 val_acc= 0.3767 time= 0.0171\n",
      "Epoch: 0017 train_loss= 1.6591 train_acc= 0.4214 val_loss= 1.7219 val_acc= 0.3733 time= 0.0170\n",
      "Epoch: 0018 train_loss= 1.6461 train_acc= 0.4214 val_loss= 1.7129 val_acc= 0.3733 time= 0.0172\n",
      "Epoch: 0019 train_loss= 1.6325 train_acc= 0.4214 val_loss= 1.7036 val_acc= 0.3767 time= 0.0176\n",
      "Epoch: 0020 train_loss= 1.6183 train_acc= 0.4214 val_loss= 1.6939 val_acc= 0.3867 time= 0.0169\n",
      "Epoch: 0021 train_loss= 1.6035 train_acc= 0.4286 val_loss= 1.6840 val_acc= 0.3900 time= 0.0177\n",
      "Epoch: 0022 train_loss= 1.5887 train_acc= 0.4429 val_loss= 1.6739 val_acc= 0.4033 time= 0.0169\n",
      "Epoch: 0023 train_loss= 1.5739 train_acc= 0.4500 val_loss= 1.6637 val_acc= 0.4067 time= 0.0180\n",
      "Epoch: 0024 train_loss= 1.5589 train_acc= 0.4571 val_loss= 1.6535 val_acc= 0.4200 time= 0.0170\n",
      "Epoch: 0025 train_loss= 1.5439 train_acc= 0.4857 val_loss= 1.6433 val_acc= 0.4367 time= 0.0169\n",
      "Epoch: 0026 train_loss= 1.5287 train_acc= 0.4929 val_loss= 1.6330 val_acc= 0.4467 time= 0.0179\n",
      "Epoch: 0027 train_loss= 1.5136 train_acc= 0.5286 val_loss= 1.6226 val_acc= 0.4700 time= 0.0172\n",
      "Epoch: 0028 train_loss= 1.4983 train_acc= 0.5357 val_loss= 1.6119 val_acc= 0.4867 time= 0.0169\n",
      "Epoch: 0029 train_loss= 1.4831 train_acc= 0.5571 val_loss= 1.6013 val_acc= 0.5033 time= 0.0169\n",
      "Epoch: 0030 train_loss= 1.4677 train_acc= 0.5571 val_loss= 1.5904 val_acc= 0.5067 time= 0.0171\n",
      "Epoch: 0031 train_loss= 1.4522 train_acc= 0.5571 val_loss= 1.5791 val_acc= 0.5067 time= 0.0178\n",
      "Epoch: 0032 train_loss= 1.4366 train_acc= 0.5643 val_loss= 1.5678 val_acc= 0.5133 time= 0.0183\n",
      "Epoch: 0033 train_loss= 1.4211 train_acc= 0.5714 val_loss= 1.5566 val_acc= 0.5133 time= 0.0165\n",
      "Epoch: 0034 train_loss= 1.4056 train_acc= 0.6000 val_loss= 1.5453 val_acc= 0.5167 time= 0.0164\n",
      "Epoch: 0035 train_loss= 1.3902 train_acc= 0.6000 val_loss= 1.5337 val_acc= 0.5200 time= 0.0172\n",
      "Epoch: 0036 train_loss= 1.3747 train_acc= 0.6071 val_loss= 1.5217 val_acc= 0.5233 time= 0.0169\n",
      "Epoch: 0037 train_loss= 1.3593 train_acc= 0.6000 val_loss= 1.5098 val_acc= 0.5300 time= 0.0168\n",
      "Epoch: 0038 train_loss= 1.3440 train_acc= 0.6000 val_loss= 1.4982 val_acc= 0.5333 time= 0.0166\n",
      "Epoch: 0039 train_loss= 1.3287 train_acc= 0.6143 val_loss= 1.4866 val_acc= 0.5367 time= 0.0169\n",
      "Epoch: 0040 train_loss= 1.3134 train_acc= 0.6286 val_loss= 1.4750 val_acc= 0.5400 time= 0.0177\n",
      "Epoch: 0041 train_loss= 1.2983 train_acc= 0.6429 val_loss= 1.4635 val_acc= 0.5467 time= 0.0165\n",
      "Epoch: 0042 train_loss= 1.2834 train_acc= 0.6500 val_loss= 1.4524 val_acc= 0.5533 time= 0.0167\n",
      "Epoch: 0043 train_loss= 1.2686 train_acc= 0.6500 val_loss= 1.4414 val_acc= 0.5633 time= 0.0167\n",
      "Epoch: 0044 train_loss= 1.2540 train_acc= 0.6500 val_loss= 1.4306 val_acc= 0.5733 time= 0.0168\n",
      "Epoch: 0045 train_loss= 1.2396 train_acc= 0.6643 val_loss= 1.4200 val_acc= 0.5733 time= 0.0161\n",
      "Epoch: 0046 train_loss= 1.2254 train_acc= 0.6643 val_loss= 1.4094 val_acc= 0.5767 time= 0.0165\n",
      "Epoch: 0047 train_loss= 1.2112 train_acc= 0.6714 val_loss= 1.3987 val_acc= 0.5800 time= 0.0182\n",
      "Epoch: 0048 train_loss= 1.1971 train_acc= 0.6857 val_loss= 1.3880 val_acc= 0.5833 time= 0.0164\n",
      "Epoch: 0049 train_loss= 1.1832 train_acc= 0.6929 val_loss= 1.3774 val_acc= 0.5967 time= 0.0169\n",
      "Epoch: 0050 train_loss= 1.1695 train_acc= 0.7143 val_loss= 1.3666 val_acc= 0.6100 time= 0.0168\n",
      "Epoch: 0051 train_loss= 1.1562 train_acc= 0.7143 val_loss= 1.3559 val_acc= 0.6200 time= 0.0172\n",
      "Epoch: 0052 train_loss= 1.1427 train_acc= 0.7143 val_loss= 1.3451 val_acc= 0.6233 time= 0.0180\n",
      "Epoch: 0053 train_loss= 1.1296 train_acc= 0.7143 val_loss= 1.3344 val_acc= 0.6333 time= 0.0208\n",
      "Epoch: 0054 train_loss= 1.1166 train_acc= 0.7214 val_loss= 1.3233 val_acc= 0.6333 time= 0.0222\n",
      "Epoch: 0055 train_loss= 1.1039 train_acc= 0.7286 val_loss= 1.3125 val_acc= 0.6333 time= 0.0175\n",
      "Epoch: 0056 train_loss= 1.0913 train_acc= 0.7286 val_loss= 1.3024 val_acc= 0.6300 time= 0.0179\n",
      "Epoch: 0057 train_loss= 1.0790 train_acc= 0.7500 val_loss= 1.2929 val_acc= 0.6367 time= 0.0178\n",
      "Epoch: 0058 train_loss= 1.0669 train_acc= 0.7571 val_loss= 1.2838 val_acc= 0.6600 time= 0.0174\n",
      "Epoch: 0059 train_loss= 1.0551 train_acc= 0.7714 val_loss= 1.2750 val_acc= 0.6733 time= 0.0179\n",
      "Epoch: 0060 train_loss= 1.0432 train_acc= 0.7786 val_loss= 1.2659 val_acc= 0.6833 time= 0.0184\n",
      "Epoch: 0061 train_loss= 1.0317 train_acc= 0.7786 val_loss= 1.2573 val_acc= 0.7033 time= 0.0176\n",
      "Epoch: 0062 train_loss= 1.0206 train_acc= 0.7857 val_loss= 1.2484 val_acc= 0.7000 time= 0.0169\n",
      "Epoch: 0063 train_loss= 1.0098 train_acc= 0.7929 val_loss= 1.2400 val_acc= 0.7033 time= 0.0181\n",
      "Epoch: 0064 train_loss= 0.9994 train_acc= 0.8000 val_loss= 1.2318 val_acc= 0.7000 time= 0.0168\n",
      "Epoch: 0065 train_loss= 0.9891 train_acc= 0.7857 val_loss= 1.2238 val_acc= 0.7000 time= 0.0160\n",
      "Epoch: 0066 train_loss= 0.9786 train_acc= 0.8000 val_loss= 1.2160 val_acc= 0.7000 time= 0.0163\n",
      "Epoch: 0067 train_loss= 0.9680 train_acc= 0.8143 val_loss= 1.2082 val_acc= 0.7033 time= 0.0161\n",
      "Epoch: 0068 train_loss= 0.9577 train_acc= 0.8214 val_loss= 1.2011 val_acc= 0.7000 time= 0.0175\n",
      "Epoch: 0069 train_loss= 0.9477 train_acc= 0.8214 val_loss= 1.1936 val_acc= 0.7000 time= 0.0165\n",
      "Epoch: 0070 train_loss= 0.9376 train_acc= 0.8214 val_loss= 1.1853 val_acc= 0.7033 time= 0.0166\n",
      "Epoch: 0071 train_loss= 0.9280 train_acc= 0.8214 val_loss= 1.1774 val_acc= 0.7000 time= 0.0176\n",
      "Epoch: 0072 train_loss= 0.9186 train_acc= 0.8214 val_loss= 1.1691 val_acc= 0.6967 time= 0.0181\n",
      "Epoch: 0073 train_loss= 0.9095 train_acc= 0.8214 val_loss= 1.1604 val_acc= 0.7033 time= 0.0206\n",
      "Epoch: 0074 train_loss= 0.9005 train_acc= 0.8214 val_loss= 1.1522 val_acc= 0.7067 time= 0.0170\n",
      "Epoch: 0075 train_loss= 0.8917 train_acc= 0.8214 val_loss= 1.1445 val_acc= 0.7067 time= 0.0175\n",
      "Epoch: 0076 train_loss= 0.8828 train_acc= 0.8214 val_loss= 1.1372 val_acc= 0.7067 time= 0.0169\n",
      "Epoch: 0077 train_loss= 0.8736 train_acc= 0.8214 val_loss= 1.1306 val_acc= 0.7033 time= 0.0166\n",
      "Epoch: 0078 train_loss= 0.8645 train_acc= 0.8429 val_loss= 1.1242 val_acc= 0.7133 time= 0.0165\n",
      "Epoch: 0079 train_loss= 0.8559 train_acc= 0.8429 val_loss= 1.1180 val_acc= 0.7100 time= 0.0166\n",
      "Epoch: 0080 train_loss= 0.8476 train_acc= 0.8500 val_loss= 1.1119 val_acc= 0.7100 time= 0.0164\n",
      "Epoch: 0081 train_loss= 0.8393 train_acc= 0.8500 val_loss= 1.1058 val_acc= 0.7200 time= 0.0175\n",
      "Epoch: 0082 train_loss= 0.8311 train_acc= 0.8571 val_loss= 1.0995 val_acc= 0.7167 time= 0.0170\n",
      "Epoch: 0083 train_loss= 0.8229 train_acc= 0.8571 val_loss= 1.0934 val_acc= 0.7233 time= 0.0172\n",
      "Epoch: 0084 train_loss= 0.8148 train_acc= 0.8571 val_loss= 1.0867 val_acc= 0.7233 time= 0.0190\n",
      "Epoch: 0085 train_loss= 0.8069 train_acc= 0.8571 val_loss= 1.0805 val_acc= 0.7233 time= 0.0180\n",
      "Epoch: 0086 train_loss= 0.7992 train_acc= 0.8571 val_loss= 1.0740 val_acc= 0.7300 time= 0.0168\n",
      "Epoch: 0087 train_loss= 0.7918 train_acc= 0.8786 val_loss= 1.0679 val_acc= 0.7400 time= 0.0170\n",
      "Epoch: 0088 train_loss= 0.7845 train_acc= 0.8786 val_loss= 1.0611 val_acc= 0.7467 time= 0.0171\n",
      "Epoch: 0089 train_loss= 0.7773 train_acc= 0.8786 val_loss= 1.0548 val_acc= 0.7467 time= 0.0169\n",
      "Epoch: 0090 train_loss= 0.7704 train_acc= 0.8786 val_loss= 1.0491 val_acc= 0.7400 time= 0.0166\n",
      "Epoch: 0091 train_loss= 0.7633 train_acc= 0.8786 val_loss= 1.0435 val_acc= 0.7433 time= 0.0166\n",
      "Epoch: 0092 train_loss= 0.7559 train_acc= 0.8786 val_loss= 1.0382 val_acc= 0.7533 time= 0.0170\n",
      "Epoch: 0093 train_loss= 0.7491 train_acc= 0.8786 val_loss= 1.0334 val_acc= 0.7467 time= 0.0169\n",
      "Epoch: 0094 train_loss= 0.7427 train_acc= 0.8857 val_loss= 1.0292 val_acc= 0.7500 time= 0.0168\n",
      "Epoch: 0095 train_loss= 0.7362 train_acc= 0.8857 val_loss= 1.0247 val_acc= 0.7500 time= 0.0176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0096 train_loss= 0.7298 train_acc= 0.8857 val_loss= 1.0197 val_acc= 0.7500 time= 0.0182\n",
      "Epoch: 0097 train_loss= 0.7234 train_acc= 0.8857 val_loss= 1.0142 val_acc= 0.7533 time= 0.0188\n",
      "Epoch: 0098 train_loss= 0.7172 train_acc= 0.8857 val_loss= 1.0093 val_acc= 0.7533 time= 0.0171\n",
      "Epoch: 0099 train_loss= 0.7110 train_acc= 0.8929 val_loss= 1.0045 val_acc= 0.7567 time= 0.0164\n",
      "Epoch: 0100 train_loss= 0.7046 train_acc= 0.8929 val_loss= 0.9993 val_acc= 0.7633 time= 0.0170\n",
      "Epoch: 0101 train_loss= 0.6986 train_acc= 0.9000 val_loss= 0.9940 val_acc= 0.7600 time= 0.0167\n",
      "Epoch: 0102 train_loss= 0.6930 train_acc= 0.9000 val_loss= 0.9892 val_acc= 0.7533 time= 0.0165\n",
      "Epoch: 0103 train_loss= 0.6874 train_acc= 0.9071 val_loss= 0.9846 val_acc= 0.7600 time= 0.0166\n",
      "Epoch: 0104 train_loss= 0.6816 train_acc= 0.9071 val_loss= 0.9795 val_acc= 0.7600 time= 0.0166\n",
      "Epoch: 0105 train_loss= 0.6757 train_acc= 0.9071 val_loss= 0.9744 val_acc= 0.7667 time= 0.0165\n",
      "Epoch: 0106 train_loss= 0.6698 train_acc= 0.9071 val_loss= 0.9696 val_acc= 0.7700 time= 0.0166\n",
      "Epoch: 0107 train_loss= 0.6647 train_acc= 0.9071 val_loss= 0.9645 val_acc= 0.7767 time= 0.0169\n",
      "Epoch: 0108 train_loss= 0.6597 train_acc= 0.9071 val_loss= 0.9602 val_acc= 0.7833 time= 0.0171\n",
      "Epoch: 0109 train_loss= 0.6545 train_acc= 0.9071 val_loss= 0.9566 val_acc= 0.7900 time= 0.0170\n",
      "Epoch: 0110 train_loss= 0.6481 train_acc= 0.9143 val_loss= 0.9529 val_acc= 0.7900 time= 0.0173\n",
      "Epoch: 0111 train_loss= 0.6424 train_acc= 0.9143 val_loss= 0.9495 val_acc= 0.7800 time= 0.0165\n",
      "Epoch: 0112 train_loss= 0.6373 train_acc= 0.9214 val_loss= 0.9475 val_acc= 0.7800 time= 0.0169\n",
      "Epoch: 0113 train_loss= 0.6324 train_acc= 0.9214 val_loss= 0.9452 val_acc= 0.7767 time= 0.0171\n",
      "Epoch: 0114 train_loss= 0.6277 train_acc= 0.9214 val_loss= 0.9420 val_acc= 0.7733 time= 0.0176\n",
      "Epoch: 0115 train_loss= 0.6226 train_acc= 0.9214 val_loss= 0.9373 val_acc= 0.7733 time= 0.0173\n",
      "Epoch: 0116 train_loss= 0.6179 train_acc= 0.9214 val_loss= 0.9330 val_acc= 0.7733 time= 0.0172\n",
      "Epoch: 0117 train_loss= 0.6135 train_acc= 0.9143 val_loss= 0.9288 val_acc= 0.7833 time= 0.0178\n",
      "Epoch: 0118 train_loss= 0.6093 train_acc= 0.9143 val_loss= 0.9253 val_acc= 0.7867 time= 0.0176\n",
      "Epoch: 0119 train_loss= 0.6056 train_acc= 0.9143 val_loss= 0.9214 val_acc= 0.7833 time= 0.0163\n",
      "Epoch: 0120 train_loss= 0.6014 train_acc= 0.9143 val_loss= 0.9176 val_acc= 0.7833 time= 0.0167\n",
      "Epoch: 0121 train_loss= 0.5964 train_acc= 0.9143 val_loss= 0.9139 val_acc= 0.7967 time= 0.0173\n",
      "Epoch: 0122 train_loss= 0.5914 train_acc= 0.9143 val_loss= 0.9100 val_acc= 0.8033 time= 0.0168\n",
      "Epoch: 0123 train_loss= 0.5858 train_acc= 0.9214 val_loss= 0.9049 val_acc= 0.8033 time= 0.0164\n",
      "Epoch: 0124 train_loss= 0.5807 train_acc= 0.9286 val_loss= 0.9013 val_acc= 0.8000 time= 0.0164\n",
      "Epoch: 0125 train_loss= 0.5766 train_acc= 0.9357 val_loss= 0.8985 val_acc= 0.7867 time= 0.0161\n",
      "Epoch: 0126 train_loss= 0.5728 train_acc= 0.9357 val_loss= 0.8954 val_acc= 0.7867 time= 0.0163\n",
      "Epoch: 0127 train_loss= 0.5690 train_acc= 0.9357 val_loss= 0.8925 val_acc= 0.7867 time= 0.0164\n",
      "Epoch: 0128 train_loss= 0.5650 train_acc= 0.9357 val_loss= 0.8894 val_acc= 0.7867 time= 0.0174\n",
      "Epoch: 0129 train_loss= 0.5601 train_acc= 0.9357 val_loss= 0.8852 val_acc= 0.7867 time= 0.0164\n",
      "Epoch: 0130 train_loss= 0.5562 train_acc= 0.9286 val_loss= 0.8803 val_acc= 0.7933 time= 0.0176\n",
      "Epoch: 0131 train_loss= 0.5530 train_acc= 0.9357 val_loss= 0.8765 val_acc= 0.7967 time= 0.0165\n",
      "Epoch: 0132 train_loss= 0.5495 train_acc= 0.9429 val_loss= 0.8731 val_acc= 0.7967 time= 0.0170\n",
      "Epoch: 0133 train_loss= 0.5461 train_acc= 0.9357 val_loss= 0.8707 val_acc= 0.7933 time= 0.0166\n",
      "Epoch: 0134 train_loss= 0.5417 train_acc= 0.9429 val_loss= 0.8686 val_acc= 0.8033 time= 0.0173\n",
      "Epoch: 0135 train_loss= 0.5375 train_acc= 0.9357 val_loss= 0.8673 val_acc= 0.8033 time= 0.0189\n",
      "Epoch: 0136 train_loss= 0.5337 train_acc= 0.9357 val_loss= 0.8666 val_acc= 0.8000 time= 0.0166\n",
      "Epoch: 0137 train_loss= 0.5301 train_acc= 0.9357 val_loss= 0.8657 val_acc= 0.7900 time= 0.0165\n",
      "Epoch: 0138 train_loss= 0.5268 train_acc= 0.9429 val_loss= 0.8647 val_acc= 0.7833 time= 0.0170\n",
      "Epoch: 0139 train_loss= 0.5229 train_acc= 0.9429 val_loss= 0.8615 val_acc= 0.7867 time= 0.0174\n",
      "Epoch: 0140 train_loss= 0.5191 train_acc= 0.9429 val_loss= 0.8575 val_acc= 0.7867 time= 0.0171\n",
      "Epoch: 0141 train_loss= 0.5157 train_acc= 0.9571 val_loss= 0.8528 val_acc= 0.7933 time= 0.0165\n",
      "Epoch: 0142 train_loss= 0.5128 train_acc= 0.9571 val_loss= 0.8492 val_acc= 0.7933 time= 0.0181\n",
      "Epoch: 0143 train_loss= 0.5101 train_acc= 0.9571 val_loss= 0.8460 val_acc= 0.7933 time= 0.0165\n",
      "Epoch: 0144 train_loss= 0.5075 train_acc= 0.9571 val_loss= 0.8442 val_acc= 0.8100 time= 0.0169\n",
      "Epoch: 0145 train_loss= 0.5047 train_acc= 0.9500 val_loss= 0.8437 val_acc= 0.8133 time= 0.0168\n",
      "Epoch: 0146 train_loss= 0.5018 train_acc= 0.9500 val_loss= 0.8429 val_acc= 0.8167 time= 0.0163\n",
      "Epoch: 0147 train_loss= 0.4982 train_acc= 0.9571 val_loss= 0.8412 val_acc= 0.8200 time= 0.0166\n",
      "Epoch: 0148 train_loss= 0.4957 train_acc= 0.9643 val_loss= 0.8396 val_acc= 0.8133 time= 0.0168\n",
      "Epoch: 0149 train_loss= 0.4931 train_acc= 0.9643 val_loss= 0.8376 val_acc= 0.8100 time= 0.0168\n",
      "Epoch: 0150 train_loss= 0.4896 train_acc= 0.9643 val_loss= 0.8326 val_acc= 0.8033 time= 0.0167\n",
      "Epoch: 0151 train_loss= 0.4860 train_acc= 0.9571 val_loss= 0.8262 val_acc= 0.7967 time= 0.0164\n",
      "Epoch: 0152 train_loss= 0.4831 train_acc= 0.9571 val_loss= 0.8208 val_acc= 0.8033 time= 0.0163\n",
      "Epoch: 0153 train_loss= 0.4817 train_acc= 0.9500 val_loss= 0.8183 val_acc= 0.8000 time= 0.0166\n",
      "Epoch: 0154 train_loss= 0.4803 train_acc= 0.9429 val_loss= 0.8171 val_acc= 0.7967 time= 0.0168\n",
      "Epoch: 0155 train_loss= 0.4768 train_acc= 0.9571 val_loss= 0.8156 val_acc= 0.7967 time= 0.0175\n",
      "Epoch: 0156 train_loss= 0.4722 train_acc= 0.9571 val_loss= 0.8147 val_acc= 0.7967 time= 0.0178\n",
      "Epoch: 0157 train_loss= 0.4683 train_acc= 0.9571 val_loss= 0.8149 val_acc= 0.8000 time= 0.0173\n",
      "Epoch: 0158 train_loss= 0.4657 train_acc= 0.9643 val_loss= 0.8171 val_acc= 0.8000 time= 0.0174\n",
      "Epoch: 0159 train_loss= 0.4632 train_acc= 0.9643 val_loss= 0.8180 val_acc= 0.8000 time= 0.0177\n",
      "Epoch: 0160 train_loss= 0.4602 train_acc= 0.9643 val_loss= 0.8166 val_acc= 0.8033 time= 0.0167\n",
      "Epoch: 0161 train_loss= 0.4567 train_acc= 0.9643 val_loss= 0.8129 val_acc= 0.8100 time= 0.0170\n",
      "Epoch: 0162 train_loss= 0.4533 train_acc= 0.9643 val_loss= 0.8079 val_acc= 0.8100 time= 0.0168\n",
      "Epoch: 0163 train_loss= 0.4509 train_acc= 0.9643 val_loss= 0.8032 val_acc= 0.8100 time= 0.0170\n",
      "Epoch: 0164 train_loss= 0.4493 train_acc= 0.9643 val_loss= 0.7998 val_acc= 0.8167 time= 0.0176\n",
      "Epoch: 0165 train_loss= 0.4475 train_acc= 0.9714 val_loss= 0.7978 val_acc= 0.8167 time= 0.0164\n",
      "Epoch: 0166 train_loss= 0.4460 train_acc= 0.9714 val_loss= 0.7958 val_acc= 0.8233 time= 0.0167\n",
      "Epoch: 0167 train_loss= 0.4443 train_acc= 0.9714 val_loss= 0.7942 val_acc= 0.8333 time= 0.0172\n",
      "Epoch: 0168 train_loss= 0.4419 train_acc= 0.9714 val_loss= 0.7929 val_acc= 0.8267 time= 0.0184\n",
      "Epoch: 0169 train_loss= 0.4388 train_acc= 0.9714 val_loss= 0.7926 val_acc= 0.8267 time= 0.0212\n",
      "Epoch: 0170 train_loss= 0.4360 train_acc= 0.9714 val_loss= 0.7935 val_acc= 0.8233 time= 0.0166\n",
      "Epoch: 0171 train_loss= 0.4337 train_acc= 0.9714 val_loss= 0.7950 val_acc= 0.8233 time= 0.0166\n",
      "Epoch: 0172 train_loss= 0.4326 train_acc= 0.9714 val_loss= 0.7986 val_acc= 0.8200 time= 0.0168\n",
      "Epoch: 0173 train_loss= 0.4317 train_acc= 0.9714 val_loss= 0.8015 val_acc= 0.8167 time= 0.0170\n",
      "Epoch: 0174 train_loss= 0.4299 train_acc= 0.9714 val_loss= 0.8002 val_acc= 0.8133 time= 0.0170\n",
      "Epoch: 0175 train_loss= 0.4274 train_acc= 0.9714 val_loss= 0.7952 val_acc= 0.8133 time= 0.0171\n",
      "Epoch: 0176 train_loss= 0.4260 train_acc= 0.9714 val_loss= 0.7916 val_acc= 0.8200 time= 0.0167\n",
      "Epoch: 0177 train_loss= 0.4244 train_acc= 0.9714 val_loss= 0.7875 val_acc= 0.8200 time= 0.0166\n",
      "Epoch: 0178 train_loss= 0.4223 train_acc= 0.9714 val_loss= 0.7842 val_acc= 0.8200 time= 0.0162\n",
      "Epoch: 0179 train_loss= 0.4198 train_acc= 0.9714 val_loss= 0.7817 val_acc= 0.8167 time= 0.0168\n",
      "Epoch: 0180 train_loss= 0.4173 train_acc= 0.9714 val_loss= 0.7797 val_acc= 0.8133 time= 0.0173\n",
      "Epoch: 0181 train_loss= 0.4157 train_acc= 0.9714 val_loss= 0.7790 val_acc= 0.8233 time= 0.0164\n",
      "Epoch: 0182 train_loss= 0.4144 train_acc= 0.9714 val_loss= 0.7792 val_acc= 0.8300 time= 0.0161\n",
      "Epoch: 0183 train_loss= 0.4127 train_acc= 0.9714 val_loss= 0.7779 val_acc= 0.8333 time= 0.0159\n",
      "Epoch: 0184 train_loss= 0.4104 train_acc= 0.9714 val_loss= 0.7759 val_acc= 0.8267 time= 0.0163\n",
      "Epoch: 0185 train_loss= 0.4074 train_acc= 0.9714 val_loss= 0.7716 val_acc= 0.8300 time= 0.0167\n",
      "Epoch: 0186 train_loss= 0.4052 train_acc= 0.9714 val_loss= 0.7687 val_acc= 0.8300 time= 0.0166\n",
      "Epoch: 0187 train_loss= 0.4040 train_acc= 0.9714 val_loss= 0.7653 val_acc= 0.8300 time= 0.0162\n",
      "Epoch: 0188 train_loss= 0.4034 train_acc= 0.9714 val_loss= 0.7638 val_acc= 0.8333 time= 0.0169\n",
      "Epoch: 0189 train_loss= 0.4018 train_acc= 0.9714 val_loss= 0.7630 val_acc= 0.8300 time= 0.0170\n",
      "Epoch: 0190 train_loss= 0.4002 train_acc= 0.9714 val_loss= 0.7623 val_acc= 0.8333 time= 0.0166\n",
      "Epoch: 0191 train_loss= 0.3970 train_acc= 0.9786 val_loss= 0.7607 val_acc= 0.8333 time= 0.0170\n",
      "Epoch: 0192 train_loss= 0.3941 train_acc= 0.9786 val_loss= 0.7599 val_acc= 0.8300 time= 0.0164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0193 train_loss= 0.3924 train_acc= 0.9786 val_loss= 0.7606 val_acc= 0.8233 time= 0.0170\n",
      "Epoch: 0194 train_loss= 0.3914 train_acc= 0.9786 val_loss= 0.7615 val_acc= 0.8200 time= 0.0167\n",
      "Epoch: 0195 train_loss= 0.3899 train_acc= 0.9714 val_loss= 0.7612 val_acc= 0.8200 time= 0.0168\n",
      "Epoch: 0196 train_loss= 0.3877 train_acc= 0.9714 val_loss= 0.7584 val_acc= 0.8200 time= 0.0172\n",
      "Epoch: 0197 train_loss= 0.3853 train_acc= 0.9714 val_loss= 0.7546 val_acc= 0.8200 time= 0.0166\n",
      "Epoch: 0198 train_loss= 0.3826 train_acc= 0.9714 val_loss= 0.7505 val_acc= 0.8200 time= 0.0188\n",
      "Epoch: 0199 train_loss= 0.3804 train_acc= 0.9714 val_loss= 0.7473 val_acc= 0.8233 time= 0.0170\n",
      "Epoch: 0200 train_loss= 0.3785 train_acc= 0.9714 val_loss= 0.7460 val_acc= 0.8200 time= 0.0180\n"
     ]
    }
   ],
   "source": [
    "NB_EPOCH = 200\n",
    "PATIENCE = 10  # early stopping patience\n",
    "# Helper variables for main training loop\n",
    "wait = 0\n",
    "preds = None\n",
    "best_val_loss = 99999\n",
    "\n",
    "# Fit\n",
    "for epoch in range(1, NB_EPOCH+1):\n",
    "\n",
    "    # Log wall-clock time\n",
    "    t = time.time()\n",
    "\n",
    "    # Single training iteration (we mask nodes without labels for loss calculation)\n",
    "    model.fit(graph, y_train, sample_weight=train_mask,\n",
    "              batch_size=A.shape[0], epochs=1, shuffle=False, verbose=0)\n",
    "\n",
    "    # Predict on full dataset\n",
    "    preds = model.predict(graph, batch_size=A.shape[0])\n",
    "\n",
    "    # Train / validation scores\n",
    "    train_val_loss, train_val_acc = evaluate_preds(preds, [y_train, y_val],\n",
    "                                                   [idx_train, idx_val])\n",
    "    print(\"Epoch: {:04d}\".format(epoch),\n",
    "          \"train_loss= {:.4f}\".format(train_val_loss[0]),\n",
    "          \"train_acc= {:.4f}\".format(train_val_acc[0]),\n",
    "          \"val_loss= {:.4f}\".format(train_val_loss[1]),\n",
    "          \"val_acc= {:.4f}\".format(train_val_acc[1]),\n",
    "          \"time= {:.4f}\".format(time.time() - t))\n",
    "\n",
    "    # Early stopping\n",
    "    if train_val_loss[1] < best_val_loss:\n",
    "        best_val_loss = train_val_loss[1]\n",
    "        wait = 0\n",
    "    else:\n",
    "        if wait >= PATIENCE:\n",
    "            print('Epoch {}: early stopping'.format(epoch))\n",
    "            break\n",
    "        wait += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.8094\n",
      "accuracy = 0.8130\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate_preds(preds, [y_test], [idx_test])\n",
    "print(f\"\"\"\n",
    "loss = {test_loss[0]:.4f}\n",
    "accuracy = {test_acc[0]:.4f}\n",
    "\"\"\".strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Graph Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "B1 = 5e-4\n",
    "B2 = 5e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1110 18:01:29.377156 139652427728704 deprecation.py:323] From /home/bitcommander/Desktop/robust-graph-convolutional-networks-against-adversarial-attacks-implementation/ggcn/ggcl.py:28: Normal.__init__ (from tensorflow.python.ops.distributions.normal) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
      "W1110 18:01:29.378515 139652427728704 deprecation.py:323] From /home/bitcommander/.local/lib/python3.7/site-packages/tensorflow/python/ops/distributions/normal.py:160: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n"
     ]
    }
   ],
   "source": [
    "H = Dropout(0.5)(X_in)\n",
    "H1 = GaussianGraphConvolution(16,\n",
    "    is_first=True,\n",
    "    activation='relu',\n",
    "    mean_regularizer=l2(B1),\n",
    "    variance_regularizer=l2(B1),\n",
    "#     dropout=0.5\n",
    ")([H]+G)\n",
    "Y = GaussianGraphConvolution(y.shape[1],\n",
    "    is_last=True,\n",
    "    activation='softmax',\n",
    ")(H1+G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1110 18:01:29.415266 139652427728704 deprecation.py:323] From /home/bitcommander/Desktop/robust-graph-convolutional-networks-against-adversarial-attacks-implementation/ggcn/losses.py:28: kl_divergence (from tensorflow.python.ops.distributions.kullback_leibler) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=[X_in]+G, outputs=Y)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.01))\n",
    "model.add_loss(kl_reg(*H1, B2), H1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 1433)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 1433)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_graph_convolution_1 (G [(None, 16), (None,  45856       dropout_3[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_graph_convolution_2 (G (None, 7)            224         gaussian_graph_convolution_1[0][0\n",
      "                                                                 gaussian_graph_convolution_1[0][1\n",
      "                                                                 input_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 46,080\n",
      "Trainable params: 46,080\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 train_loss= 1.9387 train_acc= 0.3214 val_loss= 1.9422 val_acc= 0.1933 time= 0.4881\n",
      "Epoch: 0002 train_loss= 1.9320 train_acc= 0.3714 val_loss= 1.9372 val_acc= 0.2633 time= 0.0172\n",
      "Epoch: 0003 train_loss= 1.9226 train_acc= 0.3500 val_loss= 1.9302 val_acc= 0.2833 time= 0.0174\n",
      "Epoch: 0004 train_loss= 1.9115 train_acc= 0.3643 val_loss= 1.9216 val_acc= 0.3067 time= 0.0167\n",
      "Epoch: 0005 train_loss= 1.9008 train_acc= 0.3786 val_loss= 1.9141 val_acc= 0.2867 time= 0.0168\n",
      "Epoch: 0006 train_loss= 1.8883 train_acc= 0.4214 val_loss= 1.9055 val_acc= 0.3267 time= 0.0165\n",
      "Epoch: 0007 train_loss= 1.8775 train_acc= 0.4357 val_loss= 1.8967 val_acc= 0.3433 time= 0.0164\n",
      "Epoch: 0008 train_loss= 1.8626 train_acc= 0.4500 val_loss= 1.8863 val_acc= 0.3800 time= 0.0177\n",
      "Epoch: 0009 train_loss= 1.8488 train_acc= 0.4429 val_loss= 1.8760 val_acc= 0.3833 time= 0.0172\n",
      "Epoch: 0010 train_loss= 1.8367 train_acc= 0.4500 val_loss= 1.8663 val_acc= 0.3967 time= 0.0167\n",
      "Epoch: 0011 train_loss= 1.8194 train_acc= 0.4643 val_loss= 1.8549 val_acc= 0.4067 time= 0.0169\n",
      "Epoch: 0012 train_loss= 1.8054 train_acc= 0.4571 val_loss= 1.8444 val_acc= 0.4233 time= 0.0173\n",
      "Epoch: 0013 train_loss= 1.7927 train_acc= 0.4643 val_loss= 1.8335 val_acc= 0.4133 time= 0.0190\n",
      "Epoch: 0014 train_loss= 1.7753 train_acc= 0.4643 val_loss= 1.8219 val_acc= 0.4167 time= 0.0172\n",
      "Epoch: 0015 train_loss= 1.7595 train_acc= 0.4357 val_loss= 1.8106 val_acc= 0.4033 time= 0.0176\n",
      "Epoch: 0016 train_loss= 1.7443 train_acc= 0.4571 val_loss= 1.7985 val_acc= 0.4167 time= 0.0166\n",
      "Epoch: 0017 train_loss= 1.7281 train_acc= 0.4643 val_loss= 1.7871 val_acc= 0.4267 time= 0.0171\n",
      "Epoch: 0018 train_loss= 1.7117 train_acc= 0.4714 val_loss= 1.7752 val_acc= 0.4233 time= 0.0167\n",
      "Epoch: 0019 train_loss= 1.6951 train_acc= 0.4857 val_loss= 1.7646 val_acc= 0.4267 time= 0.0166\n",
      "Epoch: 0020 train_loss= 1.6782 train_acc= 0.4786 val_loss= 1.7517 val_acc= 0.4267 time= 0.0167\n",
      "Epoch: 0021 train_loss= 1.6618 train_acc= 0.4857 val_loss= 1.7405 val_acc= 0.4367 time= 0.0164\n",
      "Epoch: 0022 train_loss= 1.6484 train_acc= 0.4786 val_loss= 1.7281 val_acc= 0.4400 time= 0.0165\n",
      "Epoch: 0023 train_loss= 1.6316 train_acc= 0.4786 val_loss= 1.7162 val_acc= 0.4400 time= 0.0170\n",
      "Epoch: 0024 train_loss= 1.6142 train_acc= 0.4929 val_loss= 1.7041 val_acc= 0.4400 time= 0.0168\n",
      "Epoch: 0025 train_loss= 1.5981 train_acc= 0.5000 val_loss= 1.6933 val_acc= 0.4500 time= 0.0168\n",
      "Epoch: 0026 train_loss= 1.5837 train_acc= 0.4929 val_loss= 1.6811 val_acc= 0.4433 time= 0.0186\n",
      "Epoch: 0027 train_loss= 1.5683 train_acc= 0.4929 val_loss= 1.6691 val_acc= 0.4467 time= 0.0183\n",
      "Epoch: 0028 train_loss= 1.5523 train_acc= 0.4929 val_loss= 1.6577 val_acc= 0.4500 time= 0.0170\n",
      "Epoch: 0029 train_loss= 1.5372 train_acc= 0.5071 val_loss= 1.6456 val_acc= 0.4567 time= 0.0169\n",
      "Epoch: 0030 train_loss= 1.5225 train_acc= 0.5143 val_loss= 1.6345 val_acc= 0.4600 time= 0.0168\n",
      "Epoch: 0031 train_loss= 1.5083 train_acc= 0.5214 val_loss= 1.6229 val_acc= 0.4600 time= 0.0174\n",
      "Epoch: 0032 train_loss= 1.4925 train_acc= 0.5429 val_loss= 1.6114 val_acc= 0.4567 time= 0.0180\n",
      "Epoch: 0033 train_loss= 1.4783 train_acc= 0.5429 val_loss= 1.5999 val_acc= 0.4633 time= 0.0170\n",
      "Epoch: 0034 train_loss= 1.4635 train_acc= 0.5429 val_loss= 1.5887 val_acc= 0.4733 time= 0.0170\n",
      "Epoch: 0035 train_loss= 1.4495 train_acc= 0.5500 val_loss= 1.5774 val_acc= 0.4800 time= 0.0172\n",
      "Epoch: 0036 train_loss= 1.4364 train_acc= 0.5571 val_loss= 1.5664 val_acc= 0.4933 time= 0.0169\n",
      "Epoch: 0037 train_loss= 1.4220 train_acc= 0.5714 val_loss= 1.5556 val_acc= 0.4933 time= 0.0194\n",
      "Epoch: 0038 train_loss= 1.4087 train_acc= 0.5786 val_loss= 1.5447 val_acc= 0.4933 time= 0.0177\n",
      "Epoch: 0039 train_loss= 1.3955 train_acc= 0.5786 val_loss= 1.5339 val_acc= 0.5100 time= 0.0177\n",
      "Epoch: 0040 train_loss= 1.3823 train_acc= 0.6071 val_loss= 1.5233 val_acc= 0.5133 time= 0.0175\n",
      "Epoch: 0041 train_loss= 1.3698 train_acc= 0.6000 val_loss= 1.5125 val_acc= 0.5233 time= 0.0174\n",
      "Epoch: 0042 train_loss= 1.3569 train_acc= 0.6071 val_loss= 1.5019 val_acc= 0.5267 time= 0.0183\n",
      "Epoch: 0043 train_loss= 1.3444 train_acc= 0.6143 val_loss= 1.4916 val_acc= 0.5333 time= 0.0180\n",
      "Epoch: 0044 train_loss= 1.3325 train_acc= 0.6214 val_loss= 1.4817 val_acc= 0.5467 time= 0.0173\n",
      "Epoch: 0045 train_loss= 1.3202 train_acc= 0.6357 val_loss= 1.4719 val_acc= 0.5500 time= 0.0167\n",
      "Epoch: 0046 train_loss= 1.3074 train_acc= 0.6500 val_loss= 1.4621 val_acc= 0.5633 time= 0.0175\n",
      "Epoch: 0047 train_loss= 1.2962 train_acc= 0.6571 val_loss= 1.4521 val_acc= 0.5667 time= 0.0169\n",
      "Epoch: 0048 train_loss= 1.2847 train_acc= 0.6571 val_loss= 1.4426 val_acc= 0.5700 time= 0.0179\n",
      "Epoch: 0049 train_loss= 1.2731 train_acc= 0.6571 val_loss= 1.4334 val_acc= 0.5733 time= 0.0172\n",
      "Epoch: 0050 train_loss= 1.2611 train_acc= 0.6643 val_loss= 1.4238 val_acc= 0.5800 time= 0.0172\n",
      "Epoch: 0051 train_loss= 1.2499 train_acc= 0.6571 val_loss= 1.4149 val_acc= 0.5800 time= 0.0172\n",
      "Epoch: 0052 train_loss= 1.2392 train_acc= 0.6571 val_loss= 1.4058 val_acc= 0.5800 time= 0.0169\n",
      "Epoch: 0053 train_loss= 1.2287 train_acc= 0.6643 val_loss= 1.3971 val_acc= 0.5867 time= 0.0172\n",
      "Epoch: 0054 train_loss= 1.2177 train_acc= 0.6714 val_loss= 1.3886 val_acc= 0.5800 time= 0.0171\n",
      "Epoch: 0055 train_loss= 1.2064 train_acc= 0.7000 val_loss= 1.3801 val_acc= 0.5800 time= 0.0168\n",
      "Epoch: 0056 train_loss= 1.1969 train_acc= 0.6857 val_loss= 1.3715 val_acc= 0.5833 time= 0.0173\n",
      "Epoch: 0057 train_loss= 1.1863 train_acc= 0.7000 val_loss= 1.3634 val_acc= 0.5833 time= 0.0167\n",
      "Epoch: 0058 train_loss= 1.1757 train_acc= 0.7000 val_loss= 1.3552 val_acc= 0.5867 time= 0.0173\n",
      "Epoch: 0059 train_loss= 1.1652 train_acc= 0.7000 val_loss= 1.3471 val_acc= 0.5933 time= 0.0165\n",
      "Epoch: 0060 train_loss= 1.1548 train_acc= 0.7143 val_loss= 1.3391 val_acc= 0.6000 time= 0.0174\n",
      "Epoch: 0061 train_loss= 1.1454 train_acc= 0.7143 val_loss= 1.3313 val_acc= 0.6067 time= 0.0180\n",
      "Epoch: 0062 train_loss= 1.1351 train_acc= 0.7143 val_loss= 1.3235 val_acc= 0.6133 time= 0.0177\n",
      "Epoch: 0063 train_loss= 1.1256 train_acc= 0.7143 val_loss= 1.3154 val_acc= 0.6200 time= 0.0168\n",
      "Epoch: 0064 train_loss= 1.1153 train_acc= 0.7214 val_loss= 1.3078 val_acc= 0.6233 time= 0.0171\n",
      "Epoch: 0065 train_loss= 1.1052 train_acc= 0.7071 val_loss= 1.3002 val_acc= 0.6267 time= 0.0168\n",
      "Epoch: 0066 train_loss= 1.0959 train_acc= 0.7286 val_loss= 1.2922 val_acc= 0.6267 time= 0.0166\n",
      "Epoch: 0067 train_loss= 1.0864 train_acc= 0.7214 val_loss= 1.2844 val_acc= 0.6267 time= 0.0174\n",
      "Epoch: 0068 train_loss= 1.0765 train_acc= 0.7357 val_loss= 1.2769 val_acc= 0.6233 time= 0.0167\n",
      "Epoch: 0069 train_loss= 1.0673 train_acc= 0.7357 val_loss= 1.2696 val_acc= 0.6267 time= 0.0172\n",
      "Epoch: 0070 train_loss= 1.0579 train_acc= 0.7429 val_loss= 1.2621 val_acc= 0.6333 time= 0.0171\n",
      "Epoch: 0071 train_loss= 1.0485 train_acc= 0.7500 val_loss= 1.2552 val_acc= 0.6367 time= 0.0173\n",
      "Epoch: 0072 train_loss= 1.0389 train_acc= 0.7643 val_loss= 1.2482 val_acc= 0.6400 time= 0.0177\n",
      "Epoch: 0073 train_loss= 1.0308 train_acc= 0.7714 val_loss= 1.2413 val_acc= 0.6467 time= 0.0171\n",
      "Epoch: 0074 train_loss= 1.0218 train_acc= 0.7714 val_loss= 1.2347 val_acc= 0.6500 time= 0.0172\n",
      "Epoch: 0075 train_loss= 1.0130 train_acc= 0.7714 val_loss= 1.2276 val_acc= 0.6567 time= 0.0180\n",
      "Epoch: 0076 train_loss= 1.0036 train_acc= 0.7714 val_loss= 1.2211 val_acc= 0.6600 time= 0.0170\n",
      "Epoch: 0077 train_loss= 0.9957 train_acc= 0.7786 val_loss= 1.2141 val_acc= 0.6733 time= 0.0176\n",
      "Epoch: 0078 train_loss= 0.9873 train_acc= 0.7786 val_loss= 1.2076 val_acc= 0.6800 time= 0.0192\n",
      "Epoch: 0079 train_loss= 0.9794 train_acc= 0.7857 val_loss= 1.2014 val_acc= 0.6900 time= 0.0176\n",
      "Epoch: 0080 train_loss= 0.9716 train_acc= 0.7929 val_loss= 1.1955 val_acc= 0.6933 time= 0.0179\n",
      "Epoch: 0081 train_loss= 0.9641 train_acc= 0.8000 val_loss= 1.1893 val_acc= 0.7000 time= 0.0201\n",
      "Epoch: 0082 train_loss= 0.9564 train_acc= 0.8071 val_loss= 1.1834 val_acc= 0.7033 time= 0.0192\n",
      "Epoch: 0083 train_loss= 0.9486 train_acc= 0.8071 val_loss= 1.1776 val_acc= 0.7033 time= 0.0171\n",
      "Epoch: 0084 train_loss= 0.9403 train_acc= 0.8143 val_loss= 1.1720 val_acc= 0.7033 time= 0.0176\n",
      "Epoch: 0085 train_loss= 0.9325 train_acc= 0.8214 val_loss= 1.1662 val_acc= 0.6967 time= 0.0177\n",
      "Epoch: 0086 train_loss= 0.9255 train_acc= 0.8214 val_loss= 1.1602 val_acc= 0.7033 time= 0.0176\n",
      "Epoch: 0087 train_loss= 0.9186 train_acc= 0.8357 val_loss= 1.1543 val_acc= 0.7033 time= 0.0172\n",
      "Epoch: 0088 train_loss= 0.9106 train_acc= 0.8357 val_loss= 1.1488 val_acc= 0.7033 time= 0.0177\n",
      "Epoch: 0089 train_loss= 0.9030 train_acc= 0.8429 val_loss= 1.1435 val_acc= 0.7033 time= 0.0173\n",
      "Epoch: 0090 train_loss= 0.8961 train_acc= 0.8500 val_loss= 1.1379 val_acc= 0.7033 time= 0.0167\n",
      "Epoch: 0091 train_loss= 0.8887 train_acc= 0.8500 val_loss= 1.1326 val_acc= 0.7067 time= 0.0169\n",
      "Epoch: 0092 train_loss= 0.8820 train_acc= 0.8571 val_loss= 1.1273 val_acc= 0.7100 time= 0.0167\n",
      "Epoch: 0093 train_loss= 0.8747 train_acc= 0.8643 val_loss= 1.1220 val_acc= 0.7167 time= 0.0170\n",
      "Epoch: 0094 train_loss= 0.8677 train_acc= 0.8643 val_loss= 1.1164 val_acc= 0.7200 time= 0.0170\n",
      "Epoch: 0095 train_loss= 0.8606 train_acc= 0.8643 val_loss= 1.1110 val_acc= 0.7200 time= 0.0173\n",
      "Epoch: 0096 train_loss= 0.8536 train_acc= 0.8786 val_loss= 1.1056 val_acc= 0.7200 time= 0.0171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0097 train_loss= 0.8471 train_acc= 0.8786 val_loss= 1.0999 val_acc= 0.7200 time= 0.0176\n",
      "Epoch: 0098 train_loss= 0.8397 train_acc= 0.8929 val_loss= 1.0946 val_acc= 0.7200 time= 0.0230\n",
      "Epoch: 0099 train_loss= 0.8329 train_acc= 0.8929 val_loss= 1.0889 val_acc= 0.7267 time= 0.0171\n",
      "Epoch: 0100 train_loss= 0.8259 train_acc= 0.8929 val_loss= 1.0836 val_acc= 0.7333 time= 0.0186\n",
      "Epoch: 0101 train_loss= 0.8196 train_acc= 0.8929 val_loss= 1.0783 val_acc= 0.7400 time= 0.0173\n",
      "Epoch: 0102 train_loss= 0.8122 train_acc= 0.9071 val_loss= 1.0729 val_acc= 0.7400 time= 0.0167\n",
      "Epoch: 0103 train_loss= 0.8059 train_acc= 0.9071 val_loss= 1.0677 val_acc= 0.7400 time= 0.0173\n",
      "Epoch: 0104 train_loss= 0.7995 train_acc= 0.9071 val_loss= 1.0624 val_acc= 0.7400 time= 0.0177\n",
      "Epoch: 0105 train_loss= 0.7927 train_acc= 0.9071 val_loss= 1.0574 val_acc= 0.7400 time= 0.0180\n",
      "Epoch: 0106 train_loss= 0.7860 train_acc= 0.9071 val_loss= 1.0519 val_acc= 0.7400 time= 0.0184\n",
      "Epoch: 0107 train_loss= 0.7795 train_acc= 0.9071 val_loss= 1.0466 val_acc= 0.7400 time= 0.0184\n",
      "Epoch: 0108 train_loss= 0.7734 train_acc= 0.9071 val_loss= 1.0413 val_acc= 0.7400 time= 0.0233\n",
      "Epoch: 0109 train_loss= 0.7671 train_acc= 0.9143 val_loss= 1.0360 val_acc= 0.7500 time= 0.0176\n",
      "Epoch: 0110 train_loss= 0.7606 train_acc= 0.9143 val_loss= 1.0311 val_acc= 0.7600 time= 0.0186\n",
      "Epoch: 0111 train_loss= 0.7547 train_acc= 0.9214 val_loss= 1.0266 val_acc= 0.7633 time= 0.0207\n",
      "Epoch: 0112 train_loss= 0.7485 train_acc= 0.9214 val_loss= 1.0222 val_acc= 0.7633 time= 0.0177\n",
      "Epoch: 0113 train_loss= 0.7429 train_acc= 0.9214 val_loss= 1.0181 val_acc= 0.7667 time= 0.0176\n",
      "Epoch: 0114 train_loss= 0.7371 train_acc= 0.9286 val_loss= 1.0142 val_acc= 0.7700 time= 0.0182\n",
      "Epoch: 0115 train_loss= 0.7313 train_acc= 0.9357 val_loss= 1.0100 val_acc= 0.7700 time= 0.0171\n",
      "Epoch: 0116 train_loss= 0.7256 train_acc= 0.9357 val_loss= 1.0058 val_acc= 0.7767 time= 0.0204\n",
      "Epoch: 0117 train_loss= 0.7201 train_acc= 0.9357 val_loss= 1.0021 val_acc= 0.7800 time= 0.0165\n",
      "Epoch: 0118 train_loss= 0.7147 train_acc= 0.9357 val_loss= 0.9982 val_acc= 0.7833 time= 0.0164\n",
      "Epoch: 0119 train_loss= 0.7094 train_acc= 0.9357 val_loss= 0.9943 val_acc= 0.7900 time= 0.0165\n",
      "Epoch: 0120 train_loss= 0.7041 train_acc= 0.9357 val_loss= 0.9904 val_acc= 0.7933 time= 0.0166\n",
      "Epoch: 0121 train_loss= 0.6985 train_acc= 0.9429 val_loss= 0.9863 val_acc= 0.7967 time= 0.0167\n",
      "Epoch: 0122 train_loss= 0.6934 train_acc= 0.9286 val_loss= 0.9817 val_acc= 0.8000 time= 0.0174\n",
      "Epoch: 0123 train_loss= 0.6880 train_acc= 0.9357 val_loss= 0.9775 val_acc= 0.8067 time= 0.0167\n",
      "Epoch: 0124 train_loss= 0.6827 train_acc= 0.9357 val_loss= 0.9731 val_acc= 0.8067 time= 0.0180\n",
      "Epoch: 0125 train_loss= 0.6773 train_acc= 0.9429 val_loss= 0.9690 val_acc= 0.8100 time= 0.0175\n",
      "Epoch: 0126 train_loss= 0.6724 train_acc= 0.9429 val_loss= 0.9648 val_acc= 0.8100 time= 0.0168\n",
      "Epoch: 0127 train_loss= 0.6672 train_acc= 0.9429 val_loss= 0.9609 val_acc= 0.8100 time= 0.0175\n",
      "Epoch: 0128 train_loss= 0.6622 train_acc= 0.9429 val_loss= 0.9569 val_acc= 0.8100 time= 0.0171\n",
      "Epoch: 0129 train_loss= 0.6573 train_acc= 0.9429 val_loss= 0.9530 val_acc= 0.8100 time= 0.0167\n",
      "Epoch: 0130 train_loss= 0.6518 train_acc= 0.9429 val_loss= 0.9494 val_acc= 0.8067 time= 0.0171\n",
      "Epoch: 0131 train_loss= 0.6471 train_acc= 0.9429 val_loss= 0.9457 val_acc= 0.8033 time= 0.0167\n",
      "Epoch: 0132 train_loss= 0.6420 train_acc= 0.9571 val_loss= 0.9426 val_acc= 0.7967 time= 0.0171\n",
      "Epoch: 0133 train_loss= 0.6377 train_acc= 0.9571 val_loss= 0.9395 val_acc= 0.7933 time= 0.0171\n",
      "Epoch: 0134 train_loss= 0.6332 train_acc= 0.9571 val_loss= 0.9362 val_acc= 0.7933 time= 0.0172\n",
      "Epoch: 0135 train_loss= 0.6288 train_acc= 0.9643 val_loss= 0.9333 val_acc= 0.7933 time= 0.0170\n",
      "Epoch: 0136 train_loss= 0.6248 train_acc= 0.9643 val_loss= 0.9303 val_acc= 0.7967 time= 0.0171\n",
      "Epoch: 0137 train_loss= 0.6201 train_acc= 0.9643 val_loss= 0.9269 val_acc= 0.8000 time= 0.0168\n",
      "Epoch: 0138 train_loss= 0.6160 train_acc= 0.9643 val_loss= 0.9235 val_acc= 0.8000 time= 0.0172\n",
      "Epoch: 0139 train_loss= 0.6118 train_acc= 0.9643 val_loss= 0.9205 val_acc= 0.8000 time= 0.0182\n",
      "Epoch: 0140 train_loss= 0.6079 train_acc= 0.9643 val_loss= 0.9174 val_acc= 0.8000 time= 0.0183\n",
      "Epoch: 0141 train_loss= 0.6036 train_acc= 0.9714 val_loss= 0.9144 val_acc= 0.8000 time= 0.0174\n",
      "Epoch: 0142 train_loss= 0.5998 train_acc= 0.9643 val_loss= 0.9115 val_acc= 0.7967 time= 0.0171\n",
      "Epoch: 0143 train_loss= 0.5960 train_acc= 0.9643 val_loss= 0.9086 val_acc= 0.7967 time= 0.0169\n",
      "Epoch: 0144 train_loss= 0.5920 train_acc= 0.9643 val_loss= 0.9060 val_acc= 0.7967 time= 0.0177\n",
      "Epoch: 0145 train_loss= 0.5881 train_acc= 0.9643 val_loss= 0.9032 val_acc= 0.8100 time= 0.0181\n",
      "Epoch: 0146 train_loss= 0.5845 train_acc= 0.9643 val_loss= 0.9005 val_acc= 0.8100 time= 0.0176\n",
      "Epoch: 0147 train_loss= 0.5803 train_acc= 0.9643 val_loss= 0.8973 val_acc= 0.8167 time= 0.0178\n",
      "Epoch: 0148 train_loss= 0.5764 train_acc= 0.9643 val_loss= 0.8950 val_acc= 0.8167 time= 0.0170\n",
      "Epoch: 0149 train_loss= 0.5727 train_acc= 0.9714 val_loss= 0.8923 val_acc= 0.8200 time= 0.0170\n",
      "Epoch: 0150 train_loss= 0.5688 train_acc= 0.9714 val_loss= 0.8899 val_acc= 0.8200 time= 0.0166\n",
      "Epoch: 0151 train_loss= 0.5652 train_acc= 0.9714 val_loss= 0.8872 val_acc= 0.8200 time= 0.0169\n",
      "Epoch: 0152 train_loss= 0.5615 train_acc= 0.9714 val_loss= 0.8850 val_acc= 0.8200 time= 0.0170\n",
      "Epoch: 0153 train_loss= 0.5584 train_acc= 0.9714 val_loss= 0.8824 val_acc= 0.8200 time= 0.0171\n",
      "Epoch: 0154 train_loss= 0.5544 train_acc= 0.9714 val_loss= 0.8795 val_acc= 0.8167 time= 0.0174\n",
      "Epoch: 0155 train_loss= 0.5506 train_acc= 0.9714 val_loss= 0.8768 val_acc= 0.8167 time= 0.0169\n",
      "Epoch: 0156 train_loss= 0.5473 train_acc= 0.9714 val_loss= 0.8740 val_acc= 0.8167 time= 0.0172\n",
      "Epoch: 0157 train_loss= 0.5434 train_acc= 0.9714 val_loss= 0.8713 val_acc= 0.8167 time= 0.0188\n",
      "Epoch: 0158 train_loss= 0.5404 train_acc= 0.9714 val_loss= 0.8688 val_acc= 0.8167 time= 0.0181\n",
      "Epoch: 0159 train_loss= 0.5371 train_acc= 0.9714 val_loss= 0.8658 val_acc= 0.8167 time= 0.0174\n",
      "Epoch: 0160 train_loss= 0.5336 train_acc= 0.9714 val_loss= 0.8627 val_acc= 0.8167 time= 0.0175\n",
      "Epoch: 0161 train_loss= 0.5302 train_acc= 0.9714 val_loss= 0.8592 val_acc= 0.8200 time= 0.0168\n",
      "Epoch: 0162 train_loss= 0.5264 train_acc= 0.9714 val_loss= 0.8556 val_acc= 0.8200 time= 0.0169\n",
      "Epoch: 0163 train_loss= 0.5231 train_acc= 0.9714 val_loss= 0.8526 val_acc= 0.8167 time= 0.0172\n",
      "Epoch: 0164 train_loss= 0.5197 train_acc= 0.9714 val_loss= 0.8495 val_acc= 0.8200 time= 0.0177\n",
      "Epoch: 0165 train_loss= 0.5168 train_acc= 0.9714 val_loss= 0.8466 val_acc= 0.8200 time= 0.0179\n",
      "Epoch: 0166 train_loss= 0.5137 train_acc= 0.9714 val_loss= 0.8447 val_acc= 0.8200 time= 0.0177\n",
      "Epoch: 0167 train_loss= 0.5108 train_acc= 0.9714 val_loss= 0.8426 val_acc= 0.8200 time= 0.0177\n",
      "Epoch: 0168 train_loss= 0.5079 train_acc= 0.9714 val_loss= 0.8407 val_acc= 0.8200 time= 0.0184\n",
      "Epoch: 0169 train_loss= 0.5052 train_acc= 0.9714 val_loss= 0.8387 val_acc= 0.8267 time= 0.0179\n",
      "Epoch: 0170 train_loss= 0.5019 train_acc= 0.9714 val_loss= 0.8364 val_acc= 0.8267 time= 0.0177\n",
      "Epoch: 0171 train_loss= 0.4991 train_acc= 0.9714 val_loss= 0.8342 val_acc= 0.8233 time= 0.0172\n",
      "Epoch: 0172 train_loss= 0.4965 train_acc= 0.9714 val_loss= 0.8321 val_acc= 0.8233 time= 0.0166\n",
      "Epoch: 0173 train_loss= 0.4938 train_acc= 0.9714 val_loss= 0.8309 val_acc= 0.8233 time= 0.0177\n",
      "Epoch: 0174 train_loss= 0.4906 train_acc= 0.9714 val_loss= 0.8290 val_acc= 0.8233 time= 0.0182\n",
      "Epoch: 0175 train_loss= 0.4881 train_acc= 0.9714 val_loss= 0.8275 val_acc= 0.8233 time= 0.0166\n",
      "Epoch: 0176 train_loss= 0.4854 train_acc= 0.9714 val_loss= 0.8259 val_acc= 0.8233 time= 0.0168\n",
      "Epoch: 0177 train_loss= 0.4827 train_acc= 0.9714 val_loss= 0.8239 val_acc= 0.8233 time= 0.0168\n",
      "Epoch: 0178 train_loss= 0.4796 train_acc= 0.9714 val_loss= 0.8216 val_acc= 0.8233 time= 0.0169\n",
      "Epoch: 0179 train_loss= 0.4768 train_acc= 0.9714 val_loss= 0.8191 val_acc= 0.8233 time= 0.0190\n",
      "Epoch: 0180 train_loss= 0.4740 train_acc= 0.9714 val_loss= 0.8165 val_acc= 0.8267 time= 0.0173\n",
      "Epoch: 0181 train_loss= 0.4709 train_acc= 0.9714 val_loss= 0.8143 val_acc= 0.8233 time= 0.0189\n",
      "Epoch: 0182 train_loss= 0.4682 train_acc= 0.9714 val_loss= 0.8123 val_acc= 0.8267 time= 0.0171\n",
      "Epoch: 0183 train_loss= 0.4652 train_acc= 0.9714 val_loss= 0.8106 val_acc= 0.8333 time= 0.0175\n",
      "Epoch: 0184 train_loss= 0.4625 train_acc= 0.9714 val_loss= 0.8090 val_acc= 0.8333 time= 0.0178\n",
      "Epoch: 0185 train_loss= 0.4596 train_acc= 0.9714 val_loss= 0.8073 val_acc= 0.8333 time= 0.0169\n",
      "Epoch: 0186 train_loss= 0.4576 train_acc= 0.9714 val_loss= 0.8053 val_acc= 0.8367 time= 0.0168\n",
      "Epoch: 0187 train_loss= 0.4548 train_acc= 0.9714 val_loss= 0.8040 val_acc= 0.8333 time= 0.0175\n",
      "Epoch: 0188 train_loss= 0.4524 train_acc= 0.9714 val_loss= 0.8023 val_acc= 0.8333 time= 0.0179\n",
      "Epoch: 0189 train_loss= 0.4503 train_acc= 0.9714 val_loss= 0.8006 val_acc= 0.8333 time= 0.0186\n",
      "Epoch: 0190 train_loss= 0.4478 train_acc= 0.9714 val_loss= 0.7993 val_acc= 0.8300 time= 0.0186\n",
      "Epoch: 0191 train_loss= 0.4458 train_acc= 0.9714 val_loss= 0.7975 val_acc= 0.8300 time= 0.0180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0192 train_loss= 0.4438 train_acc= 0.9714 val_loss= 0.7964 val_acc= 0.8300 time= 0.0172\n",
      "Epoch: 0193 train_loss= 0.4414 train_acc= 0.9714 val_loss= 0.7940 val_acc= 0.8333 time= 0.0173\n",
      "Epoch: 0194 train_loss= 0.4392 train_acc= 0.9714 val_loss= 0.7923 val_acc= 0.8333 time= 0.0172\n",
      "Epoch: 0195 train_loss= 0.4368 train_acc= 0.9714 val_loss= 0.7900 val_acc= 0.8300 time= 0.0174\n",
      "Epoch: 0196 train_loss= 0.4347 train_acc= 0.9714 val_loss= 0.7876 val_acc= 0.8333 time= 0.0174\n",
      "Epoch: 0197 train_loss= 0.4320 train_acc= 0.9714 val_loss= 0.7845 val_acc= 0.8300 time= 0.0176\n",
      "Epoch: 0198 train_loss= 0.4301 train_acc= 0.9714 val_loss= 0.7827 val_acc= 0.8300 time= 0.0168\n",
      "Epoch: 0199 train_loss= 0.4278 train_acc= 0.9714 val_loss= 0.7798 val_acc= 0.8300 time= 0.0167\n",
      "Epoch: 0200 train_loss= 0.4259 train_acc= 0.9714 val_loss= 0.7778 val_acc= 0.8300 time= 0.0175\n"
     ]
    }
   ],
   "source": [
    "NB_EPOCH = 200\n",
    "PATIENCE = 10  # early stopping patience\n",
    "# Helper variables for main training loop\n",
    "wait = 0\n",
    "preds = None\n",
    "best_val_loss = 99999\n",
    "\n",
    "# Fit\n",
    "for epoch in range(1, NB_EPOCH+1):\n",
    "\n",
    "    # Log wall-clock time\n",
    "    t = time.time()\n",
    "\n",
    "    # Single training iteration (we mask nodes without labels for loss calculation)\n",
    "    model.fit(graph, y_train, sample_weight=train_mask,\n",
    "              batch_size=A.shape[0], epochs=1, shuffle=False, verbose=0)\n",
    "\n",
    "    # Predict on full dataset\n",
    "    preds = model.predict(graph, batch_size=A.shape[0])\n",
    "\n",
    "    # Train / validation scores\n",
    "    train_val_loss, train_val_acc = evaluate_preds(preds, [y_train, y_val],\n",
    "                                                   [idx_train, idx_val])\n",
    "    print(\"Epoch: {:04d}\".format(epoch),\n",
    "          \"train_loss= {:.4f}\".format(train_val_loss[0]),\n",
    "          \"train_acc= {:.4f}\".format(train_val_acc[0]),\n",
    "          \"val_loss= {:.4f}\".format(train_val_loss[1]),\n",
    "          \"val_acc= {:.4f}\".format(train_val_acc[1]),\n",
    "          \"time= {:.4f}\".format(time.time() - t))\n",
    "\n",
    "    # Early stopping\n",
    "    if train_val_loss[1] < best_val_loss:\n",
    "        best_val_loss = train_val_loss[1]\n",
    "        wait = 0\n",
    "    else:\n",
    "        if wait >= PATIENCE:\n",
    "            print('Epoch {}: early stopping'.format(epoch))\n",
    "            break\n",
    "        wait += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.8601\n",
      "accuracy = 0.8280\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate_preds(preds, [y_test], [idx_test])\n",
    "print(f\"\"\"\n",
    "loss = {test_loss[0]:.4f}\n",
    "accuracy = {test_acc[0]:.4f}\n",
    "\"\"\".strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
