{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from keras.layers import Input, Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the path of execution\n",
    "EXE_PATH = os.path.abspath(os.path.curdir)\n",
    "# the path of the vendor files\n",
    "VENDOR_PATH = os.path.join(EXE_PATH, 'vendor')\n",
    "# the vendors to include in the system path\n",
    "VENDORS = ['keras-gcn']\n",
    "# create the absolute paths for all vendors\n",
    "VENDORS = list(map(lambda x: os.path.join(VENDOR_PATH, x), VENDORS))\n",
    "# update the Python path to include necessary vendor module\n",
    "sys.path += VENDORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kegra.layers.graph import GraphConvolution\n",
    "from kegra.utils import load_data, preprocess_adj, get_splits, evaluate_preds\n",
    "from ggcn import GaussianGraphConvolution, kl_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cora dataset...\n",
      "Dataset has 2708 nodes, 5429 edges, 1433 features.\n"
     ]
    }
   ],
   "source": [
    "X, A, y = load_data('data/cora/', dataset='cora')\n",
    "X /= X.sum(1).reshape(-1, 1)\n",
    "A = preprocess_adj(A)\n",
    "y_train, y_val, y_test, idx_train, idx_val, idx_test, train_mask = get_splits(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2708x2708 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 13264 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0]], dtype=int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1110 18:13:59.468006 140459681621824 deprecation_wrapper.py:119] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1110 18:13:59.475238 140459681621824 deprecation_wrapper.py:119] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:515: The name tf.sparse_placeholder is deprecated. Please use tf.compat.v1.sparse_placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "support = 1\n",
    "graph = [X, A]\n",
    "G = [Input(shape=(None, None), batch_shape=(None, None), sparse=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1110 18:13:59.480487 140459681621824 deprecation_wrapper.py:119] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_in = Input(shape=(X.shape[1],))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCN (baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1110 18:13:59.488501 140459681621824 deprecation_wrapper.py:119] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W1110 18:13:59.493021 140459681621824 deprecation.py:506] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W1110 18:13:59.500934 140459681621824 deprecation_wrapper.py:119] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define model architecture\n",
    "# NOTE: We pass arguments for graph convolutional layers as a list of tensors.\n",
    "# This is somewhat hacky, more elegant options would require rewriting the Layer base class.\n",
    "H = Dropout(0.5)(X_in)\n",
    "H = GraphConvolution(32, support, activation='relu', kernel_regularizer=l2(5e-4))([H]+G)\n",
    "H = Dropout(0.5)(H)\n",
    "Y = GraphConvolution(y.shape[1], support, activation='softmax')([H]+G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1110 18:13:59.545617 140459681621824 deprecation_wrapper.py:119] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=[X_in]+G, outputs=Y)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 1433)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1433)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "graph_convolution_1 (GraphConvo (None, 32)           45888       dropout_1[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 32)           0           graph_convolution_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "graph_convolution_2 (GraphConvo (None, 7)            231         dropout_2[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 46,119\n",
      "Trainable params: 46,119\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1110 18:13:59.625610 140459681621824 deprecation.py:323] From /home/bitcommander/.local/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 train_loss= 1.9280 train_acc= 0.2929 val_loss= 1.9276 val_acc= 0.3500 time= 1.1030\n",
      "Epoch: 0002 train_loss= 1.9084 train_acc= 0.2929 val_loss= 1.9086 val_acc= 0.3500 time= 0.0174\n",
      "Epoch: 0003 train_loss= 1.8874 train_acc= 0.2929 val_loss= 1.8887 val_acc= 0.3500 time= 0.0181\n",
      "Epoch: 0004 train_loss= 1.8652 train_acc= 0.2929 val_loss= 1.8678 val_acc= 0.3500 time= 0.0236\n",
      "Epoch: 0005 train_loss= 1.8421 train_acc= 0.2929 val_loss= 1.8461 val_acc= 0.3500 time= 0.0174\n",
      "Epoch: 0006 train_loss= 1.8201 train_acc= 0.2929 val_loss= 1.8257 val_acc= 0.3500 time= 0.0177\n",
      "Epoch: 0007 train_loss= 1.7993 train_acc= 0.2929 val_loss= 1.8067 val_acc= 0.3500 time= 0.0191\n",
      "Epoch: 0008 train_loss= 1.7798 train_acc= 0.2929 val_loss= 1.7896 val_acc= 0.3500 time= 0.0231\n",
      "Epoch: 0009 train_loss= 1.7620 train_acc= 0.2929 val_loss= 1.7746 val_acc= 0.3500 time= 0.0200\n",
      "Epoch: 0010 train_loss= 1.7460 train_acc= 0.2929 val_loss= 1.7621 val_acc= 0.3500 time= 0.0188\n",
      "Epoch: 0011 train_loss= 1.7314 train_acc= 0.2929 val_loss= 1.7519 val_acc= 0.3500 time= 0.0188\n",
      "Epoch: 0012 train_loss= 1.7177 train_acc= 0.2929 val_loss= 1.7434 val_acc= 0.3500 time= 0.0197\n",
      "Epoch: 0013 train_loss= 1.7044 train_acc= 0.2929 val_loss= 1.7361 val_acc= 0.3500 time= 0.0244\n",
      "Epoch: 0014 train_loss= 1.6913 train_acc= 0.3357 val_loss= 1.7293 val_acc= 0.3567 time= 0.0220\n",
      "Epoch: 0015 train_loss= 1.6779 train_acc= 0.3643 val_loss= 1.7227 val_acc= 0.3633 time= 0.0231\n",
      "Epoch: 0016 train_loss= 1.6642 train_acc= 0.4000 val_loss= 1.7162 val_acc= 0.3733 time= 0.0207\n",
      "Epoch: 0017 train_loss= 1.6502 train_acc= 0.4286 val_loss= 1.7091 val_acc= 0.3967 time= 0.0191\n",
      "Epoch: 0018 train_loss= 1.6362 train_acc= 0.4571 val_loss= 1.7017 val_acc= 0.4233 time= 0.0213\n",
      "Epoch: 0019 train_loss= 1.6219 train_acc= 0.4714 val_loss= 1.6936 val_acc= 0.4533 time= 0.0176\n",
      "Epoch: 0020 train_loss= 1.6073 train_acc= 0.4714 val_loss= 1.6849 val_acc= 0.4700 time= 0.0182\n",
      "Epoch: 0021 train_loss= 1.5925 train_acc= 0.4714 val_loss= 1.6755 val_acc= 0.4733 time= 0.0193\n",
      "Epoch: 0022 train_loss= 1.5774 train_acc= 0.4714 val_loss= 1.6652 val_acc= 0.4767 time= 0.0193\n",
      "Epoch: 0023 train_loss= 1.5625 train_acc= 0.4714 val_loss= 1.6546 val_acc= 0.4700 time= 0.0175\n",
      "Epoch: 0024 train_loss= 1.5479 train_acc= 0.4857 val_loss= 1.6440 val_acc= 0.4733 time= 0.0201\n",
      "Epoch: 0025 train_loss= 1.5336 train_acc= 0.4857 val_loss= 1.6333 val_acc= 0.4733 time= 0.0189\n",
      "Epoch: 0026 train_loss= 1.5196 train_acc= 0.4929 val_loss= 1.6224 val_acc= 0.4633 time= 0.0191\n",
      "Epoch: 0027 train_loss= 1.5057 train_acc= 0.5000 val_loss= 1.6116 val_acc= 0.4567 time= 0.0187\n",
      "Epoch: 0028 train_loss= 1.4918 train_acc= 0.5000 val_loss= 1.6007 val_acc= 0.4567 time= 0.0230\n",
      "Epoch: 0029 train_loss= 1.4778 train_acc= 0.5000 val_loss= 1.5899 val_acc= 0.4400 time= 0.0200\n",
      "Epoch: 0030 train_loss= 1.4638 train_acc= 0.5000 val_loss= 1.5793 val_acc= 0.4400 time= 0.0191\n",
      "Epoch: 0031 train_loss= 1.4495 train_acc= 0.5000 val_loss= 1.5686 val_acc= 0.4400 time= 0.0231\n",
      "Epoch: 0032 train_loss= 1.4351 train_acc= 0.5000 val_loss= 1.5582 val_acc= 0.4400 time= 0.0233\n",
      "Epoch: 0033 train_loss= 1.4207 train_acc= 0.5000 val_loss= 1.5480 val_acc= 0.4467 time= 0.0284\n",
      "Epoch: 0034 train_loss= 1.4063 train_acc= 0.5071 val_loss= 1.5381 val_acc= 0.4600 time= 0.0235\n",
      "Epoch: 0035 train_loss= 1.3919 train_acc= 0.5071 val_loss= 1.5285 val_acc= 0.4767 time= 0.0184\n",
      "Epoch: 0036 train_loss= 1.3775 train_acc= 0.5143 val_loss= 1.5191 val_acc= 0.4867 time= 0.0189\n",
      "Epoch: 0037 train_loss= 1.3634 train_acc= 0.5214 val_loss= 1.5095 val_acc= 0.4933 time= 0.0192\n",
      "Epoch: 0038 train_loss= 1.3492 train_acc= 0.5357 val_loss= 1.5000 val_acc= 0.5100 time= 0.0173\n",
      "Epoch: 0039 train_loss= 1.3351 train_acc= 0.5500 val_loss= 1.4904 val_acc= 0.5100 time= 0.0165\n",
      "Epoch: 0040 train_loss= 1.3213 train_acc= 0.5500 val_loss= 1.4808 val_acc= 0.5133 time= 0.0166\n",
      "Epoch: 0041 train_loss= 1.3074 train_acc= 0.5571 val_loss= 1.4707 val_acc= 0.5133 time= 0.0193\n",
      "Epoch: 0042 train_loss= 1.2940 train_acc= 0.5714 val_loss= 1.4605 val_acc= 0.5300 time= 0.0165\n",
      "Epoch: 0043 train_loss= 1.2810 train_acc= 0.5786 val_loss= 1.4505 val_acc= 0.5367 time= 0.0240\n",
      "Epoch: 0044 train_loss= 1.2681 train_acc= 0.5857 val_loss= 1.4407 val_acc= 0.5400 time= 0.0177\n",
      "Epoch: 0045 train_loss= 1.2549 train_acc= 0.5929 val_loss= 1.4310 val_acc= 0.5500 time= 0.0164\n",
      "Epoch: 0046 train_loss= 1.2417 train_acc= 0.6071 val_loss= 1.4216 val_acc= 0.5533 time= 0.0195\n",
      "Epoch: 0047 train_loss= 1.2286 train_acc= 0.6214 val_loss= 1.4119 val_acc= 0.5500 time= 0.0190\n",
      "Epoch: 0048 train_loss= 1.2156 train_acc= 0.6571 val_loss= 1.4024 val_acc= 0.5600 time= 0.0177\n",
      "Epoch: 0049 train_loss= 1.2026 train_acc= 0.6714 val_loss= 1.3930 val_acc= 0.5633 time= 0.0189\n",
      "Epoch: 0050 train_loss= 1.1897 train_acc= 0.6714 val_loss= 1.3832 val_acc= 0.5667 time= 0.0175\n",
      "Epoch: 0051 train_loss= 1.1771 train_acc= 0.6714 val_loss= 1.3734 val_acc= 0.5733 time= 0.0222\n",
      "Epoch: 0052 train_loss= 1.1648 train_acc= 0.6643 val_loss= 1.3640 val_acc= 0.5733 time= 0.0176\n",
      "Epoch: 0053 train_loss= 1.1526 train_acc= 0.6643 val_loss= 1.3549 val_acc= 0.5667 time= 0.0230\n",
      "Epoch: 0054 train_loss= 1.1405 train_acc= 0.6714 val_loss= 1.3461 val_acc= 0.5733 time= 0.0187\n",
      "Epoch: 0055 train_loss= 1.1286 train_acc= 0.6929 val_loss= 1.3378 val_acc= 0.5833 time= 0.0192\n",
      "Epoch: 0056 train_loss= 1.1165 train_acc= 0.7143 val_loss= 1.3291 val_acc= 0.5967 time= 0.0192\n",
      "Epoch: 0057 train_loss= 1.1042 train_acc= 0.7214 val_loss= 1.3198 val_acc= 0.5967 time= 0.0286\n",
      "Epoch: 0058 train_loss= 1.0918 train_acc= 0.7214 val_loss= 1.3101 val_acc= 0.6000 time= 0.0205\n",
      "Epoch: 0059 train_loss= 1.0795 train_acc= 0.7143 val_loss= 1.3003 val_acc= 0.6133 time= 0.0204\n",
      "Epoch: 0060 train_loss= 1.0673 train_acc= 0.7143 val_loss= 1.2905 val_acc= 0.6133 time= 0.0216\n",
      "Epoch: 0061 train_loss= 1.0553 train_acc= 0.7214 val_loss= 1.2810 val_acc= 0.6300 time= 0.0194\n",
      "Epoch: 0062 train_loss= 1.0435 train_acc= 0.7286 val_loss= 1.2717 val_acc= 0.6300 time= 0.0187\n",
      "Epoch: 0063 train_loss= 1.0319 train_acc= 0.7500 val_loss= 1.2629 val_acc= 0.6400 time= 0.0193\n",
      "Epoch: 0064 train_loss= 1.0204 train_acc= 0.7500 val_loss= 1.2539 val_acc= 0.6500 time= 0.0251\n",
      "Epoch: 0065 train_loss= 1.0087 train_acc= 0.7643 val_loss= 1.2450 val_acc= 0.6567 time= 0.0191\n",
      "Epoch: 0066 train_loss= 0.9971 train_acc= 0.7857 val_loss= 1.2361 val_acc= 0.6667 time= 0.0186\n",
      "Epoch: 0067 train_loss= 0.9855 train_acc= 0.8071 val_loss= 1.2277 val_acc= 0.6800 time= 0.0190\n",
      "Epoch: 0068 train_loss= 0.9740 train_acc= 0.8286 val_loss= 1.2192 val_acc= 0.6933 time= 0.0247\n",
      "Epoch: 0069 train_loss= 0.9629 train_acc= 0.8357 val_loss= 1.2106 val_acc= 0.7100 time= 0.0192\n",
      "Epoch: 0070 train_loss= 0.9524 train_acc= 0.8429 val_loss= 1.2021 val_acc= 0.7200 time= 0.0197\n",
      "Epoch: 0071 train_loss= 0.9421 train_acc= 0.8500 val_loss= 1.1934 val_acc= 0.7267 time= 0.0188\n",
      "Epoch: 0072 train_loss= 0.9320 train_acc= 0.8500 val_loss= 1.1846 val_acc= 0.7267 time= 0.0238\n",
      "Epoch: 0073 train_loss= 0.9220 train_acc= 0.8643 val_loss= 1.1757 val_acc= 0.7233 time= 0.0205\n",
      "Epoch: 0074 train_loss= 0.9126 train_acc= 0.8429 val_loss= 1.1671 val_acc= 0.7200 time= 0.0162\n",
      "Epoch: 0075 train_loss= 0.9021 train_acc= 0.8500 val_loss= 1.1593 val_acc= 0.7367 time= 0.0239\n",
      "Epoch: 0076 train_loss= 0.8910 train_acc= 0.8571 val_loss= 1.1519 val_acc= 0.7467 time= 0.0245\n",
      "Epoch: 0077 train_loss= 0.8807 train_acc= 0.8714 val_loss= 1.1451 val_acc= 0.7400 time= 0.0188\n",
      "Epoch: 0078 train_loss= 0.8707 train_acc= 0.8714 val_loss= 1.1388 val_acc= 0.7467 time= 0.0186\n",
      "Epoch: 0079 train_loss= 0.8610 train_acc= 0.8857 val_loss= 1.1326 val_acc= 0.7467 time= 0.0184\n",
      "Epoch: 0080 train_loss= 0.8515 train_acc= 0.8786 val_loss= 1.1265 val_acc= 0.7467 time= 0.0189\n",
      "Epoch: 0081 train_loss= 0.8417 train_acc= 0.8857 val_loss= 1.1183 val_acc= 0.7500 time= 0.0236\n",
      "Epoch: 0082 train_loss= 0.8320 train_acc= 0.8857 val_loss= 1.1098 val_acc= 0.7500 time= 0.0197\n",
      "Epoch: 0083 train_loss= 0.8229 train_acc= 0.8857 val_loss= 1.1018 val_acc= 0.7500 time= 0.0173\n",
      "Epoch: 0084 train_loss= 0.8141 train_acc= 0.8857 val_loss= 1.0939 val_acc= 0.7467 time= 0.0191\n",
      "Epoch: 0085 train_loss= 0.8055 train_acc= 0.8857 val_loss= 1.0859 val_acc= 0.7467 time= 0.0201\n",
      "Epoch: 0086 train_loss= 0.7971 train_acc= 0.8857 val_loss= 1.0780 val_acc= 0.7467 time= 0.0238\n",
      "Epoch: 0087 train_loss= 0.7888 train_acc= 0.8786 val_loss= 1.0704 val_acc= 0.7533 time= 0.0183\n",
      "Epoch: 0088 train_loss= 0.7805 train_acc= 0.8786 val_loss= 1.0633 val_acc= 0.7567 time= 0.0234\n",
      "Epoch: 0089 train_loss= 0.7712 train_acc= 0.8857 val_loss= 1.0565 val_acc= 0.7567 time= 0.0202\n",
      "Epoch: 0090 train_loss= 0.7614 train_acc= 0.8929 val_loss= 1.0505 val_acc= 0.7600 time= 0.0229\n",
      "Epoch: 0091 train_loss= 0.7523 train_acc= 0.8929 val_loss= 1.0449 val_acc= 0.7567 time= 0.0232\n",
      "Epoch: 0092 train_loss= 0.7441 train_acc= 0.9071 val_loss= 1.0412 val_acc= 0.7733 time= 0.0166\n",
      "Epoch: 0093 train_loss= 0.7368 train_acc= 0.9071 val_loss= 1.0380 val_acc= 0.7700 time= 0.0183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0094 train_loss= 0.7293 train_acc= 0.9071 val_loss= 1.0332 val_acc= 0.7733 time= 0.0180\n",
      "Epoch: 0095 train_loss= 0.7221 train_acc= 0.9071 val_loss= 1.0279 val_acc= 0.7767 time= 0.0184\n",
      "Epoch: 0096 train_loss= 0.7148 train_acc= 0.9071 val_loss= 1.0215 val_acc= 0.7767 time= 0.0183\n",
      "Epoch: 0097 train_loss= 0.7078 train_acc= 0.9071 val_loss= 1.0146 val_acc= 0.7800 time= 0.0179\n",
      "Epoch: 0098 train_loss= 0.7013 train_acc= 0.9071 val_loss= 1.0078 val_acc= 0.7800 time= 0.0185\n",
      "Epoch: 0099 train_loss= 0.6949 train_acc= 0.9071 val_loss= 1.0011 val_acc= 0.7767 time= 0.0190\n",
      "Epoch: 0100 train_loss= 0.6884 train_acc= 0.9071 val_loss= 0.9946 val_acc= 0.7733 time= 0.0183\n",
      "Epoch: 0101 train_loss= 0.6821 train_acc= 0.9071 val_loss= 0.9888 val_acc= 0.7733 time= 0.0189\n",
      "Epoch: 0102 train_loss= 0.6754 train_acc= 0.9071 val_loss= 0.9835 val_acc= 0.7800 time= 0.0173\n",
      "Epoch: 0103 train_loss= 0.6682 train_acc= 0.9143 val_loss= 0.9794 val_acc= 0.7767 time= 0.0240\n",
      "Epoch: 0104 train_loss= 0.6617 train_acc= 0.9286 val_loss= 0.9764 val_acc= 0.7867 time= 0.0169\n",
      "Epoch: 0105 train_loss= 0.6566 train_acc= 0.9286 val_loss= 0.9745 val_acc= 0.7900 time= 0.0174\n",
      "Epoch: 0106 train_loss= 0.6518 train_acc= 0.9286 val_loss= 0.9721 val_acc= 0.7900 time= 0.0229\n",
      "Epoch: 0107 train_loss= 0.6462 train_acc= 0.9286 val_loss= 0.9670 val_acc= 0.7867 time= 0.0190\n",
      "Epoch: 0108 train_loss= 0.6399 train_acc= 0.9286 val_loss= 0.9613 val_acc= 0.7867 time= 0.0228\n",
      "Epoch: 0109 train_loss= 0.6339 train_acc= 0.9286 val_loss= 0.9545 val_acc= 0.7933 time= 0.0185\n",
      "Epoch: 0110 train_loss= 0.6282 train_acc= 0.9286 val_loss= 0.9482 val_acc= 0.7933 time= 0.0186\n",
      "Epoch: 0111 train_loss= 0.6226 train_acc= 0.9286 val_loss= 0.9421 val_acc= 0.7867 time= 0.0237\n",
      "Epoch: 0112 train_loss= 0.6174 train_acc= 0.9286 val_loss= 0.9372 val_acc= 0.7833 time= 0.0181\n",
      "Epoch: 0113 train_loss= 0.6124 train_acc= 0.9214 val_loss= 0.9340 val_acc= 0.7833 time= 0.0196\n",
      "Epoch: 0114 train_loss= 0.6075 train_acc= 0.9214 val_loss= 0.9318 val_acc= 0.7800 time= 0.0186\n",
      "Epoch: 0115 train_loss= 0.6026 train_acc= 0.9214 val_loss= 0.9281 val_acc= 0.7800 time= 0.0192\n",
      "Epoch: 0116 train_loss= 0.5968 train_acc= 0.9286 val_loss= 0.9239 val_acc= 0.7867 time= 0.0224\n",
      "Epoch: 0117 train_loss= 0.5912 train_acc= 0.9286 val_loss= 0.9197 val_acc= 0.7933 time= 0.0176\n",
      "Epoch: 0118 train_loss= 0.5862 train_acc= 0.9286 val_loss= 0.9157 val_acc= 0.7967 time= 0.0188\n",
      "Epoch: 0119 train_loss= 0.5812 train_acc= 0.9286 val_loss= 0.9121 val_acc= 0.7967 time= 0.0175\n",
      "Epoch: 0120 train_loss= 0.5764 train_acc= 0.9357 val_loss= 0.9091 val_acc= 0.8033 time= 0.0188\n",
      "Epoch: 0121 train_loss= 0.5720 train_acc= 0.9357 val_loss= 0.9065 val_acc= 0.8067 time= 0.0176\n",
      "Epoch: 0122 train_loss= 0.5674 train_acc= 0.9357 val_loss= 0.9039 val_acc= 0.8067 time= 0.0172\n",
      "Epoch: 0123 train_loss= 0.5628 train_acc= 0.9357 val_loss= 0.9004 val_acc= 0.8000 time= 0.0170\n",
      "Epoch: 0124 train_loss= 0.5581 train_acc= 0.9357 val_loss= 0.8956 val_acc= 0.8000 time= 0.0187\n",
      "Epoch: 0125 train_loss= 0.5537 train_acc= 0.9357 val_loss= 0.8904 val_acc= 0.7900 time= 0.0208\n",
      "Epoch: 0126 train_loss= 0.5496 train_acc= 0.9357 val_loss= 0.8861 val_acc= 0.7900 time= 0.0190\n",
      "Epoch: 0127 train_loss= 0.5458 train_acc= 0.9429 val_loss= 0.8818 val_acc= 0.7867 time= 0.0172\n",
      "Epoch: 0128 train_loss= 0.5420 train_acc= 0.9429 val_loss= 0.8784 val_acc= 0.7933 time= 0.0192\n",
      "Epoch: 0129 train_loss= 0.5377 train_acc= 0.9429 val_loss= 0.8758 val_acc= 0.7867 time= 0.0177\n",
      "Epoch: 0130 train_loss= 0.5331 train_acc= 0.9429 val_loss= 0.8723 val_acc= 0.7900 time= 0.0178\n",
      "Epoch: 0131 train_loss= 0.5289 train_acc= 0.9429 val_loss= 0.8690 val_acc= 0.7900 time= 0.0178\n",
      "Epoch: 0132 train_loss= 0.5250 train_acc= 0.9429 val_loss= 0.8662 val_acc= 0.7933 time= 0.0191\n",
      "Epoch: 0133 train_loss= 0.5216 train_acc= 0.9357 val_loss= 0.8634 val_acc= 0.7900 time= 0.0197\n",
      "Epoch: 0134 train_loss= 0.5179 train_acc= 0.9357 val_loss= 0.8622 val_acc= 0.7967 time= 0.0181\n",
      "Epoch: 0135 train_loss= 0.5143 train_acc= 0.9357 val_loss= 0.8616 val_acc= 0.7900 time= 0.0173\n",
      "Epoch: 0136 train_loss= 0.5105 train_acc= 0.9357 val_loss= 0.8612 val_acc= 0.7900 time= 0.0241\n",
      "Epoch: 0137 train_loss= 0.5061 train_acc= 0.9429 val_loss= 0.8590 val_acc= 0.7967 time= 0.0177\n",
      "Epoch: 0138 train_loss= 0.5022 train_acc= 0.9429 val_loss= 0.8580 val_acc= 0.7967 time= 0.0188\n",
      "Epoch: 0139 train_loss= 0.4998 train_acc= 0.9500 val_loss= 0.8598 val_acc= 0.7933 time= 0.0233\n",
      "Epoch: 0140 train_loss= 0.4973 train_acc= 0.9500 val_loss= 0.8602 val_acc= 0.7933 time= 0.0195\n",
      "Epoch: 0141 train_loss= 0.4936 train_acc= 0.9571 val_loss= 0.8566 val_acc= 0.7933 time= 0.0194\n",
      "Epoch: 0142 train_loss= 0.4895 train_acc= 0.9571 val_loss= 0.8509 val_acc= 0.8033 time= 0.0184\n",
      "Epoch: 0143 train_loss= 0.4860 train_acc= 0.9500 val_loss= 0.8464 val_acc= 0.8033 time= 0.0183\n",
      "Epoch: 0144 train_loss= 0.4833 train_acc= 0.9500 val_loss= 0.8413 val_acc= 0.7967 time= 0.0212\n",
      "Epoch: 0145 train_loss= 0.4815 train_acc= 0.9500 val_loss= 0.8385 val_acc= 0.7967 time= 0.0165\n",
      "Epoch: 0146 train_loss= 0.4792 train_acc= 0.9500 val_loss= 0.8360 val_acc= 0.8033 time= 0.0226\n",
      "Epoch: 0147 train_loss= 0.4767 train_acc= 0.9500 val_loss= 0.8336 val_acc= 0.7967 time= 0.0196\n",
      "Epoch: 0148 train_loss= 0.4728 train_acc= 0.9571 val_loss= 0.8311 val_acc= 0.8000 time= 0.0258\n",
      "Epoch: 0149 train_loss= 0.4681 train_acc= 0.9643 val_loss= 0.8294 val_acc= 0.8033 time= 0.0191\n",
      "Epoch: 0150 train_loss= 0.4642 train_acc= 0.9643 val_loss= 0.8280 val_acc= 0.8000 time= 0.0231\n",
      "Epoch: 0151 train_loss= 0.4611 train_acc= 0.9643 val_loss= 0.8276 val_acc= 0.7967 time= 0.0186\n",
      "Epoch: 0152 train_loss= 0.4586 train_acc= 0.9643 val_loss= 0.8263 val_acc= 0.7967 time= 0.0183\n",
      "Epoch: 0153 train_loss= 0.4560 train_acc= 0.9643 val_loss= 0.8244 val_acc= 0.8000 time= 0.0163\n",
      "Epoch: 0154 train_loss= 0.4533 train_acc= 0.9643 val_loss= 0.8212 val_acc= 0.7900 time= 0.0192\n",
      "Epoch: 0155 train_loss= 0.4506 train_acc= 0.9643 val_loss= 0.8183 val_acc= 0.7867 time= 0.0186\n",
      "Epoch: 0156 train_loss= 0.4482 train_acc= 0.9643 val_loss= 0.8159 val_acc= 0.7867 time= 0.0175\n",
      "Epoch: 0157 train_loss= 0.4458 train_acc= 0.9643 val_loss= 0.8132 val_acc= 0.7867 time= 0.0181\n",
      "Epoch: 0158 train_loss= 0.4435 train_acc= 0.9643 val_loss= 0.8087 val_acc= 0.7867 time= 0.0182\n",
      "Epoch: 0159 train_loss= 0.4419 train_acc= 0.9643 val_loss= 0.8050 val_acc= 0.7900 time= 0.0189\n",
      "Epoch: 0160 train_loss= 0.4403 train_acc= 0.9643 val_loss= 0.8025 val_acc= 0.7967 time= 0.0183\n",
      "Epoch: 0161 train_loss= 0.4374 train_acc= 0.9643 val_loss= 0.8002 val_acc= 0.8000 time= 0.0181\n",
      "Epoch: 0162 train_loss= 0.4341 train_acc= 0.9643 val_loss= 0.7998 val_acc= 0.8033 time= 0.0200\n",
      "Epoch: 0163 train_loss= 0.4316 train_acc= 0.9643 val_loss= 0.7998 val_acc= 0.8100 time= 0.0194\n",
      "Epoch: 0164 train_loss= 0.4302 train_acc= 0.9643 val_loss= 0.8020 val_acc= 0.8200 time= 0.0175\n",
      "Epoch: 0165 train_loss= 0.4294 train_acc= 0.9643 val_loss= 0.8054 val_acc= 0.8167 time= 0.0191\n",
      "Epoch: 0166 train_loss= 0.4283 train_acc= 0.9714 val_loss= 0.8079 val_acc= 0.8133 time= 0.0186\n",
      "Epoch: 0167 train_loss= 0.4263 train_acc= 0.9714 val_loss= 0.8074 val_acc= 0.8133 time= 0.0183\n",
      "Epoch: 0168 train_loss= 0.4235 train_acc= 0.9643 val_loss= 0.8053 val_acc= 0.8167 time= 0.0186\n",
      "Epoch: 0169 train_loss= 0.4203 train_acc= 0.9643 val_loss= 0.8023 val_acc= 0.8167 time= 0.0207\n",
      "Epoch: 0170 train_loss= 0.4173 train_acc= 0.9643 val_loss= 0.7973 val_acc= 0.8133 time= 0.0199\n",
      "Epoch: 0171 train_loss= 0.4148 train_acc= 0.9714 val_loss= 0.7926 val_acc= 0.8067 time= 0.0179\n",
      "Epoch: 0172 train_loss= 0.4132 train_acc= 0.9714 val_loss= 0.7876 val_acc= 0.8067 time= 0.0186\n",
      "Epoch: 0173 train_loss= 0.4121 train_acc= 0.9714 val_loss= 0.7847 val_acc= 0.8067 time= 0.0196\n",
      "Epoch: 0174 train_loss= 0.4104 train_acc= 0.9714 val_loss= 0.7829 val_acc= 0.8100 time= 0.0192\n",
      "Epoch: 0175 train_loss= 0.4081 train_acc= 0.9643 val_loss= 0.7821 val_acc= 0.8033 time= 0.0174\n",
      "Epoch: 0176 train_loss= 0.4058 train_acc= 0.9643 val_loss= 0.7810 val_acc= 0.8033 time= 0.0209\n",
      "Epoch: 0177 train_loss= 0.4035 train_acc= 0.9643 val_loss= 0.7803 val_acc= 0.8033 time= 0.0184\n",
      "Epoch: 0178 train_loss= 0.4016 train_acc= 0.9714 val_loss= 0.7817 val_acc= 0.8033 time= 0.0192\n",
      "Epoch: 0179 train_loss= 0.4008 train_acc= 0.9786 val_loss= 0.7839 val_acc= 0.8067 time= 0.0191\n",
      "Epoch: 0180 train_loss= 0.4007 train_acc= 0.9786 val_loss= 0.7880 val_acc= 0.8100 time= 0.0174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0181 train_loss= 0.3985 train_acc= 0.9786 val_loss= 0.7860 val_acc= 0.8133 time= 0.0163\n",
      "Epoch: 0182 train_loss= 0.3960 train_acc= 0.9786 val_loss= 0.7833 val_acc= 0.8133 time= 0.0185\n",
      "Epoch: 0183 train_loss= 0.3934 train_acc= 0.9786 val_loss= 0.7784 val_acc= 0.8133 time= 0.0169\n",
      "Epoch: 0184 train_loss= 0.3925 train_acc= 0.9643 val_loss= 0.7757 val_acc= 0.8133 time= 0.0171\n",
      "Epoch: 0185 train_loss= 0.3914 train_acc= 0.9643 val_loss= 0.7747 val_acc= 0.8067 time= 0.0236\n",
      "Epoch: 0186 train_loss= 0.3888 train_acc= 0.9643 val_loss= 0.7747 val_acc= 0.8033 time= 0.0186\n",
      "Epoch: 0187 train_loss= 0.3857 train_acc= 0.9643 val_loss= 0.7730 val_acc= 0.7967 time= 0.0194\n",
      "Epoch: 0188 train_loss= 0.3832 train_acc= 0.9643 val_loss= 0.7706 val_acc= 0.7967 time= 0.0282\n",
      "Epoch: 0189 train_loss= 0.3808 train_acc= 0.9714 val_loss= 0.7672 val_acc= 0.8033 time= 0.0190\n",
      "Epoch: 0190 train_loss= 0.3792 train_acc= 0.9786 val_loss= 0.7673 val_acc= 0.8033 time= 0.0187\n",
      "Epoch: 0191 train_loss= 0.3781 train_acc= 0.9786 val_loss= 0.7660 val_acc= 0.8100 time= 0.0178\n",
      "Epoch: 0192 train_loss= 0.3772 train_acc= 0.9786 val_loss= 0.7648 val_acc= 0.8100 time= 0.0190\n",
      "Epoch: 0193 train_loss= 0.3753 train_acc= 0.9786 val_loss= 0.7639 val_acc= 0.8100 time= 0.0174\n",
      "Epoch: 0194 train_loss= 0.3728 train_acc= 0.9786 val_loss= 0.7614 val_acc= 0.8100 time= 0.0169\n",
      "Epoch: 0195 train_loss= 0.3702 train_acc= 0.9786 val_loss= 0.7606 val_acc= 0.8133 time= 0.0189\n",
      "Epoch: 0196 train_loss= 0.3680 train_acc= 0.9857 val_loss= 0.7603 val_acc= 0.8100 time= 0.0169\n",
      "Epoch: 0197 train_loss= 0.3661 train_acc= 0.9857 val_loss= 0.7598 val_acc= 0.8100 time= 0.0186\n",
      "Epoch: 0198 train_loss= 0.3647 train_acc= 0.9857 val_loss= 0.7585 val_acc= 0.8100 time= 0.0172\n",
      "Epoch: 0199 train_loss= 0.3632 train_acc= 0.9714 val_loss= 0.7579 val_acc= 0.8067 time= 0.0176\n",
      "Epoch: 0200 train_loss= 0.3618 train_acc= 0.9714 val_loss= 0.7564 val_acc= 0.8033 time= 0.0170\n"
     ]
    }
   ],
   "source": [
    "NB_EPOCH = 200\n",
    "PATIENCE = 10  # early stopping patience\n",
    "# Helper variables for main training loop\n",
    "wait = 0\n",
    "preds = None\n",
    "best_val_loss = 99999\n",
    "\n",
    "# Fit\n",
    "for epoch in range(1, NB_EPOCH+1):\n",
    "\n",
    "    # Log wall-clock time\n",
    "    t = time.time()\n",
    "\n",
    "    # Single training iteration (we mask nodes without labels for loss calculation)\n",
    "    model.fit(graph, y_train, sample_weight=train_mask,\n",
    "              batch_size=A.shape[0], epochs=1, shuffle=False, verbose=0)\n",
    "\n",
    "    # Predict on full dataset\n",
    "    preds = model.predict(graph, batch_size=A.shape[0])\n",
    "\n",
    "    # Train / validation scores\n",
    "    train_val_loss, train_val_acc = evaluate_preds(preds, [y_train, y_val],\n",
    "                                                   [idx_train, idx_val])\n",
    "    print(\"Epoch: {:04d}\".format(epoch),\n",
    "          \"train_loss= {:.4f}\".format(train_val_loss[0]),\n",
    "          \"train_acc= {:.4f}\".format(train_val_acc[0]),\n",
    "          \"val_loss= {:.4f}\".format(train_val_loss[1]),\n",
    "          \"val_acc= {:.4f}\".format(train_val_acc[1]),\n",
    "          \"time= {:.4f}\".format(time.time() - t))\n",
    "\n",
    "    # Early stopping\n",
    "    if train_val_loss[1] < best_val_loss:\n",
    "        best_val_loss = train_val_loss[1]\n",
    "        wait = 0\n",
    "    else:\n",
    "        if wait >= PATIENCE:\n",
    "            print('Epoch {}: early stopping'.format(epoch))\n",
    "            break\n",
    "        wait += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.7945\n",
      "accuracy = 0.8170\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate_preds(preds, [y_test], [idx_test])\n",
    "print(f\"\"\"\n",
    "loss = {test_loss[0]:.4f}\n",
    "accuracy = {test_acc[0]:.4f}\n",
    "\"\"\".strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Graph Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "B1 = 5e-4\n",
    "B2 = 5e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1110 18:14:04.660465 140459681621824 deprecation.py:323] From /home/bitcommander/Desktop/robust-graph-convolutional-networks-against-adversarial-attacks-implementation/ggcn/ggcl.py:165: Normal.__init__ (from tensorflow.python.ops.distributions.normal) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
      "W1110 18:14:04.661660 140459681621824 deprecation.py:323] From /home/bitcommander/.local/lib/python3.7/site-packages/tensorflow/python/ops/distributions/normal.py:160: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n"
     ]
    }
   ],
   "source": [
    "H = Dropout(0.5)(X_in)\n",
    "H1 = GaussianGraphConvolution(16,\n",
    "    is_first=True,\n",
    "    activation='relu',\n",
    "    mean_regularizer=l2(B1),\n",
    "    variance_regularizer=l2(B1),\n",
    "#     dropout=0.5\n",
    ")([H]+G)\n",
    "Y = GaussianGraphConvolution(y.shape[1],\n",
    "    is_last=True,\n",
    "    activation='softmax',\n",
    ")(H1+G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1110 18:14:04.694933 140459681621824 deprecation.py:323] From /home/bitcommander/Desktop/robust-graph-convolutional-networks-against-adversarial-attacks-implementation/ggcn/losses.py:28: kl_divergence (from tensorflow.python.ops.distributions.kullback_leibler) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=[X_in]+G, outputs=Y)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.01))\n",
    "model.add_loss(kl_reg(*H1, B2), H1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 1433)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 1433)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_graph_convolution_1 (G [(None, 16), (None,  45856       dropout_3[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_graph_convolution_2 (G (None, 7)            224         gaussian_graph_convolution_1[0][0\n",
      "                                                                 gaussian_graph_convolution_1[0][1\n",
      "                                                                 input_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 46,080\n",
      "Trainable params: 46,080\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 train_loss= 1.9385 train_acc= 0.3071 val_loss= 1.9411 val_acc= 0.2933 time= 0.4902\n",
      "Epoch: 0002 train_loss= 1.9291 train_acc= 0.4143 val_loss= 1.9347 val_acc= 0.3133 time= 0.0232\n",
      "Epoch: 0003 train_loss= 1.9227 train_acc= 0.3786 val_loss= 1.9275 val_acc= 0.3300 time= 0.0198\n",
      "Epoch: 0004 train_loss= 1.9083 train_acc= 0.4143 val_loss= 1.9195 val_acc= 0.3300 time= 0.0189\n",
      "Epoch: 0005 train_loss= 1.8978 train_acc= 0.4214 val_loss= 1.9107 val_acc= 0.3700 time= 0.0240\n",
      "Epoch: 0006 train_loss= 1.8850 train_acc= 0.4071 val_loss= 1.9025 val_acc= 0.3400 time= 0.0195\n",
      "Epoch: 0007 train_loss= 1.8714 train_acc= 0.4500 val_loss= 1.8919 val_acc= 0.3667 time= 0.0247\n",
      "Epoch: 0008 train_loss= 1.8590 train_acc= 0.4714 val_loss= 1.8831 val_acc= 0.3600 time= 0.0233\n",
      "Epoch: 0009 train_loss= 1.8443 train_acc= 0.4929 val_loss= 1.8735 val_acc= 0.3867 time= 0.0192\n",
      "Epoch: 0010 train_loss= 1.8305 train_acc= 0.4857 val_loss= 1.8625 val_acc= 0.3867 time= 0.0195\n",
      "Epoch: 0011 train_loss= 1.8153 train_acc= 0.4857 val_loss= 1.8521 val_acc= 0.4133 time= 0.0277\n",
      "Epoch: 0012 train_loss= 1.8005 train_acc= 0.4857 val_loss= 1.8407 val_acc= 0.4300 time= 0.0254\n",
      "Epoch: 0013 train_loss= 1.7852 train_acc= 0.4929 val_loss= 1.8297 val_acc= 0.4233 time= 0.0237\n",
      "Epoch: 0014 train_loss= 1.7683 train_acc= 0.5000 val_loss= 1.8179 val_acc= 0.4267 time= 0.0248\n",
      "Epoch: 0015 train_loss= 1.7524 train_acc= 0.5000 val_loss= 1.8064 val_acc= 0.4333 time= 0.0233\n",
      "Epoch: 0016 train_loss= 1.7362 train_acc= 0.5071 val_loss= 1.7950 val_acc= 0.4400 time= 0.0289\n",
      "Epoch: 0017 train_loss= 1.7204 train_acc= 0.5071 val_loss= 1.7832 val_acc= 0.4467 time= 0.0189\n",
      "Epoch: 0018 train_loss= 1.7029 train_acc= 0.5071 val_loss= 1.7717 val_acc= 0.4500 time= 0.0230\n",
      "Epoch: 0019 train_loss= 1.6871 train_acc= 0.5071 val_loss= 1.7597 val_acc= 0.4500 time= 0.0183\n",
      "Epoch: 0020 train_loss= 1.6704 train_acc= 0.5071 val_loss= 1.7478 val_acc= 0.4533 time= 0.0188\n",
      "Epoch: 0021 train_loss= 1.6541 train_acc= 0.5143 val_loss= 1.7360 val_acc= 0.4600 time= 0.0253\n",
      "Epoch: 0022 train_loss= 1.6377 train_acc= 0.5214 val_loss= 1.7240 val_acc= 0.4633 time= 0.0283\n",
      "Epoch: 0023 train_loss= 1.6211 train_acc= 0.5214 val_loss= 1.7120 val_acc= 0.4633 time= 0.0233\n",
      "Epoch: 0024 train_loss= 1.6045 train_acc= 0.5286 val_loss= 1.7000 val_acc= 0.4667 time= 0.0190\n",
      "Epoch: 0025 train_loss= 1.5887 train_acc= 0.5429 val_loss= 1.6878 val_acc= 0.4633 time= 0.0182\n",
      "Epoch: 0026 train_loss= 1.5725 train_acc= 0.5500 val_loss= 1.6758 val_acc= 0.4667 time= 0.0186\n",
      "Epoch: 0027 train_loss= 1.5562 train_acc= 0.5500 val_loss= 1.6638 val_acc= 0.4700 time= 0.0184\n",
      "Epoch: 0028 train_loss= 1.5405 train_acc= 0.5571 val_loss= 1.6517 val_acc= 0.4767 time= 0.0205\n",
      "Epoch: 0029 train_loss= 1.5242 train_acc= 0.5786 val_loss= 1.6398 val_acc= 0.4767 time= 0.0282\n",
      "Epoch: 0030 train_loss= 1.5088 train_acc= 0.5714 val_loss= 1.6276 val_acc= 0.4867 time= 0.0246\n",
      "Epoch: 0031 train_loss= 1.4933 train_acc= 0.5786 val_loss= 1.6158 val_acc= 0.4900 time= 0.0268\n",
      "Epoch: 0032 train_loss= 1.4782 train_acc= 0.5786 val_loss= 1.6039 val_acc= 0.4967 time= 0.0189\n",
      "Epoch: 0033 train_loss= 1.4627 train_acc= 0.6000 val_loss= 1.5922 val_acc= 0.5033 time= 0.0199\n",
      "Epoch: 0034 train_loss= 1.4477 train_acc= 0.6143 val_loss= 1.5807 val_acc= 0.5033 time= 0.0279\n",
      "Epoch: 0035 train_loss= 1.4330 train_acc= 0.6214 val_loss= 1.5692 val_acc= 0.5067 time= 0.0243\n",
      "Epoch: 0036 train_loss= 1.4180 train_acc= 0.6286 val_loss= 1.5577 val_acc= 0.5100 time= 0.0262\n",
      "Epoch: 0037 train_loss= 1.4033 train_acc= 0.6286 val_loss= 1.5463 val_acc= 0.5133 time= 0.0237\n",
      "Epoch: 0038 train_loss= 1.3893 train_acc= 0.6286 val_loss= 1.5355 val_acc= 0.5167 time= 0.0294\n",
      "Epoch: 0039 train_loss= 1.3749 train_acc= 0.6286 val_loss= 1.5243 val_acc= 0.5233 time= 0.0247\n",
      "Epoch: 0040 train_loss= 1.3607 train_acc= 0.6357 val_loss= 1.5134 val_acc= 0.5233 time= 0.0244\n",
      "Epoch: 0041 train_loss= 1.3474 train_acc= 0.6500 val_loss= 1.5024 val_acc= 0.5233 time= 0.0236\n",
      "Epoch: 0042 train_loss= 1.3333 train_acc= 0.6571 val_loss= 1.4919 val_acc= 0.5300 time= 0.0248\n",
      "Epoch: 0043 train_loss= 1.3197 train_acc= 0.6643 val_loss= 1.4810 val_acc= 0.5433 time= 0.0211\n",
      "Epoch: 0044 train_loss= 1.3066 train_acc= 0.6643 val_loss= 1.4705 val_acc= 0.5567 time= 0.0200\n",
      "Epoch: 0045 train_loss= 1.2934 train_acc= 0.6571 val_loss= 1.4598 val_acc= 0.5633 time= 0.0253\n",
      "Epoch: 0046 train_loss= 1.2804 train_acc= 0.6571 val_loss= 1.4495 val_acc= 0.5700 time= 0.0224\n",
      "Epoch: 0047 train_loss= 1.2673 train_acc= 0.6571 val_loss= 1.4391 val_acc= 0.5800 time= 0.0251\n",
      "Epoch: 0048 train_loss= 1.2548 train_acc= 0.6643 val_loss= 1.4289 val_acc= 0.5867 time= 0.0208\n",
      "Epoch: 0049 train_loss= 1.2424 train_acc= 0.6714 val_loss= 1.4185 val_acc= 0.5933 time= 0.0207\n",
      "Epoch: 0050 train_loss= 1.2299 train_acc= 0.6786 val_loss= 1.4084 val_acc= 0.5967 time= 0.0274\n",
      "Epoch: 0051 train_loss= 1.2175 train_acc= 0.6929 val_loss= 1.3984 val_acc= 0.6067 time= 0.0200\n",
      "Epoch: 0052 train_loss= 1.2055 train_acc= 0.7000 val_loss= 1.3887 val_acc= 0.6133 time= 0.0250\n",
      "Epoch: 0053 train_loss= 1.1938 train_acc= 0.7000 val_loss= 1.3789 val_acc= 0.6133 time= 0.0205\n",
      "Epoch: 0054 train_loss= 1.1821 train_acc= 0.7000 val_loss= 1.3694 val_acc= 0.6167 time= 0.0267\n",
      "Epoch: 0055 train_loss= 1.1708 train_acc= 0.7000 val_loss= 1.3601 val_acc= 0.6233 time= 0.0207\n",
      "Epoch: 0056 train_loss= 1.1599 train_acc= 0.7071 val_loss= 1.3511 val_acc= 0.6300 time= 0.0202\n",
      "Epoch: 0057 train_loss= 1.1485 train_acc= 0.7071 val_loss= 1.3422 val_acc= 0.6367 time= 0.0210\n",
      "Epoch: 0058 train_loss= 1.1378 train_acc= 0.7071 val_loss= 1.3334 val_acc= 0.6400 time= 0.0236\n",
      "Epoch: 0059 train_loss= 1.1273 train_acc= 0.7286 val_loss= 1.3249 val_acc= 0.6433 time= 0.0292\n",
      "Epoch: 0060 train_loss= 1.1163 train_acc= 0.7429 val_loss= 1.3164 val_acc= 0.6567 time= 0.0236\n",
      "Epoch: 0061 train_loss= 1.1059 train_acc= 0.7429 val_loss= 1.3080 val_acc= 0.6567 time= 0.0186\n",
      "Epoch: 0062 train_loss= 1.0955 train_acc= 0.7500 val_loss= 1.2996 val_acc= 0.6567 time= 0.0204\n",
      "Epoch: 0063 train_loss= 1.0858 train_acc= 0.7500 val_loss= 1.2915 val_acc= 0.6667 time= 0.0296\n",
      "Epoch: 0064 train_loss= 1.0756 train_acc= 0.7500 val_loss= 1.2833 val_acc= 0.6700 time= 0.0232\n",
      "Epoch: 0065 train_loss= 1.0652 train_acc= 0.7500 val_loss= 1.2752 val_acc= 0.6700 time= 0.0303\n",
      "Epoch: 0066 train_loss= 1.0559 train_acc= 0.7500 val_loss= 1.2673 val_acc= 0.6667 time= 0.0240\n",
      "Epoch: 0067 train_loss= 1.0461 train_acc= 0.7500 val_loss= 1.2593 val_acc= 0.6667 time= 0.0241\n",
      "Epoch: 0068 train_loss= 1.0365 train_acc= 0.7571 val_loss= 1.2516 val_acc= 0.6700 time= 0.0240\n",
      "Epoch: 0069 train_loss= 1.0270 train_acc= 0.7643 val_loss= 1.2441 val_acc= 0.6700 time= 0.0250\n",
      "Epoch: 0070 train_loss= 1.0184 train_acc= 0.7714 val_loss= 1.2366 val_acc= 0.6767 time= 0.0255\n",
      "Epoch: 0071 train_loss= 1.0082 train_acc= 0.7857 val_loss= 1.2293 val_acc= 0.6833 time= 0.0197\n",
      "Epoch: 0072 train_loss= 0.9995 train_acc= 0.7929 val_loss= 1.2221 val_acc= 0.6867 time= 0.0197\n",
      "Epoch: 0073 train_loss= 0.9909 train_acc= 0.7929 val_loss= 1.2151 val_acc= 0.6900 time= 0.0235\n",
      "Epoch: 0074 train_loss= 0.9814 train_acc= 0.8000 val_loss= 1.2075 val_acc= 0.6933 time= 0.0200\n",
      "Epoch: 0075 train_loss= 0.9729 train_acc= 0.8000 val_loss= 1.2007 val_acc= 0.6967 time= 0.0246\n",
      "Epoch: 0076 train_loss= 0.9634 train_acc= 0.8000 val_loss= 1.1939 val_acc= 0.6933 time= 0.0247\n",
      "Epoch: 0077 train_loss= 0.9561 train_acc= 0.8214 val_loss= 1.1867 val_acc= 0.6933 time= 0.0192\n",
      "Epoch: 0078 train_loss= 0.9470 train_acc= 0.8214 val_loss= 1.1803 val_acc= 0.6933 time= 0.0231\n",
      "Epoch: 0079 train_loss= 0.9396 train_acc= 0.8429 val_loss= 1.1743 val_acc= 0.7000 time= 0.0189\n",
      "Epoch: 0080 train_loss= 0.9320 train_acc= 0.8429 val_loss= 1.1668 val_acc= 0.7067 time= 0.0187\n",
      "Epoch: 0081 train_loss= 0.9223 train_acc= 0.8429 val_loss= 1.1611 val_acc= 0.7033 time= 0.0192\n",
      "Epoch: 0082 train_loss= 0.9146 train_acc= 0.8429 val_loss= 1.1549 val_acc= 0.7033 time= 0.0203\n",
      "Epoch: 0083 train_loss= 0.9065 train_acc= 0.8429 val_loss= 1.1484 val_acc= 0.7100 time= 0.0272\n",
      "Epoch: 0084 train_loss= 0.8985 train_acc= 0.8500 val_loss= 1.1419 val_acc= 0.7200 time= 0.0193\n",
      "Epoch: 0085 train_loss= 0.8901 train_acc= 0.8500 val_loss= 1.1355 val_acc= 0.7200 time= 0.0204\n",
      "Epoch: 0086 train_loss= 0.8829 train_acc= 0.8500 val_loss= 1.1292 val_acc= 0.7233 time= 0.0191\n",
      "Epoch: 0087 train_loss= 0.8745 train_acc= 0.8500 val_loss= 1.1229 val_acc= 0.7200 time= 0.0240\n",
      "Epoch: 0088 train_loss= 0.8673 train_acc= 0.8500 val_loss= 1.1170 val_acc= 0.7167 time= 0.0232\n",
      "Epoch: 0089 train_loss= 0.8602 train_acc= 0.8643 val_loss= 1.1111 val_acc= 0.7133 time= 0.0240\n",
      "Epoch: 0090 train_loss= 0.8530 train_acc= 0.8714 val_loss= 1.1054 val_acc= 0.7133 time= 0.0281\n",
      "Epoch: 0091 train_loss= 0.8455 train_acc= 0.8643 val_loss= 1.0994 val_acc= 0.7233 time= 0.0194\n",
      "Epoch: 0092 train_loss= 0.8384 train_acc= 0.8714 val_loss= 1.0937 val_acc= 0.7267 time= 0.0279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0093 train_loss= 0.8308 train_acc= 0.8786 val_loss= 1.0885 val_acc= 0.7233 time= 0.0232\n",
      "Epoch: 0094 train_loss= 0.8244 train_acc= 0.8714 val_loss= 1.0828 val_acc= 0.7300 time= 0.0203\n",
      "Epoch: 0095 train_loss= 0.8172 train_acc= 0.8786 val_loss= 1.0777 val_acc= 0.7333 time= 0.0188\n",
      "Epoch: 0096 train_loss= 0.8097 train_acc= 0.8786 val_loss= 1.0723 val_acc= 0.7300 time= 0.0231\n",
      "Epoch: 0097 train_loss= 0.8041 train_acc= 0.8786 val_loss= 1.0665 val_acc= 0.7333 time= 0.0240\n",
      "Epoch: 0098 train_loss= 0.7978 train_acc= 0.8857 val_loss= 1.0615 val_acc= 0.7400 time= 0.0240\n",
      "Epoch: 0099 train_loss= 0.7907 train_acc= 0.8857 val_loss= 1.0566 val_acc= 0.7500 time= 0.0290\n",
      "Epoch: 0100 train_loss= 0.7846 train_acc= 0.8857 val_loss= 1.0514 val_acc= 0.7500 time= 0.0234\n",
      "Epoch: 0101 train_loss= 0.7784 train_acc= 0.8857 val_loss= 1.0464 val_acc= 0.7533 time= 0.0246\n",
      "Epoch: 0102 train_loss= 0.7719 train_acc= 0.8857 val_loss= 1.0410 val_acc= 0.7533 time= 0.0287\n",
      "Epoch: 0103 train_loss= 0.7655 train_acc= 0.8857 val_loss= 1.0362 val_acc= 0.7600 time= 0.0235\n",
      "Epoch: 0104 train_loss= 0.7596 train_acc= 0.8857 val_loss= 1.0311 val_acc= 0.7567 time= 0.0237\n",
      "Epoch: 0105 train_loss= 0.7526 train_acc= 0.8857 val_loss= 1.0261 val_acc= 0.7633 time= 0.0230\n",
      "Epoch: 0106 train_loss= 0.7453 train_acc= 0.8857 val_loss= 1.0222 val_acc= 0.7633 time= 0.0288\n",
      "Epoch: 0107 train_loss= 0.7400 train_acc= 0.8929 val_loss= 1.0177 val_acc= 0.7600 time= 0.0189\n",
      "Epoch: 0108 train_loss= 0.7350 train_acc= 0.8929 val_loss= 1.0132 val_acc= 0.7700 time= 0.0191\n",
      "Epoch: 0109 train_loss= 0.7274 train_acc= 0.9071 val_loss= 1.0089 val_acc= 0.7667 time= 0.0238\n",
      "Epoch: 0110 train_loss= 0.7216 train_acc= 0.9071 val_loss= 1.0039 val_acc= 0.7767 time= 0.0291\n",
      "Epoch: 0111 train_loss= 0.7158 train_acc= 0.9071 val_loss= 0.9995 val_acc= 0.7767 time= 0.0232\n",
      "Epoch: 0112 train_loss= 0.7104 train_acc= 0.9071 val_loss= 0.9955 val_acc= 0.7733 time= 0.0199\n",
      "Epoch: 0113 train_loss= 0.7047 train_acc= 0.9143 val_loss= 0.9915 val_acc= 0.7667 time= 0.0265\n",
      "Epoch: 0114 train_loss= 0.6974 train_acc= 0.9143 val_loss= 0.9869 val_acc= 0.7700 time= 0.0203\n",
      "Epoch: 0115 train_loss= 0.6935 train_acc= 0.9143 val_loss= 0.9827 val_acc= 0.7733 time= 0.0235\n",
      "Epoch: 0116 train_loss= 0.6877 train_acc= 0.9143 val_loss= 0.9782 val_acc= 0.7767 time= 0.0277\n",
      "Epoch: 0117 train_loss= 0.6817 train_acc= 0.9143 val_loss= 0.9737 val_acc= 0.7733 time= 0.0253\n",
      "Epoch: 0118 train_loss= 0.6763 train_acc= 0.9143 val_loss= 0.9691 val_acc= 0.7767 time= 0.0208\n",
      "Epoch: 0119 train_loss= 0.6707 train_acc= 0.9214 val_loss= 0.9652 val_acc= 0.7800 time= 0.0188\n",
      "Epoch: 0120 train_loss= 0.6657 train_acc= 0.9286 val_loss= 0.9609 val_acc= 0.7800 time= 0.0239\n",
      "Epoch: 0121 train_loss= 0.6602 train_acc= 0.9286 val_loss= 0.9570 val_acc= 0.7867 time= 0.0248\n",
      "Epoch: 0122 train_loss= 0.6551 train_acc= 0.9286 val_loss= 0.9530 val_acc= 0.7833 time= 0.0288\n",
      "Epoch: 0123 train_loss= 0.6503 train_acc= 0.9357 val_loss= 0.9498 val_acc= 0.7833 time= 0.0197\n",
      "Epoch: 0124 train_loss= 0.6464 train_acc= 0.9286 val_loss= 0.9462 val_acc= 0.7833 time= 0.0291\n",
      "Epoch: 0125 train_loss= 0.6405 train_acc= 0.9357 val_loss= 0.9426 val_acc= 0.7867 time= 0.0230\n",
      "Epoch: 0126 train_loss= 0.6359 train_acc= 0.9357 val_loss= 0.9387 val_acc= 0.7867 time= 0.0196\n",
      "Epoch: 0127 train_loss= 0.6314 train_acc= 0.9357 val_loss= 0.9353 val_acc= 0.7933 time= 0.0234\n",
      "Epoch: 0128 train_loss= 0.6272 train_acc= 0.9357 val_loss= 0.9318 val_acc= 0.7933 time= 0.0227\n",
      "Epoch: 0129 train_loss= 0.6221 train_acc= 0.9357 val_loss= 0.9284 val_acc= 0.7933 time= 0.0238\n",
      "Epoch: 0130 train_loss= 0.6181 train_acc= 0.9357 val_loss= 0.9250 val_acc= 0.7967 time= 0.0202\n",
      "Epoch: 0131 train_loss= 0.6143 train_acc= 0.9357 val_loss= 0.9221 val_acc= 0.8000 time= 0.0280\n",
      "Epoch: 0132 train_loss= 0.6098 train_acc= 0.9357 val_loss= 0.9187 val_acc= 0.8033 time= 0.0253\n",
      "Epoch: 0133 train_loss= 0.6050 train_acc= 0.9357 val_loss= 0.9151 val_acc= 0.8033 time= 0.0201\n",
      "Epoch: 0134 train_loss= 0.6002 train_acc= 0.9357 val_loss= 0.9111 val_acc= 0.8033 time= 0.0286\n",
      "Epoch: 0135 train_loss= 0.5964 train_acc= 0.9357 val_loss= 0.9065 val_acc= 0.8033 time= 0.0186\n",
      "Epoch: 0136 train_loss= 0.5918 train_acc= 0.9429 val_loss= 0.9023 val_acc= 0.8000 time= 0.0243\n",
      "Epoch: 0137 train_loss= 0.5871 train_acc= 0.9357 val_loss= 0.8982 val_acc= 0.8067 time= 0.0283\n",
      "Epoch: 0138 train_loss= 0.5827 train_acc= 0.9500 val_loss= 0.8940 val_acc= 0.8100 time= 0.0198\n",
      "Epoch: 0139 train_loss= 0.5789 train_acc= 0.9429 val_loss= 0.8911 val_acc= 0.8100 time= 0.0236\n",
      "Epoch: 0140 train_loss= 0.5747 train_acc= 0.9571 val_loss= 0.8874 val_acc= 0.8100 time= 0.0193\n",
      "Epoch: 0141 train_loss= 0.5707 train_acc= 0.9429 val_loss= 0.8839 val_acc= 0.8200 time= 0.0188\n",
      "Epoch: 0142 train_loss= 0.5664 train_acc= 0.9500 val_loss= 0.8810 val_acc= 0.8233 time= 0.0185\n",
      "Epoch: 0143 train_loss= 0.5622 train_acc= 0.9500 val_loss= 0.8778 val_acc= 0.8233 time= 0.0191\n",
      "Epoch: 0144 train_loss= 0.5579 train_acc= 0.9500 val_loss= 0.8741 val_acc= 0.8233 time= 0.0248\n",
      "Epoch: 0145 train_loss= 0.5540 train_acc= 0.9500 val_loss= 0.8714 val_acc= 0.8267 time= 0.0202\n",
      "Epoch: 0146 train_loss= 0.5500 train_acc= 0.9571 val_loss= 0.8691 val_acc= 0.8267 time= 0.0245\n",
      "Epoch: 0147 train_loss= 0.5463 train_acc= 0.9643 val_loss= 0.8674 val_acc= 0.8233 time= 0.0184\n",
      "Epoch: 0148 train_loss= 0.5427 train_acc= 0.9643 val_loss= 0.8650 val_acc= 0.8233 time= 0.0197\n",
      "Epoch: 0149 train_loss= 0.5398 train_acc= 0.9643 val_loss= 0.8631 val_acc= 0.8267 time= 0.0231\n",
      "Epoch: 0150 train_loss= 0.5357 train_acc= 0.9643 val_loss= 0.8612 val_acc= 0.8233 time= 0.0192\n",
      "Epoch: 0151 train_loss= 0.5318 train_acc= 0.9714 val_loss= 0.8581 val_acc= 0.8267 time= 0.0198\n",
      "Epoch: 0152 train_loss= 0.5282 train_acc= 0.9714 val_loss= 0.8558 val_acc= 0.8267 time= 0.0186\n",
      "Epoch: 0153 train_loss= 0.5251 train_acc= 0.9714 val_loss= 0.8532 val_acc= 0.8233 time= 0.0191\n",
      "Epoch: 0154 train_loss= 0.5224 train_acc= 0.9714 val_loss= 0.8507 val_acc= 0.8233 time= 0.0233\n",
      "Epoch: 0155 train_loss= 0.5186 train_acc= 0.9714 val_loss= 0.8484 val_acc= 0.8267 time= 0.0182\n",
      "Epoch: 0156 train_loss= 0.5149 train_acc= 0.9714 val_loss= 0.8459 val_acc= 0.8267 time= 0.0232\n",
      "Epoch: 0157 train_loss= 0.5123 train_acc= 0.9714 val_loss= 0.8429 val_acc= 0.8267 time= 0.0182\n",
      "Epoch: 0158 train_loss= 0.5085 train_acc= 0.9714 val_loss= 0.8395 val_acc= 0.8267 time= 0.0193\n",
      "Epoch: 0159 train_loss= 0.5054 train_acc= 0.9714 val_loss= 0.8370 val_acc= 0.8267 time= 0.0197\n",
      "Epoch: 0160 train_loss= 0.5032 train_acc= 0.9714 val_loss= 0.8345 val_acc= 0.8267 time= 0.0198\n",
      "Epoch: 0161 train_loss= 0.4992 train_acc= 0.9714 val_loss= 0.8313 val_acc= 0.8233 time= 0.0249\n",
      "Epoch: 0162 train_loss= 0.4960 train_acc= 0.9714 val_loss= 0.8286 val_acc= 0.8267 time= 0.0189\n",
      "Epoch: 0163 train_loss= 0.4928 train_acc= 0.9714 val_loss= 0.8259 val_acc= 0.8300 time= 0.0186\n",
      "Epoch: 0164 train_loss= 0.4901 train_acc= 0.9643 val_loss= 0.8228 val_acc= 0.8300 time= 0.0186\n",
      "Epoch: 0165 train_loss= 0.4873 train_acc= 0.9643 val_loss= 0.8206 val_acc= 0.8267 time= 0.0244\n",
      "Epoch: 0166 train_loss= 0.4844 train_acc= 0.9714 val_loss= 0.8188 val_acc= 0.8300 time= 0.0242\n",
      "Epoch: 0167 train_loss= 0.4813 train_acc= 0.9714 val_loss= 0.8163 val_acc= 0.8300 time= 0.0228\n",
      "Epoch: 0168 train_loss= 0.4784 train_acc= 0.9714 val_loss= 0.8145 val_acc= 0.8300 time= 0.0235\n",
      "Epoch: 0169 train_loss= 0.4759 train_acc= 0.9714 val_loss= 0.8131 val_acc= 0.8300 time= 0.0189\n",
      "Epoch: 0170 train_loss= 0.4729 train_acc= 0.9714 val_loss= 0.8108 val_acc= 0.8267 time= 0.0191\n",
      "Epoch: 0171 train_loss= 0.4700 train_acc= 0.9714 val_loss= 0.8087 val_acc= 0.8300 time= 0.0206\n",
      "Epoch: 0172 train_loss= 0.4672 train_acc= 0.9714 val_loss= 0.8064 val_acc= 0.8300 time= 0.0186\n",
      "Epoch: 0173 train_loss= 0.4642 train_acc= 0.9714 val_loss= 0.8048 val_acc= 0.8300 time= 0.0195\n",
      "Epoch: 0174 train_loss= 0.4613 train_acc= 0.9714 val_loss= 0.8018 val_acc= 0.8300 time= 0.0186\n",
      "Epoch: 0175 train_loss= 0.4588 train_acc= 0.9714 val_loss= 0.7990 val_acc= 0.8267 time= 0.0188\n",
      "Epoch: 0176 train_loss= 0.4560 train_acc= 0.9714 val_loss= 0.7976 val_acc= 0.8300 time= 0.0205\n",
      "Epoch: 0177 train_loss= 0.4535 train_acc= 0.9714 val_loss= 0.7961 val_acc= 0.8267 time= 0.0233\n",
      "Epoch: 0178 train_loss= 0.4503 train_acc= 0.9714 val_loss= 0.7942 val_acc= 0.8300 time= 0.0194\n",
      "Epoch: 0179 train_loss= 0.4488 train_acc= 0.9714 val_loss= 0.7931 val_acc= 0.8267 time= 0.0200\n",
      "Epoch: 0180 train_loss= 0.4465 train_acc= 0.9714 val_loss= 0.7924 val_acc= 0.8267 time= 0.0234\n",
      "Epoch: 0181 train_loss= 0.4447 train_acc= 0.9714 val_loss= 0.7906 val_acc= 0.8267 time= 0.0240\n",
      "Epoch: 0182 train_loss= 0.4425 train_acc= 0.9714 val_loss= 0.7897 val_acc= 0.8267 time= 0.0233\n",
      "Epoch: 0183 train_loss= 0.4403 train_acc= 0.9714 val_loss= 0.7886 val_acc= 0.8267 time= 0.0201\n",
      "Epoch: 0184 train_loss= 0.4377 train_acc= 0.9714 val_loss= 0.7882 val_acc= 0.8267 time= 0.0188\n",
      "Epoch: 0185 train_loss= 0.4356 train_acc= 0.9714 val_loss= 0.7869 val_acc= 0.8267 time= 0.0288\n",
      "Epoch: 0186 train_loss= 0.4331 train_acc= 0.9714 val_loss= 0.7857 val_acc= 0.8233 time= 0.0244\n",
      "Epoch: 0187 train_loss= 0.4309 train_acc= 0.9714 val_loss= 0.7846 val_acc= 0.8267 time= 0.0239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0188 train_loss= 0.4286 train_acc= 0.9714 val_loss= 0.7831 val_acc= 0.8300 time= 0.0232\n",
      "Epoch: 0189 train_loss= 0.4258 train_acc= 0.9714 val_loss= 0.7814 val_acc= 0.8300 time= 0.0251\n",
      "Epoch: 0190 train_loss= 0.4236 train_acc= 0.9714 val_loss= 0.7797 val_acc= 0.8300 time= 0.0257\n",
      "Epoch: 0191 train_loss= 0.4216 train_acc= 0.9714 val_loss= 0.7779 val_acc= 0.8300 time= 0.0251\n",
      "Epoch: 0192 train_loss= 0.4195 train_acc= 0.9714 val_loss= 0.7761 val_acc= 0.8300 time= 0.0268\n",
      "Epoch: 0193 train_loss= 0.4172 train_acc= 0.9714 val_loss= 0.7743 val_acc= 0.8300 time= 0.0203\n",
      "Epoch: 0194 train_loss= 0.4152 train_acc= 0.9714 val_loss= 0.7726 val_acc= 0.8300 time= 0.0207\n",
      "Epoch: 0195 train_loss= 0.4132 train_acc= 0.9714 val_loss= 0.7710 val_acc= 0.8300 time= 0.0224\n",
      "Epoch: 0196 train_loss= 0.4103 train_acc= 0.9714 val_loss= 0.7699 val_acc= 0.8300 time= 0.0284\n",
      "Epoch: 0197 train_loss= 0.4085 train_acc= 0.9714 val_loss= 0.7688 val_acc= 0.8300 time= 0.0200\n",
      "Epoch: 0198 train_loss= 0.4068 train_acc= 0.9714 val_loss= 0.7682 val_acc= 0.8300 time= 0.0260\n",
      "Epoch: 0199 train_loss= 0.4045 train_acc= 0.9714 val_loss= 0.7668 val_acc= 0.8300 time= 0.0237\n",
      "Epoch: 0200 train_loss= 0.4026 train_acc= 0.9714 val_loss= 0.7656 val_acc= 0.8300 time= 0.0226\n"
     ]
    }
   ],
   "source": [
    "NB_EPOCH = 200\n",
    "PATIENCE = 10  # early stopping patience\n",
    "# Helper variables for main training loop\n",
    "wait = 0\n",
    "preds = None\n",
    "best_val_loss = 99999\n",
    "\n",
    "# Fit\n",
    "for epoch in range(1, NB_EPOCH+1):\n",
    "\n",
    "    # Log wall-clock time\n",
    "    t = time.time()\n",
    "\n",
    "    # Single training iteration (we mask nodes without labels for loss calculation)\n",
    "    model.fit(graph, y_train, sample_weight=train_mask,\n",
    "              batch_size=A.shape[0], epochs=1, shuffle=False, verbose=0)\n",
    "\n",
    "    # Predict on full dataset\n",
    "    preds = model.predict(graph, batch_size=A.shape[0])\n",
    "\n",
    "    # Train / validation scores\n",
    "    train_val_loss, train_val_acc = evaluate_preds(preds, [y_train, y_val],\n",
    "                                                   [idx_train, idx_val])\n",
    "    print(\"Epoch: {:04d}\".format(epoch),\n",
    "          \"train_loss= {:.4f}\".format(train_val_loss[0]),\n",
    "          \"train_acc= {:.4f}\".format(train_val_acc[0]),\n",
    "          \"val_loss= {:.4f}\".format(train_val_loss[1]),\n",
    "          \"val_acc= {:.4f}\".format(train_val_acc[1]),\n",
    "          \"time= {:.4f}\".format(time.time() - t))\n",
    "\n",
    "    # Early stopping\n",
    "    if train_val_loss[1] < best_val_loss:\n",
    "        best_val_loss = train_val_loss[1]\n",
    "        wait = 0\n",
    "    else:\n",
    "        if wait >= PATIENCE:\n",
    "            print('Epoch {}: early stopping'.format(epoch))\n",
    "            break\n",
    "        wait += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.8279\n",
      "accuracy = 0.8290\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate_preds(preds, [y_test], [idx_test])\n",
    "print(f\"\"\"\n",
    "loss = {test_loss[0]:.4f}\n",
    "accuracy = {test_acc[0]:.4f}\n",
    "\"\"\".strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
