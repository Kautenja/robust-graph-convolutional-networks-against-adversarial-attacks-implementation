{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from keras.layers import Input, Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the path of execution\n",
    "EXE_PATH = os.path.abspath(os.path.curdir)\n",
    "# the path of the vendor files\n",
    "VENDOR_PATH = os.path.join(EXE_PATH, 'vendor')\n",
    "# the vendors to include in the system path\n",
    "VENDORS = ['keras-gcn']\n",
    "# create the absolute paths for all vendors\n",
    "VENDORS = list(map(lambda x: os.path.join(VENDOR_PATH, x), VENDORS))\n",
    "# update the Python path to include necessary vendor module\n",
    "sys.path += VENDORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kegra.layers.graph import GraphConvolution\n",
    "from kegra.utils import load_data, preprocess_adj, get_splits, evaluate_preds\n",
    "from ggcn import GaussianGraphConvolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cora dataset...\n",
      "Dataset has 2708 nodes, 5429 edges, 1433 features.\n"
     ]
    }
   ],
   "source": [
    "X, A, y = load_data('data/cora/', dataset='cora')\n",
    "X /= X.sum(1).reshape(-1, 1)\n",
    "A = preprocess_adj(A)\n",
    "y_train, y_val, y_test, idx_train, idx_val, idx_test, train_mask = get_splits(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2708x2708 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 13264 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 1, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 1, 0]], dtype=int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1110 16:44:54.339621 140535297824576 deprecation_wrapper.py:119] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1110 16:44:54.346390 140535297824576 deprecation_wrapper.py:119] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:515: The name tf.sparse_placeholder is deprecated. Please use tf.compat.v1.sparse_placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "support = 1\n",
    "graph = [X, A]\n",
    "G = [Input(shape=(None, None), batch_shape=(None, None), sparse=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1110 16:44:54.351480 140535297824576 deprecation_wrapper.py:119] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_in = Input(shape=(X.shape[1],))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCN (baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1110 16:44:54.356712 140535297824576 deprecation_wrapper.py:119] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W1110 16:44:54.361202 140535297824576 deprecation.py:506] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W1110 16:44:54.369642 140535297824576 deprecation_wrapper.py:119] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define model architecture\n",
    "# NOTE: We pass arguments for graph convolutional layers as a list of tensors.\n",
    "# This is somewhat hacky, more elegant options would require rewriting the Layer base class.\n",
    "H = Dropout(0.5)(X_in)\n",
    "H = GraphConvolution(16, support, activation='relu', kernel_regularizer=l2(5e-4))([H]+G)\n",
    "H = Dropout(0.5)(H)\n",
    "Y = GraphConvolution(y.shape[1], support, activation='softmax')([H]+G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1110 16:44:54.411627 140535297824576 deprecation_wrapper.py:119] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=[X_in]+G, outputs=Y)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 1433)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1433)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "graph_convolution_1 (GraphConvo (None, 16)           22944       dropout_1[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 16)           0           graph_convolution_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "graph_convolution_2 (GraphConvo (None, 7)            119         dropout_2[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 23,063\n",
      "Trainable params: 23,063\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1110 16:44:54.489424 140535297824576 deprecation.py:323] From /home/bitcommander/.local/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 train_loss= 1.9363 train_acc= 0.4357 val_loss= 1.9380 val_acc= 0.3600 time= 1.0612\n",
      "Epoch: 0002 train_loss= 1.9262 train_acc= 0.3357 val_loss= 1.9284 val_acc= 0.3667 time= 0.0240\n",
      "Epoch: 0003 train_loss= 1.9152 train_acc= 0.3357 val_loss= 1.9187 val_acc= 0.3633 time= 0.0284\n",
      "Epoch: 0004 train_loss= 1.9035 train_acc= 0.3286 val_loss= 1.9084 val_acc= 0.3600 time= 0.0251\n",
      "Epoch: 0005 train_loss= 1.8914 train_acc= 0.3143 val_loss= 1.8978 val_acc= 0.3567 time= 0.0257\n",
      "Epoch: 0006 train_loss= 1.8792 train_acc= 0.3143 val_loss= 1.8871 val_acc= 0.3567 time= 0.0240\n",
      "Epoch: 0007 train_loss= 1.8668 train_acc= 0.3143 val_loss= 1.8763 val_acc= 0.3567 time= 0.0282\n",
      "Epoch: 0008 train_loss= 1.8541 train_acc= 0.3143 val_loss= 1.8655 val_acc= 0.3567 time= 0.0244\n",
      "Epoch: 0009 train_loss= 1.8415 train_acc= 0.3143 val_loss= 1.8547 val_acc= 0.3567 time= 0.0285\n",
      "Epoch: 0010 train_loss= 1.8288 train_acc= 0.3214 val_loss= 1.8440 val_acc= 0.3533 time= 0.0194\n",
      "Epoch: 0011 train_loss= 1.8163 train_acc= 0.3143 val_loss= 1.8334 val_acc= 0.3533 time= 0.0235\n",
      "Epoch: 0012 train_loss= 1.8040 train_acc= 0.3143 val_loss= 1.8234 val_acc= 0.3533 time= 0.0193\n",
      "Epoch: 0013 train_loss= 1.7920 train_acc= 0.3143 val_loss= 1.8137 val_acc= 0.3533 time= 0.0237\n",
      "Epoch: 0014 train_loss= 1.7804 train_acc= 0.3214 val_loss= 1.8045 val_acc= 0.3567 time= 0.0239\n",
      "Epoch: 0015 train_loss= 1.7691 train_acc= 0.3214 val_loss= 1.7957 val_acc= 0.3567 time= 0.0190\n",
      "Epoch: 0016 train_loss= 1.7582 train_acc= 0.3286 val_loss= 1.7872 val_acc= 0.3567 time= 0.0228\n",
      "Epoch: 0017 train_loss= 1.7477 train_acc= 0.3214 val_loss= 1.7791 val_acc= 0.3567 time= 0.0213\n",
      "Epoch: 0018 train_loss= 1.7377 train_acc= 0.3143 val_loss= 1.7713 val_acc= 0.3533 time= 0.0199\n",
      "Epoch: 0019 train_loss= 1.7280 train_acc= 0.3143 val_loss= 1.7640 val_acc= 0.3533 time= 0.0278\n",
      "Epoch: 0020 train_loss= 1.7186 train_acc= 0.3286 val_loss= 1.7572 val_acc= 0.3567 time= 0.0188\n",
      "Epoch: 0021 train_loss= 1.7093 train_acc= 0.3357 val_loss= 1.7507 val_acc= 0.3567 time= 0.0238\n",
      "Epoch: 0022 train_loss= 1.7002 train_acc= 0.3500 val_loss= 1.7445 val_acc= 0.3600 time= 0.0188\n",
      "Epoch: 0023 train_loss= 1.6912 train_acc= 0.3643 val_loss= 1.7384 val_acc= 0.3600 time= 0.0183\n",
      "Epoch: 0024 train_loss= 1.6821 train_acc= 0.3714 val_loss= 1.7326 val_acc= 0.3633 time= 0.0190\n",
      "Epoch: 0025 train_loss= 1.6730 train_acc= 0.3786 val_loss= 1.7269 val_acc= 0.3633 time= 0.0225\n",
      "Epoch: 0026 train_loss= 1.6638 train_acc= 0.3857 val_loss= 1.7213 val_acc= 0.3667 time= 0.0237\n",
      "Epoch: 0027 train_loss= 1.6544 train_acc= 0.4071 val_loss= 1.7156 val_acc= 0.3667 time= 0.0191\n",
      "Epoch: 0028 train_loss= 1.6448 train_acc= 0.4143 val_loss= 1.7099 val_acc= 0.3700 time= 0.0236\n",
      "Epoch: 0029 train_loss= 1.6351 train_acc= 0.4143 val_loss= 1.7041 val_acc= 0.3767 time= 0.0200\n",
      "Epoch: 0030 train_loss= 1.6253 train_acc= 0.4357 val_loss= 1.6983 val_acc= 0.3867 time= 0.0198\n",
      "Epoch: 0031 train_loss= 1.6153 train_acc= 0.4357 val_loss= 1.6920 val_acc= 0.3967 time= 0.0201\n",
      "Epoch: 0032 train_loss= 1.6051 train_acc= 0.4429 val_loss= 1.6855 val_acc= 0.4033 time= 0.0191\n",
      "Epoch: 0033 train_loss= 1.5948 train_acc= 0.4429 val_loss= 1.6790 val_acc= 0.4167 time= 0.0194\n",
      "Epoch: 0034 train_loss= 1.5846 train_acc= 0.4500 val_loss= 1.6724 val_acc= 0.4167 time= 0.0185\n",
      "Epoch: 0035 train_loss= 1.5742 train_acc= 0.4571 val_loss= 1.6657 val_acc= 0.4167 time= 0.0230\n",
      "Epoch: 0036 train_loss= 1.5638 train_acc= 0.4643 val_loss= 1.6589 val_acc= 0.4233 time= 0.0189\n",
      "Epoch: 0037 train_loss= 1.5533 train_acc= 0.4786 val_loss= 1.6521 val_acc= 0.4333 time= 0.0198\n",
      "Epoch: 0038 train_loss= 1.5428 train_acc= 0.4857 val_loss= 1.6451 val_acc= 0.4433 time= 0.0241\n",
      "Epoch: 0039 train_loss= 1.5323 train_acc= 0.4929 val_loss= 1.6381 val_acc= 0.4567 time= 0.0187\n",
      "Epoch: 0040 train_loss= 1.5217 train_acc= 0.5000 val_loss= 1.6309 val_acc= 0.4667 time= 0.0199\n",
      "Epoch: 0041 train_loss= 1.5110 train_acc= 0.5071 val_loss= 1.6235 val_acc= 0.4700 time= 0.0233\n",
      "Epoch: 0042 train_loss= 1.5002 train_acc= 0.5143 val_loss= 1.6157 val_acc= 0.4733 time= 0.0187\n",
      "Epoch: 0043 train_loss= 1.4895 train_acc= 0.5286 val_loss= 1.6078 val_acc= 0.4733 time= 0.0194\n",
      "Epoch: 0044 train_loss= 1.4787 train_acc= 0.5214 val_loss= 1.5996 val_acc= 0.4733 time= 0.0241\n",
      "Epoch: 0045 train_loss= 1.4678 train_acc= 0.5357 val_loss= 1.5915 val_acc= 0.4767 time= 0.0281\n",
      "Epoch: 0046 train_loss= 1.4567 train_acc= 0.5357 val_loss= 1.5832 val_acc= 0.4767 time= 0.0230\n",
      "Epoch: 0047 train_loss= 1.4457 train_acc= 0.5429 val_loss= 1.5753 val_acc= 0.4800 time= 0.0192\n",
      "Epoch: 0048 train_loss= 1.4347 train_acc= 0.5429 val_loss= 1.5676 val_acc= 0.4900 time= 0.0189\n",
      "Epoch: 0049 train_loss= 1.4237 train_acc= 0.5571 val_loss= 1.5599 val_acc= 0.4967 time= 0.0241\n",
      "Epoch: 0050 train_loss= 1.4126 train_acc= 0.5714 val_loss= 1.5521 val_acc= 0.5067 time= 0.0191\n",
      "Epoch: 0051 train_loss= 1.4015 train_acc= 0.5929 val_loss= 1.5447 val_acc= 0.5200 time= 0.0203\n",
      "Epoch: 0052 train_loss= 1.3906 train_acc= 0.6071 val_loss= 1.5373 val_acc= 0.5200 time= 0.0224\n",
      "Epoch: 0053 train_loss= 1.3798 train_acc= 0.6143 val_loss= 1.5298 val_acc= 0.5333 time= 0.0231\n",
      "Epoch: 0054 train_loss= 1.3689 train_acc= 0.6214 val_loss= 1.5222 val_acc= 0.5367 time= 0.0242\n",
      "Epoch: 0055 train_loss= 1.3579 train_acc= 0.6429 val_loss= 1.5145 val_acc= 0.5433 time= 0.0236\n",
      "Epoch: 0056 train_loss= 1.3469 train_acc= 0.6571 val_loss= 1.5066 val_acc= 0.5567 time= 0.0234\n",
      "Epoch: 0057 train_loss= 1.3361 train_acc= 0.6571 val_loss= 1.4986 val_acc= 0.5567 time= 0.0190\n",
      "Epoch: 0058 train_loss= 1.3253 train_acc= 0.6643 val_loss= 1.4903 val_acc= 0.5567 time= 0.0239\n",
      "Epoch: 0059 train_loss= 1.3146 train_acc= 0.6714 val_loss= 1.4824 val_acc= 0.5600 time= 0.0284\n",
      "Epoch: 0060 train_loss= 1.3039 train_acc= 0.6714 val_loss= 1.4743 val_acc= 0.5633 time= 0.0242\n",
      "Epoch: 0061 train_loss= 1.2932 train_acc= 0.6857 val_loss= 1.4663 val_acc= 0.5667 time= 0.0198\n",
      "Epoch: 0062 train_loss= 1.2825 train_acc= 0.6857 val_loss= 1.4582 val_acc= 0.5633 time= 0.0232\n",
      "Epoch: 0063 train_loss= 1.2721 train_acc= 0.6857 val_loss= 1.4501 val_acc= 0.5633 time= 0.0262\n",
      "Epoch: 0064 train_loss= 1.2618 train_acc= 0.6857 val_loss= 1.4423 val_acc= 0.5633 time= 0.0271\n",
      "Epoch: 0065 train_loss= 1.2516 train_acc= 0.6857 val_loss= 1.4350 val_acc= 0.5733 time= 0.0243\n",
      "Epoch: 0066 train_loss= 1.2414 train_acc= 0.7000 val_loss= 1.4280 val_acc= 0.5800 time= 0.0251\n",
      "Epoch: 0067 train_loss= 1.2316 train_acc= 0.7000 val_loss= 1.4214 val_acc= 0.5867 time= 0.0192\n",
      "Epoch: 0068 train_loss= 1.2221 train_acc= 0.7071 val_loss= 1.4147 val_acc= 0.5967 time= 0.0231\n",
      "Epoch: 0069 train_loss= 1.2125 train_acc= 0.7143 val_loss= 1.4076 val_acc= 0.5967 time= 0.0197\n",
      "Epoch: 0070 train_loss= 1.2030 train_acc= 0.7214 val_loss= 1.4001 val_acc= 0.6100 time= 0.0198\n",
      "Epoch: 0071 train_loss= 1.1933 train_acc= 0.7286 val_loss= 1.3930 val_acc= 0.6100 time= 0.0184\n",
      "Epoch: 0072 train_loss= 1.1838 train_acc= 0.7357 val_loss= 1.3860 val_acc= 0.6200 time= 0.0192\n",
      "Epoch: 0073 train_loss= 1.1744 train_acc= 0.7357 val_loss= 1.3792 val_acc= 0.6233 time= 0.0194\n",
      "Epoch: 0074 train_loss= 1.1650 train_acc= 0.7429 val_loss= 1.3725 val_acc= 0.6333 time= 0.0185\n",
      "Epoch: 0075 train_loss= 1.1558 train_acc= 0.7429 val_loss= 1.3654 val_acc= 0.6367 time= 0.0192\n",
      "Epoch: 0076 train_loss= 1.1471 train_acc= 0.7429 val_loss= 1.3592 val_acc= 0.6367 time= 0.0193\n",
      "Epoch: 0077 train_loss= 1.1384 train_acc= 0.7571 val_loss= 1.3532 val_acc= 0.6500 time= 0.0185\n",
      "Epoch: 0078 train_loss= 1.1298 train_acc= 0.7714 val_loss= 1.3469 val_acc= 0.6600 time= 0.0187\n",
      "Epoch: 0079 train_loss= 1.1214 train_acc= 0.7714 val_loss= 1.3409 val_acc= 0.6667 time= 0.0194\n",
      "Epoch: 0080 train_loss= 1.1129 train_acc= 0.7714 val_loss= 1.3345 val_acc= 0.6700 time= 0.0200\n",
      "Epoch: 0081 train_loss= 1.1046 train_acc= 0.7643 val_loss= 1.3277 val_acc= 0.6733 time= 0.0186\n",
      "Epoch: 0082 train_loss= 1.0959 train_acc= 0.7643 val_loss= 1.3204 val_acc= 0.6700 time= 0.0221\n",
      "Epoch: 0083 train_loss= 1.0872 train_acc= 0.7643 val_loss= 1.3127 val_acc= 0.6767 time= 0.0195\n",
      "Epoch: 0084 train_loss= 1.0784 train_acc= 0.7714 val_loss= 1.3059 val_acc= 0.6833 time= 0.0226\n",
      "Epoch: 0085 train_loss= 1.0696 train_acc= 0.7714 val_loss= 1.2992 val_acc= 0.6733 time= 0.0186\n",
      "Epoch: 0086 train_loss= 1.0612 train_acc= 0.7786 val_loss= 1.2926 val_acc= 0.6700 time= 0.0214\n",
      "Epoch: 0087 train_loss= 1.0532 train_acc= 0.7857 val_loss= 1.2865 val_acc= 0.6767 time= 0.0191\n",
      "Epoch: 0088 train_loss= 1.0457 train_acc= 0.7857 val_loss= 1.2802 val_acc= 0.6700 time= 0.0191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0089 train_loss= 1.0384 train_acc= 0.7929 val_loss= 1.2754 val_acc= 0.6733 time= 0.0218\n",
      "Epoch: 0090 train_loss= 1.0313 train_acc= 0.7929 val_loss= 1.2708 val_acc= 0.6733 time= 0.0253\n",
      "Epoch: 0091 train_loss= 1.0239 train_acc= 0.7929 val_loss= 1.2658 val_acc= 0.6767 time= 0.0245\n",
      "Epoch: 0092 train_loss= 1.0163 train_acc= 0.7929 val_loss= 1.2610 val_acc= 0.6833 time= 0.0232\n",
      "Epoch: 0093 train_loss= 1.0086 train_acc= 0.7929 val_loss= 1.2555 val_acc= 0.6867 time= 0.0182\n",
      "Epoch: 0094 train_loss= 1.0010 train_acc= 0.8000 val_loss= 1.2498 val_acc= 0.6867 time= 0.0184\n",
      "Epoch: 0095 train_loss= 0.9937 train_acc= 0.8000 val_loss= 1.2439 val_acc= 0.6867 time= 0.0227\n",
      "Epoch: 0096 train_loss= 0.9868 train_acc= 0.8000 val_loss= 1.2386 val_acc= 0.6867 time= 0.0186\n",
      "Epoch: 0097 train_loss= 0.9802 train_acc= 0.8000 val_loss= 1.2342 val_acc= 0.7033 time= 0.0278\n",
      "Epoch: 0098 train_loss= 0.9736 train_acc= 0.7929 val_loss= 1.2290 val_acc= 0.7000 time= 0.0227\n",
      "Epoch: 0099 train_loss= 0.9669 train_acc= 0.7929 val_loss= 1.2234 val_acc= 0.7000 time= 0.0196\n",
      "Epoch: 0100 train_loss= 0.9600 train_acc= 0.7929 val_loss= 1.2184 val_acc= 0.7000 time= 0.0180\n",
      "Epoch: 0101 train_loss= 0.9527 train_acc= 0.7929 val_loss= 1.2124 val_acc= 0.7033 time= 0.0188\n",
      "Epoch: 0102 train_loss= 0.9453 train_acc= 0.8071 val_loss= 1.2065 val_acc= 0.6967 time= 0.0205\n",
      "Epoch: 0103 train_loss= 0.9387 train_acc= 0.8071 val_loss= 1.2011 val_acc= 0.6867 time= 0.0189\n",
      "Epoch: 0104 train_loss= 0.9325 train_acc= 0.8071 val_loss= 1.1963 val_acc= 0.6867 time= 0.0187\n",
      "Epoch: 0105 train_loss= 0.9263 train_acc= 0.8214 val_loss= 1.1917 val_acc= 0.6900 time= 0.0235\n",
      "Epoch: 0106 train_loss= 0.9197 train_acc= 0.8214 val_loss= 1.1871 val_acc= 0.7067 time= 0.0276\n",
      "Epoch: 0107 train_loss= 0.9129 train_acc= 0.8286 val_loss= 1.1826 val_acc= 0.7067 time= 0.0257\n",
      "Epoch: 0108 train_loss= 0.9063 train_acc= 0.8357 val_loss= 1.1781 val_acc= 0.7100 time= 0.0253\n",
      "Epoch: 0109 train_loss= 0.8994 train_acc= 0.8429 val_loss= 1.1733 val_acc= 0.7167 time= 0.0231\n",
      "Epoch: 0110 train_loss= 0.8927 train_acc= 0.8429 val_loss= 1.1694 val_acc= 0.7133 time= 0.0246\n",
      "Epoch: 0111 train_loss= 0.8861 train_acc= 0.8429 val_loss= 1.1641 val_acc= 0.7167 time= 0.0282\n",
      "Epoch: 0112 train_loss= 0.8797 train_acc= 0.8429 val_loss= 1.1590 val_acc= 0.7233 time= 0.0195\n",
      "Epoch: 0113 train_loss= 0.8736 train_acc= 0.8429 val_loss= 1.1535 val_acc= 0.7233 time= 0.0233\n",
      "Epoch: 0114 train_loss= 0.8680 train_acc= 0.8357 val_loss= 1.1491 val_acc= 0.7200 time= 0.0185\n",
      "Epoch: 0115 train_loss= 0.8625 train_acc= 0.8357 val_loss= 1.1446 val_acc= 0.7200 time= 0.0203\n",
      "Epoch: 0116 train_loss= 0.8569 train_acc= 0.8357 val_loss= 1.1403 val_acc= 0.7200 time= 0.0253\n",
      "Epoch: 0117 train_loss= 0.8513 train_acc= 0.8357 val_loss= 1.1367 val_acc= 0.7233 time= 0.0184\n",
      "Epoch: 0118 train_loss= 0.8461 train_acc= 0.8429 val_loss= 1.1324 val_acc= 0.7233 time= 0.0247\n",
      "Epoch: 0119 train_loss= 0.8414 train_acc= 0.8429 val_loss= 1.1276 val_acc= 0.7267 time= 0.0276\n",
      "Epoch: 0120 train_loss= 0.8364 train_acc= 0.8429 val_loss= 1.1226 val_acc= 0.7333 time= 0.0193\n",
      "Epoch: 0121 train_loss= 0.8320 train_acc= 0.8429 val_loss= 1.1178 val_acc= 0.7333 time= 0.0248\n",
      "Epoch: 0122 train_loss= 0.8270 train_acc= 0.8429 val_loss= 1.1136 val_acc= 0.7333 time= 0.0192\n",
      "Epoch: 0123 train_loss= 0.8213 train_acc= 0.8500 val_loss= 1.1099 val_acc= 0.7333 time= 0.0233\n",
      "Epoch: 0124 train_loss= 0.8153 train_acc= 0.8500 val_loss= 1.1074 val_acc= 0.7333 time= 0.0202\n",
      "Epoch: 0125 train_loss= 0.8099 train_acc= 0.8571 val_loss= 1.1051 val_acc= 0.7300 time= 0.0196\n",
      "Epoch: 0126 train_loss= 0.8047 train_acc= 0.8571 val_loss= 1.1027 val_acc= 0.7300 time= 0.0238\n",
      "Epoch: 0127 train_loss= 0.7995 train_acc= 0.8571 val_loss= 1.0993 val_acc= 0.7333 time= 0.0238\n",
      "Epoch: 0128 train_loss= 0.7944 train_acc= 0.8571 val_loss= 1.0958 val_acc= 0.7300 time= 0.0247\n",
      "Epoch: 0129 train_loss= 0.7895 train_acc= 0.8571 val_loss= 1.0917 val_acc= 0.7300 time= 0.0276\n",
      "Epoch: 0130 train_loss= 0.7849 train_acc= 0.8571 val_loss= 1.0885 val_acc= 0.7267 time= 0.0230\n",
      "Epoch: 0131 train_loss= 0.7802 train_acc= 0.8571 val_loss= 1.0842 val_acc= 0.7333 time= 0.0235\n",
      "Epoch: 0132 train_loss= 0.7756 train_acc= 0.8643 val_loss= 1.0796 val_acc= 0.7400 time= 0.0194\n",
      "Epoch: 0133 train_loss= 0.7714 train_acc= 0.8643 val_loss= 1.0764 val_acc= 0.7367 time= 0.0189\n",
      "Epoch: 0134 train_loss= 0.7674 train_acc= 0.8643 val_loss= 1.0735 val_acc= 0.7367 time= 0.0226\n",
      "Epoch: 0135 train_loss= 0.7636 train_acc= 0.8643 val_loss= 1.0694 val_acc= 0.7433 time= 0.0250\n",
      "Epoch: 0136 train_loss= 0.7603 train_acc= 0.8643 val_loss= 1.0656 val_acc= 0.7433 time= 0.0253\n",
      "Epoch: 0137 train_loss= 0.7567 train_acc= 0.8643 val_loss= 1.0621 val_acc= 0.7433 time= 0.0242\n",
      "Epoch: 0138 train_loss= 0.7532 train_acc= 0.8643 val_loss= 1.0584 val_acc= 0.7367 time= 0.0184\n",
      "Epoch: 0139 train_loss= 0.7493 train_acc= 0.8643 val_loss= 1.0552 val_acc= 0.7400 time= 0.0193\n",
      "Epoch: 0140 train_loss= 0.7455 train_acc= 0.8643 val_loss= 1.0521 val_acc= 0.7433 time= 0.0193\n",
      "Epoch: 0141 train_loss= 0.7422 train_acc= 0.8643 val_loss= 1.0494 val_acc= 0.7467 time= 0.0242\n",
      "Epoch: 0142 train_loss= 0.7383 train_acc= 0.8786 val_loss= 1.0471 val_acc= 0.7467 time= 0.0238\n",
      "Epoch: 0143 train_loss= 0.7341 train_acc= 0.8786 val_loss= 1.0455 val_acc= 0.7467 time= 0.0227\n",
      "Epoch: 0144 train_loss= 0.7300 train_acc= 0.8786 val_loss= 1.0440 val_acc= 0.7433 time= 0.0180\n",
      "Epoch: 0145 train_loss= 0.7257 train_acc= 0.8786 val_loss= 1.0417 val_acc= 0.7467 time= 0.0251\n",
      "Epoch: 0146 train_loss= 0.7211 train_acc= 0.8786 val_loss= 1.0381 val_acc= 0.7467 time= 0.0227\n",
      "Epoch: 0147 train_loss= 0.7164 train_acc= 0.8786 val_loss= 1.0343 val_acc= 0.7400 time= 0.0243\n",
      "Epoch: 0148 train_loss= 0.7120 train_acc= 0.8786 val_loss= 1.0301 val_acc= 0.7400 time= 0.0235\n",
      "Epoch: 0149 train_loss= 0.7080 train_acc= 0.8786 val_loss= 1.0263 val_acc= 0.7467 time= 0.0258\n",
      "Epoch: 0150 train_loss= 0.7041 train_acc= 0.8786 val_loss= 1.0230 val_acc= 0.7467 time= 0.0288\n",
      "Epoch: 0151 train_loss= 0.7001 train_acc= 0.8857 val_loss= 1.0197 val_acc= 0.7533 time= 0.0218\n",
      "Epoch: 0152 train_loss= 0.6959 train_acc= 0.9000 val_loss= 1.0167 val_acc= 0.7600 time= 0.0305\n",
      "Epoch: 0153 train_loss= 0.6916 train_acc= 0.9000 val_loss= 1.0138 val_acc= 0.7600 time= 0.0221\n",
      "Epoch: 0154 train_loss= 0.6875 train_acc= 0.9000 val_loss= 1.0113 val_acc= 0.7567 time= 0.0283\n",
      "Epoch: 0155 train_loss= 0.6837 train_acc= 0.9000 val_loss= 1.0079 val_acc= 0.7567 time= 0.0195\n",
      "Epoch: 0156 train_loss= 0.6802 train_acc= 0.9000 val_loss= 1.0053 val_acc= 0.7633 time= 0.0217\n",
      "Epoch: 0157 train_loss= 0.6772 train_acc= 0.9000 val_loss= 1.0029 val_acc= 0.7633 time= 0.0255\n",
      "Epoch: 0158 train_loss= 0.6744 train_acc= 0.9000 val_loss= 1.0012 val_acc= 0.7633 time= 0.0238\n",
      "Epoch: 0159 train_loss= 0.6718 train_acc= 0.9000 val_loss= 0.9997 val_acc= 0.7633 time= 0.0234\n",
      "Epoch: 0160 train_loss= 0.6689 train_acc= 0.9000 val_loss= 0.9984 val_acc= 0.7567 time= 0.0241\n",
      "Epoch: 0161 train_loss= 0.6660 train_acc= 0.8929 val_loss= 0.9967 val_acc= 0.7533 time= 0.0195\n",
      "Epoch: 0162 train_loss= 0.6635 train_acc= 0.8929 val_loss= 0.9959 val_acc= 0.7567 time= 0.0258\n",
      "Epoch: 0163 train_loss= 0.6608 train_acc= 0.8929 val_loss= 0.9960 val_acc= 0.7600 time= 0.0192\n",
      "Epoch: 0164 train_loss= 0.6582 train_acc= 0.8929 val_loss= 0.9951 val_acc= 0.7533 time= 0.0251\n",
      "Epoch: 0165 train_loss= 0.6549 train_acc= 0.8929 val_loss= 0.9920 val_acc= 0.7567 time= 0.0233\n",
      "Epoch: 0166 train_loss= 0.6516 train_acc= 0.8929 val_loss= 0.9895 val_acc= 0.7567 time= 0.0247\n",
      "Epoch: 0167 train_loss= 0.6479 train_acc= 0.9000 val_loss= 0.9868 val_acc= 0.7700 time= 0.0208\n",
      "Epoch: 0168 train_loss= 0.6436 train_acc= 0.9000 val_loss= 0.9829 val_acc= 0.7667 time= 0.0261\n",
      "Epoch: 0169 train_loss= 0.6401 train_acc= 0.9000 val_loss= 0.9792 val_acc= 0.7733 time= 0.0296\n",
      "Epoch: 0170 train_loss= 0.6369 train_acc= 0.9000 val_loss= 0.9757 val_acc= 0.7700 time= 0.0242\n",
      "Epoch: 0171 train_loss= 0.6344 train_acc= 0.9000 val_loss= 0.9730 val_acc= 0.7700 time= 0.0206\n",
      "Epoch: 0172 train_loss= 0.6319 train_acc= 0.9000 val_loss= 0.9701 val_acc= 0.7667 time= 0.0204\n",
      "Epoch: 0173 train_loss= 0.6291 train_acc= 0.9000 val_loss= 0.9665 val_acc= 0.7667 time= 0.0279\n",
      "Epoch: 0174 train_loss= 0.6260 train_acc= 0.9000 val_loss= 0.9630 val_acc= 0.7667 time= 0.0210\n",
      "Epoch: 0175 train_loss= 0.6219 train_acc= 0.9000 val_loss= 0.9612 val_acc= 0.7667 time= 0.0199\n",
      "Epoch: 0176 train_loss= 0.6185 train_acc= 0.9000 val_loss= 0.9612 val_acc= 0.7700 time= 0.0239\n",
      "Epoch: 0177 train_loss= 0.6160 train_acc= 0.9000 val_loss= 0.9608 val_acc= 0.7667 time= 0.0238\n",
      "Epoch: 0178 train_loss= 0.6134 train_acc= 0.9000 val_loss= 0.9587 val_acc= 0.7667 time= 0.0232\n",
      "Epoch: 0179 train_loss= 0.6101 train_acc= 0.9000 val_loss= 0.9558 val_acc= 0.7600 time= 0.0241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0180 train_loss= 0.6070 train_acc= 0.9071 val_loss= 0.9522 val_acc= 0.7667 time= 0.0237\n",
      "Epoch: 0181 train_loss= 0.6040 train_acc= 0.9000 val_loss= 0.9492 val_acc= 0.7667 time= 0.0208\n",
      "Epoch: 0182 train_loss= 0.6011 train_acc= 0.9000 val_loss= 0.9464 val_acc= 0.7733 time= 0.0232\n",
      "Epoch: 0183 train_loss= 0.5978 train_acc= 0.9000 val_loss= 0.9443 val_acc= 0.7767 time= 0.0251\n",
      "Epoch: 0184 train_loss= 0.5944 train_acc= 0.9000 val_loss= 0.9423 val_acc= 0.7767 time= 0.0206\n",
      "Epoch: 0185 train_loss= 0.5909 train_acc= 0.9000 val_loss= 0.9411 val_acc= 0.7767 time= 0.0229\n",
      "Epoch: 0186 train_loss= 0.5879 train_acc= 0.9000 val_loss= 0.9419 val_acc= 0.7833 time= 0.0237\n",
      "Epoch: 0187 train_loss= 0.5855 train_acc= 0.9000 val_loss= 0.9407 val_acc= 0.7833 time= 0.0232\n",
      "Epoch: 0188 train_loss= 0.5833 train_acc= 0.9000 val_loss= 0.9393 val_acc= 0.7767 time= 0.0288\n",
      "Epoch: 0189 train_loss= 0.5812 train_acc= 0.9000 val_loss= 0.9381 val_acc= 0.7767 time= 0.0235\n",
      "Epoch: 0190 train_loss= 0.5791 train_acc= 0.9000 val_loss= 0.9361 val_acc= 0.7800 time= 0.0239\n",
      "Epoch: 0191 train_loss= 0.5774 train_acc= 0.9000 val_loss= 0.9332 val_acc= 0.7800 time= 0.0200\n",
      "Epoch: 0192 train_loss= 0.5754 train_acc= 0.9071 val_loss= 0.9304 val_acc= 0.7800 time= 0.0192\n",
      "Epoch: 0193 train_loss= 0.5729 train_acc= 0.9071 val_loss= 0.9280 val_acc= 0.7800 time= 0.0284\n",
      "Epoch: 0194 train_loss= 0.5704 train_acc= 0.9071 val_loss= 0.9256 val_acc= 0.7800 time= 0.0198\n",
      "Epoch: 0195 train_loss= 0.5680 train_acc= 0.9071 val_loss= 0.9234 val_acc= 0.7867 time= 0.0229\n",
      "Epoch: 0196 train_loss= 0.5658 train_acc= 0.9000 val_loss= 0.9219 val_acc= 0.7867 time= 0.0209\n",
      "Epoch: 0197 train_loss= 0.5635 train_acc= 0.9000 val_loss= 0.9206 val_acc= 0.7867 time= 0.0237\n",
      "Epoch: 0198 train_loss= 0.5612 train_acc= 0.9000 val_loss= 0.9189 val_acc= 0.7867 time= 0.0242\n",
      "Epoch: 0199 train_loss= 0.5589 train_acc= 0.9000 val_loss= 0.9174 val_acc= 0.7867 time= 0.0201\n",
      "Epoch: 0200 train_loss= 0.5562 train_acc= 0.9000 val_loss= 0.9148 val_acc= 0.7867 time= 0.0192\n"
     ]
    }
   ],
   "source": [
    "NB_EPOCH = 200\n",
    "PATIENCE = 10  # early stopping patience\n",
    "# Helper variables for main training loop\n",
    "wait = 0\n",
    "preds = None\n",
    "best_val_loss = 99999\n",
    "\n",
    "# Fit\n",
    "for epoch in range(1, NB_EPOCH+1):\n",
    "\n",
    "    # Log wall-clock time\n",
    "    t = time.time()\n",
    "\n",
    "    # Single training iteration (we mask nodes without labels for loss calculation)\n",
    "    model.fit(graph, y_train, sample_weight=train_mask,\n",
    "              batch_size=A.shape[0], epochs=1, shuffle=False, verbose=0)\n",
    "\n",
    "    # Predict on full dataset\n",
    "    preds = model.predict(graph, batch_size=A.shape[0])\n",
    "\n",
    "    # Train / validation scores\n",
    "    train_val_loss, train_val_acc = evaluate_preds(preds, [y_train, y_val],\n",
    "                                                   [idx_train, idx_val])\n",
    "    print(\"Epoch: {:04d}\".format(epoch),\n",
    "          \"train_loss= {:.4f}\".format(train_val_loss[0]),\n",
    "          \"train_acc= {:.4f}\".format(train_val_acc[0]),\n",
    "          \"val_loss= {:.4f}\".format(train_val_loss[1]),\n",
    "          \"val_acc= {:.4f}\".format(train_val_acc[1]),\n",
    "          \"time= {:.4f}\".format(time.time() - t))\n",
    "\n",
    "    # Early stopping\n",
    "    if train_val_loss[1] < best_val_loss:\n",
    "        best_val_loss = train_val_loss[1]\n",
    "        wait = 0\n",
    "    else:\n",
    "        if wait >= PATIENCE:\n",
    "            print('Epoch {}: early stopping'.format(epoch))\n",
    "            break\n",
    "        wait += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.9675\n",
      "accuracy = 0.7370\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate_preds(preds, [y_test], [idx_test])\n",
    "print(f\"\"\"\n",
    "loss = {test_loss[0]:.4f}\n",
    "accuracy = {test_acc[0]:.4f}\n",
    "\"\"\".strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Graph Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1110 16:45:00.016038 140535297824576 deprecation.py:323] From /home/bitcommander/Desktop/robust-graph-convolutional-networks-against-adversarial-attacks-implementation/ggcn/ggcl.py:163: Normal.__init__ (from tensorflow.python.ops.distributions.normal) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
      "W1110 16:45:00.017428 140535297824576 deprecation.py:323] From /home/bitcommander/.local/lib/python3.7/site-packages/tensorflow/python/ops/distributions/normal.py:160: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n"
     ]
    }
   ],
   "source": [
    "H = Dropout(0.5)(X_in)\n",
    "H = GaussianGraphConvolution(16, A.shape[0], \n",
    "    is_first=True, \n",
    "    activation='relu', \n",
    "    kernel_regularizer=l2(5e-4)\n",
    ")([H]+G)\n",
    "Y = GaussianGraphConvolution(y.shape[1], A.shape[0], \n",
    "    is_last=True,\n",
    "    activation='softmax'\n",
    ")(H+G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[X_in]+G, outputs=Y)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 1433)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 1433)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_graph_convolution_1 (G [(None, 16), (None,  45856       dropout_3[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_graph_convolution_2 (G (None, 7)            224         gaussian_graph_convolution_1[0][0\n",
      "                                                                 gaussian_graph_convolution_1[0][1\n",
      "                                                                 input_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 46,080\n",
      "Trainable params: 46,080\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 train_loss= 1.9396 train_acc= 0.3786 val_loss= 1.9416 val_acc= 0.3300 time= 0.4114\n",
      "Epoch: 0002 train_loss= 1.9315 train_acc= 0.5786 val_loss= 1.9362 val_acc= 0.4233 time= 0.0182\n",
      "Epoch: 0003 train_loss= 1.9222 train_acc= 0.5929 val_loss= 1.9295 val_acc= 0.4733 time= 0.0227\n",
      "Epoch: 0004 train_loss= 1.9107 train_acc= 0.6714 val_loss= 1.9213 val_acc= 0.5467 time= 0.0228\n",
      "Epoch: 0005 train_loss= 1.8989 train_acc= 0.7143 val_loss= 1.9131 val_acc= 0.5500 time= 0.0179\n",
      "Epoch: 0006 train_loss= 1.8871 train_acc= 0.7500 val_loss= 1.9040 val_acc= 0.5967 time= 0.0236\n",
      "Epoch: 0007 train_loss= 1.8726 train_acc= 0.7429 val_loss= 1.8928 val_acc= 0.6400 time= 0.0224\n",
      "Epoch: 0008 train_loss= 1.8602 train_acc= 0.7286 val_loss= 1.8845 val_acc= 0.6200 time= 0.0190\n",
      "Epoch: 0009 train_loss= 1.8432 train_acc= 0.7286 val_loss= 1.8729 val_acc= 0.6300 time= 0.0232\n",
      "Epoch: 0010 train_loss= 1.8301 train_acc= 0.7000 val_loss= 1.8615 val_acc= 0.6267 time= 0.0225\n",
      "Epoch: 0011 train_loss= 1.8125 train_acc= 0.7429 val_loss= 1.8492 val_acc= 0.6067 time= 0.0184\n",
      "Epoch: 0012 train_loss= 1.7964 train_acc= 0.6929 val_loss= 1.8354 val_acc= 0.6100 time= 0.0187\n",
      "Epoch: 0013 train_loss= 1.7784 train_acc= 0.6857 val_loss= 1.8234 val_acc= 0.5900 time= 0.0226\n",
      "Epoch: 0014 train_loss= 1.7570 train_acc= 0.6929 val_loss= 1.8088 val_acc= 0.5967 time= 0.0235\n",
      "Epoch: 0015 train_loss= 1.7384 train_acc= 0.6714 val_loss= 1.7938 val_acc= 0.5767 time= 0.0189\n",
      "Epoch: 0016 train_loss= 1.7199 train_acc= 0.6643 val_loss= 1.7800 val_acc= 0.5767 time= 0.0186\n",
      "Epoch: 0017 train_loss= 1.6974 train_acc= 0.6429 val_loss= 1.7633 val_acc= 0.5800 time= 0.0186\n",
      "Epoch: 0018 train_loss= 1.6778 train_acc= 0.6429 val_loss= 1.7473 val_acc= 0.5767 time= 0.0233\n",
      "Epoch: 0019 train_loss= 1.6533 train_acc= 0.6714 val_loss= 1.7302 val_acc= 0.5800 time= 0.0186\n",
      "Epoch: 0020 train_loss= 1.6315 train_acc= 0.6500 val_loss= 1.7129 val_acc= 0.5800 time= 0.0190\n",
      "Epoch: 0021 train_loss= 1.6076 train_acc= 0.6643 val_loss= 1.6954 val_acc= 0.5867 time= 0.0231\n",
      "Epoch: 0022 train_loss= 1.5844 train_acc= 0.6500 val_loss= 1.6771 val_acc= 0.5800 time= 0.0191\n",
      "Epoch: 0023 train_loss= 1.5580 train_acc= 0.6571 val_loss= 1.6587 val_acc= 0.5867 time= 0.0233\n",
      "Epoch: 0024 train_loss= 1.5334 train_acc= 0.6429 val_loss= 1.6399 val_acc= 0.5900 time= 0.0187\n",
      "Epoch: 0025 train_loss= 1.5086 train_acc= 0.6643 val_loss= 1.6208 val_acc= 0.5900 time= 0.0197\n",
      "Epoch: 0026 train_loss= 1.4833 train_acc= 0.6643 val_loss= 1.6015 val_acc= 0.5900 time= 0.0237\n",
      "Epoch: 0027 train_loss= 1.4560 train_acc= 0.6643 val_loss= 1.5813 val_acc= 0.5933 time= 0.0186\n",
      "Epoch: 0028 train_loss= 1.4311 train_acc= 0.6643 val_loss= 1.5615 val_acc= 0.5967 time= 0.0225\n",
      "Epoch: 0029 train_loss= 1.4046 train_acc= 0.6643 val_loss= 1.5424 val_acc= 0.6000 time= 0.0225\n",
      "Epoch: 0030 train_loss= 1.3778 train_acc= 0.6643 val_loss= 1.5225 val_acc= 0.5967 time= 0.0187\n",
      "Epoch: 0031 train_loss= 1.3496 train_acc= 0.6714 val_loss= 1.5017 val_acc= 0.6033 time= 0.0184\n",
      "Epoch: 0032 train_loss= 1.3241 train_acc= 0.6786 val_loss= 1.4817 val_acc= 0.6133 time= 0.0213\n",
      "Epoch: 0033 train_loss= 1.2963 train_acc= 0.6857 val_loss= 1.4620 val_acc= 0.6167 time= 0.0182\n",
      "Epoch: 0034 train_loss= 1.2702 train_acc= 0.6929 val_loss= 1.4413 val_acc= 0.6133 time= 0.0181\n",
      "Epoch: 0035 train_loss= 1.2435 train_acc= 0.6929 val_loss= 1.4217 val_acc= 0.6267 time= 0.0182\n",
      "Epoch: 0036 train_loss= 1.2174 train_acc= 0.7214 val_loss= 1.4004 val_acc= 0.6300 time= 0.0186\n",
      "Epoch: 0037 train_loss= 1.1915 train_acc= 0.7143 val_loss= 1.3797 val_acc= 0.6433 time= 0.0184\n",
      "Epoch: 0038 train_loss= 1.1653 train_acc= 0.7357 val_loss= 1.3601 val_acc= 0.6400 time= 0.0183\n",
      "Epoch: 0039 train_loss= 1.1378 train_acc= 0.7500 val_loss= 1.3399 val_acc= 0.6433 time= 0.0181\n",
      "Epoch: 0040 train_loss= 1.1128 train_acc= 0.7571 val_loss= 1.3205 val_acc= 0.6467 time= 0.0184\n",
      "Epoch: 0041 train_loss= 1.0860 train_acc= 0.7786 val_loss= 1.3002 val_acc= 0.6467 time= 0.0205\n",
      "Epoch: 0042 train_loss= 1.0606 train_acc= 0.7929 val_loss= 1.2808 val_acc= 0.6633 time= 0.0233\n",
      "Epoch: 0043 train_loss= 1.0359 train_acc= 0.8071 val_loss= 1.2618 val_acc= 0.6667 time= 0.0200\n",
      "Epoch: 0044 train_loss= 1.0094 train_acc= 0.8286 val_loss= 1.2423 val_acc= 0.6800 time= 0.0184\n",
      "Epoch: 0045 train_loss= 0.9865 train_acc= 0.8357 val_loss= 1.2227 val_acc= 0.6867 time= 0.0226\n",
      "Epoch: 0046 train_loss= 0.9608 train_acc= 0.8500 val_loss= 1.2039 val_acc= 0.6967 time= 0.0181\n",
      "Epoch: 0047 train_loss= 0.9372 train_acc= 0.8500 val_loss= 1.1859 val_acc= 0.7167 time= 0.0182\n",
      "Epoch: 0048 train_loss= 0.9132 train_acc= 0.8714 val_loss= 1.1683 val_acc= 0.7267 time= 0.0228\n",
      "Epoch: 0049 train_loss= 0.8908 train_acc= 0.8714 val_loss= 1.1494 val_acc= 0.7400 time= 0.0238\n",
      "Epoch: 0050 train_loss= 0.8688 train_acc= 0.8857 val_loss= 1.1322 val_acc= 0.7500 time= 0.0190\n",
      "Epoch: 0051 train_loss= 0.8460 train_acc= 0.8929 val_loss= 1.1157 val_acc= 0.7567 time= 0.0232\n",
      "Epoch: 0052 train_loss= 0.8240 train_acc= 0.8929 val_loss= 1.0986 val_acc= 0.7667 time= 0.0242\n",
      "Epoch: 0053 train_loss= 0.8046 train_acc= 0.8929 val_loss= 1.0823 val_acc= 0.7700 time= 0.0243\n",
      "Epoch: 0054 train_loss= 0.7833 train_acc= 0.8929 val_loss= 1.0643 val_acc= 0.7800 time= 0.0196\n",
      "Epoch: 0055 train_loss= 0.7636 train_acc= 0.8929 val_loss= 1.0504 val_acc= 0.7800 time= 0.0198\n",
      "Epoch: 0056 train_loss= 0.7419 train_acc= 0.9000 val_loss= 1.0338 val_acc= 0.7833 time= 0.0209\n",
      "Epoch: 0057 train_loss= 0.7231 train_acc= 0.9071 val_loss= 1.0175 val_acc= 0.7867 time= 0.0225\n",
      "Epoch: 0058 train_loss= 0.7039 train_acc= 0.9071 val_loss= 1.0025 val_acc= 0.7900 time= 0.0255\n",
      "Epoch: 0059 train_loss= 0.6869 train_acc= 0.9071 val_loss= 0.9874 val_acc= 0.7867 time= 0.0200\n",
      "Epoch: 0060 train_loss= 0.6670 train_acc= 0.9071 val_loss= 0.9736 val_acc= 0.7867 time= 0.0196\n",
      "Epoch: 0061 train_loss= 0.6511 train_acc= 0.9071 val_loss= 0.9604 val_acc= 0.7833 time= 0.0202\n",
      "Epoch: 0062 train_loss= 0.6325 train_acc= 0.9071 val_loss= 0.9457 val_acc= 0.7867 time= 0.0196\n",
      "Epoch: 0063 train_loss= 0.6172 train_acc= 0.9071 val_loss= 0.9325 val_acc= 0.7933 time= 0.0197\n",
      "Epoch: 0064 train_loss= 0.6022 train_acc= 0.9071 val_loss= 0.9197 val_acc= 0.8033 time= 0.0192\n",
      "Epoch: 0065 train_loss= 0.5846 train_acc= 0.9071 val_loss= 0.9083 val_acc= 0.8033 time= 0.0190\n",
      "Epoch: 0066 train_loss= 0.5705 train_acc= 0.9143 val_loss= 0.8957 val_acc= 0.8033 time= 0.0243\n",
      "Epoch: 0067 train_loss= 0.5545 train_acc= 0.9214 val_loss= 0.8838 val_acc= 0.8033 time= 0.0229\n",
      "Epoch: 0068 train_loss= 0.5399 train_acc= 0.9214 val_loss= 0.8733 val_acc= 0.8033 time= 0.0187\n",
      "Epoch: 0069 train_loss= 0.5273 train_acc= 0.9214 val_loss= 0.8617 val_acc= 0.8033 time= 0.0192\n",
      "Epoch: 0070 train_loss= 0.5141 train_acc= 0.9214 val_loss= 0.8513 val_acc= 0.8033 time= 0.0192\n",
      "Epoch: 0071 train_loss= 0.5004 train_acc= 0.9214 val_loss= 0.8405 val_acc= 0.8033 time= 0.0193\n",
      "Epoch: 0072 train_loss= 0.4868 train_acc= 0.9214 val_loss= 0.8309 val_acc= 0.8033 time= 0.0190\n",
      "Epoch: 0073 train_loss= 0.4765 train_acc= 0.9214 val_loss= 0.8218 val_acc= 0.8067 time= 0.0193\n",
      "Epoch: 0074 train_loss= 0.4627 train_acc= 0.9286 val_loss= 0.8128 val_acc= 0.8067 time= 0.0188\n",
      "Epoch: 0075 train_loss= 0.4516 train_acc= 0.9286 val_loss= 0.8052 val_acc= 0.8100 time= 0.0198\n",
      "Epoch: 0076 train_loss= 0.4399 train_acc= 0.9286 val_loss= 0.7953 val_acc= 0.8100 time= 0.0190\n",
      "Epoch: 0077 train_loss= 0.4305 train_acc= 0.9286 val_loss= 0.7879 val_acc= 0.8100 time= 0.0196\n",
      "Epoch: 0078 train_loss= 0.4199 train_acc= 0.9286 val_loss= 0.7807 val_acc= 0.8067 time= 0.0191\n",
      "Epoch: 0079 train_loss= 0.4102 train_acc= 0.9286 val_loss= 0.7744 val_acc= 0.8033 time= 0.0195\n",
      "Epoch: 0080 train_loss= 0.3993 train_acc= 0.9286 val_loss= 0.7658 val_acc= 0.8000 time= 0.0192\n",
      "Epoch: 0081 train_loss= 0.3894 train_acc= 0.9286 val_loss= 0.7593 val_acc= 0.7967 time= 0.0199\n",
      "Epoch: 0082 train_loss= 0.3821 train_acc= 0.9286 val_loss= 0.7534 val_acc= 0.7967 time= 0.0205\n",
      "Epoch: 0083 train_loss= 0.3732 train_acc= 0.9286 val_loss= 0.7475 val_acc= 0.7967 time= 0.0193\n",
      "Epoch: 0084 train_loss= 0.3632 train_acc= 0.9286 val_loss= 0.7417 val_acc= 0.7967 time= 0.0214\n",
      "Epoch: 0085 train_loss= 0.3566 train_acc= 0.9286 val_loss= 0.7349 val_acc= 0.7967 time= 0.0191\n",
      "Epoch: 0086 train_loss= 0.3492 train_acc= 0.9286 val_loss= 0.7290 val_acc= 0.7967 time= 0.0202\n",
      "Epoch: 0087 train_loss= 0.3398 train_acc= 0.9286 val_loss= 0.7245 val_acc= 0.7967 time= 0.0192\n",
      "Epoch: 0088 train_loss= 0.3323 train_acc= 0.9286 val_loss= 0.7189 val_acc= 0.7967 time= 0.0192\n",
      "Epoch: 0089 train_loss= 0.3245 train_acc= 0.9286 val_loss= 0.7143 val_acc= 0.7967 time= 0.0186\n",
      "Epoch: 0090 train_loss= 0.3186 train_acc= 0.9286 val_loss= 0.7093 val_acc= 0.7967 time= 0.0236\n",
      "Epoch: 0091 train_loss= 0.3116 train_acc= 0.9357 val_loss= 0.7042 val_acc= 0.7967 time= 0.0184\n",
      "Epoch: 0092 train_loss= 0.3046 train_acc= 0.9357 val_loss= 0.6990 val_acc= 0.7967 time= 0.0244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0093 train_loss= 0.2972 train_acc= 0.9357 val_loss= 0.6936 val_acc= 0.7967 time= 0.0208\n",
      "Epoch: 0094 train_loss= 0.2909 train_acc= 0.9357 val_loss= 0.6915 val_acc= 0.8000 time= 0.0197\n",
      "Epoch: 0095 train_loss= 0.2854 train_acc= 0.9357 val_loss= 0.6862 val_acc= 0.8000 time= 0.0188\n",
      "Epoch: 0096 train_loss= 0.2805 train_acc= 0.9357 val_loss= 0.6820 val_acc= 0.7967 time= 0.0231\n",
      "Epoch: 0097 train_loss= 0.2746 train_acc= 0.9357 val_loss= 0.6797 val_acc= 0.8000 time= 0.0184\n",
      "Epoch: 0098 train_loss= 0.2683 train_acc= 0.9357 val_loss= 0.6746 val_acc= 0.8000 time= 0.0185\n",
      "Epoch: 0099 train_loss= 0.2616 train_acc= 0.9357 val_loss= 0.6724 val_acc= 0.8000 time= 0.0279\n",
      "Epoch: 0100 train_loss= 0.2564 train_acc= 0.9357 val_loss= 0.6691 val_acc= 0.8000 time= 0.0242\n",
      "Epoch: 0101 train_loss= 0.2534 train_acc= 0.9357 val_loss= 0.6658 val_acc= 0.8000 time= 0.0190\n",
      "Epoch: 0102 train_loss= 0.2484 train_acc= 0.9357 val_loss= 0.6634 val_acc= 0.8033 time= 0.0273\n",
      "Epoch: 0103 train_loss= 0.2430 train_acc= 0.9357 val_loss= 0.6608 val_acc= 0.8033 time= 0.0283\n",
      "Epoch: 0104 train_loss= 0.2370 train_acc= 0.9357 val_loss= 0.6590 val_acc= 0.8033 time= 0.0231\n",
      "Epoch: 0105 train_loss= 0.2331 train_acc= 0.9429 val_loss= 0.6572 val_acc= 0.8067 time= 0.0187\n",
      "Epoch: 0106 train_loss= 0.2272 train_acc= 0.9429 val_loss= 0.6540 val_acc= 0.8067 time= 0.0224\n",
      "Epoch: 0107 train_loss= 0.2233 train_acc= 0.9429 val_loss= 0.6511 val_acc= 0.8067 time= 0.0189\n",
      "Epoch: 0108 train_loss= 0.2194 train_acc= 0.9429 val_loss= 0.6492 val_acc= 0.8067 time= 0.0187\n",
      "Epoch: 0109 train_loss= 0.2154 train_acc= 0.9429 val_loss= 0.6475 val_acc= 0.8067 time= 0.0185\n",
      "Epoch: 0110 train_loss= 0.2112 train_acc= 0.9429 val_loss= 0.6449 val_acc= 0.8100 time= 0.0258\n",
      "Epoch: 0111 train_loss= 0.2064 train_acc= 0.9500 val_loss= 0.6427 val_acc= 0.8100 time= 0.0240\n",
      "Epoch: 0112 train_loss= 0.2022 train_acc= 0.9500 val_loss= 0.6404 val_acc= 0.8100 time= 0.0194\n",
      "Epoch: 0113 train_loss= 0.1983 train_acc= 0.9500 val_loss= 0.6375 val_acc= 0.8100 time= 0.0235\n",
      "Epoch: 0114 train_loss= 0.1939 train_acc= 0.9571 val_loss= 0.6345 val_acc= 0.8100 time= 0.0208\n",
      "Epoch: 0115 train_loss= 0.1900 train_acc= 0.9571 val_loss= 0.6320 val_acc= 0.8133 time= 0.0185\n",
      "Epoch: 0116 train_loss= 0.1868 train_acc= 0.9571 val_loss= 0.6307 val_acc= 0.8167 time= 0.0185\n",
      "Epoch: 0117 train_loss= 0.1829 train_acc= 0.9571 val_loss= 0.6288 val_acc= 0.8133 time= 0.0186\n",
      "Epoch: 0118 train_loss= 0.1793 train_acc= 0.9643 val_loss= 0.6258 val_acc= 0.8133 time= 0.0203\n",
      "Epoch: 0119 train_loss= 0.1765 train_acc= 0.9643 val_loss= 0.6242 val_acc= 0.8133 time= 0.0188\n",
      "Epoch: 0120 train_loss= 0.1731 train_acc= 0.9643 val_loss= 0.6235 val_acc= 0.8167 time= 0.0188\n",
      "Epoch: 0121 train_loss= 0.1695 train_acc= 0.9714 val_loss= 0.6205 val_acc= 0.8200 time= 0.0187\n",
      "Epoch: 0122 train_loss= 0.1667 train_acc= 0.9643 val_loss= 0.6199 val_acc= 0.8200 time= 0.0183\n",
      "Epoch: 0123 train_loss= 0.1626 train_acc= 0.9786 val_loss= 0.6176 val_acc= 0.8200 time= 0.0238\n",
      "Epoch: 0124 train_loss= 0.1596 train_acc= 0.9857 val_loss= 0.6168 val_acc= 0.8267 time= 0.0186\n",
      "Epoch: 0125 train_loss= 0.1558 train_acc= 0.9857 val_loss= 0.6152 val_acc= 0.8267 time= 0.0196\n",
      "Epoch: 0126 train_loss= 0.1527 train_acc= 0.9857 val_loss= 0.6140 val_acc= 0.8300 time= 0.0195\n",
      "Epoch: 0127 train_loss= 0.1500 train_acc= 0.9857 val_loss= 0.6131 val_acc= 0.8300 time= 0.0188\n",
      "Epoch: 0128 train_loss= 0.1469 train_acc= 0.9857 val_loss= 0.6121 val_acc= 0.8367 time= 0.0198\n",
      "Epoch: 0129 train_loss= 0.1442 train_acc= 0.9857 val_loss= 0.6112 val_acc= 0.8367 time= 0.0243\n",
      "Epoch: 0130 train_loss= 0.1412 train_acc= 0.9857 val_loss= 0.6106 val_acc= 0.8333 time= 0.0189\n",
      "Epoch: 0131 train_loss= 0.1386 train_acc= 0.9857 val_loss= 0.6089 val_acc= 0.8367 time= 0.0186\n",
      "Epoch: 0132 train_loss= 0.1365 train_acc= 0.9857 val_loss= 0.6089 val_acc= 0.8367 time= 0.0236\n",
      "Epoch: 0133 train_loss= 0.1332 train_acc= 0.9857 val_loss= 0.6082 val_acc= 0.8367 time= 0.0207\n",
      "Epoch: 0134 train_loss= 0.1312 train_acc= 0.9857 val_loss= 0.6071 val_acc= 0.8367 time= 0.0202\n",
      "Epoch: 0135 train_loss= 0.1280 train_acc= 0.9857 val_loss= 0.6072 val_acc= 0.8367 time= 0.0237\n",
      "Epoch: 0136 train_loss= 0.1262 train_acc= 0.9857 val_loss= 0.6054 val_acc= 0.8400 time= 0.0194\n",
      "Epoch: 0137 train_loss= 0.1229 train_acc= 0.9857 val_loss= 0.6063 val_acc= 0.8367 time= 0.0214\n",
      "Epoch: 0138 train_loss= 0.1207 train_acc= 0.9857 val_loss= 0.6054 val_acc= 0.8433 time= 0.0199\n",
      "Epoch: 0139 train_loss= 0.1180 train_acc= 0.9929 val_loss= 0.6044 val_acc= 0.8433 time= 0.0197\n",
      "Epoch: 0140 train_loss= 0.1168 train_acc= 0.9929 val_loss= 0.6035 val_acc= 0.8400 time= 0.0195\n",
      "Epoch: 0141 train_loss= 0.1139 train_acc= 0.9929 val_loss= 0.6038 val_acc= 0.8400 time= 0.0191\n",
      "Epoch: 0142 train_loss= 0.1117 train_acc= 0.9929 val_loss= 0.6017 val_acc= 0.8400 time= 0.0189\n",
      "Epoch: 0143 train_loss= 0.1097 train_acc= 0.9929 val_loss= 0.6005 val_acc= 0.8400 time= 0.0187\n",
      "Epoch: 0144 train_loss= 0.1075 train_acc= 0.9929 val_loss= 0.6014 val_acc= 0.8367 time= 0.0190\n",
      "Epoch: 0145 train_loss= 0.1054 train_acc= 0.9929 val_loss= 0.6003 val_acc= 0.8367 time= 0.0236\n",
      "Epoch: 0146 train_loss= 0.1036 train_acc= 0.9929 val_loss= 0.5990 val_acc= 0.8333 time= 0.0186\n",
      "Epoch: 0147 train_loss= 0.1009 train_acc= 0.9929 val_loss= 0.5997 val_acc= 0.8300 time= 0.0188\n",
      "Epoch: 0148 train_loss= 0.0993 train_acc= 0.9929 val_loss= 0.5975 val_acc= 0.8300 time= 0.0187\n",
      "Epoch: 0149 train_loss= 0.0971 train_acc= 0.9929 val_loss= 0.5974 val_acc= 0.8267 time= 0.0189\n",
      "Epoch: 0150 train_loss= 0.0959 train_acc= 0.9929 val_loss= 0.5961 val_acc= 0.8267 time= 0.0193\n",
      "Epoch: 0151 train_loss= 0.0936 train_acc= 0.9929 val_loss= 0.5947 val_acc= 0.8267 time= 0.0185\n",
      "Epoch: 0152 train_loss= 0.0925 train_acc= 0.9929 val_loss= 0.5951 val_acc= 0.8267 time= 0.0191\n",
      "Epoch: 0153 train_loss= 0.0903 train_acc= 0.9929 val_loss= 0.5934 val_acc= 0.8267 time= 0.0186\n",
      "Epoch: 0154 train_loss= 0.0885 train_acc= 0.9929 val_loss= 0.5931 val_acc= 0.8267 time= 0.0200\n",
      "Epoch: 0155 train_loss= 0.0867 train_acc= 0.9929 val_loss= 0.5921 val_acc= 0.8267 time= 0.0232\n",
      "Epoch: 0156 train_loss= 0.0854 train_acc= 0.9929 val_loss= 0.5918 val_acc= 0.8300 time= 0.0184\n",
      "Epoch: 0157 train_loss= 0.0838 train_acc= 0.9929 val_loss= 0.5923 val_acc= 0.8267 time= 0.0209\n",
      "Epoch: 0158 train_loss= 0.0820 train_acc= 0.9929 val_loss= 0.5908 val_acc= 0.8300 time= 0.0186\n",
      "Epoch: 0159 train_loss= 0.0801 train_acc= 0.9929 val_loss= 0.5913 val_acc= 0.8333 time= 0.0192\n",
      "Epoch: 0160 train_loss= 0.0794 train_acc= 0.9929 val_loss= 0.5918 val_acc= 0.8300 time= 0.0188\n",
      "Epoch: 0161 train_loss= 0.0778 train_acc= 0.9929 val_loss= 0.5915 val_acc= 0.8233 time= 0.0223\n",
      "Epoch: 0162 train_loss= 0.0761 train_acc= 0.9929 val_loss= 0.5911 val_acc= 0.8267 time= 0.0210\n",
      "Epoch: 0163 train_loss= 0.0752 train_acc= 0.9929 val_loss= 0.5920 val_acc= 0.8267 time= 0.0199\n",
      "Epoch: 0164 train_loss= 0.0735 train_acc= 0.9929 val_loss= 0.5919 val_acc= 0.8233 time= 0.0200\n",
      "Epoch: 0165 train_loss= 0.0722 train_acc= 0.9929 val_loss= 0.5912 val_acc= 0.8267 time= 0.0231\n",
      "Epoch: 0166 train_loss= 0.0712 train_acc= 0.9929 val_loss= 0.5931 val_acc= 0.8300 time= 0.0194\n",
      "Epoch: 0167 train_loss= 0.0700 train_acc= 0.9929 val_loss= 0.5927 val_acc= 0.8267 time= 0.0189\n",
      "Epoch: 0168 train_loss= 0.0688 train_acc= 0.9929 val_loss= 0.5923 val_acc= 0.8267 time= 0.0195\n",
      "Epoch: 0169 train_loss= 0.0667 train_acc= 0.9929 val_loss= 0.5933 val_acc= 0.8233 time= 0.0190\n",
      "Epoch 169: early stopping\n"
     ]
    }
   ],
   "source": [
    "NB_EPOCH = 200\n",
    "PATIENCE = 10  # early stopping patience\n",
    "# Helper variables for main training loop\n",
    "wait = 0\n",
    "preds = None\n",
    "best_val_loss = 99999\n",
    "\n",
    "# Fit\n",
    "for epoch in range(1, NB_EPOCH+1):\n",
    "\n",
    "    # Log wall-clock time\n",
    "    t = time.time()\n",
    "\n",
    "    # Single training iteration (we mask nodes without labels for loss calculation)\n",
    "    model.fit(graph, y_train, sample_weight=train_mask,\n",
    "              batch_size=A.shape[0], epochs=1, shuffle=False, verbose=0)\n",
    "\n",
    "    # Predict on full dataset\n",
    "    preds = model.predict(graph, batch_size=A.shape[0])\n",
    "\n",
    "    # Train / validation scores\n",
    "    train_val_loss, train_val_acc = evaluate_preds(preds, [y_train, y_val],\n",
    "                                                   [idx_train, idx_val])\n",
    "    print(\"Epoch: {:04d}\".format(epoch),\n",
    "          \"train_loss= {:.4f}\".format(train_val_loss[0]),\n",
    "          \"train_acc= {:.4f}\".format(train_val_acc[0]),\n",
    "          \"val_loss= {:.4f}\".format(train_val_loss[1]),\n",
    "          \"val_acc= {:.4f}\".format(train_val_acc[1]),\n",
    "          \"time= {:.4f}\".format(time.time() - t))\n",
    "\n",
    "    # Early stopping\n",
    "    if train_val_loss[1] < best_val_loss:\n",
    "        best_val_loss = train_val_loss[1]\n",
    "        wait = 0\n",
    "    else:\n",
    "        if wait >= PATIENCE:\n",
    "            print('Epoch {}: early stopping'.format(epoch))\n",
    "            break\n",
    "        wait += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.6044\n",
      "accuracy = 0.8120\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate_preds(preds, [y_test], [idx_test])\n",
    "print(f\"\"\"\n",
    "loss = {test_loss[0]:.4f}\n",
    "accuracy = {test_acc[0]:.4f}\n",
    "\"\"\".strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
