{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from keras.layers import Input, Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the path of execution\n",
    "EXE_PATH = os.path.abspath(os.path.curdir)\n",
    "# the path of the vendor files\n",
    "VENDOR_PATH = os.path.join(EXE_PATH, 'vendor')\n",
    "# the vendors to include in the system path\n",
    "VENDORS = ['keras-gcn']\n",
    "# create the absolute paths for all vendors\n",
    "VENDORS = list(map(lambda x: os.path.join(VENDOR_PATH, x), VENDORS))\n",
    "# update the Python path to include necessary vendor module\n",
    "sys.path += VENDORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kegra.layers.graph import GraphConvolution\n",
    "from kegra.utils import load_data, preprocess_adj, get_splits, evaluate_preds\n",
    "from ggcn import GaussianGraphConvolution, kl_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cora dataset...\n",
      "Dataset has 2708 nodes, 5429 edges, 1433 features.\n"
     ]
    }
   ],
   "source": [
    "X, A, y = load_data('data/cora/', dataset='cora')\n",
    "X /= X.sum(1).reshape(-1, 1)\n",
    "A = preprocess_adj(A)\n",
    "y_train, y_val, y_test, idx_train, idx_val, idx_test, train_mask = get_splits(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2708x2708 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 13264 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 1, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 0]], dtype=int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1110 17:54:38.822537 140209855174464 deprecation_wrapper.py:119] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1110 17:54:38.829378 140209855174464 deprecation_wrapper.py:119] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:515: The name tf.sparse_placeholder is deprecated. Please use tf.compat.v1.sparse_placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "support = 1\n",
    "graph = [X, A]\n",
    "G = [Input(shape=(None, None), batch_shape=(None, None), sparse=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1110 17:54:38.835401 140209855174464 deprecation_wrapper.py:119] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_in = Input(shape=(X.shape[1],))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCN (baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1110 17:54:38.840952 140209855174464 deprecation_wrapper.py:119] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W1110 17:54:38.845859 140209855174464 deprecation.py:506] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W1110 17:54:38.854705 140209855174464 deprecation_wrapper.py:119] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define model architecture\n",
    "# NOTE: We pass arguments for graph convolutional layers as a list of tensors.\n",
    "# This is somewhat hacky, more elegant options would require rewriting the Layer base class.\n",
    "H = Dropout(0.5)(X_in)\n",
    "H = GraphConvolution(32, support, activation='relu', kernel_regularizer=l2(5e-4))([H]+G)\n",
    "H = Dropout(0.5)(H)\n",
    "Y = GraphConvolution(y.shape[1], support, activation='softmax')([H]+G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1110 17:54:38.898071 140209855174464 deprecation_wrapper.py:119] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=[X_in]+G, outputs=Y)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 1433)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1433)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "graph_convolution_1 (GraphConvo (None, 32)           45888       dropout_1[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 32)           0           graph_convolution_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "graph_convolution_2 (GraphConvo (None, 7)            231         dropout_2[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 46,119\n",
      "Trainable params: 46,119\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1110 17:54:38.974126 140209855174464 deprecation.py:323] From /home/bitcommander/.local/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 train_loss= 1.9280 train_acc= 0.4357 val_loss= 1.9314 val_acc= 0.4133 time= 1.1280\n",
      "Epoch: 0002 train_loss= 1.9093 train_acc= 0.4500 val_loss= 1.9157 val_acc= 0.4333 time= 0.0236\n",
      "Epoch: 0003 train_loss= 1.8882 train_acc= 0.4571 val_loss= 1.8982 val_acc= 0.4400 time= 0.0288\n",
      "Epoch: 0004 train_loss= 1.8657 train_acc= 0.4643 val_loss= 1.8800 val_acc= 0.4467 time= 0.0272\n",
      "Epoch: 0005 train_loss= 1.8425 train_acc= 0.4643 val_loss= 1.8613 val_acc= 0.4667 time= 0.0183\n",
      "Epoch: 0006 train_loss= 1.8193 train_acc= 0.4643 val_loss= 1.8429 val_acc= 0.4700 time= 0.0199\n",
      "Epoch: 0007 train_loss= 1.7969 train_acc= 0.4643 val_loss= 1.8254 val_acc= 0.4733 time= 0.0201\n",
      "Epoch: 0008 train_loss= 1.7754 train_acc= 0.4643 val_loss= 1.8088 val_acc= 0.4700 time= 0.0241\n",
      "Epoch: 0009 train_loss= 1.7554 train_acc= 0.4643 val_loss= 1.7933 val_acc= 0.4600 time= 0.0249\n",
      "Epoch: 0010 train_loss= 1.7374 train_acc= 0.4643 val_loss= 1.7797 val_acc= 0.4333 time= 0.0251\n",
      "Epoch: 0011 train_loss= 1.7217 train_acc= 0.4500 val_loss= 1.7681 val_acc= 0.4233 time= 0.0198\n",
      "Epoch: 0012 train_loss= 1.7078 train_acc= 0.4357 val_loss= 1.7582 val_acc= 0.4100 time= 0.0206\n",
      "Epoch: 0013 train_loss= 1.6953 train_acc= 0.4357 val_loss= 1.7495 val_acc= 0.4067 time= 0.0188\n",
      "Epoch: 0014 train_loss= 1.6833 train_acc= 0.4286 val_loss= 1.7413 val_acc= 0.3967 time= 0.0185\n",
      "Epoch: 0015 train_loss= 1.6713 train_acc= 0.4214 val_loss= 1.7331 val_acc= 0.3900 time= 0.0236\n",
      "Epoch: 0016 train_loss= 1.6585 train_acc= 0.4214 val_loss= 1.7246 val_acc= 0.3933 time= 0.0241\n",
      "Epoch: 0017 train_loss= 1.6447 train_acc= 0.4357 val_loss= 1.7155 val_acc= 0.3967 time= 0.0241\n",
      "Epoch: 0018 train_loss= 1.6297 train_acc= 0.4357 val_loss= 1.7053 val_acc= 0.4000 time= 0.0249\n",
      "Epoch: 0019 train_loss= 1.6140 train_acc= 0.4357 val_loss= 1.6947 val_acc= 0.4100 time= 0.0236\n",
      "Epoch: 0020 train_loss= 1.5979 train_acc= 0.4500 val_loss= 1.6841 val_acc= 0.4167 time= 0.0262\n",
      "Epoch: 0021 train_loss= 1.5820 train_acc= 0.4571 val_loss= 1.6737 val_acc= 0.4233 time= 0.0237\n",
      "Epoch: 0022 train_loss= 1.5665 train_acc= 0.4571 val_loss= 1.6636 val_acc= 0.4267 time= 0.0194\n",
      "Epoch: 0023 train_loss= 1.5512 train_acc= 0.4571 val_loss= 1.6533 val_acc= 0.4433 time= 0.0189\n",
      "Epoch: 0024 train_loss= 1.5361 train_acc= 0.4571 val_loss= 1.6432 val_acc= 0.4433 time= 0.0193\n",
      "Epoch: 0025 train_loss= 1.5210 train_acc= 0.4643 val_loss= 1.6333 val_acc= 0.4600 time= 0.0234\n",
      "Epoch: 0026 train_loss= 1.5060 train_acc= 0.4786 val_loss= 1.6235 val_acc= 0.4567 time= 0.0215\n",
      "Epoch: 0027 train_loss= 1.4908 train_acc= 0.4857 val_loss= 1.6134 val_acc= 0.4600 time= 0.0228\n",
      "Epoch: 0028 train_loss= 1.4754 train_acc= 0.4857 val_loss= 1.6031 val_acc= 0.4700 time= 0.0187\n",
      "Epoch: 0029 train_loss= 1.4598 train_acc= 0.4857 val_loss= 1.5927 val_acc= 0.4767 time= 0.0232\n",
      "Epoch: 0030 train_loss= 1.4441 train_acc= 0.5000 val_loss= 1.5821 val_acc= 0.4700 time= 0.0195\n",
      "Epoch: 0031 train_loss= 1.4285 train_acc= 0.5143 val_loss= 1.5711 val_acc= 0.4767 time= 0.0231\n",
      "Epoch: 0032 train_loss= 1.4129 train_acc= 0.5143 val_loss= 1.5600 val_acc= 0.4767 time= 0.0199\n",
      "Epoch: 0033 train_loss= 1.3974 train_acc= 0.5214 val_loss= 1.5486 val_acc= 0.4767 time= 0.0232\n",
      "Epoch: 0034 train_loss= 1.3819 train_acc= 0.5214 val_loss= 1.5372 val_acc= 0.4767 time= 0.0241\n",
      "Epoch: 0035 train_loss= 1.3666 train_acc= 0.5143 val_loss= 1.5259 val_acc= 0.4767 time= 0.0234\n",
      "Epoch: 0036 train_loss= 1.3510 train_acc= 0.5143 val_loss= 1.5143 val_acc= 0.4800 time= 0.0233\n",
      "Epoch: 0037 train_loss= 1.3354 train_acc= 0.5143 val_loss= 1.5026 val_acc= 0.4867 time= 0.0241\n",
      "Epoch: 0038 train_loss= 1.3199 train_acc= 0.5143 val_loss= 1.4912 val_acc= 0.4967 time= 0.0253\n",
      "Epoch: 0039 train_loss= 1.3044 train_acc= 0.5143 val_loss= 1.4799 val_acc= 0.5000 time= 0.0193\n",
      "Epoch: 0040 train_loss= 1.2888 train_acc= 0.5143 val_loss= 1.4686 val_acc= 0.5033 time= 0.0206\n",
      "Epoch: 0041 train_loss= 1.2730 train_acc= 0.5429 val_loss= 1.4573 val_acc= 0.5100 time= 0.0229\n",
      "Epoch: 0042 train_loss= 1.2569 train_acc= 0.5571 val_loss= 1.4464 val_acc= 0.5267 time= 0.0280\n",
      "Epoch: 0043 train_loss= 1.2409 train_acc= 0.6000 val_loss= 1.4355 val_acc= 0.5400 time= 0.0275\n",
      "Epoch: 0044 train_loss= 1.2253 train_acc= 0.6714 val_loss= 1.4247 val_acc= 0.5467 time= 0.0191\n",
      "Epoch: 0045 train_loss= 1.2099 train_acc= 0.7071 val_loss= 1.4139 val_acc= 0.5633 time= 0.0277\n",
      "Epoch: 0046 train_loss= 1.1945 train_acc= 0.7429 val_loss= 1.4026 val_acc= 0.5867 time= 0.0182\n",
      "Epoch: 0047 train_loss= 1.1793 train_acc= 0.7500 val_loss= 1.3911 val_acc= 0.5967 time= 0.0184\n",
      "Epoch: 0048 train_loss= 1.1644 train_acc= 0.7500 val_loss= 1.3794 val_acc= 0.6067 time= 0.0244\n",
      "Epoch: 0049 train_loss= 1.1493 train_acc= 0.7500 val_loss= 1.3678 val_acc= 0.6133 time= 0.0240\n",
      "Epoch: 0050 train_loss= 1.1342 train_acc= 0.7571 val_loss= 1.3560 val_acc= 0.6200 time= 0.0224\n",
      "Epoch: 0051 train_loss= 1.1190 train_acc= 0.7643 val_loss= 1.3443 val_acc= 0.6267 time= 0.0243\n",
      "Epoch: 0052 train_loss= 1.1039 train_acc= 0.7786 val_loss= 1.3328 val_acc= 0.6267 time= 0.0186\n",
      "Epoch: 0053 train_loss= 1.0891 train_acc= 0.7857 val_loss= 1.3212 val_acc= 0.6300 time= 0.0295\n",
      "Epoch: 0054 train_loss= 1.0742 train_acc= 0.7786 val_loss= 1.3093 val_acc= 0.6367 time= 0.0236\n",
      "Epoch: 0055 train_loss= 1.0597 train_acc= 0.7786 val_loss= 1.2977 val_acc= 0.6400 time= 0.0229\n",
      "Epoch: 0056 train_loss= 1.0450 train_acc= 0.7786 val_loss= 1.2859 val_acc= 0.6467 time= 0.0230\n",
      "Epoch: 0057 train_loss= 1.0303 train_acc= 0.7929 val_loss= 1.2739 val_acc= 0.6567 time= 0.0258\n",
      "Epoch: 0058 train_loss= 1.0153 train_acc= 0.8071 val_loss= 1.2619 val_acc= 0.6667 time= 0.0241\n",
      "Epoch: 0059 train_loss= 1.0007 train_acc= 0.8214 val_loss= 1.2502 val_acc= 0.6767 time= 0.0256\n",
      "Epoch: 0060 train_loss= 0.9862 train_acc= 0.8286 val_loss= 1.2383 val_acc= 0.6933 time= 0.0286\n",
      "Epoch: 0061 train_loss= 0.9719 train_acc= 0.8286 val_loss= 1.2268 val_acc= 0.7000 time= 0.0217\n",
      "Epoch: 0062 train_loss= 0.9580 train_acc= 0.8286 val_loss= 1.2151 val_acc= 0.7000 time= 0.0232\n",
      "Epoch: 0063 train_loss= 0.9442 train_acc= 0.8286 val_loss= 1.2035 val_acc= 0.7067 time= 0.0226\n",
      "Epoch: 0064 train_loss= 0.9304 train_acc= 0.8286 val_loss= 1.1920 val_acc= 0.7200 time= 0.0197\n",
      "Epoch: 0065 train_loss= 0.9169 train_acc= 0.8357 val_loss= 1.1807 val_acc= 0.7200 time= 0.0286\n",
      "Epoch: 0066 train_loss= 0.9038 train_acc= 0.8357 val_loss= 1.1696 val_acc= 0.7200 time= 0.0230\n",
      "Epoch: 0067 train_loss= 0.8911 train_acc= 0.8429 val_loss= 1.1589 val_acc= 0.7233 time= 0.0240\n",
      "Epoch: 0068 train_loss= 0.8785 train_acc= 0.8500 val_loss= 1.1488 val_acc= 0.7233 time= 0.0278\n",
      "Epoch: 0069 train_loss= 0.8662 train_acc= 0.8571 val_loss= 1.1388 val_acc= 0.7233 time= 0.0199\n",
      "Epoch: 0070 train_loss= 0.8539 train_acc= 0.8571 val_loss= 1.1291 val_acc= 0.7267 time= 0.0293\n",
      "Epoch: 0071 train_loss= 0.8418 train_acc= 0.8571 val_loss= 1.1205 val_acc= 0.7267 time= 0.0192\n",
      "Epoch: 0072 train_loss= 0.8301 train_acc= 0.8571 val_loss= 1.1127 val_acc= 0.7433 time= 0.0228\n",
      "Epoch: 0073 train_loss= 0.8188 train_acc= 0.8643 val_loss= 1.1050 val_acc= 0.7500 time= 0.0196\n",
      "Epoch: 0074 train_loss= 0.8080 train_acc= 0.8643 val_loss= 1.0978 val_acc= 0.7500 time= 0.0188\n",
      "Epoch: 0075 train_loss= 0.7978 train_acc= 0.8786 val_loss= 1.0913 val_acc= 0.7567 time= 0.0231\n",
      "Epoch: 0076 train_loss= 0.7877 train_acc= 0.8786 val_loss= 1.0837 val_acc= 0.7567 time= 0.0231\n",
      "Epoch: 0077 train_loss= 0.7769 train_acc= 0.8929 val_loss= 1.0738 val_acc= 0.7533 time= 0.0212\n",
      "Epoch: 0078 train_loss= 0.7662 train_acc= 0.9071 val_loss= 1.0634 val_acc= 0.7567 time= 0.0204\n",
      "Epoch: 0079 train_loss= 0.7562 train_acc= 0.8857 val_loss= 1.0527 val_acc= 0.7500 time= 0.0271\n",
      "Epoch: 0080 train_loss= 0.7479 train_acc= 0.8786 val_loss= 1.0433 val_acc= 0.7433 time= 0.0196\n",
      "Epoch: 0081 train_loss= 0.7404 train_acc= 0.8786 val_loss= 1.0358 val_acc= 0.7433 time= 0.0280\n",
      "Epoch: 0082 train_loss= 0.7317 train_acc= 0.8786 val_loss= 1.0287 val_acc= 0.7433 time= 0.0253\n",
      "Epoch: 0083 train_loss= 0.7224 train_acc= 0.8857 val_loss= 1.0216 val_acc= 0.7533 time= 0.0227\n",
      "Epoch: 0084 train_loss= 0.7126 train_acc= 0.8857 val_loss= 1.0158 val_acc= 0.7667 time= 0.0250\n",
      "Epoch: 0085 train_loss= 0.7040 train_acc= 0.9071 val_loss= 1.0113 val_acc= 0.7700 time= 0.0282\n",
      "Epoch: 0086 train_loss= 0.6968 train_acc= 0.9071 val_loss= 1.0077 val_acc= 0.7733 time= 0.0187\n",
      "Epoch: 0087 train_loss= 0.6897 train_acc= 0.9071 val_loss= 1.0033 val_acc= 0.7733 time= 0.0229\n",
      "Epoch: 0088 train_loss= 0.6818 train_acc= 0.9143 val_loss= 0.9964 val_acc= 0.7733 time= 0.0227\n",
      "Epoch: 0089 train_loss= 0.6736 train_acc= 0.9143 val_loss= 0.9876 val_acc= 0.7767 time= 0.0202\n",
      "Epoch: 0090 train_loss= 0.6659 train_acc= 0.9143 val_loss= 0.9790 val_acc= 0.7767 time= 0.0227\n",
      "Epoch: 0091 train_loss= 0.6598 train_acc= 0.9143 val_loss= 0.9718 val_acc= 0.7667 time= 0.0188\n",
      "Epoch: 0092 train_loss= 0.6538 train_acc= 0.9143 val_loss= 0.9659 val_acc= 0.7667 time= 0.0182\n",
      "Epoch: 0093 train_loss= 0.6467 train_acc= 0.9143 val_loss= 0.9602 val_acc= 0.7733 time= 0.0231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0094 train_loss= 0.6395 train_acc= 0.9143 val_loss= 0.9549 val_acc= 0.7833 time= 0.0251\n",
      "Epoch: 0095 train_loss= 0.6326 train_acc= 0.9143 val_loss= 0.9503 val_acc= 0.7933 time= 0.0226\n",
      "Epoch: 0096 train_loss= 0.6263 train_acc= 0.9214 val_loss= 0.9463 val_acc= 0.7900 time= 0.0243\n",
      "Epoch: 0097 train_loss= 0.6206 train_acc= 0.9214 val_loss= 0.9437 val_acc= 0.7933 time= 0.0193\n",
      "Epoch: 0098 train_loss= 0.6151 train_acc= 0.9214 val_loss= 0.9399 val_acc= 0.7967 time= 0.0288\n",
      "Epoch: 0099 train_loss= 0.6096 train_acc= 0.9214 val_loss= 0.9353 val_acc= 0.8000 time= 0.0246\n",
      "Epoch: 0100 train_loss= 0.6045 train_acc= 0.9286 val_loss= 0.9305 val_acc= 0.7967 time= 0.0232\n",
      "Epoch: 0101 train_loss= 0.5991 train_acc= 0.9286 val_loss= 0.9247 val_acc= 0.8000 time= 0.0231\n",
      "Epoch: 0102 train_loss= 0.5937 train_acc= 0.9214 val_loss= 0.9188 val_acc= 0.8000 time= 0.0249\n",
      "Epoch: 0103 train_loss= 0.5894 train_acc= 0.9214 val_loss= 0.9143 val_acc= 0.7967 time= 0.0242\n",
      "Epoch: 0104 train_loss= 0.5851 train_acc= 0.9143 val_loss= 0.9107 val_acc= 0.7933 time= 0.0188\n",
      "Epoch: 0105 train_loss= 0.5802 train_acc= 0.9214 val_loss= 0.9075 val_acc= 0.7900 time= 0.0245\n",
      "Epoch: 0106 train_loss= 0.5746 train_acc= 0.9214 val_loss= 0.9048 val_acc= 0.7933 time= 0.0280\n",
      "Epoch: 0107 train_loss= 0.5693 train_acc= 0.9286 val_loss= 0.9029 val_acc= 0.7900 time= 0.0191\n",
      "Epoch: 0108 train_loss= 0.5662 train_acc= 0.9357 val_loss= 0.9039 val_acc= 0.7900 time= 0.0239\n",
      "Epoch: 0109 train_loss= 0.5628 train_acc= 0.9357 val_loss= 0.9030 val_acc= 0.7833 time= 0.0252\n",
      "Epoch: 0110 train_loss= 0.5583 train_acc= 0.9429 val_loss= 0.8999 val_acc= 0.7800 time= 0.0243\n",
      "Epoch: 0111 train_loss= 0.5517 train_acc= 0.9500 val_loss= 0.8918 val_acc= 0.7900 time= 0.0182\n",
      "Epoch: 0112 train_loss= 0.5456 train_acc= 0.9500 val_loss= 0.8838 val_acc= 0.7933 time= 0.0245\n",
      "Epoch: 0113 train_loss= 0.5417 train_acc= 0.9500 val_loss= 0.8777 val_acc= 0.7900 time= 0.0190\n",
      "Epoch: 0114 train_loss= 0.5400 train_acc= 0.9500 val_loss= 0.8751 val_acc= 0.7867 time= 0.0250\n",
      "Epoch: 0115 train_loss= 0.5375 train_acc= 0.9429 val_loss= 0.8738 val_acc= 0.7867 time= 0.0281\n",
      "Epoch: 0116 train_loss= 0.5321 train_acc= 0.9429 val_loss= 0.8723 val_acc= 0.7900 time= 0.0193\n",
      "Epoch: 0117 train_loss= 0.5263 train_acc= 0.9429 val_loss= 0.8708 val_acc= 0.8000 time= 0.0275\n",
      "Epoch: 0118 train_loss= 0.5208 train_acc= 0.9429 val_loss= 0.8689 val_acc= 0.7967 time= 0.0216\n",
      "Epoch: 0119 train_loss= 0.5156 train_acc= 0.9500 val_loss= 0.8653 val_acc= 0.7900 time= 0.0194\n",
      "Epoch: 0120 train_loss= 0.5106 train_acc= 0.9571 val_loss= 0.8608 val_acc= 0.7867 time= 0.0283\n",
      "Epoch: 0121 train_loss= 0.5067 train_acc= 0.9571 val_loss= 0.8573 val_acc= 0.7833 time= 0.0240\n",
      "Epoch: 0122 train_loss= 0.5037 train_acc= 0.9571 val_loss= 0.8548 val_acc= 0.7867 time= 0.0196\n",
      "Epoch: 0123 train_loss= 0.5006 train_acc= 0.9571 val_loss= 0.8516 val_acc= 0.7900 time= 0.0235\n",
      "Epoch: 0124 train_loss= 0.4970 train_acc= 0.9571 val_loss= 0.8465 val_acc= 0.7933 time= 0.0232\n",
      "Epoch: 0125 train_loss= 0.4931 train_acc= 0.9643 val_loss= 0.8414 val_acc= 0.7933 time= 0.0247\n",
      "Epoch: 0126 train_loss= 0.4898 train_acc= 0.9571 val_loss= 0.8372 val_acc= 0.7967 time= 0.0240\n",
      "Epoch: 0127 train_loss= 0.4872 train_acc= 0.9571 val_loss= 0.8344 val_acc= 0.7933 time= 0.0235\n",
      "Epoch: 0128 train_loss= 0.4845 train_acc= 0.9571 val_loss= 0.8331 val_acc= 0.8033 time= 0.0229\n",
      "Epoch: 0129 train_loss= 0.4811 train_acc= 0.9571 val_loss= 0.8321 val_acc= 0.8067 time= 0.0187\n",
      "Epoch: 0130 train_loss= 0.4771 train_acc= 0.9643 val_loss= 0.8315 val_acc= 0.8033 time= 0.0232\n",
      "Epoch: 0131 train_loss= 0.4732 train_acc= 0.9643 val_loss= 0.8314 val_acc= 0.7967 time= 0.0187\n",
      "Epoch: 0132 train_loss= 0.4702 train_acc= 0.9643 val_loss= 0.8320 val_acc= 0.8000 time= 0.0190\n",
      "Epoch: 0133 train_loss= 0.4663 train_acc= 0.9643 val_loss= 0.8287 val_acc= 0.8033 time= 0.0239\n",
      "Epoch: 0134 train_loss= 0.4625 train_acc= 0.9643 val_loss= 0.8249 val_acc= 0.8033 time= 0.0178\n",
      "Epoch: 0135 train_loss= 0.4591 train_acc= 0.9643 val_loss= 0.8211 val_acc= 0.8033 time= 0.0223\n",
      "Epoch: 0136 train_loss= 0.4560 train_acc= 0.9643 val_loss= 0.8177 val_acc= 0.8033 time= 0.0189\n",
      "Epoch: 0137 train_loss= 0.4534 train_acc= 0.9643 val_loss= 0.8145 val_acc= 0.8033 time= 0.0187\n",
      "Epoch: 0138 train_loss= 0.4512 train_acc= 0.9643 val_loss= 0.8122 val_acc= 0.7900 time= 0.0229\n",
      "Epoch: 0139 train_loss= 0.4485 train_acc= 0.9643 val_loss= 0.8101 val_acc= 0.7933 time= 0.0182\n",
      "Epoch: 0140 train_loss= 0.4445 train_acc= 0.9643 val_loss= 0.8077 val_acc= 0.8033 time= 0.0187\n",
      "Epoch: 0141 train_loss= 0.4409 train_acc= 0.9643 val_loss= 0.8054 val_acc= 0.8067 time= 0.0231\n",
      "Epoch: 0142 train_loss= 0.4381 train_acc= 0.9643 val_loss= 0.8052 val_acc= 0.8100 time= 0.0279\n",
      "Epoch: 0143 train_loss= 0.4362 train_acc= 0.9643 val_loss= 0.8062 val_acc= 0.8167 time= 0.0242\n",
      "Epoch: 0144 train_loss= 0.4341 train_acc= 0.9714 val_loss= 0.8060 val_acc= 0.8267 time= 0.0232\n",
      "Epoch: 0145 train_loss= 0.4313 train_acc= 0.9714 val_loss= 0.8041 val_acc= 0.8267 time= 0.0185\n",
      "Epoch: 0146 train_loss= 0.4281 train_acc= 0.9714 val_loss= 0.7999 val_acc= 0.8267 time= 0.0197\n",
      "Epoch: 0147 train_loss= 0.4257 train_acc= 0.9714 val_loss= 0.7945 val_acc= 0.8233 time= 0.0237\n",
      "Epoch: 0148 train_loss= 0.4236 train_acc= 0.9714 val_loss= 0.7921 val_acc= 0.8167 time= 0.0224\n",
      "Epoch: 0149 train_loss= 0.4211 train_acc= 0.9643 val_loss= 0.7919 val_acc= 0.8167 time= 0.0199\n",
      "Epoch: 0150 train_loss= 0.4194 train_acc= 0.9643 val_loss= 0.7913 val_acc= 0.8100 time= 0.0288\n",
      "Epoch: 0151 train_loss= 0.4175 train_acc= 0.9643 val_loss= 0.7903 val_acc= 0.8067 time= 0.0237\n",
      "Epoch: 0152 train_loss= 0.4153 train_acc= 0.9643 val_loss= 0.7885 val_acc= 0.8067 time= 0.0238\n",
      "Epoch: 0153 train_loss= 0.4130 train_acc= 0.9714 val_loss= 0.7863 val_acc= 0.8067 time= 0.0252\n",
      "Epoch: 0154 train_loss= 0.4107 train_acc= 0.9714 val_loss= 0.7839 val_acc= 0.8133 time= 0.0239\n",
      "Epoch: 0155 train_loss= 0.4084 train_acc= 0.9714 val_loss= 0.7819 val_acc= 0.8167 time= 0.0248\n",
      "Epoch: 0156 train_loss= 0.4072 train_acc= 0.9714 val_loss= 0.7798 val_acc= 0.8133 time= 0.0186\n",
      "Epoch: 0157 train_loss= 0.4055 train_acc= 0.9714 val_loss= 0.7791 val_acc= 0.8100 time= 0.0240\n",
      "Epoch: 0158 train_loss= 0.4045 train_acc= 0.9643 val_loss= 0.7806 val_acc= 0.8100 time= 0.0236\n",
      "Epoch: 0159 train_loss= 0.4036 train_acc= 0.9643 val_loss= 0.7843 val_acc= 0.8067 time= 0.0232\n",
      "Epoch: 0160 train_loss= 0.4024 train_acc= 0.9714 val_loss= 0.7863 val_acc= 0.8100 time= 0.0193\n",
      "Epoch: 0161 train_loss= 0.3995 train_acc= 0.9786 val_loss= 0.7853 val_acc= 0.8033 time= 0.0187\n",
      "Epoch: 0162 train_loss= 0.3957 train_acc= 0.9786 val_loss= 0.7812 val_acc= 0.8133 time= 0.0242\n",
      "Epoch: 0163 train_loss= 0.3913 train_acc= 0.9643 val_loss= 0.7737 val_acc= 0.8133 time= 0.0248\n",
      "Epoch: 0164 train_loss= 0.3888 train_acc= 0.9714 val_loss= 0.7682 val_acc= 0.8000 time= 0.0281\n",
      "Epoch: 0165 train_loss= 0.3873 train_acc= 0.9714 val_loss= 0.7645 val_acc= 0.8100 time= 0.0233\n",
      "Epoch: 0166 train_loss= 0.3847 train_acc= 0.9714 val_loss= 0.7601 val_acc= 0.8100 time= 0.0236\n",
      "Epoch: 0167 train_loss= 0.3813 train_acc= 0.9714 val_loss= 0.7555 val_acc= 0.8133 time= 0.0278\n",
      "Epoch: 0168 train_loss= 0.3780 train_acc= 0.9714 val_loss= 0.7521 val_acc= 0.8233 time= 0.0204\n",
      "Epoch: 0169 train_loss= 0.3757 train_acc= 0.9714 val_loss= 0.7496 val_acc= 0.8333 time= 0.0281\n",
      "Epoch: 0170 train_loss= 0.3748 train_acc= 0.9714 val_loss= 0.7481 val_acc= 0.8367 time= 0.0203\n",
      "Epoch: 0171 train_loss= 0.3734 train_acc= 0.9714 val_loss= 0.7467 val_acc= 0.8300 time= 0.0284\n",
      "Epoch: 0172 train_loss= 0.3707 train_acc= 0.9714 val_loss= 0.7464 val_acc= 0.8233 time= 0.0242\n",
      "Epoch: 0173 train_loss= 0.3679 train_acc= 0.9714 val_loss= 0.7474 val_acc= 0.8267 time= 0.0245\n",
      "Epoch: 0174 train_loss= 0.3658 train_acc= 0.9786 val_loss= 0.7497 val_acc= 0.8267 time= 0.0282\n",
      "Epoch: 0175 train_loss= 0.3642 train_acc= 0.9786 val_loss= 0.7510 val_acc= 0.8200 time= 0.0233\n",
      "Epoch: 0176 train_loss= 0.3628 train_acc= 0.9786 val_loss= 0.7514 val_acc= 0.8200 time= 0.0240\n",
      "Epoch: 0177 train_loss= 0.3613 train_acc= 0.9786 val_loss= 0.7501 val_acc= 0.8200 time= 0.0192\n",
      "Epoch: 0178 train_loss= 0.3595 train_acc= 0.9786 val_loss= 0.7475 val_acc= 0.8233 time= 0.0224\n",
      "Epoch: 0179 train_loss= 0.3574 train_acc= 0.9714 val_loss= 0.7416 val_acc= 0.8267 time= 0.0222\n",
      "Epoch: 0180 train_loss= 0.3563 train_acc= 0.9714 val_loss= 0.7369 val_acc= 0.8333 time= 0.0191\n",
      "Epoch: 0181 train_loss= 0.3558 train_acc= 0.9714 val_loss= 0.7344 val_acc= 0.8300 time= 0.0194\n",
      "Epoch: 0182 train_loss= 0.3541 train_acc= 0.9714 val_loss= 0.7332 val_acc= 0.8233 time= 0.0272\n",
      "Epoch: 0183 train_loss= 0.3516 train_acc= 0.9714 val_loss= 0.7329 val_acc= 0.8233 time= 0.0269\n",
      "Epoch: 0184 train_loss= 0.3488 train_acc= 0.9714 val_loss= 0.7338 val_acc= 0.8233 time= 0.0195\n",
      "Epoch: 0185 train_loss= 0.3470 train_acc= 0.9786 val_loss= 0.7365 val_acc= 0.8267 time= 0.0230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0186 train_loss= 0.3460 train_acc= 0.9786 val_loss= 0.7388 val_acc= 0.8200 time= 0.0242\n",
      "Epoch: 0187 train_loss= 0.3457 train_acc= 0.9786 val_loss= 0.7409 val_acc= 0.8233 time= 0.0237\n",
      "Epoch: 0188 train_loss= 0.3445 train_acc= 0.9786 val_loss= 0.7400 val_acc= 0.8200 time= 0.0191\n",
      "Epoch: 0189 train_loss= 0.3427 train_acc= 0.9786 val_loss= 0.7377 val_acc= 0.8167 time= 0.0245\n",
      "Epoch: 0190 train_loss= 0.3409 train_acc= 0.9786 val_loss= 0.7339 val_acc= 0.8200 time= 0.0280\n",
      "Epoch: 0191 train_loss= 0.3399 train_acc= 0.9714 val_loss= 0.7304 val_acc= 0.8267 time= 0.0257\n",
      "Epoch: 0192 train_loss= 0.3395 train_acc= 0.9714 val_loss= 0.7294 val_acc= 0.8267 time= 0.0242\n",
      "Epoch: 0193 train_loss= 0.3394 train_acc= 0.9714 val_loss= 0.7291 val_acc= 0.8333 time= 0.0246\n",
      "Epoch: 0194 train_loss= 0.3379 train_acc= 0.9714 val_loss= 0.7275 val_acc= 0.8400 time= 0.0202\n",
      "Epoch: 0195 train_loss= 0.3348 train_acc= 0.9786 val_loss= 0.7262 val_acc= 0.8367 time= 0.0246\n",
      "Epoch: 0196 train_loss= 0.3323 train_acc= 0.9786 val_loss= 0.7268 val_acc= 0.8300 time= 0.0233\n",
      "Epoch: 0197 train_loss= 0.3322 train_acc= 0.9786 val_loss= 0.7303 val_acc= 0.8233 time= 0.0212\n",
      "Epoch: 0198 train_loss= 0.3338 train_acc= 0.9786 val_loss= 0.7356 val_acc= 0.8133 time= 0.0248\n",
      "Epoch: 0199 train_loss= 0.3333 train_acc= 0.9786 val_loss= 0.7355 val_acc= 0.8133 time= 0.0199\n",
      "Epoch: 0200 train_loss= 0.3304 train_acc= 0.9786 val_loss= 0.7309 val_acc= 0.8133 time= 0.0233\n"
     ]
    }
   ],
   "source": [
    "NB_EPOCH = 200\n",
    "PATIENCE = 10  # early stopping patience\n",
    "# Helper variables for main training loop\n",
    "wait = 0\n",
    "preds = None\n",
    "best_val_loss = 99999\n",
    "\n",
    "# Fit\n",
    "for epoch in range(1, NB_EPOCH+1):\n",
    "\n",
    "    # Log wall-clock time\n",
    "    t = time.time()\n",
    "\n",
    "    # Single training iteration (we mask nodes without labels for loss calculation)\n",
    "    model.fit(graph, y_train, sample_weight=train_mask,\n",
    "              batch_size=A.shape[0], epochs=1, shuffle=False, verbose=0)\n",
    "\n",
    "    # Predict on full dataset\n",
    "    preds = model.predict(graph, batch_size=A.shape[0])\n",
    "\n",
    "    # Train / validation scores\n",
    "    train_val_loss, train_val_acc = evaluate_preds(preds, [y_train, y_val],\n",
    "                                                   [idx_train, idx_val])\n",
    "    print(\"Epoch: {:04d}\".format(epoch),\n",
    "          \"train_loss= {:.4f}\".format(train_val_loss[0]),\n",
    "          \"train_acc= {:.4f}\".format(train_val_acc[0]),\n",
    "          \"val_loss= {:.4f}\".format(train_val_loss[1]),\n",
    "          \"val_acc= {:.4f}\".format(train_val_acc[1]),\n",
    "          \"time= {:.4f}\".format(time.time() - t))\n",
    "\n",
    "    # Early stopping\n",
    "    if train_val_loss[1] < best_val_loss:\n",
    "        best_val_loss = train_val_loss[1]\n",
    "        wait = 0\n",
    "    else:\n",
    "        if wait >= PATIENCE:\n",
    "            print('Epoch {}: early stopping'.format(epoch))\n",
    "            break\n",
    "        wait += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.7818\n",
      "accuracy = 0.8110\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate_preds(preds, [y_test], [idx_test])\n",
    "print(f\"\"\"\n",
    "loss = {test_loss[0]:.4f}\n",
    "accuracy = {test_acc[0]:.4f}\n",
    "\"\"\".strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Graph Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "B1 = 5e-4\n",
    "B2 = 5e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1110 17:54:44.703981 140209855174464 deprecation.py:323] From /home/bitcommander/Desktop/robust-graph-convolutional-networks-against-adversarial-attacks-implementation/ggcn/ggcl.py:28: Normal.__init__ (from tensorflow.python.ops.distributions.normal) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
      "W1110 17:54:44.705257 140209855174464 deprecation.py:323] From /home/bitcommander/.local/lib/python3.7/site-packages/tensorflow/python/ops/distributions/normal.py:160: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n"
     ]
    }
   ],
   "source": [
    "H = Dropout(0.5)(X_in)\n",
    "H1 = GaussianGraphConvolution(16,\n",
    "    is_first=True,\n",
    "    activation='relu',\n",
    "    mean_regularizer=l2(B1),\n",
    "    variance_regularizer=l2(B1),\n",
    ")([H]+G)\n",
    "Y = GaussianGraphConvolution(y.shape[1],\n",
    "    is_last=True,\n",
    "    activation='softmax',\n",
    ")(H1+G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1110 17:54:44.744564 140209855174464 deprecation.py:323] From /home/bitcommander/Desktop/robust-graph-convolutional-networks-against-adversarial-attacks-implementation/ggcn/losses.py:28: kl_divergence (from tensorflow.python.ops.distributions.kullback_leibler) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=[X_in]+G, outputs=Y)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.01))\n",
    "model.add_loss(kl_reg(*H1, B2), H1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 1433)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 1433)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_graph_convolution_1 (G [(None, 16), (None,  45856       dropout_3[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_graph_convolution_2 (G (None, 7)            224         gaussian_graph_convolution_1[0][0\n",
      "                                                                 gaussian_graph_convolution_1[0][1\n",
      "                                                                 input_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 46,080\n",
      "Trainable params: 46,080\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 train_loss= 1.9415 train_acc= 0.3143 val_loss= 1.9418 val_acc= 0.3400 time= 0.5033\n",
      "Epoch: 0002 train_loss= 1.9344 train_acc= 0.4000 val_loss= 1.9371 val_acc= 0.3867 time= 0.0238\n",
      "Epoch: 0003 train_loss= 1.9290 train_acc= 0.4571 val_loss= 1.9324 val_acc= 0.4233 time= 0.0280\n",
      "Epoch: 0004 train_loss= 1.9204 train_acc= 0.4714 val_loss= 1.9260 val_acc= 0.4767 time= 0.0228\n",
      "Epoch: 0005 train_loss= 1.9126 train_acc= 0.5357 val_loss= 1.9202 val_acc= 0.4833 time= 0.0232\n",
      "Epoch: 0006 train_loss= 1.9049 train_acc= 0.5714 val_loss= 1.9135 val_acc= 0.5100 time= 0.0237\n",
      "Epoch: 0007 train_loss= 1.8963 train_acc= 0.5857 val_loss= 1.9066 val_acc= 0.4933 time= 0.0183\n",
      "Epoch: 0008 train_loss= 1.8867 train_acc= 0.5929 val_loss= 1.8993 val_acc= 0.4833 time= 0.0235\n",
      "Epoch: 0009 train_loss= 1.8764 train_acc= 0.6071 val_loss= 1.8919 val_acc= 0.4933 time= 0.0189\n",
      "Epoch: 0010 train_loss= 1.8653 train_acc= 0.6071 val_loss= 1.8830 val_acc= 0.5167 time= 0.0276\n",
      "Epoch: 0011 train_loss= 1.8566 train_acc= 0.6071 val_loss= 1.8756 val_acc= 0.5233 time= 0.0197\n",
      "Epoch: 0012 train_loss= 1.8440 train_acc= 0.6214 val_loss= 1.8660 val_acc= 0.5267 time= 0.0234\n",
      "Epoch: 0013 train_loss= 1.8340 train_acc= 0.6000 val_loss= 1.8573 val_acc= 0.5300 time= 0.0229\n",
      "Epoch: 0014 train_loss= 1.8199 train_acc= 0.6214 val_loss= 1.8488 val_acc= 0.5333 time= 0.0242\n",
      "Epoch: 0015 train_loss= 1.8080 train_acc= 0.6071 val_loss= 1.8396 val_acc= 0.5467 time= 0.0228\n",
      "Epoch: 0016 train_loss= 1.7943 train_acc= 0.6143 val_loss= 1.8299 val_acc= 0.5333 time= 0.0195\n",
      "Epoch: 0017 train_loss= 1.7812 train_acc= 0.6214 val_loss= 1.8206 val_acc= 0.5333 time= 0.0245\n",
      "Epoch: 0018 train_loss= 1.7670 train_acc= 0.6429 val_loss= 1.8096 val_acc= 0.5333 time= 0.0242\n",
      "Epoch: 0019 train_loss= 1.7541 train_acc= 0.6286 val_loss= 1.7995 val_acc= 0.5333 time= 0.0284\n",
      "Epoch: 0020 train_loss= 1.7412 train_acc= 0.6214 val_loss= 1.7896 val_acc= 0.5367 time= 0.0281\n",
      "Epoch: 0021 train_loss= 1.7261 train_acc= 0.6143 val_loss= 1.7777 val_acc= 0.5367 time= 0.0200\n",
      "Epoch: 0022 train_loss= 1.7092 train_acc= 0.6286 val_loss= 1.7669 val_acc= 0.5433 time= 0.0237\n",
      "Epoch: 0023 train_loss= 1.6954 train_acc= 0.6214 val_loss= 1.7555 val_acc= 0.5400 time= 0.0283\n",
      "Epoch: 0024 train_loss= 1.6801 train_acc= 0.6286 val_loss= 1.7438 val_acc= 0.5433 time= 0.0278\n",
      "Epoch: 0025 train_loss= 1.6639 train_acc= 0.6143 val_loss= 1.7324 val_acc= 0.5433 time= 0.0232\n",
      "Epoch: 0026 train_loss= 1.6473 train_acc= 0.6214 val_loss= 1.7201 val_acc= 0.5467 time= 0.0181\n",
      "Epoch: 0027 train_loss= 1.6308 train_acc= 0.6143 val_loss= 1.7083 val_acc= 0.5467 time= 0.0232\n",
      "Epoch: 0028 train_loss= 1.6143 train_acc= 0.6071 val_loss= 1.6964 val_acc= 0.5533 time= 0.0189\n",
      "Epoch: 0029 train_loss= 1.5972 train_acc= 0.6071 val_loss= 1.6844 val_acc= 0.5533 time= 0.0200\n",
      "Epoch: 0030 train_loss= 1.5805 train_acc= 0.6071 val_loss= 1.6715 val_acc= 0.5533 time= 0.0194\n",
      "Epoch: 0031 train_loss= 1.5630 train_acc= 0.6143 val_loss= 1.6592 val_acc= 0.5533 time= 0.0229\n",
      "Epoch: 0032 train_loss= 1.5458 train_acc= 0.6071 val_loss= 1.6460 val_acc= 0.5700 time= 0.0236\n",
      "Epoch: 0033 train_loss= 1.5276 train_acc= 0.6143 val_loss= 1.6332 val_acc= 0.5667 time= 0.0283\n",
      "Epoch: 0034 train_loss= 1.5104 train_acc= 0.6071 val_loss= 1.6204 val_acc= 0.5833 time= 0.0225\n",
      "Epoch: 0035 train_loss= 1.4924 train_acc= 0.6143 val_loss= 1.6068 val_acc= 0.5867 time= 0.0225\n",
      "Epoch: 0036 train_loss= 1.4746 train_acc= 0.6071 val_loss= 1.5939 val_acc= 0.5867 time= 0.0233\n",
      "Epoch: 0037 train_loss= 1.4572 train_acc= 0.6143 val_loss= 1.5810 val_acc= 0.5867 time= 0.0184\n",
      "Epoch: 0038 train_loss= 1.4397 train_acc= 0.6143 val_loss= 1.5678 val_acc= 0.5867 time= 0.0205\n",
      "Epoch: 0039 train_loss= 1.4216 train_acc= 0.6143 val_loss= 1.5546 val_acc= 0.5867 time= 0.0274\n",
      "Epoch: 0040 train_loss= 1.4040 train_acc= 0.6286 val_loss= 1.5414 val_acc= 0.5867 time= 0.0183\n",
      "Epoch: 0041 train_loss= 1.3866 train_acc= 0.6429 val_loss= 1.5288 val_acc= 0.5900 time= 0.0235\n",
      "Epoch: 0042 train_loss= 1.3690 train_acc= 0.6357 val_loss= 1.5162 val_acc= 0.5900 time= 0.0225\n",
      "Epoch: 0043 train_loss= 1.3521 train_acc= 0.6429 val_loss= 1.5035 val_acc= 0.5900 time= 0.0235\n",
      "Epoch: 0044 train_loss= 1.3343 train_acc= 0.6429 val_loss= 1.4907 val_acc= 0.5967 time= 0.0235\n",
      "Epoch: 0045 train_loss= 1.3181 train_acc= 0.6429 val_loss= 1.4785 val_acc= 0.5967 time= 0.0194\n",
      "Epoch: 0046 train_loss= 1.3009 train_acc= 0.6500 val_loss= 1.4660 val_acc= 0.5967 time= 0.0190\n",
      "Epoch: 0047 train_loss= 1.2853 train_acc= 0.6500 val_loss= 1.4545 val_acc= 0.5933 time= 0.0210\n",
      "Epoch: 0048 train_loss= 1.2686 train_acc= 0.6571 val_loss= 1.4428 val_acc= 0.6033 time= 0.0284\n",
      "Epoch: 0049 train_loss= 1.2527 train_acc= 0.6643 val_loss= 1.4313 val_acc= 0.6100 time= 0.0195\n",
      "Epoch: 0050 train_loss= 1.2370 train_acc= 0.6714 val_loss= 1.4194 val_acc= 0.6133 time= 0.0186\n",
      "Epoch: 0051 train_loss= 1.2216 train_acc= 0.6786 val_loss= 1.4079 val_acc= 0.6133 time= 0.0179\n",
      "Epoch: 0052 train_loss= 1.2069 train_acc= 0.7000 val_loss= 1.3960 val_acc= 0.6267 time= 0.0185\n",
      "Epoch: 0053 train_loss= 1.1917 train_acc= 0.7071 val_loss= 1.3845 val_acc= 0.6333 time= 0.0183\n",
      "Epoch: 0054 train_loss= 1.1772 train_acc= 0.7143 val_loss= 1.3736 val_acc= 0.6467 time= 0.0184\n",
      "Epoch: 0055 train_loss= 1.1630 train_acc= 0.7286 val_loss= 1.3626 val_acc= 0.6433 time= 0.0182\n",
      "Epoch: 0056 train_loss= 1.1486 train_acc= 0.7357 val_loss= 1.3516 val_acc= 0.6467 time= 0.0189\n",
      "Epoch: 0057 train_loss= 1.1343 train_acc= 0.7500 val_loss= 1.3409 val_acc= 0.6500 time= 0.0280\n",
      "Epoch: 0058 train_loss= 1.1211 train_acc= 0.7429 val_loss= 1.3305 val_acc= 0.6567 time= 0.0294\n",
      "Epoch: 0059 train_loss= 1.1083 train_acc= 0.7429 val_loss= 1.3207 val_acc= 0.6600 time= 0.0241\n",
      "Epoch: 0060 train_loss= 1.0949 train_acc= 0.7571 val_loss= 1.3110 val_acc= 0.6667 time= 0.0226\n",
      "Epoch: 0061 train_loss= 1.0825 train_acc= 0.7571 val_loss= 1.3011 val_acc= 0.6700 time= 0.0283\n",
      "Epoch: 0062 train_loss= 1.0699 train_acc= 0.7571 val_loss= 1.2913 val_acc= 0.6767 time= 0.0238\n",
      "Epoch: 0063 train_loss= 1.0574 train_acc= 0.7571 val_loss= 1.2820 val_acc= 0.6833 time= 0.0228\n",
      "Epoch: 0064 train_loss= 1.0456 train_acc= 0.7786 val_loss= 1.2727 val_acc= 0.6867 time= 0.0186\n",
      "Epoch: 0065 train_loss= 1.0340 train_acc= 0.7929 val_loss= 1.2644 val_acc= 0.6867 time= 0.0239\n",
      "Epoch: 0066 train_loss= 1.0229 train_acc= 0.7857 val_loss= 1.2550 val_acc= 0.6900 time= 0.0249\n",
      "Epoch: 0067 train_loss= 1.0126 train_acc= 0.7929 val_loss= 1.2471 val_acc= 0.6933 time= 0.0277\n",
      "Epoch: 0068 train_loss= 1.0022 train_acc= 0.7929 val_loss= 1.2390 val_acc= 0.6967 time= 0.0242\n",
      "Epoch: 0069 train_loss= 0.9915 train_acc= 0.7929 val_loss= 1.2309 val_acc= 0.7000 time= 0.0208\n",
      "Epoch: 0070 train_loss= 0.9813 train_acc= 0.7929 val_loss= 1.2233 val_acc= 0.7000 time= 0.0233\n",
      "Epoch: 0071 train_loss= 0.9711 train_acc= 0.8000 val_loss= 1.2158 val_acc= 0.7033 time= 0.0319\n",
      "Epoch: 0072 train_loss= 0.9618 train_acc= 0.8000 val_loss= 1.2090 val_acc= 0.7033 time= 0.0303\n",
      "Epoch: 0073 train_loss= 0.9528 train_acc= 0.8071 val_loss= 1.2016 val_acc= 0.7067 time= 0.0195\n",
      "Epoch: 0074 train_loss= 0.9443 train_acc= 0.8071 val_loss= 1.1939 val_acc= 0.7100 time= 0.0302\n",
      "Epoch: 0075 train_loss= 0.9334 train_acc= 0.8214 val_loss= 1.1871 val_acc= 0.7133 time= 0.0248\n",
      "Epoch: 0076 train_loss= 0.9237 train_acc= 0.8286 val_loss= 1.1787 val_acc= 0.7200 time= 0.0246\n",
      "Epoch: 0077 train_loss= 0.9157 train_acc= 0.8286 val_loss= 1.1717 val_acc= 0.7200 time= 0.0280\n",
      "Epoch: 0078 train_loss= 0.9072 train_acc= 0.8357 val_loss= 1.1654 val_acc= 0.7233 time= 0.0244\n",
      "Epoch: 0079 train_loss= 0.8983 train_acc= 0.8500 val_loss= 1.1586 val_acc= 0.7300 time= 0.0230\n",
      "Epoch: 0080 train_loss= 0.8891 train_acc= 0.8571 val_loss= 1.1516 val_acc= 0.7333 time= 0.0234\n",
      "Epoch: 0081 train_loss= 0.8814 train_acc= 0.8571 val_loss= 1.1448 val_acc= 0.7367 time= 0.0227\n",
      "Epoch: 0082 train_loss= 0.8732 train_acc= 0.8571 val_loss= 1.1384 val_acc= 0.7333 time= 0.0185\n",
      "Epoch: 0083 train_loss= 0.8655 train_acc= 0.8571 val_loss= 1.1320 val_acc= 0.7367 time= 0.0182\n",
      "Epoch: 0084 train_loss= 0.8572 train_acc= 0.8571 val_loss= 1.1261 val_acc= 0.7367 time= 0.0209\n",
      "Epoch: 0085 train_loss= 0.8498 train_acc= 0.8643 val_loss= 1.1194 val_acc= 0.7367 time= 0.0187\n",
      "Epoch: 0086 train_loss= 0.8418 train_acc= 0.8571 val_loss= 1.1137 val_acc= 0.7400 time= 0.0241\n",
      "Epoch: 0087 train_loss= 0.8343 train_acc= 0.8714 val_loss= 1.1081 val_acc= 0.7400 time= 0.0232\n",
      "Epoch: 0088 train_loss= 0.8266 train_acc= 0.8714 val_loss= 1.1028 val_acc= 0.7367 time= 0.0191\n",
      "Epoch: 0089 train_loss= 0.8195 train_acc= 0.8714 val_loss= 1.0980 val_acc= 0.7367 time= 0.0183\n",
      "Epoch: 0090 train_loss= 0.8120 train_acc= 0.8714 val_loss= 1.0936 val_acc= 0.7333 time= 0.0245\n",
      "Epoch: 0091 train_loss= 0.8051 train_acc= 0.8714 val_loss= 1.0888 val_acc= 0.7433 time= 0.0228\n",
      "Epoch: 0092 train_loss= 0.7983 train_acc= 0.8786 val_loss= 1.0844 val_acc= 0.7433 time= 0.0237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0093 train_loss= 0.7911 train_acc= 0.8857 val_loss= 1.0794 val_acc= 0.7433 time= 0.0246\n",
      "Epoch: 0094 train_loss= 0.7847 train_acc= 0.8786 val_loss= 1.0744 val_acc= 0.7467 time= 0.0193\n",
      "Epoch: 0095 train_loss= 0.7780 train_acc= 0.8929 val_loss= 1.0691 val_acc= 0.7567 time= 0.0186\n",
      "Epoch: 0096 train_loss= 0.7714 train_acc= 0.8857 val_loss= 1.0631 val_acc= 0.7600 time= 0.0191\n",
      "Epoch: 0097 train_loss= 0.7644 train_acc= 0.8857 val_loss= 1.0574 val_acc= 0.7600 time= 0.0188\n",
      "Epoch: 0098 train_loss= 0.7580 train_acc= 0.8857 val_loss= 1.0522 val_acc= 0.7600 time= 0.0192\n",
      "Epoch: 0099 train_loss= 0.7522 train_acc= 0.8857 val_loss= 1.0467 val_acc= 0.7633 time= 0.0202\n",
      "Epoch: 0100 train_loss= 0.7470 train_acc= 0.8857 val_loss= 1.0416 val_acc= 0.7600 time= 0.0198\n",
      "Epoch: 0101 train_loss= 0.7403 train_acc= 0.8857 val_loss= 1.0358 val_acc= 0.7667 time= 0.0195\n",
      "Epoch: 0102 train_loss= 0.7347 train_acc= 0.8929 val_loss= 1.0312 val_acc= 0.7700 time= 0.0195\n",
      "Epoch: 0103 train_loss= 0.7293 train_acc= 0.8929 val_loss= 1.0271 val_acc= 0.7733 time= 0.0221\n",
      "Epoch: 0104 train_loss= 0.7231 train_acc= 0.8929 val_loss= 1.0225 val_acc= 0.7767 time= 0.0299\n",
      "Epoch: 0105 train_loss= 0.7174 train_acc= 0.9000 val_loss= 1.0185 val_acc= 0.7733 time= 0.0202\n",
      "Epoch: 0106 train_loss= 0.7123 train_acc= 0.9000 val_loss= 1.0145 val_acc= 0.7733 time= 0.0210\n",
      "Epoch: 0107 train_loss= 0.7063 train_acc= 0.9000 val_loss= 1.0108 val_acc= 0.7767 time= 0.0186\n",
      "Epoch: 0108 train_loss= 0.7010 train_acc= 0.9000 val_loss= 1.0071 val_acc= 0.7767 time= 0.0281\n",
      "Epoch: 0109 train_loss= 0.6953 train_acc= 0.9000 val_loss= 1.0041 val_acc= 0.7767 time= 0.0184\n",
      "Epoch: 0110 train_loss= 0.6893 train_acc= 0.9071 val_loss= 1.0005 val_acc= 0.7767 time= 0.0187\n",
      "Epoch: 0111 train_loss= 0.6850 train_acc= 0.9071 val_loss= 0.9971 val_acc= 0.7800 time= 0.0186\n",
      "Epoch: 0112 train_loss= 0.6796 train_acc= 0.9071 val_loss= 0.9937 val_acc= 0.7800 time= 0.0184\n",
      "Epoch: 0113 train_loss= 0.6746 train_acc= 0.9071 val_loss= 0.9900 val_acc= 0.7800 time= 0.0182\n",
      "Epoch: 0114 train_loss= 0.6693 train_acc= 0.9071 val_loss= 0.9856 val_acc= 0.7800 time= 0.0281\n",
      "Epoch: 0115 train_loss= 0.6642 train_acc= 0.9143 val_loss= 0.9817 val_acc= 0.7800 time= 0.0251\n",
      "Epoch: 0116 train_loss= 0.6592 train_acc= 0.9143 val_loss= 0.9770 val_acc= 0.7800 time= 0.0235\n",
      "Epoch: 0117 train_loss= 0.6545 train_acc= 0.9143 val_loss= 0.9722 val_acc= 0.7800 time= 0.0202\n",
      "Epoch: 0118 train_loss= 0.6500 train_acc= 0.9071 val_loss= 0.9675 val_acc= 0.7833 time= 0.0229\n",
      "Epoch: 0119 train_loss= 0.6452 train_acc= 0.9071 val_loss= 0.9632 val_acc= 0.7800 time= 0.0193\n",
      "Epoch: 0120 train_loss= 0.6409 train_acc= 0.9143 val_loss= 0.9594 val_acc= 0.7833 time= 0.0205\n",
      "Epoch: 0121 train_loss= 0.6368 train_acc= 0.9071 val_loss= 0.9552 val_acc= 0.7800 time= 0.0192\n",
      "Epoch: 0122 train_loss= 0.6324 train_acc= 0.9071 val_loss= 0.9519 val_acc= 0.7800 time= 0.0237\n",
      "Epoch: 0123 train_loss= 0.6280 train_acc= 0.9071 val_loss= 0.9485 val_acc= 0.7833 time= 0.0246\n",
      "Epoch: 0124 train_loss= 0.6235 train_acc= 0.9071 val_loss= 0.9453 val_acc= 0.7900 time= 0.0287\n",
      "Epoch: 0125 train_loss= 0.6189 train_acc= 0.9071 val_loss= 0.9423 val_acc= 0.7933 time= 0.0191\n",
      "Epoch: 0126 train_loss= 0.6154 train_acc= 0.9143 val_loss= 0.9408 val_acc= 0.7933 time= 0.0190\n",
      "Epoch: 0127 train_loss= 0.6110 train_acc= 0.9143 val_loss= 0.9385 val_acc= 0.8033 time= 0.0182\n",
      "Epoch: 0128 train_loss= 0.6070 train_acc= 0.9214 val_loss= 0.9363 val_acc= 0.8067 time= 0.0181\n",
      "Epoch: 0129 train_loss= 0.6023 train_acc= 0.9214 val_loss= 0.9335 val_acc= 0.8133 time= 0.0183\n",
      "Epoch: 0130 train_loss= 0.5983 train_acc= 0.9286 val_loss= 0.9307 val_acc= 0.8133 time= 0.0233\n",
      "Epoch: 0131 train_loss= 0.5945 train_acc= 0.9286 val_loss= 0.9276 val_acc= 0.8133 time= 0.0317\n",
      "Epoch: 0132 train_loss= 0.5899 train_acc= 0.9214 val_loss= 0.9245 val_acc= 0.8133 time= 0.0244\n",
      "Epoch: 0133 train_loss= 0.5862 train_acc= 0.9214 val_loss= 0.9215 val_acc= 0.8100 time= 0.0224\n",
      "Epoch: 0134 train_loss= 0.5823 train_acc= 0.9214 val_loss= 0.9186 val_acc= 0.8100 time= 0.0203\n",
      "Epoch: 0135 train_loss= 0.5782 train_acc= 0.9214 val_loss= 0.9157 val_acc= 0.8133 time= 0.0194\n",
      "Epoch: 0136 train_loss= 0.5748 train_acc= 0.9214 val_loss= 0.9123 val_acc= 0.8067 time= 0.0238\n",
      "Epoch: 0137 train_loss= 0.5709 train_acc= 0.9214 val_loss= 0.9087 val_acc= 0.8033 time= 0.0238\n",
      "Epoch: 0138 train_loss= 0.5671 train_acc= 0.9357 val_loss= 0.9058 val_acc= 0.8033 time= 0.0279\n",
      "Epoch: 0139 train_loss= 0.5642 train_acc= 0.9286 val_loss= 0.9025 val_acc= 0.8067 time= 0.0241\n",
      "Epoch: 0140 train_loss= 0.5605 train_acc= 0.9214 val_loss= 0.8995 val_acc= 0.8033 time= 0.0236\n",
      "Epoch: 0141 train_loss= 0.5570 train_acc= 0.9286 val_loss= 0.8968 val_acc= 0.8067 time= 0.0198\n",
      "Epoch: 0142 train_loss= 0.5537 train_acc= 0.9286 val_loss= 0.8936 val_acc= 0.8067 time= 0.0302\n",
      "Epoch: 0143 train_loss= 0.5504 train_acc= 0.9286 val_loss= 0.8908 val_acc= 0.8067 time= 0.0275\n",
      "Epoch: 0144 train_loss= 0.5470 train_acc= 0.9286 val_loss= 0.8882 val_acc= 0.8067 time= 0.0187\n",
      "Epoch: 0145 train_loss= 0.5432 train_acc= 0.9357 val_loss= 0.8860 val_acc= 0.8067 time= 0.0199\n",
      "Epoch: 0146 train_loss= 0.5395 train_acc= 0.9357 val_loss= 0.8845 val_acc= 0.8133 time= 0.0240\n",
      "Epoch: 0147 train_loss= 0.5362 train_acc= 0.9429 val_loss= 0.8833 val_acc= 0.8133 time= 0.0248\n",
      "Epoch: 0148 train_loss= 0.5329 train_acc= 0.9429 val_loss= 0.8823 val_acc= 0.8133 time= 0.0188\n",
      "Epoch: 0149 train_loss= 0.5299 train_acc= 0.9429 val_loss= 0.8807 val_acc= 0.8133 time= 0.0243\n",
      "Epoch: 0150 train_loss= 0.5270 train_acc= 0.9429 val_loss= 0.8787 val_acc= 0.8133 time= 0.0237\n",
      "Epoch: 0151 train_loss= 0.5239 train_acc= 0.9429 val_loss= 0.8762 val_acc= 0.8133 time= 0.0202\n",
      "Epoch: 0152 train_loss= 0.5204 train_acc= 0.9429 val_loss= 0.8731 val_acc= 0.8133 time= 0.0241\n",
      "Epoch: 0153 train_loss= 0.5181 train_acc= 0.9500 val_loss= 0.8704 val_acc= 0.8133 time= 0.0289\n",
      "Epoch: 0154 train_loss= 0.5150 train_acc= 0.9500 val_loss= 0.8668 val_acc= 0.8133 time= 0.0289\n",
      "Epoch: 0155 train_loss= 0.5112 train_acc= 0.9500 val_loss= 0.8630 val_acc= 0.8100 time= 0.0231\n",
      "Epoch: 0156 train_loss= 0.5087 train_acc= 0.9500 val_loss= 0.8602 val_acc= 0.8133 time= 0.0245\n",
      "Epoch: 0157 train_loss= 0.5061 train_acc= 0.9500 val_loss= 0.8572 val_acc= 0.8167 time= 0.0240\n",
      "Epoch: 0158 train_loss= 0.5032 train_acc= 0.9500 val_loss= 0.8544 val_acc= 0.8200 time= 0.0235\n",
      "Epoch: 0159 train_loss= 0.5001 train_acc= 0.9500 val_loss= 0.8526 val_acc= 0.8233 time= 0.0241\n",
      "Epoch: 0160 train_loss= 0.4977 train_acc= 0.9500 val_loss= 0.8505 val_acc= 0.8267 time= 0.0192\n",
      "Epoch: 0161 train_loss= 0.4947 train_acc= 0.9500 val_loss= 0.8485 val_acc= 0.8267 time= 0.0185\n",
      "Epoch: 0162 train_loss= 0.4919 train_acc= 0.9500 val_loss= 0.8462 val_acc= 0.8267 time= 0.0262\n",
      "Epoch: 0163 train_loss= 0.4887 train_acc= 0.9500 val_loss= 0.8447 val_acc= 0.8233 time= 0.0245\n",
      "Epoch: 0164 train_loss= 0.4862 train_acc= 0.9500 val_loss= 0.8425 val_acc= 0.8233 time= 0.0244\n",
      "Epoch: 0165 train_loss= 0.4826 train_acc= 0.9500 val_loss= 0.8405 val_acc= 0.8267 time= 0.0237\n",
      "Epoch: 0166 train_loss= 0.4803 train_acc= 0.9500 val_loss= 0.8392 val_acc= 0.8167 time= 0.0191\n",
      "Epoch: 0167 train_loss= 0.4774 train_acc= 0.9571 val_loss= 0.8372 val_acc= 0.8233 time= 0.0194\n",
      "Epoch: 0168 train_loss= 0.4753 train_acc= 0.9643 val_loss= 0.8364 val_acc= 0.8267 time= 0.0186\n",
      "Epoch: 0169 train_loss= 0.4728 train_acc= 0.9643 val_loss= 0.8346 val_acc= 0.8267 time= 0.0205\n",
      "Epoch: 0170 train_loss= 0.4701 train_acc= 0.9643 val_loss= 0.8329 val_acc= 0.8300 time= 0.0189\n",
      "Epoch: 0171 train_loss= 0.4682 train_acc= 0.9643 val_loss= 0.8311 val_acc= 0.8200 time= 0.0226\n",
      "Epoch: 0172 train_loss= 0.4652 train_acc= 0.9643 val_loss= 0.8288 val_acc= 0.8233 time= 0.0187\n",
      "Epoch: 0173 train_loss= 0.4631 train_acc= 0.9643 val_loss= 0.8267 val_acc= 0.8233 time= 0.0237\n",
      "Epoch: 0174 train_loss= 0.4616 train_acc= 0.9643 val_loss= 0.8243 val_acc= 0.8200 time= 0.0196\n",
      "Epoch: 0175 train_loss= 0.4591 train_acc= 0.9643 val_loss= 0.8224 val_acc= 0.8200 time= 0.0271\n",
      "Epoch: 0176 train_loss= 0.4576 train_acc= 0.9643 val_loss= 0.8211 val_acc= 0.8167 time= 0.0242\n",
      "Epoch: 0177 train_loss= 0.4560 train_acc= 0.9643 val_loss= 0.8200 val_acc= 0.8200 time= 0.0239\n",
      "Epoch: 0178 train_loss= 0.4540 train_acc= 0.9643 val_loss= 0.8187 val_acc= 0.8200 time= 0.0284\n",
      "Epoch: 0179 train_loss= 0.4523 train_acc= 0.9643 val_loss= 0.8172 val_acc= 0.8233 time= 0.0283\n",
      "Epoch: 0180 train_loss= 0.4512 train_acc= 0.9643 val_loss= 0.8153 val_acc= 0.8233 time= 0.0193\n",
      "Epoch: 0181 train_loss= 0.4485 train_acc= 0.9714 val_loss= 0.8143 val_acc= 0.8233 time= 0.0191\n",
      "Epoch: 0182 train_loss= 0.4464 train_acc= 0.9643 val_loss= 0.8132 val_acc= 0.8233 time= 0.0187\n",
      "Epoch: 0183 train_loss= 0.4445 train_acc= 0.9643 val_loss= 0.8113 val_acc= 0.8233 time= 0.0187\n",
      "Epoch: 0184 train_loss= 0.4424 train_acc= 0.9643 val_loss= 0.8103 val_acc= 0.8233 time= 0.0292\n",
      "Epoch: 0185 train_loss= 0.4402 train_acc= 0.9643 val_loss= 0.8088 val_acc= 0.8267 time= 0.0284\n",
      "Epoch: 0186 train_loss= 0.4384 train_acc= 0.9643 val_loss= 0.8074 val_acc= 0.8267 time= 0.0233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0187 train_loss= 0.4361 train_acc= 0.9643 val_loss= 0.8066 val_acc= 0.8267 time= 0.0244\n",
      "Epoch: 0188 train_loss= 0.4340 train_acc= 0.9643 val_loss= 0.8047 val_acc= 0.8267 time= 0.0246\n",
      "Epoch: 0189 train_loss= 0.4313 train_acc= 0.9643 val_loss= 0.8037 val_acc= 0.8267 time= 0.0288\n",
      "Epoch: 0190 train_loss= 0.4292 train_acc= 0.9643 val_loss= 0.8025 val_acc= 0.8300 time= 0.0230\n",
      "Epoch: 0191 train_loss= 0.4273 train_acc= 0.9643 val_loss= 0.8030 val_acc= 0.8300 time= 0.0240\n",
      "Epoch: 0192 train_loss= 0.4250 train_acc= 0.9643 val_loss= 0.8020 val_acc= 0.8300 time= 0.0298\n",
      "Epoch: 0193 train_loss= 0.4232 train_acc= 0.9643 val_loss= 0.8009 val_acc= 0.8300 time= 0.0295\n",
      "Epoch: 0194 train_loss= 0.4202 train_acc= 0.9643 val_loss= 0.7995 val_acc= 0.8300 time= 0.0287\n",
      "Epoch: 0195 train_loss= 0.4185 train_acc= 0.9643 val_loss= 0.7977 val_acc= 0.8300 time= 0.0246\n",
      "Epoch: 0196 train_loss= 0.4155 train_acc= 0.9643 val_loss= 0.7961 val_acc= 0.8300 time= 0.0188\n",
      "Epoch: 0197 train_loss= 0.4137 train_acc= 0.9643 val_loss= 0.7954 val_acc= 0.8300 time= 0.0188\n",
      "Epoch: 0198 train_loss= 0.4114 train_acc= 0.9643 val_loss= 0.7934 val_acc= 0.8300 time= 0.0189\n",
      "Epoch: 0199 train_loss= 0.4090 train_acc= 0.9643 val_loss= 0.7916 val_acc= 0.8300 time= 0.0196\n",
      "Epoch: 0200 train_loss= 0.4075 train_acc= 0.9643 val_loss= 0.7896 val_acc= 0.8300 time= 0.0197\n"
     ]
    }
   ],
   "source": [
    "NB_EPOCH = 200\n",
    "PATIENCE = 10  # early stopping patience\n",
    "# Helper variables for main training loop\n",
    "wait = 0\n",
    "preds = None\n",
    "best_val_loss = 99999\n",
    "\n",
    "# Fit\n",
    "for epoch in range(1, NB_EPOCH+1):\n",
    "\n",
    "    # Log wall-clock time\n",
    "    t = time.time()\n",
    "\n",
    "    # Single training iteration (we mask nodes without labels for loss calculation)\n",
    "    model.fit(graph, y_train, sample_weight=train_mask,\n",
    "              batch_size=A.shape[0], epochs=1, shuffle=False, verbose=0)\n",
    "\n",
    "    # Predict on full dataset\n",
    "    preds = model.predict(graph, batch_size=A.shape[0])\n",
    "\n",
    "    # Train / validation scores\n",
    "    train_val_loss, train_val_acc = evaluate_preds(preds, [y_train, y_val],\n",
    "                                                   [idx_train, idx_val])\n",
    "    print(\"Epoch: {:04d}\".format(epoch),\n",
    "          \"train_loss= {:.4f}\".format(train_val_loss[0]),\n",
    "          \"train_acc= {:.4f}\".format(train_val_acc[0]),\n",
    "          \"val_loss= {:.4f}\".format(train_val_loss[1]),\n",
    "          \"val_acc= {:.4f}\".format(train_val_acc[1]),\n",
    "          \"time= {:.4f}\".format(time.time() - t))\n",
    "\n",
    "    # Early stopping\n",
    "    if train_val_loss[1] < best_val_loss:\n",
    "        best_val_loss = train_val_loss[1]\n",
    "        wait = 0\n",
    "    else:\n",
    "        if wait >= PATIENCE:\n",
    "            print('Epoch {}: early stopping'.format(epoch))\n",
    "            break\n",
    "        wait += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.8237\n",
      "accuracy = 0.8250\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate_preds(preds, [y_test], [idx_test])\n",
    "print(f\"\"\"\n",
    "loss = {test_loss[0]:.4f}\n",
    "accuracy = {test_acc[0]:.4f}\n",
    "\"\"\".strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
