{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from keras.layers import Input, Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the path of execution\n",
    "EXE_PATH = os.path.abspath(os.path.curdir)\n",
    "# the path of the vendor files\n",
    "VENDOR_PATH = os.path.join(EXE_PATH, 'vendor')\n",
    "# the vendors to include in the system path\n",
    "VENDORS = ['keras-gcn']\n",
    "# create the absolute paths for all vendors\n",
    "VENDORS = list(map(lambda x: os.path.join(VENDOR_PATH, x), VENDORS))\n",
    "# update the Python path to include necessary vendor module\n",
    "sys.path += VENDORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kegra.layers.graph import GraphConvolution\n",
    "from kegra.utils import load_data, preprocess_adj, get_splits, evaluate_preds\n",
    "from ggcn import GaussianGraphConvolution, kl_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cora dataset...\n",
      "Dataset has 2708 nodes, 5429 edges, 1433 features.\n"
     ]
    }
   ],
   "source": [
    "X, A, y = load_data('data/cora/', dataset='cora')\n",
    "X /= X.sum(1).reshape(-1, 1)\n",
    "A = preprocess_adj(A)\n",
    "y_train, y_val, y_test, idx_train, idx_val, idx_test, train_mask = get_splits(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2708x2708 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 13264 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 1, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1110 18:28:15.185354 139734109144896 deprecation_wrapper.py:119] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1110 18:28:15.192788 139734109144896 deprecation_wrapper.py:119] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:515: The name tf.sparse_placeholder is deprecated. Please use tf.compat.v1.sparse_placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "support = 1\n",
    "graph = [X, A]\n",
    "G = [Input(shape=(None, None), batch_shape=(None, None), sparse=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1110 18:28:15.197443 139734109144896 deprecation_wrapper.py:119] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_in = Input(shape=(X.shape[1],))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCN (baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1110 18:28:15.204402 139734109144896 deprecation_wrapper.py:119] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W1110 18:28:15.209995 139734109144896 deprecation.py:506] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W1110 18:28:15.218433 139734109144896 deprecation_wrapper.py:119] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define model architecture\n",
    "# NOTE: We pass arguments for graph convolutional layers as a list of tensors.\n",
    "# This is somewhat hacky, more elegant options would require rewriting the Layer base class.\n",
    "H = Dropout(0.5)(X_in)\n",
    "H = GraphConvolution(32, support, activation='relu', kernel_regularizer=l2(5e-4))([H]+G)\n",
    "H = Dropout(0.5)(H)\n",
    "Y = GraphConvolution(y.shape[1], support, activation='softmax')([H]+G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1110 18:28:15.259835 139734109144896 deprecation_wrapper.py:119] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=[X_in]+G, outputs=Y)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 1433)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1433)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "graph_convolution_1 (GraphConvo (None, 32)           45888       dropout_1[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 32)           0           graph_convolution_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "graph_convolution_2 (GraphConvo (None, 7)            231         dropout_2[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 46,119\n",
      "Trainable params: 46,119\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1110 18:28:15.336023 139734109144896 deprecation.py:323] From /home/bitcommander/.local/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 train_loss= 1.9301 train_acc= 0.2929 val_loss= 1.9316 val_acc= 0.3500 time= 1.0769\n",
      "Epoch: 0002 train_loss= 1.9141 train_acc= 0.2929 val_loss= 1.9172 val_acc= 0.3500 time= 0.0226\n",
      "Epoch: 0003 train_loss= 1.8963 train_acc= 0.2929 val_loss= 1.9009 val_acc= 0.3500 time= 0.0229\n",
      "Epoch: 0004 train_loss= 1.8770 train_acc= 0.2929 val_loss= 1.8836 val_acc= 0.3500 time= 0.0178\n",
      "Epoch: 0005 train_loss= 1.8571 train_acc= 0.2929 val_loss= 1.8657 val_acc= 0.3500 time= 0.0250\n",
      "Epoch: 0006 train_loss= 1.8373 train_acc= 0.2929 val_loss= 1.8481 val_acc= 0.3500 time= 0.0239\n",
      "Epoch: 0007 train_loss= 1.8168 train_acc= 0.2929 val_loss= 1.8295 val_acc= 0.3500 time= 0.0227\n",
      "Epoch: 0008 train_loss= 1.7969 train_acc= 0.2929 val_loss= 1.8117 val_acc= 0.3500 time= 0.0246\n",
      "Epoch: 0009 train_loss= 1.7779 train_acc= 0.2929 val_loss= 1.7954 val_acc= 0.3500 time= 0.0191\n",
      "Epoch: 0010 train_loss= 1.7597 train_acc= 0.2929 val_loss= 1.7807 val_acc= 0.3500 time= 0.0294\n",
      "Epoch: 0011 train_loss= 1.7425 train_acc= 0.2929 val_loss= 1.7676 val_acc= 0.3500 time= 0.0240\n",
      "Epoch: 0012 train_loss= 1.7265 train_acc= 0.3000 val_loss= 1.7564 val_acc= 0.3533 time= 0.0236\n",
      "Epoch: 0013 train_loss= 1.7114 train_acc= 0.3429 val_loss= 1.7469 val_acc= 0.3567 time= 0.0232\n",
      "Epoch: 0014 train_loss= 1.6971 train_acc= 0.3643 val_loss= 1.7386 val_acc= 0.3633 time= 0.0237\n",
      "Epoch: 0015 train_loss= 1.6835 train_acc= 0.4071 val_loss= 1.7310 val_acc= 0.3667 time= 0.0188\n",
      "Epoch: 0016 train_loss= 1.6702 train_acc= 0.4143 val_loss= 1.7237 val_acc= 0.3800 time= 0.0185\n",
      "Epoch: 0017 train_loss= 1.6566 train_acc= 0.4286 val_loss= 1.7164 val_acc= 0.3967 time= 0.0193\n",
      "Epoch: 0018 train_loss= 1.6426 train_acc= 0.4429 val_loss= 1.7082 val_acc= 0.4133 time= 0.0230\n",
      "Epoch: 0019 train_loss= 1.6280 train_acc= 0.4571 val_loss= 1.6994 val_acc= 0.4200 time= 0.0208\n",
      "Epoch: 0020 train_loss= 1.6130 train_acc= 0.4643 val_loss= 1.6899 val_acc= 0.4333 time= 0.0222\n",
      "Epoch: 0021 train_loss= 1.5978 train_acc= 0.4643 val_loss= 1.6796 val_acc= 0.4433 time= 0.0217\n",
      "Epoch: 0022 train_loss= 1.5823 train_acc= 0.4643 val_loss= 1.6687 val_acc= 0.4433 time= 0.0202\n",
      "Epoch: 0023 train_loss= 1.5666 train_acc= 0.4643 val_loss= 1.6575 val_acc= 0.4433 time= 0.0296\n",
      "Epoch: 0024 train_loss= 1.5506 train_acc= 0.4643 val_loss= 1.6459 val_acc= 0.4433 time= 0.0282\n",
      "Epoch: 0025 train_loss= 1.5345 train_acc= 0.4643 val_loss= 1.6343 val_acc= 0.4433 time= 0.0229\n",
      "Epoch: 0026 train_loss= 1.5183 train_acc= 0.4643 val_loss= 1.6228 val_acc= 0.4433 time= 0.0200\n",
      "Epoch: 0027 train_loss= 1.5019 train_acc= 0.4786 val_loss= 1.6114 val_acc= 0.4467 time= 0.0253\n",
      "Epoch: 0028 train_loss= 1.4854 train_acc= 0.4857 val_loss= 1.6004 val_acc= 0.4533 time= 0.0257\n",
      "Epoch: 0029 train_loss= 1.4687 train_acc= 0.5000 val_loss= 1.5895 val_acc= 0.4700 time= 0.0249\n",
      "Epoch: 0030 train_loss= 1.4521 train_acc= 0.5071 val_loss= 1.5785 val_acc= 0.4767 time= 0.0238\n",
      "Epoch: 0031 train_loss= 1.4353 train_acc= 0.5071 val_loss= 1.5673 val_acc= 0.4867 time= 0.0190\n",
      "Epoch: 0032 train_loss= 1.4186 train_acc= 0.5214 val_loss= 1.5560 val_acc= 0.5033 time= 0.0187\n",
      "Epoch: 0033 train_loss= 1.4018 train_acc= 0.5214 val_loss= 1.5445 val_acc= 0.5133 time= 0.0195\n",
      "Epoch: 0034 train_loss= 1.3850 train_acc= 0.5286 val_loss= 1.5327 val_acc= 0.5167 time= 0.0194\n",
      "Epoch: 0035 train_loss= 1.3684 train_acc= 0.5571 val_loss= 1.5209 val_acc= 0.5267 time= 0.0249\n",
      "Epoch: 0036 train_loss= 1.3518 train_acc= 0.5643 val_loss= 1.5089 val_acc= 0.5267 time= 0.0190\n",
      "Epoch: 0037 train_loss= 1.3349 train_acc= 0.5786 val_loss= 1.4965 val_acc= 0.5333 time= 0.0188\n",
      "Epoch: 0038 train_loss= 1.3179 train_acc= 0.5857 val_loss= 1.4839 val_acc= 0.5433 time= 0.0216\n",
      "Epoch: 0039 train_loss= 1.3007 train_acc= 0.5929 val_loss= 1.4707 val_acc= 0.5500 time= 0.0193\n",
      "Epoch: 0040 train_loss= 1.2838 train_acc= 0.6071 val_loss= 1.4581 val_acc= 0.5533 time= 0.0188\n",
      "Epoch: 0041 train_loss= 1.2672 train_acc= 0.6214 val_loss= 1.4456 val_acc= 0.5533 time= 0.0206\n",
      "Epoch: 0042 train_loss= 1.2507 train_acc= 0.6214 val_loss= 1.4331 val_acc= 0.5600 time= 0.0187\n",
      "Epoch: 0043 train_loss= 1.2344 train_acc= 0.6429 val_loss= 1.4211 val_acc= 0.5667 time= 0.0200\n",
      "Epoch: 0044 train_loss= 1.2179 train_acc= 0.6500 val_loss= 1.4092 val_acc= 0.5733 time= 0.0193\n",
      "Epoch: 0045 train_loss= 1.2018 train_acc= 0.6643 val_loss= 1.3978 val_acc= 0.5900 time= 0.0221\n",
      "Epoch: 0046 train_loss= 1.1859 train_acc= 0.6786 val_loss= 1.3861 val_acc= 0.6000 time= 0.0213\n",
      "Epoch: 0047 train_loss= 1.1701 train_acc= 0.6857 val_loss= 1.3744 val_acc= 0.6033 time= 0.0186\n",
      "Epoch: 0048 train_loss= 1.1546 train_acc= 0.7071 val_loss= 1.3628 val_acc= 0.6067 time= 0.0180\n",
      "Epoch: 0049 train_loss= 1.1392 train_acc= 0.7429 val_loss= 1.3520 val_acc= 0.6233 time= 0.0198\n",
      "Epoch: 0050 train_loss= 1.1241 train_acc= 0.7500 val_loss= 1.3414 val_acc= 0.6200 time= 0.0230\n",
      "Epoch: 0051 train_loss= 1.1091 train_acc= 0.7571 val_loss= 1.3303 val_acc= 0.6167 time= 0.0214\n",
      "Epoch: 0052 train_loss= 1.0943 train_acc= 0.7714 val_loss= 1.3185 val_acc= 0.6300 time= 0.0228\n",
      "Epoch: 0053 train_loss= 1.0797 train_acc= 0.7786 val_loss= 1.3072 val_acc= 0.6333 time= 0.0250\n",
      "Epoch: 0054 train_loss= 1.0653 train_acc= 0.7857 val_loss= 1.2956 val_acc= 0.6367 time= 0.0189\n",
      "Epoch: 0055 train_loss= 1.0509 train_acc= 0.7857 val_loss= 1.2838 val_acc= 0.6500 time= 0.0263\n",
      "Epoch: 0056 train_loss= 1.0368 train_acc= 0.7929 val_loss= 1.2719 val_acc= 0.6600 time= 0.0244\n",
      "Epoch: 0057 train_loss= 1.0231 train_acc= 0.7929 val_loss= 1.2605 val_acc= 0.6800 time= 0.0207\n",
      "Epoch: 0058 train_loss= 1.0096 train_acc= 0.8000 val_loss= 1.2498 val_acc= 0.6933 time= 0.0242\n",
      "Epoch: 0059 train_loss= 0.9961 train_acc= 0.8000 val_loss= 1.2397 val_acc= 0.7133 time= 0.0196\n",
      "Epoch: 0060 train_loss= 0.9831 train_acc= 0.8143 val_loss= 1.2301 val_acc= 0.7133 time= 0.0193\n",
      "Epoch: 0061 train_loss= 0.9705 train_acc= 0.8357 val_loss= 1.2208 val_acc= 0.7133 time= 0.0192\n",
      "Epoch: 0062 train_loss= 0.9577 train_acc= 0.8429 val_loss= 1.2107 val_acc= 0.7300 time= 0.0187\n",
      "Epoch: 0063 train_loss= 0.9454 train_acc= 0.8357 val_loss= 1.2015 val_acc= 0.7300 time= 0.0218\n",
      "Epoch: 0064 train_loss= 0.9334 train_acc= 0.8429 val_loss= 1.1920 val_acc= 0.7267 time= 0.0190\n",
      "Epoch: 0065 train_loss= 0.9215 train_acc= 0.8500 val_loss= 1.1815 val_acc= 0.7267 time= 0.0195\n",
      "Epoch: 0066 train_loss= 0.9099 train_acc= 0.8500 val_loss= 1.1722 val_acc= 0.7300 time= 0.0261\n",
      "Epoch: 0067 train_loss= 0.8983 train_acc= 0.8500 val_loss= 1.1630 val_acc= 0.7300 time= 0.0192\n",
      "Epoch: 0068 train_loss= 0.8866 train_acc= 0.8500 val_loss= 1.1535 val_acc= 0.7300 time= 0.0229\n",
      "Epoch: 0069 train_loss= 0.8749 train_acc= 0.8643 val_loss= 1.1445 val_acc= 0.7400 time= 0.0194\n",
      "Epoch: 0070 train_loss= 0.8636 train_acc= 0.8643 val_loss= 1.1350 val_acc= 0.7433 time= 0.0200\n",
      "Epoch: 0071 train_loss= 0.8526 train_acc= 0.8643 val_loss= 1.1259 val_acc= 0.7500 time= 0.0239\n",
      "Epoch: 0072 train_loss= 0.8417 train_acc= 0.8643 val_loss= 1.1167 val_acc= 0.7500 time= 0.0238\n",
      "Epoch: 0073 train_loss= 0.8310 train_acc= 0.8714 val_loss= 1.1080 val_acc= 0.7500 time= 0.0207\n",
      "Epoch: 0074 train_loss= 0.8205 train_acc= 0.8786 val_loss= 1.0999 val_acc= 0.7500 time= 0.0197\n",
      "Epoch: 0075 train_loss= 0.8103 train_acc= 0.8857 val_loss= 1.0919 val_acc= 0.7433 time= 0.0202\n",
      "Epoch: 0076 train_loss= 0.8001 train_acc= 0.8857 val_loss= 1.0845 val_acc= 0.7500 time= 0.0200\n",
      "Epoch: 0077 train_loss= 0.7901 train_acc= 0.8857 val_loss= 1.0768 val_acc= 0.7567 time= 0.0240\n",
      "Epoch: 0078 train_loss= 0.7803 train_acc= 0.8857 val_loss= 1.0693 val_acc= 0.7567 time= 0.0190\n",
      "Epoch: 0079 train_loss= 0.7710 train_acc= 0.8857 val_loss= 1.0611 val_acc= 0.7767 time= 0.0234\n",
      "Epoch: 0080 train_loss= 0.7621 train_acc= 0.8857 val_loss= 1.0539 val_acc= 0.7767 time= 0.0196\n",
      "Epoch: 0081 train_loss= 0.7532 train_acc= 0.8857 val_loss= 1.0468 val_acc= 0.7833 time= 0.0234\n",
      "Epoch: 0082 train_loss= 0.7442 train_acc= 0.8929 val_loss= 1.0411 val_acc= 0.7800 time= 0.0241\n",
      "Epoch: 0083 train_loss= 0.7359 train_acc= 0.9000 val_loss= 1.0360 val_acc= 0.7767 time= 0.0229\n",
      "Epoch: 0084 train_loss= 0.7284 train_acc= 0.9214 val_loss= 1.0312 val_acc= 0.7800 time= 0.0231\n",
      "Epoch: 0085 train_loss= 0.7216 train_acc= 0.9214 val_loss= 1.0277 val_acc= 0.7800 time= 0.0194\n",
      "Epoch: 0086 train_loss= 0.7141 train_acc= 0.9286 val_loss= 1.0227 val_acc= 0.7800 time= 0.0229\n",
      "Epoch: 0087 train_loss= 0.7060 train_acc= 0.9214 val_loss= 1.0160 val_acc= 0.7833 time= 0.0231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0088 train_loss= 0.6978 train_acc= 0.9214 val_loss= 1.0075 val_acc= 0.7867 time= 0.0217\n",
      "Epoch: 0089 train_loss= 0.6906 train_acc= 0.9143 val_loss= 0.9990 val_acc= 0.7900 time= 0.0195\n",
      "Epoch: 0090 train_loss= 0.6850 train_acc= 0.9000 val_loss= 0.9919 val_acc= 0.7933 time= 0.0224\n",
      "Epoch: 0091 train_loss= 0.6786 train_acc= 0.9000 val_loss= 0.9862 val_acc= 0.7967 time= 0.0275\n",
      "Epoch: 0092 train_loss= 0.6708 train_acc= 0.9071 val_loss= 0.9814 val_acc= 0.7933 time= 0.0258\n",
      "Epoch: 0093 train_loss= 0.6627 train_acc= 0.9214 val_loss= 0.9780 val_acc= 0.7967 time= 0.0191\n",
      "Epoch: 0094 train_loss= 0.6556 train_acc= 0.9214 val_loss= 0.9760 val_acc= 0.7900 time= 0.0242\n",
      "Epoch: 0095 train_loss= 0.6498 train_acc= 0.9286 val_loss= 0.9736 val_acc= 0.7867 time= 0.0245\n",
      "Epoch: 0096 train_loss= 0.6442 train_acc= 0.9357 val_loss= 0.9703 val_acc= 0.7833 time= 0.0185\n",
      "Epoch: 0097 train_loss= 0.6378 train_acc= 0.9357 val_loss= 0.9657 val_acc= 0.7833 time= 0.0191\n",
      "Epoch: 0098 train_loss= 0.6299 train_acc= 0.9357 val_loss= 0.9582 val_acc= 0.7833 time= 0.0242\n",
      "Epoch: 0099 train_loss= 0.6222 train_acc= 0.9357 val_loss= 0.9504 val_acc= 0.7833 time= 0.0231\n",
      "Epoch: 0100 train_loss= 0.6151 train_acc= 0.9357 val_loss= 0.9422 val_acc= 0.7833 time= 0.0193\n",
      "Epoch: 0101 train_loss= 0.6092 train_acc= 0.9357 val_loss= 0.9347 val_acc= 0.7867 time= 0.0187\n",
      "Epoch: 0102 train_loss= 0.6049 train_acc= 0.9357 val_loss= 0.9293 val_acc= 0.7867 time= 0.0237\n",
      "Epoch: 0103 train_loss= 0.6011 train_acc= 0.9214 val_loss= 0.9251 val_acc= 0.7967 time= 0.0182\n",
      "Epoch: 0104 train_loss= 0.5968 train_acc= 0.9214 val_loss= 0.9219 val_acc= 0.7967 time= 0.0183\n",
      "Epoch: 0105 train_loss= 0.5914 train_acc= 0.9214 val_loss= 0.9185 val_acc= 0.8000 time= 0.0184\n",
      "Epoch: 0106 train_loss= 0.5841 train_acc= 0.9429 val_loss= 0.9152 val_acc= 0.7967 time= 0.0202\n",
      "Epoch: 0107 train_loss= 0.5782 train_acc= 0.9429 val_loss= 0.9136 val_acc= 0.7967 time= 0.0239\n",
      "Epoch: 0108 train_loss= 0.5735 train_acc= 0.9429 val_loss= 0.9118 val_acc= 0.7933 time= 0.0225\n",
      "Epoch: 0109 train_loss= 0.5687 train_acc= 0.9429 val_loss= 0.9079 val_acc= 0.7933 time= 0.0196\n",
      "Epoch: 0110 train_loss= 0.5639 train_acc= 0.9429 val_loss= 0.9027 val_acc= 0.7933 time= 0.0231\n",
      "Epoch: 0111 train_loss= 0.5593 train_acc= 0.9429 val_loss= 0.8979 val_acc= 0.8000 time= 0.0239\n",
      "Epoch: 0112 train_loss= 0.5547 train_acc= 0.9500 val_loss= 0.8929 val_acc= 0.8000 time= 0.0200\n",
      "Epoch: 0113 train_loss= 0.5504 train_acc= 0.9500 val_loss= 0.8884 val_acc= 0.8000 time= 0.0278\n",
      "Epoch: 0114 train_loss= 0.5459 train_acc= 0.9500 val_loss= 0.8849 val_acc= 0.7967 time= 0.0193\n",
      "Epoch: 0115 train_loss= 0.5416 train_acc= 0.9500 val_loss= 0.8840 val_acc= 0.7967 time= 0.0193\n",
      "Epoch: 0116 train_loss= 0.5377 train_acc= 0.9500 val_loss= 0.8828 val_acc= 0.7967 time= 0.0187\n",
      "Epoch: 0117 train_loss= 0.5338 train_acc= 0.9500 val_loss= 0.8804 val_acc= 0.7967 time= 0.0191\n",
      "Epoch: 0118 train_loss= 0.5298 train_acc= 0.9500 val_loss= 0.8769 val_acc= 0.7967 time= 0.0191\n",
      "Epoch: 0119 train_loss= 0.5261 train_acc= 0.9429 val_loss= 0.8739 val_acc= 0.8000 time= 0.0193\n",
      "Epoch: 0120 train_loss= 0.5221 train_acc= 0.9429 val_loss= 0.8714 val_acc= 0.8000 time= 0.0239\n",
      "Epoch: 0121 train_loss= 0.5182 train_acc= 0.9429 val_loss= 0.8687 val_acc= 0.8033 time= 0.0227\n",
      "Epoch: 0122 train_loss= 0.5143 train_acc= 0.9429 val_loss= 0.8663 val_acc= 0.8033 time= 0.0187\n",
      "Epoch: 0123 train_loss= 0.5107 train_acc= 0.9500 val_loss= 0.8649 val_acc= 0.8067 time= 0.0237\n",
      "Epoch: 0124 train_loss= 0.5071 train_acc= 0.9500 val_loss= 0.8629 val_acc= 0.8033 time= 0.0183\n",
      "Epoch: 0125 train_loss= 0.5034 train_acc= 0.9500 val_loss= 0.8594 val_acc= 0.8033 time= 0.0207\n",
      "Epoch: 0126 train_loss= 0.4992 train_acc= 0.9500 val_loss= 0.8536 val_acc= 0.8100 time= 0.0237\n",
      "Epoch: 0127 train_loss= 0.4951 train_acc= 0.9571 val_loss= 0.8474 val_acc= 0.8133 time= 0.0211\n",
      "Epoch: 0128 train_loss= 0.4916 train_acc= 0.9571 val_loss= 0.8417 val_acc= 0.8100 time= 0.0235\n",
      "Epoch: 0129 train_loss= 0.4878 train_acc= 0.9643 val_loss= 0.8368 val_acc= 0.8133 time= 0.0201\n",
      "Epoch: 0130 train_loss= 0.4840 train_acc= 0.9643 val_loss= 0.8332 val_acc= 0.8167 time= 0.0206\n",
      "Epoch: 0131 train_loss= 0.4796 train_acc= 0.9714 val_loss= 0.8306 val_acc= 0.8200 time= 0.0247\n",
      "Epoch: 0132 train_loss= 0.4751 train_acc= 0.9643 val_loss= 0.8296 val_acc= 0.8100 time= 0.0243\n",
      "Epoch: 0133 train_loss= 0.4718 train_acc= 0.9643 val_loss= 0.8310 val_acc= 0.8000 time= 0.0193\n",
      "Epoch: 0134 train_loss= 0.4694 train_acc= 0.9643 val_loss= 0.8320 val_acc= 0.8067 time= 0.0208\n",
      "Epoch: 0135 train_loss= 0.4667 train_acc= 0.9643 val_loss= 0.8303 val_acc= 0.8067 time= 0.0200\n",
      "Epoch: 0136 train_loss= 0.4635 train_acc= 0.9643 val_loss= 0.8271 val_acc= 0.8067 time= 0.0242\n",
      "Epoch: 0137 train_loss= 0.4601 train_acc= 0.9714 val_loss= 0.8219 val_acc= 0.8100 time= 0.0234\n",
      "Epoch: 0138 train_loss= 0.4569 train_acc= 0.9714 val_loss= 0.8162 val_acc= 0.8133 time= 0.0241\n",
      "Epoch: 0139 train_loss= 0.4545 train_acc= 0.9714 val_loss= 0.8111 val_acc= 0.8200 time= 0.0179\n",
      "Epoch: 0140 train_loss= 0.4519 train_acc= 0.9714 val_loss= 0.8091 val_acc= 0.8200 time= 0.0223\n",
      "Epoch: 0141 train_loss= 0.4494 train_acc= 0.9714 val_loss= 0.8084 val_acc= 0.8233 time= 0.0225\n",
      "Epoch: 0142 train_loss= 0.4473 train_acc= 0.9714 val_loss= 0.8078 val_acc= 0.8200 time= 0.0235\n",
      "Epoch: 0143 train_loss= 0.4450 train_acc= 0.9714 val_loss= 0.8070 val_acc= 0.8200 time= 0.0225\n",
      "Epoch: 0144 train_loss= 0.4422 train_acc= 0.9714 val_loss= 0.8067 val_acc= 0.8233 time= 0.0178\n",
      "Epoch: 0145 train_loss= 0.4395 train_acc= 0.9714 val_loss= 0.8054 val_acc= 0.8233 time= 0.0195\n",
      "Epoch: 0146 train_loss= 0.4368 train_acc= 0.9714 val_loss= 0.8032 val_acc= 0.8233 time= 0.0233\n",
      "Epoch: 0147 train_loss= 0.4345 train_acc= 0.9714 val_loss= 0.8032 val_acc= 0.8133 time= 0.0182\n",
      "Epoch: 0148 train_loss= 0.4325 train_acc= 0.9714 val_loss= 0.8028 val_acc= 0.8167 time= 0.0185\n",
      "Epoch: 0149 train_loss= 0.4300 train_acc= 0.9714 val_loss= 0.8006 val_acc= 0.8167 time= 0.0192\n",
      "Epoch: 0150 train_loss= 0.4277 train_acc= 0.9714 val_loss= 0.7986 val_acc= 0.8167 time= 0.0197\n",
      "Epoch: 0151 train_loss= 0.4249 train_acc= 0.9714 val_loss= 0.7954 val_acc= 0.8100 time= 0.0185\n",
      "Epoch: 0152 train_loss= 0.4227 train_acc= 0.9714 val_loss= 0.7913 val_acc= 0.8100 time= 0.0232\n",
      "Epoch: 0153 train_loss= 0.4213 train_acc= 0.9714 val_loss= 0.7887 val_acc= 0.8233 time= 0.0237\n",
      "Epoch: 0154 train_loss= 0.4201 train_acc= 0.9714 val_loss= 0.7877 val_acc= 0.8233 time= 0.0199\n",
      "Epoch: 0155 train_loss= 0.4181 train_acc= 0.9714 val_loss= 0.7880 val_acc= 0.8167 time= 0.0195\n",
      "Epoch: 0156 train_loss= 0.4152 train_acc= 0.9714 val_loss= 0.7893 val_acc= 0.8133 time= 0.0213\n",
      "Epoch: 0157 train_loss= 0.4133 train_acc= 0.9714 val_loss= 0.7916 val_acc= 0.8200 time= 0.0233\n",
      "Epoch: 0158 train_loss= 0.4125 train_acc= 0.9786 val_loss= 0.7951 val_acc= 0.8167 time= 0.0190\n",
      "Epoch: 0159 train_loss= 0.4116 train_acc= 0.9786 val_loss= 0.7969 val_acc= 0.8167 time= 0.0188\n",
      "Epoch: 0160 train_loss= 0.4092 train_acc= 0.9857 val_loss= 0.7950 val_acc= 0.8167 time= 0.0247\n",
      "Epoch: 0161 train_loss= 0.4058 train_acc= 0.9786 val_loss= 0.7898 val_acc= 0.8167 time= 0.0192\n",
      "Epoch: 0162 train_loss= 0.4028 train_acc= 0.9714 val_loss= 0.7847 val_acc= 0.8267 time= 0.0211\n",
      "Epoch: 0163 train_loss= 0.4008 train_acc= 0.9714 val_loss= 0.7797 val_acc= 0.8367 time= 0.0239\n",
      "Epoch: 0164 train_loss= 0.3986 train_acc= 0.9714 val_loss= 0.7776 val_acc= 0.8300 time= 0.0207\n",
      "Epoch: 0165 train_loss= 0.3959 train_acc= 0.9714 val_loss= 0.7762 val_acc= 0.8167 time= 0.0249\n",
      "Epoch: 0166 train_loss= 0.3929 train_acc= 0.9714 val_loss= 0.7741 val_acc= 0.8200 time= 0.0219\n",
      "Epoch: 0167 train_loss= 0.3908 train_acc= 0.9714 val_loss= 0.7745 val_acc= 0.8133 time= 0.0193\n",
      "Epoch: 0168 train_loss= 0.3891 train_acc= 0.9714 val_loss= 0.7737 val_acc= 0.8133 time= 0.0197\n",
      "Epoch: 0169 train_loss= 0.3870 train_acc= 0.9714 val_loss= 0.7711 val_acc= 0.8100 time= 0.0241\n",
      "Epoch: 0170 train_loss= 0.3849 train_acc= 0.9714 val_loss= 0.7695 val_acc= 0.8100 time= 0.0188\n",
      "Epoch: 0171 train_loss= 0.3825 train_acc= 0.9714 val_loss= 0.7660 val_acc= 0.8233 time= 0.0245\n",
      "Epoch: 0172 train_loss= 0.3808 train_acc= 0.9714 val_loss= 0.7622 val_acc= 0.8267 time= 0.0238\n",
      "Epoch: 0173 train_loss= 0.3782 train_acc= 0.9714 val_loss= 0.7589 val_acc= 0.8300 time= 0.0210\n",
      "Epoch: 0174 train_loss= 0.3743 train_acc= 0.9714 val_loss= 0.7561 val_acc= 0.8267 time= 0.0214\n",
      "Epoch: 0175 train_loss= 0.3704 train_acc= 0.9714 val_loss= 0.7545 val_acc= 0.8300 time= 0.0191\n",
      "Epoch: 0176 train_loss= 0.3680 train_acc= 0.9714 val_loss= 0.7554 val_acc= 0.8367 time= 0.0252\n",
      "Epoch: 0177 train_loss= 0.3673 train_acc= 0.9786 val_loss= 0.7576 val_acc= 0.8200 time= 0.0194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0178 train_loss= 0.3667 train_acc= 0.9786 val_loss= 0.7581 val_acc= 0.8167 time= 0.0217\n",
      "Epoch: 0179 train_loss= 0.3658 train_acc= 0.9786 val_loss= 0.7579 val_acc= 0.8167 time= 0.0244\n",
      "Epoch: 0180 train_loss= 0.3633 train_acc= 0.9786 val_loss= 0.7531 val_acc= 0.8167 time= 0.0241\n",
      "Epoch: 0181 train_loss= 0.3608 train_acc= 0.9714 val_loss= 0.7487 val_acc= 0.8233 time= 0.0235\n",
      "Epoch: 0182 train_loss= 0.3587 train_acc= 0.9714 val_loss= 0.7427 val_acc= 0.8433 time= 0.0246\n",
      "Epoch: 0183 train_loss= 0.3577 train_acc= 0.9714 val_loss= 0.7390 val_acc= 0.8400 time= 0.0200\n",
      "Epoch: 0184 train_loss= 0.3575 train_acc= 0.9714 val_loss= 0.7384 val_acc= 0.8333 time= 0.0235\n",
      "Epoch: 0185 train_loss= 0.3561 train_acc= 0.9714 val_loss= 0.7395 val_acc= 0.8333 time= 0.0192\n",
      "Epoch: 0186 train_loss= 0.3546 train_acc= 0.9714 val_loss= 0.7409 val_acc= 0.8333 time= 0.0224\n",
      "Epoch: 0187 train_loss= 0.3521 train_acc= 0.9714 val_loss= 0.7424 val_acc= 0.8333 time= 0.0177\n",
      "Epoch: 0188 train_loss= 0.3504 train_acc= 0.9786 val_loss= 0.7460 val_acc= 0.8300 time= 0.0185\n",
      "Epoch: 0189 train_loss= 0.3510 train_acc= 0.9786 val_loss= 0.7518 val_acc= 0.8233 time= 0.0201\n",
      "Epoch: 0190 train_loss= 0.3521 train_acc= 0.9786 val_loss= 0.7560 val_acc= 0.8167 time= 0.0229\n",
      "Epoch: 0191 train_loss= 0.3504 train_acc= 0.9786 val_loss= 0.7529 val_acc= 0.8167 time= 0.0191\n",
      "Epoch: 0192 train_loss= 0.3466 train_acc= 0.9786 val_loss= 0.7441 val_acc= 0.8233 time= 0.0240\n",
      "Epoch: 0193 train_loss= 0.3443 train_acc= 0.9786 val_loss= 0.7353 val_acc= 0.8300 time= 0.0241\n",
      "Epoch: 0194 train_loss= 0.3454 train_acc= 0.9786 val_loss= 0.7301 val_acc= 0.8367 time= 0.0247\n",
      "Epoch: 0195 train_loss= 0.3462 train_acc= 0.9714 val_loss= 0.7280 val_acc= 0.8333 time= 0.0246\n",
      "Epoch: 0196 train_loss= 0.3452 train_acc= 0.9714 val_loss= 0.7259 val_acc= 0.8333 time= 0.0242\n",
      "Epoch: 0197 train_loss= 0.3416 train_acc= 0.9714 val_loss= 0.7239 val_acc= 0.8333 time= 0.0254\n",
      "Epoch: 0198 train_loss= 0.3377 train_acc= 0.9714 val_loss= 0.7239 val_acc= 0.8400 time= 0.0205\n",
      "Epoch: 0199 train_loss= 0.3357 train_acc= 0.9786 val_loss= 0.7274 val_acc= 0.8167 time= 0.0211\n",
      "Epoch: 0200 train_loss= 0.3363 train_acc= 0.9786 val_loss= 0.7339 val_acc= 0.8100 time= 0.0199\n"
     ]
    }
   ],
   "source": [
    "NB_EPOCH = 200\n",
    "PATIENCE = 10  # early stopping patience\n",
    "# Helper variables for main training loop\n",
    "wait = 0\n",
    "preds = None\n",
    "best_val_loss = 99999\n",
    "\n",
    "# Fit\n",
    "for epoch in range(1, NB_EPOCH+1):\n",
    "\n",
    "    # Log wall-clock time\n",
    "    t = time.time()\n",
    "\n",
    "    # Single training iteration (we mask nodes without labels for loss calculation)\n",
    "    model.fit(graph, y_train, sample_weight=train_mask,\n",
    "              batch_size=A.shape[0], epochs=1, shuffle=False, verbose=0)\n",
    "\n",
    "    # Predict on full dataset\n",
    "    preds = model.predict(graph, batch_size=A.shape[0])\n",
    "\n",
    "    # Train / validation scores\n",
    "    train_val_loss, train_val_acc = evaluate_preds(preds, [y_train, y_val],\n",
    "                                                   [idx_train, idx_val])\n",
    "    print(\"Epoch: {:04d}\".format(epoch),\n",
    "          \"train_loss= {:.4f}\".format(train_val_loss[0]),\n",
    "          \"train_acc= {:.4f}\".format(train_val_acc[0]),\n",
    "          \"val_loss= {:.4f}\".format(train_val_loss[1]),\n",
    "          \"val_acc= {:.4f}\".format(train_val_acc[1]),\n",
    "          \"time= {:.4f}\".format(time.time() - t))\n",
    "\n",
    "    # Early stopping\n",
    "    if train_val_loss[1] < best_val_loss:\n",
    "        best_val_loss = train_val_loss[1]\n",
    "        wait = 0\n",
    "    else:\n",
    "        if wait >= PATIENCE:\n",
    "            print('Epoch {}: early stopping'.format(epoch))\n",
    "            break\n",
    "        wait += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.7723\n",
      "accuracy = 0.8280\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate_preds(preds, [y_test], [idx_test])\n",
    "print(f\"\"\"\n",
    "loss = {test_loss[0]:.4f}\n",
    "accuracy = {test_acc[0]:.4f}\n",
    "\"\"\".strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Graph Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "B1 = 5e-4\n",
    "B2 = 5e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1110 18:28:20.746490 139734109144896 deprecation.py:323] From /home/bitcommander/Desktop/robust-graph-convolutional-networks-against-adversarial-attacks-implementation/ggcn/ggcl.py:174: Normal.__init__ (from tensorflow.python.ops.distributions.normal) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
      "W1110 18:28:20.747943 139734109144896 deprecation.py:323] From /home/bitcommander/.local/lib/python3.7/site-packages/tensorflow/python/ops/distributions/normal.py:160: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n"
     ]
    }
   ],
   "source": [
    "H = Dropout(0.5)(X_in)\n",
    "H1 = GaussianGraphConvolution(16,\n",
    "    is_first=True,\n",
    "    activation='relu',\n",
    "    mean_regularizer=l2(B1),\n",
    "    variance_regularizer=l2(B1),\n",
    "#     dropout=0.5\n",
    ")([H]+G)\n",
    "Y = GaussianGraphConvolution(y.shape[1],\n",
    "    is_last=True,\n",
    "    activation='softmax',\n",
    ")(H1+G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1110 18:28:20.784544 139734109144896 deprecation.py:323] From /home/bitcommander/Desktop/robust-graph-convolutional-networks-against-adversarial-attacks-implementation/ggcn/losses.py:28: kl_divergence (from tensorflow.python.ops.distributions.kullback_leibler) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=[X_in]+G, outputs=Y)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.01))\n",
    "model.add_loss(kl_reg(*H1, B2), H1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 1433)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 1433)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_graph_convolution_1 (G [(None, 16), (None,  45856       dropout_3[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_graph_convolution_2 (G (None, 7)            224         gaussian_graph_convolution_1[0][0\n",
      "                                                                 gaussian_graph_convolution_1[0][1\n",
      "                                                                 input_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 46,080\n",
      "Trainable params: 46,080\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 train_loss= 1.9431 train_acc= 0.3000 val_loss= 1.9438 val_acc= 0.2567 time= 0.4663\n",
      "Epoch: 0002 train_loss= 1.9375 train_acc= 0.4143 val_loss= 1.9397 val_acc= 0.3000 time= 0.0238\n",
      "Epoch: 0003 train_loss= 1.9312 train_acc= 0.4143 val_loss= 1.9335 val_acc= 0.4133 time= 0.0270\n",
      "Epoch: 0004 train_loss= 1.9245 train_acc= 0.4214 val_loss= 1.9271 val_acc= 0.4400 time= 0.0185\n",
      "Epoch: 0005 train_loss= 1.9151 train_acc= 0.4786 val_loss= 1.9204 val_acc= 0.4567 time= 0.0229\n",
      "Epoch: 0006 train_loss= 1.9059 train_acc= 0.4857 val_loss= 1.9132 val_acc= 0.4733 time= 0.0257\n",
      "Epoch: 0007 train_loss= 1.8968 train_acc= 0.5286 val_loss= 1.9057 val_acc= 0.4700 time= 0.0264\n",
      "Epoch: 0008 train_loss= 1.8864 train_acc= 0.5429 val_loss= 1.8980 val_acc= 0.4833 time= 0.0248\n",
      "Epoch: 0009 train_loss= 1.8761 train_acc= 0.5571 val_loss= 1.8906 val_acc= 0.5000 time= 0.0191\n",
      "Epoch: 0010 train_loss= 1.8654 train_acc= 0.5500 val_loss= 1.8824 val_acc= 0.4833 time= 0.0228\n",
      "Epoch: 0011 train_loss= 1.8525 train_acc= 0.5786 val_loss= 1.8728 val_acc= 0.5133 time= 0.0198\n",
      "Epoch: 0012 train_loss= 1.8404 train_acc= 0.6071 val_loss= 1.8623 val_acc= 0.5100 time= 0.0200\n",
      "Epoch: 0013 train_loss= 1.8293 train_acc= 0.5786 val_loss= 1.8538 val_acc= 0.5000 time= 0.0192\n",
      "Epoch: 0014 train_loss= 1.8158 train_acc= 0.6071 val_loss= 1.8433 val_acc= 0.5033 time= 0.0212\n",
      "Epoch: 0015 train_loss= 1.8032 train_acc= 0.6000 val_loss= 1.8342 val_acc= 0.5100 time= 0.0191\n",
      "Epoch: 0016 train_loss= 1.7904 train_acc= 0.5929 val_loss= 1.8232 val_acc= 0.5033 time= 0.0198\n",
      "Epoch: 0017 train_loss= 1.7756 train_acc= 0.5929 val_loss= 1.8124 val_acc= 0.5167 time= 0.0213\n",
      "Epoch: 0018 train_loss= 1.7604 train_acc= 0.6071 val_loss= 1.8013 val_acc= 0.5167 time= 0.0237\n",
      "Epoch: 0019 train_loss= 1.7467 train_acc= 0.5929 val_loss= 1.7902 val_acc= 0.5167 time= 0.0188\n",
      "Epoch: 0020 train_loss= 1.7323 train_acc= 0.6071 val_loss= 1.7794 val_acc= 0.5233 time= 0.0192\n",
      "Epoch: 0021 train_loss= 1.7174 train_acc= 0.6000 val_loss= 1.7682 val_acc= 0.5233 time= 0.0196\n",
      "Epoch: 0022 train_loss= 1.7020 train_acc= 0.6000 val_loss= 1.7567 val_acc= 0.5300 time= 0.0210\n",
      "Epoch: 0023 train_loss= 1.6861 train_acc= 0.6000 val_loss= 1.7448 val_acc= 0.5367 time= 0.0282\n",
      "Epoch: 0024 train_loss= 1.6703 train_acc= 0.6071 val_loss= 1.7327 val_acc= 0.5467 time= 0.0241\n",
      "Epoch: 0025 train_loss= 1.6540 train_acc= 0.6071 val_loss= 1.7207 val_acc= 0.5500 time= 0.0244\n",
      "Epoch: 0026 train_loss= 1.6376 train_acc= 0.6071 val_loss= 1.7082 val_acc= 0.5500 time= 0.0212\n",
      "Epoch: 0027 train_loss= 1.6208 train_acc= 0.6071 val_loss= 1.6953 val_acc= 0.5500 time= 0.0236\n",
      "Epoch: 0028 train_loss= 1.6030 train_acc= 0.6071 val_loss= 1.6829 val_acc= 0.5533 time= 0.0203\n",
      "Epoch: 0029 train_loss= 1.5859 train_acc= 0.6286 val_loss= 1.6697 val_acc= 0.5533 time= 0.0233\n",
      "Epoch: 0030 train_loss= 1.5683 train_acc= 0.6286 val_loss= 1.6565 val_acc= 0.5600 time= 0.0216\n",
      "Epoch: 0031 train_loss= 1.5498 train_acc= 0.6429 val_loss= 1.6432 val_acc= 0.5733 time= 0.0239\n",
      "Epoch: 0032 train_loss= 1.5316 train_acc= 0.6500 val_loss= 1.6300 val_acc= 0.5800 time= 0.0211\n",
      "Epoch: 0033 train_loss= 1.5131 train_acc= 0.6714 val_loss= 1.6162 val_acc= 0.5800 time= 0.0239\n",
      "Epoch: 0034 train_loss= 1.4944 train_acc= 0.6714 val_loss= 1.6028 val_acc= 0.5800 time= 0.0276\n",
      "Epoch: 0035 train_loss= 1.4764 train_acc= 0.6786 val_loss= 1.5889 val_acc= 0.5800 time= 0.0198\n",
      "Epoch: 0036 train_loss= 1.4575 train_acc= 0.6929 val_loss= 1.5752 val_acc= 0.5833 time= 0.0207\n",
      "Epoch: 0037 train_loss= 1.4381 train_acc= 0.7000 val_loss= 1.5616 val_acc= 0.5900 time= 0.0203\n",
      "Epoch: 0038 train_loss= 1.4196 train_acc= 0.7071 val_loss= 1.5475 val_acc= 0.5967 time= 0.0253\n",
      "Epoch: 0039 train_loss= 1.4007 train_acc= 0.7143 val_loss= 1.5337 val_acc= 0.6133 time= 0.0260\n",
      "Epoch: 0040 train_loss= 1.3813 train_acc= 0.7286 val_loss= 1.5200 val_acc= 0.6167 time= 0.0248\n",
      "Epoch: 0041 train_loss= 1.3626 train_acc= 0.7429 val_loss= 1.5059 val_acc= 0.6233 time= 0.0282\n",
      "Epoch: 0042 train_loss= 1.3430 train_acc= 0.7571 val_loss= 1.4921 val_acc= 0.6367 time= 0.0192\n",
      "Epoch: 0043 train_loss= 1.3242 train_acc= 0.7643 val_loss= 1.4784 val_acc= 0.6433 time= 0.0197\n",
      "Epoch: 0044 train_loss= 1.3048 train_acc= 0.7857 val_loss= 1.4647 val_acc= 0.6600 time= 0.0193\n",
      "Epoch: 0045 train_loss= 1.2862 train_acc= 0.7929 val_loss= 1.4511 val_acc= 0.6733 time= 0.0189\n",
      "Epoch: 0046 train_loss= 1.2672 train_acc= 0.8000 val_loss= 1.4375 val_acc= 0.6800 time= 0.0241\n",
      "Epoch: 0047 train_loss= 1.2493 train_acc= 0.8214 val_loss= 1.4241 val_acc= 0.6833 time= 0.0191\n",
      "Epoch: 0048 train_loss= 1.2307 train_acc= 0.8286 val_loss= 1.4105 val_acc= 0.6900 time= 0.0216\n",
      "Epoch: 0049 train_loss= 1.2125 train_acc= 0.8357 val_loss= 1.3974 val_acc= 0.7000 time= 0.0231\n",
      "Epoch: 0050 train_loss= 1.1951 train_acc= 0.8500 val_loss= 1.3849 val_acc= 0.7133 time= 0.0290\n",
      "Epoch: 0051 train_loss= 1.1776 train_acc= 0.8500 val_loss= 1.3718 val_acc= 0.7133 time= 0.0233\n",
      "Epoch: 0052 train_loss= 1.1598 train_acc= 0.8500 val_loss= 1.3593 val_acc= 0.7133 time= 0.0200\n",
      "Epoch: 0053 train_loss= 1.1431 train_acc= 0.8500 val_loss= 1.3468 val_acc= 0.7200 time= 0.0237\n",
      "Epoch: 0054 train_loss= 1.1267 train_acc= 0.8500 val_loss= 1.3344 val_acc= 0.7367 time= 0.0237\n",
      "Epoch: 0055 train_loss= 1.1109 train_acc= 0.8500 val_loss= 1.3223 val_acc= 0.7500 time= 0.0263\n",
      "Epoch: 0056 train_loss= 1.0945 train_acc= 0.8500 val_loss= 1.3105 val_acc= 0.7633 time= 0.0236\n",
      "Epoch: 0057 train_loss= 1.0789 train_acc= 0.8571 val_loss= 1.2989 val_acc= 0.7667 time= 0.0244\n",
      "Epoch: 0058 train_loss= 1.0628 train_acc= 0.8786 val_loss= 1.2877 val_acc= 0.7667 time= 0.0211\n",
      "Epoch: 0059 train_loss= 1.0483 train_acc= 0.8786 val_loss= 1.2762 val_acc= 0.7633 time= 0.0232\n",
      "Epoch: 0060 train_loss= 1.0335 train_acc= 0.8786 val_loss= 1.2656 val_acc= 0.7667 time= 0.0189\n",
      "Epoch: 0061 train_loss= 1.0189 train_acc= 0.8786 val_loss= 1.2544 val_acc= 0.7667 time= 0.0237\n",
      "Epoch: 0062 train_loss= 1.0046 train_acc= 0.8786 val_loss= 1.2431 val_acc= 0.7700 time= 0.0188\n",
      "Epoch: 0063 train_loss= 0.9912 train_acc= 0.8786 val_loss= 1.2329 val_acc= 0.7667 time= 0.0190\n",
      "Epoch: 0064 train_loss= 0.9783 train_acc= 0.8786 val_loss= 1.2223 val_acc= 0.7633 time= 0.0237\n",
      "Epoch: 0065 train_loss= 0.9654 train_acc= 0.8786 val_loss= 1.2123 val_acc= 0.7667 time= 0.0217\n",
      "Epoch: 0066 train_loss= 0.9521 train_acc= 0.8786 val_loss= 1.2025 val_acc= 0.7633 time= 0.0199\n",
      "Epoch: 0067 train_loss= 0.9398 train_acc= 0.8786 val_loss= 1.1924 val_acc= 0.7633 time= 0.0195\n",
      "Epoch: 0068 train_loss= 0.9276 train_acc= 0.8786 val_loss= 1.1833 val_acc= 0.7633 time= 0.0193\n",
      "Epoch: 0069 train_loss= 0.9158 train_acc= 0.8786 val_loss= 1.1739 val_acc= 0.7633 time= 0.0201\n",
      "Epoch: 0070 train_loss= 0.9042 train_acc= 0.8857 val_loss= 1.1652 val_acc= 0.7700 time= 0.0196\n",
      "Epoch: 0071 train_loss= 0.8932 train_acc= 0.8857 val_loss= 1.1563 val_acc= 0.7700 time= 0.0201\n",
      "Epoch: 0072 train_loss= 0.8824 train_acc= 0.8857 val_loss= 1.1476 val_acc= 0.7667 time= 0.0196\n",
      "Epoch: 0073 train_loss= 0.8717 train_acc= 0.8857 val_loss= 1.1394 val_acc= 0.7633 time= 0.0209\n",
      "Epoch: 0074 train_loss= 0.8614 train_acc= 0.8857 val_loss= 1.1315 val_acc= 0.7667 time= 0.0200\n",
      "Epoch: 0075 train_loss= 0.8515 train_acc= 0.8929 val_loss= 1.1239 val_acc= 0.7700 time= 0.0233\n",
      "Epoch: 0076 train_loss= 0.8418 train_acc= 0.8929 val_loss= 1.1162 val_acc= 0.7700 time= 0.0254\n",
      "Epoch: 0077 train_loss= 0.8318 train_acc= 0.8929 val_loss= 1.1086 val_acc= 0.7733 time= 0.0230\n",
      "Epoch: 0078 train_loss= 0.8226 train_acc= 0.8929 val_loss= 1.1010 val_acc= 0.7733 time= 0.0235\n",
      "Epoch: 0079 train_loss= 0.8137 train_acc= 0.8929 val_loss= 1.0935 val_acc= 0.7733 time= 0.0196\n",
      "Epoch: 0080 train_loss= 0.8047 train_acc= 0.8929 val_loss= 1.0862 val_acc= 0.7733 time= 0.0236\n",
      "Epoch: 0081 train_loss= 0.7957 train_acc= 0.8929 val_loss= 1.0787 val_acc= 0.7733 time= 0.0199\n",
      "Epoch: 0082 train_loss= 0.7872 train_acc= 0.8929 val_loss= 1.0715 val_acc= 0.7767 time= 0.0196\n",
      "Epoch: 0083 train_loss= 0.7790 train_acc= 0.8929 val_loss= 1.0647 val_acc= 0.7767 time= 0.0247\n",
      "Epoch: 0084 train_loss= 0.7707 train_acc= 0.8929 val_loss= 1.0577 val_acc= 0.7833 time= 0.0210\n",
      "Epoch: 0085 train_loss= 0.7628 train_acc= 0.8929 val_loss= 1.0511 val_acc= 0.7867 time= 0.0199\n",
      "Epoch: 0086 train_loss= 0.7551 train_acc= 0.8929 val_loss= 1.0448 val_acc= 0.7867 time= 0.0186\n",
      "Epoch: 0087 train_loss= 0.7473 train_acc= 0.9071 val_loss= 1.0384 val_acc= 0.7867 time= 0.0246\n",
      "Epoch: 0088 train_loss= 0.7397 train_acc= 0.9071 val_loss= 1.0324 val_acc= 0.7867 time= 0.0293\n",
      "Epoch: 0089 train_loss= 0.7321 train_acc= 0.9071 val_loss= 1.0270 val_acc= 0.7867 time= 0.0293\n",
      "Epoch: 0090 train_loss= 0.7249 train_acc= 0.9071 val_loss= 1.0209 val_acc= 0.7867 time= 0.0234\n",
      "Epoch: 0091 train_loss= 0.7178 train_acc= 0.9071 val_loss= 1.0150 val_acc= 0.7867 time= 0.0248\n",
      "Epoch: 0092 train_loss= 0.7112 train_acc= 0.9143 val_loss= 1.0094 val_acc= 0.7867 time= 0.0282\n",
      "Epoch: 0093 train_loss= 0.7036 train_acc= 0.9143 val_loss= 1.0040 val_acc= 0.7867 time= 0.0226\n",
      "Epoch: 0094 train_loss= 0.6970 train_acc= 0.9143 val_loss= 0.9991 val_acc= 0.7867 time= 0.0210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0095 train_loss= 0.6906 train_acc= 0.9143 val_loss= 0.9938 val_acc= 0.7833 time= 0.0227\n",
      "Epoch: 0096 train_loss= 0.6840 train_acc= 0.9143 val_loss= 0.9892 val_acc= 0.7833 time= 0.0203\n",
      "Epoch: 0097 train_loss= 0.6778 train_acc= 0.9143 val_loss= 0.9845 val_acc= 0.7833 time= 0.0232\n",
      "Epoch: 0098 train_loss= 0.6720 train_acc= 0.9143 val_loss= 0.9797 val_acc= 0.7767 time= 0.0231\n",
      "Epoch: 0099 train_loss= 0.6660 train_acc= 0.9143 val_loss= 0.9753 val_acc= 0.7767 time= 0.0184\n",
      "Epoch: 0100 train_loss= 0.6606 train_acc= 0.9143 val_loss= 0.9710 val_acc= 0.7767 time= 0.0185\n",
      "Epoch: 0101 train_loss= 0.6545 train_acc= 0.9143 val_loss= 0.9666 val_acc= 0.7833 time= 0.0186\n",
      "Epoch: 0102 train_loss= 0.6489 train_acc= 0.9143 val_loss= 0.9626 val_acc= 0.7833 time= 0.0184\n",
      "Epoch: 0103 train_loss= 0.6433 train_acc= 0.9143 val_loss= 0.9583 val_acc= 0.7833 time= 0.0230\n",
      "Epoch: 0104 train_loss= 0.6380 train_acc= 0.9143 val_loss= 0.9540 val_acc= 0.7833 time= 0.0185\n",
      "Epoch: 0105 train_loss= 0.6328 train_acc= 0.9143 val_loss= 0.9497 val_acc= 0.7833 time= 0.0188\n",
      "Epoch: 0106 train_loss= 0.6277 train_acc= 0.9143 val_loss= 0.9457 val_acc= 0.7867 time= 0.0238\n",
      "Epoch: 0107 train_loss= 0.6225 train_acc= 0.9143 val_loss= 0.9410 val_acc= 0.7967 time= 0.0234\n",
      "Epoch: 0108 train_loss= 0.6174 train_acc= 0.9214 val_loss= 0.9369 val_acc= 0.7933 time= 0.0234\n",
      "Epoch: 0109 train_loss= 0.6126 train_acc= 0.9286 val_loss= 0.9328 val_acc= 0.7967 time= 0.0194\n",
      "Epoch: 0110 train_loss= 0.6083 train_acc= 0.9357 val_loss= 0.9299 val_acc= 0.7967 time= 0.0244\n",
      "Epoch: 0111 train_loss= 0.6035 train_acc= 0.9357 val_loss= 0.9260 val_acc= 0.8033 time= 0.0242\n",
      "Epoch: 0112 train_loss= 0.5987 train_acc= 0.9357 val_loss= 0.9223 val_acc= 0.8033 time= 0.0231\n",
      "Epoch: 0113 train_loss= 0.5947 train_acc= 0.9429 val_loss= 0.9181 val_acc= 0.8067 time= 0.0250\n",
      "Epoch: 0114 train_loss= 0.5902 train_acc= 0.9429 val_loss= 0.9145 val_acc= 0.8067 time= 0.0238\n",
      "Epoch: 0115 train_loss= 0.5865 train_acc= 0.9429 val_loss= 0.9113 val_acc= 0.8067 time= 0.0215\n",
      "Epoch: 0116 train_loss= 0.5825 train_acc= 0.9429 val_loss= 0.9080 val_acc= 0.8067 time= 0.0239\n",
      "Epoch: 0117 train_loss= 0.5780 train_acc= 0.9429 val_loss= 0.9052 val_acc= 0.8033 time= 0.0188\n",
      "Epoch: 0118 train_loss= 0.5740 train_acc= 0.9429 val_loss= 0.9028 val_acc= 0.7933 time= 0.0245\n",
      "Epoch: 0119 train_loss= 0.5703 train_acc= 0.9429 val_loss= 0.9002 val_acc= 0.7933 time= 0.0187\n",
      "Epoch: 0120 train_loss= 0.5662 train_acc= 0.9429 val_loss= 0.8985 val_acc= 0.7933 time= 0.0194\n",
      "Epoch: 0121 train_loss= 0.5624 train_acc= 0.9500 val_loss= 0.8961 val_acc= 0.7933 time= 0.0187\n",
      "Epoch: 0122 train_loss= 0.5586 train_acc= 0.9500 val_loss= 0.8938 val_acc= 0.7900 time= 0.0205\n",
      "Epoch: 0123 train_loss= 0.5549 train_acc= 0.9500 val_loss= 0.8906 val_acc= 0.7967 time= 0.0277\n",
      "Epoch: 0124 train_loss= 0.5510 train_acc= 0.9500 val_loss= 0.8869 val_acc= 0.7933 time= 0.0234\n",
      "Epoch: 0125 train_loss= 0.5475 train_acc= 0.9500 val_loss= 0.8842 val_acc= 0.8000 time= 0.0200\n",
      "Epoch: 0126 train_loss= 0.5434 train_acc= 0.9500 val_loss= 0.8805 val_acc= 0.8000 time= 0.0235\n",
      "Epoch: 0127 train_loss= 0.5398 train_acc= 0.9500 val_loss= 0.8771 val_acc= 0.8000 time= 0.0252\n",
      "Epoch: 0128 train_loss= 0.5360 train_acc= 0.9500 val_loss= 0.8736 val_acc= 0.8000 time= 0.0194\n",
      "Epoch: 0129 train_loss= 0.5323 train_acc= 0.9500 val_loss= 0.8698 val_acc= 0.8100 time= 0.0191\n",
      "Epoch: 0130 train_loss= 0.5295 train_acc= 0.9500 val_loss= 0.8662 val_acc= 0.8100 time= 0.0235\n",
      "Epoch: 0131 train_loss= 0.5249 train_acc= 0.9500 val_loss= 0.8633 val_acc= 0.8100 time= 0.0234\n",
      "Epoch: 0132 train_loss= 0.5221 train_acc= 0.9500 val_loss= 0.8610 val_acc= 0.8100 time= 0.0200\n",
      "Epoch: 0133 train_loss= 0.5192 train_acc= 0.9500 val_loss= 0.8579 val_acc= 0.8200 time= 0.0192\n",
      "Epoch: 0134 train_loss= 0.5161 train_acc= 0.9500 val_loss= 0.8564 val_acc= 0.8133 time= 0.0199\n",
      "Epoch: 0135 train_loss= 0.5136 train_acc= 0.9500 val_loss= 0.8545 val_acc= 0.8167 time= 0.0210\n",
      "Epoch: 0136 train_loss= 0.5105 train_acc= 0.9571 val_loss= 0.8530 val_acc= 0.8133 time= 0.0252\n",
      "Epoch: 0137 train_loss= 0.5069 train_acc= 0.9571 val_loss= 0.8518 val_acc= 0.8133 time= 0.0235\n",
      "Epoch: 0138 train_loss= 0.5041 train_acc= 0.9643 val_loss= 0.8513 val_acc= 0.8100 time= 0.0236\n",
      "Epoch: 0139 train_loss= 0.5011 train_acc= 0.9643 val_loss= 0.8500 val_acc= 0.8067 time= 0.0196\n",
      "Epoch: 0140 train_loss= 0.4986 train_acc= 0.9643 val_loss= 0.8489 val_acc= 0.8067 time= 0.0232\n",
      "Epoch: 0141 train_loss= 0.4958 train_acc= 0.9643 val_loss= 0.8478 val_acc= 0.8033 time= 0.0227\n",
      "Epoch: 0142 train_loss= 0.4931 train_acc= 0.9643 val_loss= 0.8462 val_acc= 0.8067 time= 0.0248\n",
      "Epoch: 0143 train_loss= 0.4902 train_acc= 0.9714 val_loss= 0.8444 val_acc= 0.8100 time= 0.0245\n",
      "Epoch: 0144 train_loss= 0.4878 train_acc= 0.9643 val_loss= 0.8423 val_acc= 0.8133 time= 0.0283\n",
      "Epoch: 0145 train_loss= 0.4848 train_acc= 0.9714 val_loss= 0.8403 val_acc= 0.8133 time= 0.0236\n",
      "Epoch: 0146 train_loss= 0.4817 train_acc= 0.9714 val_loss= 0.8376 val_acc= 0.8167 time= 0.0185\n",
      "Epoch: 0147 train_loss= 0.4789 train_acc= 0.9714 val_loss= 0.8344 val_acc= 0.8167 time= 0.0189\n",
      "Epoch: 0148 train_loss= 0.4760 train_acc= 0.9714 val_loss= 0.8312 val_acc= 0.8200 time= 0.0188\n",
      "Epoch: 0149 train_loss= 0.4740 train_acc= 0.9714 val_loss= 0.8288 val_acc= 0.8167 time= 0.0198\n",
      "Epoch: 0150 train_loss= 0.4707 train_acc= 0.9714 val_loss= 0.8269 val_acc= 0.8167 time= 0.0213\n",
      "Epoch: 0151 train_loss= 0.4678 train_acc= 0.9714 val_loss= 0.8246 val_acc= 0.8167 time= 0.0232\n",
      "Epoch: 0152 train_loss= 0.4654 train_acc= 0.9714 val_loss= 0.8230 val_acc= 0.8200 time= 0.0191\n",
      "Epoch: 0153 train_loss= 0.4628 train_acc= 0.9714 val_loss= 0.8220 val_acc= 0.8133 time= 0.0228\n",
      "Epoch: 0154 train_loss= 0.4603 train_acc= 0.9714 val_loss= 0.8207 val_acc= 0.8133 time= 0.0192\n",
      "Epoch: 0155 train_loss= 0.4581 train_acc= 0.9714 val_loss= 0.8189 val_acc= 0.8133 time= 0.0231\n",
      "Epoch: 0156 train_loss= 0.4555 train_acc= 0.9714 val_loss= 0.8180 val_acc= 0.8167 time= 0.0245\n",
      "Epoch: 0157 train_loss= 0.4530 train_acc= 0.9714 val_loss= 0.8172 val_acc= 0.8200 time= 0.0208\n",
      "Epoch: 0158 train_loss= 0.4503 train_acc= 0.9714 val_loss= 0.8164 val_acc= 0.8200 time= 0.0232\n",
      "Epoch: 0159 train_loss= 0.4479 train_acc= 0.9714 val_loss= 0.8158 val_acc= 0.8200 time= 0.0206\n",
      "Epoch: 0160 train_loss= 0.4455 train_acc= 0.9714 val_loss= 0.8137 val_acc= 0.8167 time= 0.0240\n",
      "Epoch: 0161 train_loss= 0.4442 train_acc= 0.9714 val_loss= 0.8118 val_acc= 0.8167 time= 0.0244\n",
      "Epoch: 0162 train_loss= 0.4412 train_acc= 0.9714 val_loss= 0.8090 val_acc= 0.8200 time= 0.0209\n",
      "Epoch: 0163 train_loss= 0.4384 train_acc= 0.9714 val_loss= 0.8066 val_acc= 0.8233 time= 0.0209\n",
      "Epoch: 0164 train_loss= 0.4371 train_acc= 0.9714 val_loss= 0.8043 val_acc= 0.8233 time= 0.0283\n",
      "Epoch: 0165 train_loss= 0.4335 train_acc= 0.9643 val_loss= 0.8026 val_acc= 0.8233 time= 0.0232\n",
      "Epoch: 0166 train_loss= 0.4320 train_acc= 0.9643 val_loss= 0.8000 val_acc= 0.8233 time= 0.0245\n",
      "Epoch: 0167 train_loss= 0.4294 train_acc= 0.9643 val_loss= 0.7985 val_acc= 0.8233 time= 0.0241\n",
      "Epoch: 0168 train_loss= 0.4275 train_acc= 0.9714 val_loss= 0.7960 val_acc= 0.8233 time= 0.0190\n",
      "Epoch: 0169 train_loss= 0.4248 train_acc= 0.9786 val_loss= 0.7941 val_acc= 0.8233 time= 0.0235\n",
      "Epoch: 0170 train_loss= 0.4226 train_acc= 0.9714 val_loss= 0.7928 val_acc= 0.8233 time= 0.0253\n",
      "Epoch: 0171 train_loss= 0.4202 train_acc= 0.9714 val_loss= 0.7914 val_acc= 0.8233 time= 0.0292\n",
      "Epoch: 0172 train_loss= 0.4188 train_acc= 0.9786 val_loss= 0.7907 val_acc= 0.8233 time= 0.0188\n",
      "Epoch: 0173 train_loss= 0.4173 train_acc= 0.9714 val_loss= 0.7901 val_acc= 0.8233 time= 0.0184\n",
      "Epoch: 0174 train_loss= 0.4153 train_acc= 0.9714 val_loss= 0.7903 val_acc= 0.8200 time= 0.0201\n",
      "Epoch: 0175 train_loss= 0.4131 train_acc= 0.9714 val_loss= 0.7896 val_acc= 0.8200 time= 0.0278\n",
      "Epoch: 0176 train_loss= 0.4120 train_acc= 0.9714 val_loss= 0.7878 val_acc= 0.8200 time= 0.0231\n",
      "Epoch: 0177 train_loss= 0.4100 train_acc= 0.9714 val_loss= 0.7868 val_acc= 0.8200 time= 0.0201\n",
      "Epoch: 0178 train_loss= 0.4077 train_acc= 0.9714 val_loss= 0.7854 val_acc= 0.8167 time= 0.0279\n",
      "Epoch: 0179 train_loss= 0.4061 train_acc= 0.9714 val_loss= 0.7850 val_acc= 0.8167 time= 0.0193\n",
      "Epoch: 0180 train_loss= 0.4050 train_acc= 0.9714 val_loss= 0.7839 val_acc= 0.8133 time= 0.0237\n",
      "Epoch: 0181 train_loss= 0.4029 train_acc= 0.9714 val_loss= 0.7831 val_acc= 0.8133 time= 0.0214\n",
      "Epoch: 0182 train_loss= 0.4005 train_acc= 0.9786 val_loss= 0.7828 val_acc= 0.8133 time= 0.0192\n",
      "Epoch: 0183 train_loss= 0.3986 train_acc= 0.9786 val_loss= 0.7808 val_acc= 0.8133 time= 0.0183\n",
      "Epoch: 0184 train_loss= 0.3973 train_acc= 0.9857 val_loss= 0.7805 val_acc= 0.8133 time= 0.0234\n",
      "Epoch: 0185 train_loss= 0.3951 train_acc= 0.9786 val_loss= 0.7799 val_acc= 0.8133 time= 0.0186\n",
      "Epoch: 0186 train_loss= 0.3935 train_acc= 0.9857 val_loss= 0.7787 val_acc= 0.8133 time= 0.0180\n",
      "Epoch: 0187 train_loss= 0.3918 train_acc= 0.9857 val_loss= 0.7763 val_acc= 0.8133 time= 0.0184\n",
      "Epoch: 0188 train_loss= 0.3900 train_acc= 0.9857 val_loss= 0.7745 val_acc= 0.8167 time= 0.0233\n",
      "Epoch: 0189 train_loss= 0.3878 train_acc= 0.9857 val_loss= 0.7725 val_acc= 0.8167 time= 0.0211\n",
      "Epoch: 0190 train_loss= 0.3866 train_acc= 0.9857 val_loss= 0.7713 val_acc= 0.8167 time= 0.0302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0191 train_loss= 0.3851 train_acc= 0.9857 val_loss= 0.7704 val_acc= 0.8167 time= 0.0278\n",
      "Epoch: 0192 train_loss= 0.3837 train_acc= 0.9857 val_loss= 0.7687 val_acc= 0.8133 time= 0.0286\n",
      "Epoch: 0193 train_loss= 0.3814 train_acc= 0.9857 val_loss= 0.7669 val_acc= 0.8133 time= 0.0190\n",
      "Epoch: 0194 train_loss= 0.3803 train_acc= 0.9857 val_loss= 0.7653 val_acc= 0.8100 time= 0.0241\n",
      "Epoch: 0195 train_loss= 0.3783 train_acc= 0.9786 val_loss= 0.7636 val_acc= 0.8100 time= 0.0190\n",
      "Epoch: 0196 train_loss= 0.3762 train_acc= 0.9857 val_loss= 0.7619 val_acc= 0.8100 time= 0.0188\n",
      "Epoch: 0197 train_loss= 0.3747 train_acc= 0.9786 val_loss= 0.7605 val_acc= 0.8100 time= 0.0241\n",
      "Epoch: 0198 train_loss= 0.3729 train_acc= 0.9786 val_loss= 0.7588 val_acc= 0.8100 time= 0.0187\n",
      "Epoch: 0199 train_loss= 0.3706 train_acc= 0.9786 val_loss= 0.7571 val_acc= 0.8100 time= 0.0195\n",
      "Epoch: 0200 train_loss= 0.3688 train_acc= 0.9786 val_loss= 0.7558 val_acc= 0.8100 time= 0.0189\n"
     ]
    }
   ],
   "source": [
    "NB_EPOCH = 200\n",
    "PATIENCE = 10  # early stopping patience\n",
    "# Helper variables for main training loop\n",
    "wait = 0\n",
    "preds = None\n",
    "best_val_loss = 99999\n",
    "\n",
    "# Fit\n",
    "for epoch in range(1, NB_EPOCH+1):\n",
    "\n",
    "    # Log wall-clock time\n",
    "    t = time.time()\n",
    "\n",
    "    # Single training iteration (we mask nodes without labels for loss calculation)\n",
    "    model.fit(graph, y_train, sample_weight=train_mask,\n",
    "              batch_size=A.shape[0], epochs=1, shuffle=False, verbose=0)\n",
    "\n",
    "    # Predict on full dataset\n",
    "    preds = model.predict(graph, batch_size=A.shape[0])\n",
    "\n",
    "    # Train / validation scores\n",
    "    train_val_loss, train_val_acc = evaluate_preds(preds, [y_train, y_val],\n",
    "                                                   [idx_train, idx_val])\n",
    "    print(\"Epoch: {:04d}\".format(epoch),\n",
    "          \"train_loss= {:.4f}\".format(train_val_loss[0]),\n",
    "          \"train_acc= {:.4f}\".format(train_val_acc[0]),\n",
    "          \"val_loss= {:.4f}\".format(train_val_loss[1]),\n",
    "          \"val_acc= {:.4f}\".format(train_val_acc[1]),\n",
    "          \"time= {:.4f}\".format(time.time() - t))\n",
    "\n",
    "    # Early stopping\n",
    "    if train_val_loss[1] < best_val_loss:\n",
    "        best_val_loss = train_val_loss[1]\n",
    "        wait = 0\n",
    "    else:\n",
    "        if wait >= PATIENCE:\n",
    "            print('Epoch {}: early stopping'.format(epoch))\n",
    "            break\n",
    "        wait += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.7987\n",
      "accuracy = 0.8210\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate_preds(preds, [y_test], [idx_test])\n",
    "print(f\"\"\"\n",
    "loss = {test_loss[0]:.4f}\n",
    "accuracy = {test_acc[0]:.4f}\n",
    "\"\"\".strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
