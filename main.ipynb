{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from keras.layers import Input, Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the path of execution\n",
    "EXE_PATH = os.path.abspath(os.path.curdir)\n",
    "# the path of the vendor files\n",
    "VENDOR_PATH = os.path.join(EXE_PATH, 'vendor')\n",
    "# the vendors to include in the system path\n",
    "VENDORS = ['gcn', 'keras-gcn']\n",
    "# create the absolute paths for all vendors\n",
    "VENDORS = list(map(lambda x: os.path.join(VENDOR_PATH, x), VENDORS))\n",
    "# update the Python path to include necessary vendor module\n",
    "sys.path += VENDORS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kegra.utils import load_data, preprocess_adj, get_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cora dataset...\n",
      "Dataset has 2708 nodes, 5429 edges, 1433 features.\n"
     ]
    }
   ],
   "source": [
    "X, A, y = load_data('data/cora/', dataset='cora')\n",
    "X /= X.sum(1).reshape(-1, 1)\n",
    "A = preprocess_adj(A)\n",
    "y_train, y_val, y_test, idx_train, idx_val, idx_test, train_mask = get_splits(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2708x2708 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 13264 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 1, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 1, 0]], dtype=int32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1110 13:22:38.579905 140016016086848 deprecation_wrapper.py:119] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1110 13:22:38.587121 140016016086848 deprecation_wrapper.py:119] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:515: The name tf.sparse_placeholder is deprecated. Please use tf.compat.v1.sparse_placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "support = 1\n",
    "graph = [X, A]\n",
    "G = [Input(shape=(None, None), batch_shape=(None, None), sparse=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1110 13:22:50.261755 140016016086848 deprecation_wrapper.py:119] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_in = Input(shape=(X.shape[1],))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCN (baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kegra.layers.graph import GraphConvolution\n",
    "from kegra.utils import evaluate_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1110 13:23:14.492358 140016016086848 deprecation_wrapper.py:119] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W1110 13:23:14.505705 140016016086848 deprecation.py:506] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W1110 13:23:14.515266 140016016086848 deprecation_wrapper.py:119] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define model architecture\n",
    "# NOTE: We pass arguments for graph convolutional layers as a list of tensors.\n",
    "# This is somewhat hacky, more elegant options would require rewriting the Layer base class.\n",
    "H = Dropout(0.5)(X_in)\n",
    "H = GraphConvolution(16, support, activation='relu', kernel_regularizer=l2(5e-4))([H]+G)\n",
    "H = Dropout(0.5)(H)\n",
    "Y = GraphConvolution(y.shape[1], support, activation='softmax')([H]+G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1110 13:23:15.699908 140016016086848 deprecation_wrapper.py:119] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=[X_in]+G, outputs=Y)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 train_loss= 1.9193 train_acc= 0.2929 val_loss= 1.9219 val_acc= 0.3500 time= 0.0390\n",
      "Epoch: 0002 train_loss= 1.9044 train_acc= 0.2929 val_loss= 1.9089 val_acc= 0.3500 time= 0.0194\n",
      "Epoch: 0003 train_loss= 1.8894 train_acc= 0.2929 val_loss= 1.8958 val_acc= 0.3500 time= 0.0232\n",
      "Epoch: 0004 train_loss= 1.8742 train_acc= 0.2929 val_loss= 1.8825 val_acc= 0.3500 time= 0.0182\n",
      "Epoch: 0005 train_loss= 1.8591 train_acc= 0.2929 val_loss= 1.8693 val_acc= 0.3500 time= 0.0234\n",
      "Epoch: 0006 train_loss= 1.8441 train_acc= 0.2929 val_loss= 1.8562 val_acc= 0.3500 time= 0.0200\n",
      "Epoch: 0007 train_loss= 1.8294 train_acc= 0.2929 val_loss= 1.8435 val_acc= 0.3500 time= 0.0195\n",
      "Epoch: 0008 train_loss= 1.8153 train_acc= 0.2929 val_loss= 1.8317 val_acc= 0.3500 time= 0.0233\n",
      "Epoch: 0009 train_loss= 1.8019 train_acc= 0.2929 val_loss= 1.8205 val_acc= 0.3500 time= 0.0199\n",
      "Epoch: 0010 train_loss= 1.7891 train_acc= 0.2929 val_loss= 1.8101 val_acc= 0.3500 time= 0.0215\n",
      "Epoch: 0011 train_loss= 1.7770 train_acc= 0.2929 val_loss= 1.8005 val_acc= 0.3500 time= 0.0195\n",
      "Epoch: 0012 train_loss= 1.7657 train_acc= 0.2929 val_loss= 1.7918 val_acc= 0.3500 time= 0.0193\n",
      "Epoch: 0013 train_loss= 1.7551 train_acc= 0.2929 val_loss= 1.7838 val_acc= 0.3500 time= 0.0209\n",
      "Epoch: 0014 train_loss= 1.7453 train_acc= 0.2929 val_loss= 1.7766 val_acc= 0.3500 time= 0.0189\n",
      "Epoch: 0015 train_loss= 1.7362 train_acc= 0.2929 val_loss= 1.7702 val_acc= 0.3500 time= 0.0230\n",
      "Epoch: 0016 train_loss= 1.7274 train_acc= 0.2929 val_loss= 1.7642 val_acc= 0.3500 time= 0.0189\n",
      "Epoch: 0017 train_loss= 1.7187 train_acc= 0.2929 val_loss= 1.7583 val_acc= 0.3500 time= 0.0198\n",
      "Epoch: 0018 train_loss= 1.7101 train_acc= 0.2929 val_loss= 1.7523 val_acc= 0.3500 time= 0.0184\n",
      "Epoch: 0019 train_loss= 1.7015 train_acc= 0.2929 val_loss= 1.7463 val_acc= 0.3500 time= 0.0213\n",
      "Epoch: 0020 train_loss= 1.6926 train_acc= 0.2929 val_loss= 1.7400 val_acc= 0.3500 time= 0.0230\n",
      "Epoch: 0021 train_loss= 1.6835 train_acc= 0.2929 val_loss= 1.7334 val_acc= 0.3500 time= 0.0213\n",
      "Epoch: 0022 train_loss= 1.6741 train_acc= 0.2929 val_loss= 1.7268 val_acc= 0.3500 time= 0.0203\n",
      "Epoch: 0023 train_loss= 1.6645 train_acc= 0.2929 val_loss= 1.7201 val_acc= 0.3500 time= 0.0185\n",
      "Epoch: 0024 train_loss= 1.6546 train_acc= 0.2929 val_loss= 1.7135 val_acc= 0.3500 time= 0.0187\n",
      "Epoch: 0025 train_loss= 1.6447 train_acc= 0.3143 val_loss= 1.7071 val_acc= 0.3467 time= 0.0197\n",
      "Epoch: 0026 train_loss= 1.6348 train_acc= 0.3357 val_loss= 1.7005 val_acc= 0.3500 time= 0.0197\n",
      "Epoch: 0027 train_loss= 1.6249 train_acc= 0.3429 val_loss= 1.6940 val_acc= 0.3567 time= 0.0231\n",
      "Epoch: 0028 train_loss= 1.6148 train_acc= 0.3714 val_loss= 1.6873 val_acc= 0.3633 time= 0.0196\n",
      "Epoch: 0029 train_loss= 1.6048 train_acc= 0.3929 val_loss= 1.6806 val_acc= 0.3767 time= 0.0231\n",
      "Epoch: 0030 train_loss= 1.5946 train_acc= 0.4000 val_loss= 1.6737 val_acc= 0.3867 time= 0.0229\n",
      "Epoch: 0031 train_loss= 1.5843 train_acc= 0.4357 val_loss= 1.6667 val_acc= 0.4100 time= 0.0203\n",
      "Epoch: 0032 train_loss= 1.5740 train_acc= 0.4429 val_loss= 1.6593 val_acc= 0.4133 time= 0.0242\n",
      "Epoch: 0033 train_loss= 1.5635 train_acc= 0.4643 val_loss= 1.6518 val_acc= 0.4167 time= 0.0234\n",
      "Epoch: 0034 train_loss= 1.5527 train_acc= 0.4786 val_loss= 1.6442 val_acc= 0.4167 time= 0.0190\n",
      "Epoch: 0035 train_loss= 1.5415 train_acc= 0.5071 val_loss= 1.6366 val_acc= 0.4300 time= 0.0236\n",
      "Epoch: 0036 train_loss= 1.5301 train_acc= 0.5286 val_loss= 1.6288 val_acc= 0.4333 time= 0.0229\n",
      "Epoch: 0037 train_loss= 1.5187 train_acc= 0.5357 val_loss= 1.6208 val_acc= 0.4367 time= 0.0189\n",
      "Epoch: 0038 train_loss= 1.5074 train_acc= 0.5357 val_loss= 1.6129 val_acc= 0.4467 time= 0.0183\n",
      "Epoch: 0039 train_loss= 1.4962 train_acc= 0.5500 val_loss= 1.6046 val_acc= 0.4500 time= 0.0188\n",
      "Epoch: 0040 train_loss= 1.4848 train_acc= 0.5500 val_loss= 1.5963 val_acc= 0.4533 time= 0.0223\n",
      "Epoch: 0041 train_loss= 1.4734 train_acc= 0.5571 val_loss= 1.5880 val_acc= 0.4600 time= 0.0194\n",
      "Epoch: 0042 train_loss= 1.4620 train_acc= 0.5571 val_loss= 1.5798 val_acc= 0.4700 time= 0.0232\n",
      "Epoch: 0043 train_loss= 1.4506 train_acc= 0.5714 val_loss= 1.5715 val_acc= 0.4700 time= 0.0185\n",
      "Epoch: 0044 train_loss= 1.4395 train_acc= 0.5857 val_loss= 1.5640 val_acc= 0.4767 time= 0.0187\n",
      "Epoch: 0045 train_loss= 1.4284 train_acc= 0.6071 val_loss= 1.5566 val_acc= 0.4833 time= 0.0178\n",
      "Epoch: 0046 train_loss= 1.4173 train_acc= 0.6357 val_loss= 1.5493 val_acc= 0.5067 time= 0.0227\n",
      "Epoch: 0047 train_loss= 1.4063 train_acc= 0.6357 val_loss= 1.5418 val_acc= 0.5200 time= 0.0181\n",
      "Epoch: 0048 train_loss= 1.3953 train_acc= 0.6429 val_loss= 1.5343 val_acc= 0.5400 time= 0.0225\n",
      "Epoch: 0049 train_loss= 1.3842 train_acc= 0.6429 val_loss= 1.5264 val_acc= 0.5433 time= 0.0183\n",
      "Epoch: 0050 train_loss= 1.3732 train_acc= 0.6571 val_loss= 1.5185 val_acc= 0.5467 time= 0.0178\n",
      "Epoch: 0051 train_loss= 1.3624 train_acc= 0.6571 val_loss= 1.5105 val_acc= 0.5467 time= 0.0238\n",
      "Epoch: 0052 train_loss= 1.3516 train_acc= 0.6714 val_loss= 1.5023 val_acc= 0.5500 time= 0.0213\n",
      "Epoch: 0053 train_loss= 1.3407 train_acc= 0.6857 val_loss= 1.4941 val_acc= 0.5533 time= 0.0231\n",
      "Epoch: 0054 train_loss= 1.3300 train_acc= 0.6857 val_loss= 1.4860 val_acc= 0.5567 time= 0.0232\n",
      "Epoch: 0055 train_loss= 1.3195 train_acc= 0.6857 val_loss= 1.4777 val_acc= 0.5500 time= 0.0239\n",
      "Epoch: 0056 train_loss= 1.3088 train_acc= 0.6929 val_loss= 1.4697 val_acc= 0.5567 time= 0.0183\n",
      "Epoch: 0057 train_loss= 1.2982 train_acc= 0.7000 val_loss= 1.4619 val_acc= 0.5600 time= 0.0190\n",
      "Epoch: 0058 train_loss= 1.2874 train_acc= 0.7000 val_loss= 1.4542 val_acc= 0.5633 time= 0.0203\n",
      "Epoch: 0059 train_loss= 1.2766 train_acc= 0.7000 val_loss= 1.4463 val_acc= 0.5900 time= 0.0234\n",
      "Epoch: 0060 train_loss= 1.2659 train_acc= 0.7000 val_loss= 1.4384 val_acc= 0.6000 time= 0.0187\n",
      "Epoch: 0061 train_loss= 1.2554 train_acc= 0.7000 val_loss= 1.4307 val_acc= 0.6033 time= 0.0206\n",
      "Epoch: 0062 train_loss= 1.2452 train_acc= 0.7000 val_loss= 1.4228 val_acc= 0.6100 time= 0.0249\n",
      "Epoch: 0063 train_loss= 1.2351 train_acc= 0.7143 val_loss= 1.4152 val_acc= 0.6100 time= 0.0235\n",
      "Epoch: 0064 train_loss= 1.2252 train_acc= 0.7143 val_loss= 1.4073 val_acc= 0.6133 time= 0.0191\n",
      "Epoch: 0065 train_loss= 1.2153 train_acc= 0.7214 val_loss= 1.3993 val_acc= 0.6100 time= 0.0252\n",
      "Epoch: 0066 train_loss= 1.2056 train_acc= 0.7286 val_loss= 1.3915 val_acc= 0.6200 time= 0.0237\n",
      "Epoch: 0067 train_loss= 1.1960 train_acc= 0.7286 val_loss= 1.3837 val_acc= 0.6200 time= 0.0244\n",
      "Epoch: 0068 train_loss= 1.1866 train_acc= 0.7357 val_loss= 1.3762 val_acc= 0.6200 time= 0.0189\n",
      "Epoch: 0069 train_loss= 1.1772 train_acc= 0.7357 val_loss= 1.3690 val_acc= 0.6333 time= 0.0191\n",
      "Epoch: 0070 train_loss= 1.1680 train_acc= 0.7357 val_loss= 1.3617 val_acc= 0.6400 time= 0.0234\n",
      "Epoch: 0071 train_loss= 1.1588 train_acc= 0.7500 val_loss= 1.3551 val_acc= 0.6433 time= 0.0229\n",
      "Epoch: 0072 train_loss= 1.1497 train_acc= 0.7500 val_loss= 1.3488 val_acc= 0.6567 time= 0.0192\n",
      "Epoch: 0073 train_loss= 1.1409 train_acc= 0.7643 val_loss= 1.3424 val_acc= 0.6600 time= 0.0289\n",
      "Epoch: 0074 train_loss= 1.1320 train_acc= 0.7643 val_loss= 1.3363 val_acc= 0.6767 time= 0.0180\n",
      "Epoch: 0075 train_loss= 1.1235 train_acc= 0.7643 val_loss= 1.3296 val_acc= 0.6767 time= 0.0240\n",
      "Epoch: 0076 train_loss= 1.1146 train_acc= 0.7643 val_loss= 1.3225 val_acc= 0.6767 time= 0.0267\n",
      "Epoch: 0077 train_loss= 1.1059 train_acc= 0.7714 val_loss= 1.3157 val_acc= 0.6800 time= 0.0227\n",
      "Epoch: 0078 train_loss= 1.0974 train_acc= 0.7714 val_loss= 1.3089 val_acc= 0.6833 time= 0.0182\n",
      "Epoch: 0079 train_loss= 1.0890 train_acc= 0.7786 val_loss= 1.3030 val_acc= 0.6900 time= 0.0223\n",
      "Epoch: 0080 train_loss= 1.0811 train_acc= 0.7857 val_loss= 1.2976 val_acc= 0.7000 time= 0.0188\n",
      "Epoch: 0081 train_loss= 1.0729 train_acc= 0.7857 val_loss= 1.2915 val_acc= 0.7033 time= 0.0185\n",
      "Epoch: 0082 train_loss= 1.0646 train_acc= 0.7929 val_loss= 1.2855 val_acc= 0.7033 time= 0.0198\n",
      "Epoch: 0083 train_loss= 1.0563 train_acc= 0.8000 val_loss= 1.2791 val_acc= 0.7067 time= 0.0229\n",
      "Epoch: 0084 train_loss= 1.0482 train_acc= 0.8000 val_loss= 1.2726 val_acc= 0.7067 time= 0.0182\n",
      "Epoch: 0085 train_loss= 1.0402 train_acc= 0.8000 val_loss= 1.2660 val_acc= 0.7067 time= 0.0184\n",
      "Epoch: 0086 train_loss= 1.0324 train_acc= 0.7929 val_loss= 1.2594 val_acc= 0.7100 time= 0.0183\n",
      "Epoch: 0087 train_loss= 1.0246 train_acc= 0.7929 val_loss= 1.2525 val_acc= 0.7100 time= 0.0231\n",
      "Epoch: 0088 train_loss= 1.0169 train_acc= 0.7929 val_loss= 1.2455 val_acc= 0.7067 time= 0.0183\n",
      "Epoch: 0089 train_loss= 1.0096 train_acc= 0.7929 val_loss= 1.2386 val_acc= 0.7067 time= 0.0184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0090 train_loss= 1.0024 train_acc= 0.7929 val_loss= 1.2320 val_acc= 0.7067 time= 0.0186\n",
      "Epoch: 0091 train_loss= 0.9956 train_acc= 0.7929 val_loss= 1.2257 val_acc= 0.7000 time= 0.0186\n",
      "Epoch: 0092 train_loss= 0.9889 train_acc= 0.7929 val_loss= 1.2200 val_acc= 0.6967 time= 0.0177\n",
      "Epoch: 0093 train_loss= 0.9825 train_acc= 0.7929 val_loss= 1.2145 val_acc= 0.6967 time= 0.0191\n",
      "Epoch: 0094 train_loss= 0.9756 train_acc= 0.7929 val_loss= 1.2094 val_acc= 0.7000 time= 0.0179\n",
      "Epoch: 0095 train_loss= 0.9684 train_acc= 0.7929 val_loss= 1.2042 val_acc= 0.7000 time= 0.0180\n",
      "Epoch: 0096 train_loss= 0.9610 train_acc= 0.7929 val_loss= 1.1995 val_acc= 0.7067 time= 0.0180\n",
      "Epoch: 0097 train_loss= 0.9535 train_acc= 0.8000 val_loss= 1.1949 val_acc= 0.7100 time= 0.0176\n",
      "Epoch: 0098 train_loss= 0.9462 train_acc= 0.8071 val_loss= 1.1907 val_acc= 0.7100 time= 0.0185\n",
      "Epoch: 0099 train_loss= 0.9392 train_acc= 0.8143 val_loss= 1.1863 val_acc= 0.7067 time= 0.0182\n",
      "Epoch: 0100 train_loss= 0.9326 train_acc= 0.8214 val_loss= 1.1822 val_acc= 0.7100 time= 0.0181\n",
      "Epoch: 0101 train_loss= 0.9260 train_acc= 0.8214 val_loss= 1.1777 val_acc= 0.7067 time= 0.0184\n",
      "Epoch: 0102 train_loss= 0.9197 train_acc= 0.8214 val_loss= 1.1736 val_acc= 0.7100 time= 0.0194\n",
      "Epoch: 0103 train_loss= 0.9131 train_acc= 0.8214 val_loss= 1.1681 val_acc= 0.7100 time= 0.0182\n",
      "Epoch: 0104 train_loss= 0.9067 train_acc= 0.8286 val_loss= 1.1615 val_acc= 0.7233 time= 0.0184\n",
      "Epoch: 0105 train_loss= 0.9004 train_acc= 0.8286 val_loss= 1.1550 val_acc= 0.7300 time= 0.0182\n",
      "Epoch: 0106 train_loss= 0.8942 train_acc= 0.8357 val_loss= 1.1489 val_acc= 0.7367 time= 0.0182\n",
      "Epoch: 0107 train_loss= 0.8878 train_acc= 0.8429 val_loss= 1.1432 val_acc= 0.7367 time= 0.0184\n",
      "Epoch: 0108 train_loss= 0.8816 train_acc= 0.8500 val_loss= 1.1379 val_acc= 0.7333 time= 0.0180\n",
      "Epoch: 0109 train_loss= 0.8752 train_acc= 0.8429 val_loss= 1.1334 val_acc= 0.7333 time= 0.0226\n",
      "Epoch: 0110 train_loss= 0.8684 train_acc= 0.8429 val_loss= 1.1292 val_acc= 0.7267 time= 0.0189\n",
      "Epoch: 0111 train_loss= 0.8617 train_acc= 0.8429 val_loss= 1.1251 val_acc= 0.7267 time= 0.0180\n",
      "Epoch: 0112 train_loss= 0.8555 train_acc= 0.8500 val_loss= 1.1210 val_acc= 0.7300 time= 0.0208\n",
      "Epoch: 0113 train_loss= 0.8496 train_acc= 0.8500 val_loss= 1.1172 val_acc= 0.7333 time= 0.0188\n",
      "Epoch: 0114 train_loss= 0.8439 train_acc= 0.8500 val_loss= 1.1130 val_acc= 0.7333 time= 0.0231\n",
      "Epoch: 0115 train_loss= 0.8379 train_acc= 0.8500 val_loss= 1.1083 val_acc= 0.7333 time= 0.0185\n",
      "Epoch: 0116 train_loss= 0.8321 train_acc= 0.8643 val_loss= 1.1032 val_acc= 0.7433 time= 0.0179\n",
      "Epoch: 0117 train_loss= 0.8263 train_acc= 0.8714 val_loss= 1.0981 val_acc= 0.7467 time= 0.0188\n",
      "Epoch: 0118 train_loss= 0.8206 train_acc= 0.8786 val_loss= 1.0922 val_acc= 0.7567 time= 0.0180\n",
      "Epoch: 0119 train_loss= 0.8156 train_acc= 0.8786 val_loss= 1.0860 val_acc= 0.7567 time= 0.0185\n",
      "Epoch: 0120 train_loss= 0.8111 train_acc= 0.8786 val_loss= 1.0806 val_acc= 0.7533 time= 0.0185\n",
      "Epoch: 0121 train_loss= 0.8060 train_acc= 0.8714 val_loss= 1.0762 val_acc= 0.7567 time= 0.0185\n",
      "Epoch: 0122 train_loss= 0.8003 train_acc= 0.8786 val_loss= 1.0720 val_acc= 0.7533 time= 0.0185\n",
      "Epoch: 0123 train_loss= 0.7948 train_acc= 0.8714 val_loss= 1.0680 val_acc= 0.7500 time= 0.0184\n",
      "Epoch: 0124 train_loss= 0.7890 train_acc= 0.8714 val_loss= 1.0648 val_acc= 0.7533 time= 0.0192\n",
      "Epoch: 0125 train_loss= 0.7832 train_acc= 0.8714 val_loss= 1.0617 val_acc= 0.7600 time= 0.0182\n",
      "Epoch: 0126 train_loss= 0.7776 train_acc= 0.8786 val_loss= 1.0593 val_acc= 0.7500 time= 0.0191\n",
      "Epoch: 0127 train_loss= 0.7731 train_acc= 0.8786 val_loss= 1.0579 val_acc= 0.7533 time= 0.0182\n",
      "Epoch: 0128 train_loss= 0.7691 train_acc= 0.8857 val_loss= 1.0563 val_acc= 0.7500 time= 0.0182\n",
      "Epoch: 0129 train_loss= 0.7645 train_acc= 0.8857 val_loss= 1.0537 val_acc= 0.7567 time= 0.0179\n",
      "Epoch: 0130 train_loss= 0.7593 train_acc= 0.9000 val_loss= 1.0495 val_acc= 0.7633 time= 0.0190\n",
      "Epoch: 0131 train_loss= 0.7541 train_acc= 0.9000 val_loss= 1.0449 val_acc= 0.7733 time= 0.0183\n",
      "Epoch: 0132 train_loss= 0.7490 train_acc= 0.9000 val_loss= 1.0389 val_acc= 0.7867 time= 0.0184\n",
      "Epoch: 0133 train_loss= 0.7445 train_acc= 0.9000 val_loss= 1.0342 val_acc= 0.7867 time= 0.0184\n",
      "Epoch: 0134 train_loss= 0.7398 train_acc= 0.9000 val_loss= 1.0299 val_acc= 0.7867 time= 0.0183\n",
      "Epoch: 0135 train_loss= 0.7344 train_acc= 0.9000 val_loss= 1.0251 val_acc= 0.7833 time= 0.0191\n",
      "Epoch: 0136 train_loss= 0.7290 train_acc= 0.9000 val_loss= 1.0207 val_acc= 0.7867 time= 0.0181\n",
      "Epoch: 0137 train_loss= 0.7234 train_acc= 0.9000 val_loss= 1.0167 val_acc= 0.7900 time= 0.0184\n",
      "Epoch: 0138 train_loss= 0.7182 train_acc= 0.9000 val_loss= 1.0133 val_acc= 0.7933 time= 0.0181\n",
      "Epoch: 0139 train_loss= 0.7134 train_acc= 0.9000 val_loss= 1.0107 val_acc= 0.7867 time= 0.0186\n",
      "Epoch: 0140 train_loss= 0.7090 train_acc= 0.9000 val_loss= 1.0077 val_acc= 0.7867 time= 0.0187\n",
      "Epoch: 0141 train_loss= 0.7046 train_acc= 0.9000 val_loss= 1.0037 val_acc= 0.7900 time= 0.0188\n",
      "Epoch: 0142 train_loss= 0.7001 train_acc= 0.9000 val_loss= 0.9996 val_acc= 0.7800 time= 0.0187\n",
      "Epoch: 0143 train_loss= 0.6957 train_acc= 0.9071 val_loss= 0.9954 val_acc= 0.7767 time= 0.0188\n",
      "Epoch: 0144 train_loss= 0.6914 train_acc= 0.9071 val_loss= 0.9928 val_acc= 0.7800 time= 0.0184\n",
      "Epoch: 0145 train_loss= 0.6872 train_acc= 0.9071 val_loss= 0.9902 val_acc= 0.7800 time= 0.0180\n",
      "Epoch: 0146 train_loss= 0.6829 train_acc= 0.9071 val_loss= 0.9870 val_acc= 0.7800 time= 0.0182\n",
      "Epoch: 0147 train_loss= 0.6783 train_acc= 0.9071 val_loss= 0.9829 val_acc= 0.7800 time= 0.0182\n",
      "Epoch: 0148 train_loss= 0.6742 train_acc= 0.9071 val_loss= 0.9787 val_acc= 0.7900 time= 0.0179\n",
      "Epoch: 0149 train_loss= 0.6707 train_acc= 0.9071 val_loss= 0.9752 val_acc= 0.7933 time= 0.0177\n",
      "Epoch: 0150 train_loss= 0.6674 train_acc= 0.9071 val_loss= 0.9715 val_acc= 0.7900 time= 0.0183\n",
      "Epoch: 0151 train_loss= 0.6643 train_acc= 0.9071 val_loss= 0.9679 val_acc= 0.7900 time= 0.0181\n",
      "Epoch: 0152 train_loss= 0.6610 train_acc= 0.9071 val_loss= 0.9651 val_acc= 0.7900 time= 0.0182\n",
      "Epoch: 0153 train_loss= 0.6575 train_acc= 0.9071 val_loss= 0.9617 val_acc= 0.7933 time= 0.0183\n",
      "Epoch: 0154 train_loss= 0.6535 train_acc= 0.9071 val_loss= 0.9581 val_acc= 0.7933 time= 0.0181\n",
      "Epoch: 0155 train_loss= 0.6487 train_acc= 0.9071 val_loss= 0.9542 val_acc= 0.7933 time= 0.0184\n",
      "Epoch: 0156 train_loss= 0.6436 train_acc= 0.9143 val_loss= 0.9507 val_acc= 0.7967 time= 0.0187\n",
      "Epoch: 0157 train_loss= 0.6386 train_acc= 0.9143 val_loss= 0.9478 val_acc= 0.7967 time= 0.0187\n",
      "Epoch: 0158 train_loss= 0.6342 train_acc= 0.9143 val_loss= 0.9451 val_acc= 0.7933 time= 0.0199\n",
      "Epoch: 0159 train_loss= 0.6305 train_acc= 0.9071 val_loss= 0.9442 val_acc= 0.7900 time= 0.0205\n",
      "Epoch: 0160 train_loss= 0.6276 train_acc= 0.9071 val_loss= 0.9441 val_acc= 0.7900 time= 0.0216\n",
      "Epoch: 0161 train_loss= 0.6246 train_acc= 0.9071 val_loss= 0.9431 val_acc= 0.7900 time= 0.0190\n",
      "Epoch: 0162 train_loss= 0.6212 train_acc= 0.9071 val_loss= 0.9402 val_acc= 0.7967 time= 0.0212\n",
      "Epoch: 0163 train_loss= 0.6172 train_acc= 0.9071 val_loss= 0.9345 val_acc= 0.7933 time= 0.0208\n",
      "Epoch: 0164 train_loss= 0.6136 train_acc= 0.9143 val_loss= 0.9285 val_acc= 0.7933 time= 0.0200\n",
      "Epoch: 0165 train_loss= 0.6106 train_acc= 0.9143 val_loss= 0.9235 val_acc= 0.8033 time= 0.0191\n",
      "Epoch: 0166 train_loss= 0.6081 train_acc= 0.9214 val_loss= 0.9196 val_acc= 0.8067 time= 0.0193\n",
      "Epoch: 0167 train_loss= 0.6057 train_acc= 0.9214 val_loss= 0.9168 val_acc= 0.8100 time= 0.0194\n",
      "Epoch: 0168 train_loss= 0.6029 train_acc= 0.9214 val_loss= 0.9149 val_acc= 0.8100 time= 0.0192\n",
      "Epoch: 0169 train_loss= 0.5998 train_acc= 0.9286 val_loss= 0.9133 val_acc= 0.8100 time= 0.0187\n",
      "Epoch: 0170 train_loss= 0.5963 train_acc= 0.9214 val_loss= 0.9122 val_acc= 0.8067 time= 0.0182\n",
      "Epoch: 0171 train_loss= 0.5925 train_acc= 0.9214 val_loss= 0.9124 val_acc= 0.8067 time= 0.0184\n",
      "Epoch: 0172 train_loss= 0.5897 train_acc= 0.9214 val_loss= 0.9139 val_acc= 0.8067 time= 0.0188\n",
      "Epoch: 0173 train_loss= 0.5872 train_acc= 0.9214 val_loss= 0.9155 val_acc= 0.8000 time= 0.0184\n",
      "Epoch: 0174 train_loss= 0.5842 train_acc= 0.9214 val_loss= 0.9147 val_acc= 0.7967 time= 0.0183\n",
      "Epoch: 0175 train_loss= 0.5803 train_acc= 0.9214 val_loss= 0.9109 val_acc= 0.7967 time= 0.0198\n",
      "Epoch: 0176 train_loss= 0.5768 train_acc= 0.9214 val_loss= 0.9066 val_acc= 0.8033 time= 0.0196\n",
      "Epoch: 0177 train_loss= 0.5733 train_acc= 0.9214 val_loss= 0.9003 val_acc= 0.8000 time= 0.0199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0178 train_loss= 0.5709 train_acc= 0.9214 val_loss= 0.8960 val_acc= 0.8100 time= 0.0207\n",
      "Epoch: 0179 train_loss= 0.5689 train_acc= 0.9214 val_loss= 0.8925 val_acc= 0.8100 time= 0.0245\n",
      "Epoch: 0180 train_loss= 0.5663 train_acc= 0.9286 val_loss= 0.8899 val_acc= 0.8133 time= 0.0188\n",
      "Epoch: 0181 train_loss= 0.5639 train_acc= 0.9286 val_loss= 0.8873 val_acc= 0.8167 time= 0.0202\n",
      "Epoch: 0182 train_loss= 0.5613 train_acc= 0.9214 val_loss= 0.8851 val_acc= 0.8167 time= 0.0220\n",
      "Epoch: 0183 train_loss= 0.5581 train_acc= 0.9214 val_loss= 0.8836 val_acc= 0.8133 time= 0.0196\n",
      "Epoch: 0184 train_loss= 0.5550 train_acc= 0.9357 val_loss= 0.8828 val_acc= 0.8100 time= 0.0190\n",
      "Epoch: 0185 train_loss= 0.5522 train_acc= 0.9357 val_loss= 0.8833 val_acc= 0.8133 time= 0.0197\n",
      "Epoch: 0186 train_loss= 0.5503 train_acc= 0.9429 val_loss= 0.8842 val_acc= 0.8133 time= 0.0189\n",
      "Epoch: 0187 train_loss= 0.5489 train_acc= 0.9429 val_loss= 0.8852 val_acc= 0.8100 time= 0.0206\n",
      "Epoch: 0188 train_loss= 0.5472 train_acc= 0.9429 val_loss= 0.8859 val_acc= 0.7967 time= 0.0190\n",
      "Epoch: 0189 train_loss= 0.5444 train_acc= 0.9429 val_loss= 0.8843 val_acc= 0.8000 time= 0.0189\n",
      "Epoch: 0190 train_loss= 0.5406 train_acc= 0.9429 val_loss= 0.8809 val_acc= 0.8000 time= 0.0202\n",
      "Epoch: 0191 train_loss= 0.5369 train_acc= 0.9357 val_loss= 0.8767 val_acc= 0.8033 time= 0.0189\n",
      "Epoch: 0192 train_loss= 0.5341 train_acc= 0.9357 val_loss= 0.8724 val_acc= 0.8033 time= 0.0191\n",
      "Epoch: 0193 train_loss= 0.5328 train_acc= 0.9286 val_loss= 0.8690 val_acc= 0.8000 time= 0.0187\n",
      "Epoch: 0194 train_loss= 0.5325 train_acc= 0.9286 val_loss= 0.8667 val_acc= 0.8067 time= 0.0180\n",
      "Epoch: 0195 train_loss= 0.5299 train_acc= 0.9286 val_loss= 0.8644 val_acc= 0.8133 time= 0.0183\n",
      "Epoch: 0196 train_loss= 0.5273 train_acc= 0.9286 val_loss= 0.8627 val_acc= 0.8167 time= 0.0190\n",
      "Epoch: 0197 train_loss= 0.5248 train_acc= 0.9286 val_loss= 0.8619 val_acc= 0.8133 time= 0.0240\n",
      "Epoch: 0198 train_loss= 0.5223 train_acc= 0.9286 val_loss= 0.8606 val_acc= 0.8133 time= 0.0185\n",
      "Epoch: 0199 train_loss= 0.5191 train_acc= 0.9286 val_loss= 0.8602 val_acc= 0.8167 time= 0.0251\n",
      "Epoch: 0200 train_loss= 0.5159 train_acc= 0.9357 val_loss= 0.8597 val_acc= 0.8100 time= 0.0196\n"
     ]
    }
   ],
   "source": [
    "NB_EPOCH = 200\n",
    "PATIENCE = 10  # early stopping patience\n",
    "# Helper variables for main training loop\n",
    "wait = 0\n",
    "preds = None\n",
    "best_val_loss = 99999\n",
    "\n",
    "# Fit\n",
    "for epoch in range(1, NB_EPOCH+1):\n",
    "\n",
    "    # Log wall-clock time\n",
    "    t = time.time()\n",
    "\n",
    "    # Single training iteration (we mask nodes without labels for loss calculation)\n",
    "    model.fit(graph, y_train, sample_weight=train_mask,\n",
    "              batch_size=A.shape[0], epochs=1, shuffle=False, verbose=0)\n",
    "\n",
    "    # Predict on full dataset\n",
    "    preds = model.predict(graph, batch_size=A.shape[0])\n",
    "\n",
    "    # Train / validation scores\n",
    "    train_val_loss, train_val_acc = evaluate_preds(preds, [y_train, y_val],\n",
    "                                                   [idx_train, idx_val])\n",
    "    print(\"Epoch: {:04d}\".format(epoch),\n",
    "          \"train_loss= {:.4f}\".format(train_val_loss[0]),\n",
    "          \"train_acc= {:.4f}\".format(train_val_acc[0]),\n",
    "          \"val_loss= {:.4f}\".format(train_val_loss[1]),\n",
    "          \"val_acc= {:.4f}\".format(train_val_acc[1]),\n",
    "          \"time= {:.4f}\".format(time.time() - t))\n",
    "\n",
    "    # Early stopping\n",
    "    if train_val_loss[1] < best_val_loss:\n",
    "        best_val_loss = train_val_loss[1]\n",
    "        wait = 0\n",
    "    else:\n",
    "        if wait >= PATIENCE:\n",
    "            print('Epoch {}: early stopping'.format(epoch))\n",
    "            break\n",
    "        wait += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.9183\n",
      "accuracy = 0.7780\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate_preds(preds, [y_test], [idx_test])\n",
    "print(f\"\"\"\n",
    "loss = {test_loss[0]:.4f}\n",
    "accuracy = {test_acc[0]:.4f}\n",
    "\"\"\".strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Graph Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gaussian_graph_convolution import GaussianGraphConvolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = Dropout(0.5)(X_in)\n",
    "H = GaussianGraphConvolution(16, support, activation='relu', kernel_regularizer=l2(5e-4))([H]+G)\n",
    "H = Dropout(0.5)(H)\n",
    "Y = GaussianGraphConvolution(y.shape[1], support, activation='softmax')([H]+G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[X_in]+G, outputs=Y)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 train_loss= 1.9385 train_acc= 0.3500 val_loss= 1.9393 val_acc= 0.3633 time= 0.4442\n",
      "Epoch: 0002 train_loss= 1.9303 train_acc= 0.3571 val_loss= 1.9320 val_acc= 0.3833 time= 0.0296\n",
      "Epoch: 0003 train_loss= 1.9205 train_acc= 0.3500 val_loss= 1.9230 val_acc= 0.3567 time= 0.0271\n",
      "Epoch: 0004 train_loss= 1.9108 train_acc= 0.3357 val_loss= 1.9144 val_acc= 0.3533 time= 0.0203\n",
      "Epoch: 0005 train_loss= 1.9011 train_acc= 0.3643 val_loss= 1.9060 val_acc= 0.3600 time= 0.0187\n",
      "Epoch: 0006 train_loss= 1.8910 train_acc= 0.3786 val_loss= 1.8972 val_acc= 0.3633 time= 0.0236\n",
      "Epoch: 0007 train_loss= 1.8807 train_acc= 0.3857 val_loss= 1.8880 val_acc= 0.3633 time= 0.0245\n",
      "Epoch: 0008 train_loss= 1.8701 train_acc= 0.3643 val_loss= 1.8785 val_acc= 0.3633 time= 0.0190\n",
      "Epoch: 0009 train_loss= 1.8595 train_acc= 0.3643 val_loss= 1.8691 val_acc= 0.3633 time= 0.0194\n",
      "Epoch: 0010 train_loss= 1.8489 train_acc= 0.3643 val_loss= 1.8596 val_acc= 0.3633 time= 0.0240\n",
      "Epoch: 0011 train_loss= 1.8384 train_acc= 0.3571 val_loss= 1.8503 val_acc= 0.3633 time= 0.0211\n",
      "Epoch: 0012 train_loss= 1.8279 train_acc= 0.3643 val_loss= 1.8413 val_acc= 0.3633 time= 0.0236\n",
      "Epoch: 0013 train_loss= 1.8175 train_acc= 0.3643 val_loss= 1.8325 val_acc= 0.3633 time= 0.0193\n",
      "Epoch: 0014 train_loss= 1.8069 train_acc= 0.3714 val_loss= 1.8240 val_acc= 0.3633 time= 0.0230\n",
      "Epoch: 0015 train_loss= 1.7963 train_acc= 0.3857 val_loss= 1.8156 val_acc= 0.3667 time= 0.0238\n",
      "Epoch: 0016 train_loss= 1.7860 train_acc= 0.4000 val_loss= 1.8079 val_acc= 0.3700 time= 0.0230\n",
      "Epoch: 0017 train_loss= 1.7760 train_acc= 0.4071 val_loss= 1.8006 val_acc= 0.3767 time= 0.0241\n",
      "Epoch: 0018 train_loss= 1.7661 train_acc= 0.4071 val_loss= 1.7931 val_acc= 0.3800 time= 0.0228\n",
      "Epoch: 0019 train_loss= 1.7563 train_acc= 0.4143 val_loss= 1.7860 val_acc= 0.3800 time= 0.0251\n",
      "Epoch: 0020 train_loss= 1.7466 train_acc= 0.4214 val_loss= 1.7791 val_acc= 0.3800 time= 0.0313\n",
      "Epoch: 0021 train_loss= 1.7369 train_acc= 0.4214 val_loss= 1.7722 val_acc= 0.3800 time= 0.0237\n",
      "Epoch: 0022 train_loss= 1.7272 train_acc= 0.4214 val_loss= 1.7654 val_acc= 0.3833 time= 0.0236\n",
      "Epoch: 0023 train_loss= 1.7175 train_acc= 0.4214 val_loss= 1.7588 val_acc= 0.3900 time= 0.0190\n",
      "Epoch: 0024 train_loss= 1.7077 train_acc= 0.4286 val_loss= 1.7523 val_acc= 0.3933 time= 0.0231\n",
      "Epoch: 0025 train_loss= 1.6977 train_acc= 0.4286 val_loss= 1.7456 val_acc= 0.4000 time= 0.0223\n",
      "Epoch: 0026 train_loss= 1.6876 train_acc= 0.4357 val_loss= 1.7388 val_acc= 0.4033 time= 0.0188\n",
      "Epoch: 0027 train_loss= 1.6773 train_acc= 0.4357 val_loss= 1.7317 val_acc= 0.4033 time= 0.0219\n",
      "Epoch: 0028 train_loss= 1.6667 train_acc= 0.4357 val_loss= 1.7244 val_acc= 0.4067 time= 0.0228\n",
      "Epoch: 0029 train_loss= 1.6559 train_acc= 0.4429 val_loss= 1.7171 val_acc= 0.4133 time= 0.0200\n",
      "Epoch: 0030 train_loss= 1.6447 train_acc= 0.4571 val_loss= 1.7096 val_acc= 0.4167 time= 0.0234\n",
      "Epoch: 0031 train_loss= 1.6332 train_acc= 0.4571 val_loss= 1.7019 val_acc= 0.4200 time= 0.0236\n",
      "Epoch: 0032 train_loss= 1.6216 train_acc= 0.4643 val_loss= 1.6939 val_acc= 0.4233 time= 0.0227\n",
      "Epoch: 0033 train_loss= 1.6098 train_acc= 0.4643 val_loss= 1.6859 val_acc= 0.4267 time= 0.0242\n",
      "Epoch: 0034 train_loss= 1.5980 train_acc= 0.4714 val_loss= 1.6777 val_acc= 0.4300 time= 0.0256\n",
      "Epoch: 0035 train_loss= 1.5862 train_acc= 0.4714 val_loss= 1.6697 val_acc= 0.4300 time= 0.0247\n",
      "Epoch: 0036 train_loss= 1.5742 train_acc= 0.4714 val_loss= 1.6617 val_acc= 0.4400 time= 0.0234\n",
      "Epoch: 0037 train_loss= 1.5623 train_acc= 0.4714 val_loss= 1.6539 val_acc= 0.4500 time= 0.0205\n",
      "Epoch: 0038 train_loss= 1.5501 train_acc= 0.4857 val_loss= 1.6461 val_acc= 0.4567 time= 0.0218\n",
      "Epoch: 0039 train_loss= 1.5378 train_acc= 0.4857 val_loss= 1.6382 val_acc= 0.4667 time= 0.0189\n",
      "Epoch: 0040 train_loss= 1.5252 train_acc= 0.4929 val_loss= 1.6297 val_acc= 0.4767 time= 0.0250\n",
      "Epoch: 0041 train_loss= 1.5123 train_acc= 0.5143 val_loss= 1.6214 val_acc= 0.4767 time= 0.0234\n",
      "Epoch: 0042 train_loss= 1.4992 train_acc= 0.5214 val_loss= 1.6126 val_acc= 0.4833 time= 0.0231\n",
      "Epoch: 0043 train_loss= 1.4860 train_acc= 0.5429 val_loss= 1.6038 val_acc= 0.4900 time= 0.0203\n",
      "Epoch: 0044 train_loss= 1.4728 train_acc= 0.5429 val_loss= 1.5949 val_acc= 0.4900 time= 0.0196\n",
      "Epoch: 0045 train_loss= 1.4593 train_acc= 0.5500 val_loss= 1.5854 val_acc= 0.4867 time= 0.0236\n",
      "Epoch: 0046 train_loss= 1.4459 train_acc= 0.5571 val_loss= 1.5758 val_acc= 0.4967 time= 0.0228\n",
      "Epoch: 0047 train_loss= 1.4325 train_acc= 0.5643 val_loss= 1.5657 val_acc= 0.4967 time= 0.0189\n",
      "Epoch: 0048 train_loss= 1.4191 train_acc= 0.5643 val_loss= 1.5556 val_acc= 0.5067 time= 0.0196\n",
      "Epoch: 0049 train_loss= 1.4057 train_acc= 0.5643 val_loss= 1.5450 val_acc= 0.5167 time= 0.0233\n",
      "Epoch: 0050 train_loss= 1.3925 train_acc= 0.5786 val_loss= 1.5345 val_acc= 0.5167 time= 0.0184\n",
      "Epoch: 0051 train_loss= 1.3794 train_acc= 0.5857 val_loss= 1.5245 val_acc= 0.5167 time= 0.0183\n",
      "Epoch: 0052 train_loss= 1.3663 train_acc= 0.5786 val_loss= 1.5146 val_acc= 0.5267 time= 0.0228\n",
      "Epoch: 0053 train_loss= 1.3531 train_acc= 0.5929 val_loss= 1.5049 val_acc= 0.5500 time= 0.0193\n",
      "Epoch: 0054 train_loss= 1.3399 train_acc= 0.6071 val_loss= 1.4953 val_acc= 0.5567 time= 0.0230\n",
      "Epoch: 0055 train_loss= 1.3269 train_acc= 0.6143 val_loss= 1.4858 val_acc= 0.5700 time= 0.0189\n",
      "Epoch: 0056 train_loss= 1.3140 train_acc= 0.6429 val_loss= 1.4765 val_acc= 0.5800 time= 0.0186\n",
      "Epoch: 0057 train_loss= 1.3012 train_acc= 0.6643 val_loss= 1.4672 val_acc= 0.5900 time= 0.0238\n",
      "Epoch: 0058 train_loss= 1.2886 train_acc= 0.7000 val_loss= 1.4581 val_acc= 0.6067 time= 0.0192\n",
      "Epoch: 0059 train_loss= 1.2761 train_acc= 0.7357 val_loss= 1.4490 val_acc= 0.6233 time= 0.0196\n",
      "Epoch: 0060 train_loss= 1.2636 train_acc= 0.7500 val_loss= 1.4396 val_acc= 0.6333 time= 0.0188\n",
      "Epoch: 0061 train_loss= 1.2512 train_acc= 0.7643 val_loss= 1.4295 val_acc= 0.6367 time= 0.0192\n",
      "Epoch: 0062 train_loss= 1.2390 train_acc= 0.7643 val_loss= 1.4195 val_acc= 0.6500 time= 0.0218\n",
      "Epoch: 0063 train_loss= 1.2269 train_acc= 0.7643 val_loss= 1.4099 val_acc= 0.6533 time= 0.0243\n",
      "Epoch: 0064 train_loss= 1.2150 train_acc= 0.7643 val_loss= 1.4005 val_acc= 0.6600 time= 0.0241\n",
      "Epoch: 0065 train_loss= 1.2031 train_acc= 0.7714 val_loss= 1.3911 val_acc= 0.6600 time= 0.0184\n",
      "Epoch: 0066 train_loss= 1.1913 train_acc= 0.7714 val_loss= 1.3821 val_acc= 0.6600 time= 0.0252\n",
      "Epoch: 0067 train_loss= 1.1795 train_acc= 0.7857 val_loss= 1.3731 val_acc= 0.6633 time= 0.0207\n",
      "Epoch: 0068 train_loss= 1.1676 train_acc= 0.8000 val_loss= 1.3642 val_acc= 0.6667 time= 0.0259\n",
      "Epoch: 0069 train_loss= 1.1559 train_acc= 0.8071 val_loss= 1.3556 val_acc= 0.6800 time= 0.0233\n",
      "Epoch: 0070 train_loss= 1.1441 train_acc= 0.8143 val_loss= 1.3468 val_acc= 0.6900 time= 0.0203\n",
      "Epoch: 0071 train_loss= 1.1326 train_acc= 0.8357 val_loss= 1.3382 val_acc= 0.7033 time= 0.0235\n",
      "Epoch: 0072 train_loss= 1.1211 train_acc= 0.8357 val_loss= 1.3297 val_acc= 0.7067 time= 0.0189\n",
      "Epoch: 0073 train_loss= 1.1097 train_acc= 0.8357 val_loss= 1.3208 val_acc= 0.7200 time= 0.0197\n",
      "Epoch: 0074 train_loss= 1.0985 train_acc= 0.8429 val_loss= 1.3119 val_acc= 0.7233 time= 0.0185\n",
      "Epoch: 0075 train_loss= 1.0876 train_acc= 0.8429 val_loss= 1.3030 val_acc= 0.7233 time= 0.0230\n",
      "Epoch: 0076 train_loss= 1.0769 train_acc= 0.8429 val_loss= 1.2943 val_acc= 0.7233 time= 0.0225\n",
      "Epoch: 0077 train_loss= 1.0662 train_acc= 0.8500 val_loss= 1.2861 val_acc= 0.7300 time= 0.0239\n",
      "Epoch: 0078 train_loss= 1.0555 train_acc= 0.8500 val_loss= 1.2781 val_acc= 0.7300 time= 0.0243\n",
      "Epoch: 0079 train_loss= 1.0450 train_acc= 0.8500 val_loss= 1.2702 val_acc= 0.7300 time= 0.0278\n",
      "Epoch: 0080 train_loss= 1.0347 train_acc= 0.8500 val_loss= 1.2618 val_acc= 0.7267 time= 0.0239\n",
      "Epoch: 0081 train_loss= 1.0246 train_acc= 0.8571 val_loss= 1.2541 val_acc= 0.7300 time= 0.0274\n",
      "Epoch: 0082 train_loss= 1.0150 train_acc= 0.8571 val_loss= 1.2469 val_acc= 0.7267 time= 0.0189\n",
      "Epoch: 0083 train_loss= 1.0062 train_acc= 0.8571 val_loss= 1.2401 val_acc= 0.7267 time= 0.0228\n",
      "Epoch: 0084 train_loss= 0.9973 train_acc= 0.8643 val_loss= 1.2329 val_acc= 0.7400 time= 0.0195\n",
      "Epoch: 0085 train_loss= 0.9881 train_acc= 0.8643 val_loss= 1.2250 val_acc= 0.7367 time= 0.0231\n",
      "Epoch: 0086 train_loss= 0.9787 train_acc= 0.8643 val_loss= 1.2167 val_acc= 0.7367 time= 0.0234\n",
      "Epoch: 0087 train_loss= 0.9696 train_acc= 0.8714 val_loss= 1.2087 val_acc= 0.7400 time= 0.0242\n",
      "Epoch: 0088 train_loss= 0.9608 train_acc= 0.8786 val_loss= 1.2011 val_acc= 0.7400 time= 0.0240\n",
      "Epoch: 0089 train_loss= 0.9527 train_acc= 0.8786 val_loss= 1.1938 val_acc= 0.7400 time= 0.0275\n",
      "Epoch: 0090 train_loss= 0.9449 train_acc= 0.8786 val_loss= 1.1875 val_acc= 0.7400 time= 0.0187\n",
      "Epoch: 0091 train_loss= 0.9368 train_acc= 0.8786 val_loss= 1.1814 val_acc= 0.7467 time= 0.0274\n",
      "Epoch: 0092 train_loss= 0.9284 train_acc= 0.9000 val_loss= 1.1763 val_acc= 0.7633 time= 0.0233\n",
      "Epoch: 0093 train_loss= 0.9205 train_acc= 0.9000 val_loss= 1.1718 val_acc= 0.7667 time= 0.0291\n",
      "Epoch: 0094 train_loss= 0.9128 train_acc= 0.9000 val_loss= 1.1680 val_acc= 0.7667 time= 0.0189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0095 train_loss= 0.9056 train_acc= 0.9000 val_loss= 1.1636 val_acc= 0.7767 time= 0.0195\n",
      "Epoch: 0096 train_loss= 0.8980 train_acc= 0.9000 val_loss= 1.1580 val_acc= 0.7733 time= 0.0185\n",
      "Epoch: 0097 train_loss= 0.8899 train_acc= 0.9000 val_loss= 1.1505 val_acc= 0.7667 time= 0.0183\n",
      "Epoch: 0098 train_loss= 0.8822 train_acc= 0.9000 val_loss= 1.1426 val_acc= 0.7700 time= 0.0236\n",
      "Epoch: 0099 train_loss= 0.8750 train_acc= 0.9000 val_loss= 1.1350 val_acc= 0.7667 time= 0.0187\n",
      "Epoch: 0100 train_loss= 0.8682 train_acc= 0.9000 val_loss= 1.1283 val_acc= 0.7800 time= 0.0197\n",
      "Epoch: 0101 train_loss= 0.8615 train_acc= 0.9000 val_loss= 1.1221 val_acc= 0.7733 time= 0.0185\n",
      "Epoch: 0102 train_loss= 0.8550 train_acc= 0.9000 val_loss= 1.1165 val_acc= 0.7700 time= 0.0228\n",
      "Epoch: 0103 train_loss= 0.8483 train_acc= 0.9000 val_loss= 1.1113 val_acc= 0.7733 time= 0.0232\n",
      "Epoch: 0104 train_loss= 0.8413 train_acc= 0.9000 val_loss= 1.1069 val_acc= 0.7767 time= 0.0182\n",
      "Epoch: 0105 train_loss= 0.8343 train_acc= 0.9000 val_loss= 1.1030 val_acc= 0.7767 time= 0.0239\n",
      "Epoch: 0106 train_loss= 0.8275 train_acc= 0.9000 val_loss= 1.0991 val_acc= 0.7833 time= 0.0190\n",
      "Epoch: 0107 train_loss= 0.8209 train_acc= 0.9000 val_loss= 1.0948 val_acc= 0.7900 time= 0.0227\n",
      "Epoch: 0108 train_loss= 0.8145 train_acc= 0.9000 val_loss= 1.0905 val_acc= 0.7933 time= 0.0182\n",
      "Epoch: 0109 train_loss= 0.8081 train_acc= 0.9000 val_loss= 1.0856 val_acc= 0.7867 time= 0.0238\n",
      "Epoch: 0110 train_loss= 0.8019 train_acc= 0.9000 val_loss= 1.0801 val_acc= 0.7867 time= 0.0185\n",
      "Epoch: 0111 train_loss= 0.7957 train_acc= 0.9000 val_loss= 1.0744 val_acc= 0.7933 time= 0.0192\n",
      "Epoch: 0112 train_loss= 0.7894 train_acc= 0.9000 val_loss= 1.0679 val_acc= 0.7933 time= 0.0193\n",
      "Epoch: 0113 train_loss= 0.7834 train_acc= 0.9000 val_loss= 1.0614 val_acc= 0.7933 time= 0.0212\n",
      "Epoch: 0114 train_loss= 0.7779 train_acc= 0.9000 val_loss= 1.0556 val_acc= 0.7867 time= 0.0184\n",
      "Epoch: 0115 train_loss= 0.7729 train_acc= 0.9071 val_loss= 1.0502 val_acc= 0.7833 time= 0.0192\n",
      "Epoch: 0116 train_loss= 0.7680 train_acc= 0.9071 val_loss= 1.0454 val_acc= 0.7867 time= 0.0182\n",
      "Epoch: 0117 train_loss= 0.7626 train_acc= 0.9071 val_loss= 1.0404 val_acc= 0.7833 time= 0.0202\n",
      "Epoch: 0118 train_loss= 0.7565 train_acc= 0.9071 val_loss= 1.0356 val_acc= 0.7800 time= 0.0226\n",
      "Epoch: 0119 train_loss= 0.7503 train_acc= 0.9143 val_loss= 1.0308 val_acc= 0.7800 time= 0.0229\n",
      "Epoch: 0120 train_loss= 0.7444 train_acc= 0.9143 val_loss= 1.0262 val_acc= 0.7867 time= 0.0195\n",
      "Epoch: 0121 train_loss= 0.7390 train_acc= 0.9143 val_loss= 1.0215 val_acc= 0.7867 time= 0.0232\n",
      "Epoch: 0122 train_loss= 0.7336 train_acc= 0.9143 val_loss= 1.0172 val_acc= 0.7867 time= 0.0198\n",
      "Epoch: 0123 train_loss= 0.7284 train_acc= 0.9143 val_loss= 1.0127 val_acc= 0.7867 time= 0.0203\n",
      "Epoch: 0124 train_loss= 0.7232 train_acc= 0.9143 val_loss= 1.0084 val_acc= 0.7867 time= 0.0202\n",
      "Epoch: 0125 train_loss= 0.7180 train_acc= 0.9143 val_loss= 1.0048 val_acc= 0.7867 time= 0.0212\n",
      "Epoch: 0126 train_loss= 0.7130 train_acc= 0.9143 val_loss= 1.0019 val_acc= 0.7933 time= 0.0200\n",
      "Epoch: 0127 train_loss= 0.7085 train_acc= 0.9143 val_loss= 0.9992 val_acc= 0.7933 time= 0.0232\n",
      "Epoch: 0128 train_loss= 0.7043 train_acc= 0.9143 val_loss= 0.9967 val_acc= 0.7867 time= 0.0230\n",
      "Epoch: 0129 train_loss= 0.7002 train_acc= 0.9071 val_loss= 0.9942 val_acc= 0.7867 time= 0.0187\n",
      "Epoch: 0130 train_loss= 0.6960 train_acc= 0.9071 val_loss= 0.9909 val_acc= 0.7867 time= 0.0188\n",
      "Epoch: 0131 train_loss= 0.6915 train_acc= 0.9071 val_loss= 0.9861 val_acc= 0.7900 time= 0.0187\n",
      "Epoch: 0132 train_loss= 0.6875 train_acc= 0.9071 val_loss= 0.9821 val_acc= 0.7900 time= 0.0187\n",
      "Epoch: 0133 train_loss= 0.6839 train_acc= 0.9071 val_loss= 0.9789 val_acc= 0.7933 time= 0.0233\n",
      "Epoch: 0134 train_loss= 0.6803 train_acc= 0.9071 val_loss= 0.9752 val_acc= 0.7933 time= 0.0201\n",
      "Epoch: 0135 train_loss= 0.6761 train_acc= 0.9143 val_loss= 0.9717 val_acc= 0.7933 time= 0.0230\n",
      "Epoch: 0136 train_loss= 0.6713 train_acc= 0.9143 val_loss= 0.9681 val_acc= 0.7900 time= 0.0232\n",
      "Epoch: 0137 train_loss= 0.6667 train_acc= 0.9214 val_loss= 0.9647 val_acc= 0.7900 time= 0.0197\n",
      "Epoch: 0138 train_loss= 0.6626 train_acc= 0.9214 val_loss= 0.9615 val_acc= 0.7900 time= 0.0200\n",
      "Epoch: 0139 train_loss= 0.6589 train_acc= 0.9214 val_loss= 0.9585 val_acc= 0.7900 time= 0.0241\n",
      "Epoch: 0140 train_loss= 0.6558 train_acc= 0.9214 val_loss= 0.9560 val_acc= 0.7833 time= 0.0236\n",
      "Epoch: 0141 train_loss= 0.6528 train_acc= 0.9214 val_loss= 0.9531 val_acc= 0.7833 time= 0.0188\n",
      "Epoch: 0142 train_loss= 0.6496 train_acc= 0.9214 val_loss= 0.9506 val_acc= 0.7833 time= 0.0189\n",
      "Epoch: 0143 train_loss= 0.6458 train_acc= 0.9214 val_loss= 0.9477 val_acc= 0.7933 time= 0.0185\n",
      "Epoch: 0144 train_loss= 0.6420 train_acc= 0.9214 val_loss= 0.9448 val_acc= 0.7900 time= 0.0187\n",
      "Epoch: 0145 train_loss= 0.6383 train_acc= 0.9143 val_loss= 0.9419 val_acc= 0.7933 time= 0.0187\n",
      "Epoch: 0146 train_loss= 0.6343 train_acc= 0.9143 val_loss= 0.9386 val_acc= 0.7967 time= 0.0185\n",
      "Epoch: 0147 train_loss= 0.6304 train_acc= 0.9143 val_loss= 0.9360 val_acc= 0.7933 time= 0.0187\n",
      "Epoch: 0148 train_loss= 0.6266 train_acc= 0.9143 val_loss= 0.9338 val_acc= 0.7933 time= 0.0190\n",
      "Epoch: 0149 train_loss= 0.6233 train_acc= 0.9143 val_loss= 0.9321 val_acc= 0.7933 time= 0.0192\n",
      "Epoch: 0150 train_loss= 0.6201 train_acc= 0.9143 val_loss= 0.9307 val_acc= 0.7900 time= 0.0232\n",
      "Epoch: 0151 train_loss= 0.6172 train_acc= 0.9143 val_loss= 0.9303 val_acc= 0.7900 time= 0.0290\n",
      "Epoch: 0152 train_loss= 0.6139 train_acc= 0.9143 val_loss= 0.9293 val_acc= 0.7900 time= 0.0190\n",
      "Epoch: 0153 train_loss= 0.6106 train_acc= 0.9286 val_loss= 0.9282 val_acc= 0.7900 time= 0.0186\n",
      "Epoch: 0154 train_loss= 0.6071 train_acc= 0.9286 val_loss= 0.9253 val_acc= 0.8000 time= 0.0191\n",
      "Epoch: 0155 train_loss= 0.6036 train_acc= 0.9357 val_loss= 0.9216 val_acc= 0.8000 time= 0.0200\n",
      "Epoch: 0156 train_loss= 0.6005 train_acc= 0.9357 val_loss= 0.9185 val_acc= 0.8000 time= 0.0190\n",
      "Epoch: 0157 train_loss= 0.5976 train_acc= 0.9429 val_loss= 0.9151 val_acc= 0.8000 time= 0.0240\n",
      "Epoch: 0158 train_loss= 0.5947 train_acc= 0.9429 val_loss= 0.9115 val_acc= 0.7967 time= 0.0188\n",
      "Epoch: 0159 train_loss= 0.5921 train_acc= 0.9429 val_loss= 0.9071 val_acc= 0.7967 time= 0.0190\n",
      "Epoch: 0160 train_loss= 0.5901 train_acc= 0.9429 val_loss= 0.9039 val_acc= 0.8000 time= 0.0194\n",
      "Epoch: 0161 train_loss= 0.5877 train_acc= 0.9429 val_loss= 0.9013 val_acc= 0.8000 time= 0.0185\n",
      "Epoch: 0162 train_loss= 0.5852 train_acc= 0.9429 val_loss= 0.8987 val_acc= 0.8000 time= 0.0186\n",
      "Epoch: 0163 train_loss= 0.5827 train_acc= 0.9429 val_loss= 0.8966 val_acc= 0.7967 time= 0.0188\n",
      "Epoch: 0164 train_loss= 0.5797 train_acc= 0.9429 val_loss= 0.8945 val_acc= 0.8000 time= 0.0237\n",
      "Epoch: 0165 train_loss= 0.5763 train_acc= 0.9357 val_loss= 0.8927 val_acc= 0.8000 time= 0.0225\n",
      "Epoch: 0166 train_loss= 0.5725 train_acc= 0.9357 val_loss= 0.8923 val_acc= 0.8033 time= 0.0183\n",
      "Epoch: 0167 train_loss= 0.5697 train_acc= 0.9357 val_loss= 0.8927 val_acc= 0.8000 time= 0.0183\n",
      "Epoch: 0168 train_loss= 0.5672 train_acc= 0.9429 val_loss= 0.8918 val_acc= 0.8000 time= 0.0191\n",
      "Epoch: 0169 train_loss= 0.5648 train_acc= 0.9429 val_loss= 0.8903 val_acc= 0.8000 time= 0.0184\n",
      "Epoch: 0170 train_loss= 0.5621 train_acc= 0.9429 val_loss= 0.8878 val_acc= 0.7967 time= 0.0178\n",
      "Epoch: 0171 train_loss= 0.5594 train_acc= 0.9429 val_loss= 0.8852 val_acc= 0.7967 time= 0.0237\n",
      "Epoch: 0172 train_loss= 0.5568 train_acc= 0.9429 val_loss= 0.8817 val_acc= 0.7967 time= 0.0183\n",
      "Epoch: 0173 train_loss= 0.5542 train_acc= 0.9429 val_loss= 0.8783 val_acc= 0.7967 time= 0.0235\n",
      "Epoch: 0174 train_loss= 0.5518 train_acc= 0.9429 val_loss= 0.8746 val_acc= 0.7933 time= 0.0183\n",
      "Epoch: 0175 train_loss= 0.5496 train_acc= 0.9429 val_loss= 0.8712 val_acc= 0.8000 time= 0.0247\n",
      "Epoch: 0176 train_loss= 0.5477 train_acc= 0.9429 val_loss= 0.8686 val_acc= 0.7967 time= 0.0227\n",
      "Epoch: 0177 train_loss= 0.5451 train_acc= 0.9429 val_loss= 0.8668 val_acc= 0.7967 time= 0.0186\n",
      "Epoch: 0178 train_loss= 0.5422 train_acc= 0.9357 val_loss= 0.8658 val_acc= 0.8000 time= 0.0188\n",
      "Epoch: 0179 train_loss= 0.5403 train_acc= 0.9357 val_loss= 0.8656 val_acc= 0.8000 time= 0.0192\n",
      "Epoch: 0180 train_loss= 0.5392 train_acc= 0.9357 val_loss= 0.8664 val_acc= 0.7967 time= 0.0204\n",
      "Epoch: 0181 train_loss= 0.5374 train_acc= 0.9357 val_loss= 0.8665 val_acc= 0.7967 time= 0.0192\n",
      "Epoch: 0182 train_loss= 0.5357 train_acc= 0.9357 val_loss= 0.8676 val_acc= 0.8000 time= 0.0194\n",
      "Epoch: 0183 train_loss= 0.5339 train_acc= 0.9357 val_loss= 0.8666 val_acc= 0.7967 time= 0.0240\n",
      "Epoch: 0184 train_loss= 0.5316 train_acc= 0.9429 val_loss= 0.8644 val_acc= 0.8033 time= 0.0187\n",
      "Epoch: 0185 train_loss= 0.5292 train_acc= 0.9429 val_loss= 0.8613 val_acc= 0.7967 time= 0.0193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0186 train_loss= 0.5269 train_acc= 0.9429 val_loss= 0.8579 val_acc= 0.7967 time= 0.0237\n",
      "Epoch: 0187 train_loss= 0.5246 train_acc= 0.9500 val_loss= 0.8539 val_acc= 0.7967 time= 0.0185\n",
      "Epoch: 0188 train_loss= 0.5225 train_acc= 0.9500 val_loss= 0.8495 val_acc= 0.7967 time= 0.0193\n",
      "Epoch: 0189 train_loss= 0.5208 train_acc= 0.9500 val_loss= 0.8459 val_acc= 0.7900 time= 0.0187\n",
      "Epoch: 0190 train_loss= 0.5191 train_acc= 0.9500 val_loss= 0.8435 val_acc= 0.7933 time= 0.0228\n",
      "Epoch: 0191 train_loss= 0.5173 train_acc= 0.9500 val_loss= 0.8416 val_acc= 0.7933 time= 0.0187\n",
      "Epoch: 0192 train_loss= 0.5150 train_acc= 0.9500 val_loss= 0.8406 val_acc= 0.8000 time= 0.0231\n",
      "Epoch: 0193 train_loss= 0.5120 train_acc= 0.9500 val_loss= 0.8402 val_acc= 0.8033 time= 0.0184\n",
      "Epoch: 0194 train_loss= 0.5085 train_acc= 0.9500 val_loss= 0.8406 val_acc= 0.8000 time= 0.0190\n",
      "Epoch: 0195 train_loss= 0.5056 train_acc= 0.9500 val_loss= 0.8412 val_acc= 0.8100 time= 0.0253\n",
      "Epoch: 0196 train_loss= 0.5038 train_acc= 0.9500 val_loss= 0.8425 val_acc= 0.8133 time= 0.0208\n",
      "Epoch: 0197 train_loss= 0.5018 train_acc= 0.9500 val_loss= 0.8410 val_acc= 0.8133 time= 0.0193\n",
      "Epoch: 0198 train_loss= 0.4997 train_acc= 0.9500 val_loss= 0.8385 val_acc= 0.8100 time= 0.0234\n",
      "Epoch: 0199 train_loss= 0.4976 train_acc= 0.9500 val_loss= 0.8353 val_acc= 0.8000 time= 0.0195\n",
      "Epoch: 0200 train_loss= 0.4961 train_acc= 0.9500 val_loss= 0.8318 val_acc= 0.8000 time= 0.0238\n"
     ]
    }
   ],
   "source": [
    "NB_EPOCH = 200\n",
    "PATIENCE = 10  # early stopping patience\n",
    "# Helper variables for main training loop\n",
    "wait = 0\n",
    "preds = None\n",
    "best_val_loss = 99999\n",
    "\n",
    "# Fit\n",
    "for epoch in range(1, NB_EPOCH+1):\n",
    "\n",
    "    # Log wall-clock time\n",
    "    t = time.time()\n",
    "\n",
    "    # Single training iteration (we mask nodes without labels for loss calculation)\n",
    "    model.fit(graph, y_train, sample_weight=train_mask,\n",
    "              batch_size=A.shape[0], epochs=1, shuffle=False, verbose=0)\n",
    "\n",
    "    # Predict on full dataset\n",
    "    preds = model.predict(graph, batch_size=A.shape[0])\n",
    "\n",
    "    # Train / validation scores\n",
    "    train_val_loss, train_val_acc = evaluate_preds(preds, [y_train, y_val],\n",
    "                                                   [idx_train, idx_val])\n",
    "    print(\"Epoch: {:04d}\".format(epoch),\n",
    "          \"train_loss= {:.4f}\".format(train_val_loss[0]),\n",
    "          \"train_acc= {:.4f}\".format(train_val_acc[0]),\n",
    "          \"val_loss= {:.4f}\".format(train_val_loss[1]),\n",
    "          \"val_acc= {:.4f}\".format(train_val_acc[1]),\n",
    "          \"time= {:.4f}\".format(time.time() - t))\n",
    "\n",
    "    # Early stopping\n",
    "    if train_val_loss[1] < best_val_loss:\n",
    "        best_val_loss = train_val_loss[1]\n",
    "        wait = 0\n",
    "    else:\n",
    "        if wait >= PATIENCE:\n",
    "            print('Epoch {}: early stopping'.format(epoch))\n",
    "            break\n",
    "        wait += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.9019\n",
      "accuracy = 0.7860\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate_preds(preds, [y_test], [idx_test])\n",
    "print(f\"\"\"\n",
    "loss = {test_loss[0]:.4f}\n",
    "accuracy = {test_acc[0]:.4f}\n",
    "\"\"\".strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
