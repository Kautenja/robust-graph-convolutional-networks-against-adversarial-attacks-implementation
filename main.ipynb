{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from keras.layers import Input, Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the path of execution\n",
    "EXE_PATH = os.path.abspath(os.path.curdir)\n",
    "# the path of the vendor files\n",
    "VENDOR_PATH = os.path.join(EXE_PATH, 'vendor')\n",
    "# the vendors to include in the system path\n",
    "VENDORS = ['keras-gcn']\n",
    "# create the absolute paths for all vendors\n",
    "VENDORS = list(map(lambda x: os.path.join(VENDOR_PATH, x), VENDORS))\n",
    "# update the Python path to include necessary vendor module\n",
    "sys.path += VENDORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kegra.layers.graph import GraphConvolution\n",
    "from kegra.utils import load_data, preprocess_adj, get_splits, evaluate_preds\n",
    "from ggcn import GaussianGraphConvolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cora dataset...\n",
      "Dataset has 2708 nodes, 5429 edges, 1433 features.\n"
     ]
    }
   ],
   "source": [
    "X, A, y = load_data('data/cora/', dataset='cora')\n",
    "X /= X.sum(1).reshape(-1, 1)\n",
    "A = preprocess_adj(A)\n",
    "y_train, y_val, y_test, idx_train, idx_val, idx_test, train_mask = get_splits(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2708x2708 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 13264 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 1, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 1, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 0]], dtype=int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1110 16:40:59.504956 140115358799680 deprecation_wrapper.py:119] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1110 16:40:59.511889 140115358799680 deprecation_wrapper.py:119] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:515: The name tf.sparse_placeholder is deprecated. Please use tf.compat.v1.sparse_placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "support = 1\n",
    "graph = [X, A]\n",
    "G = [Input(shape=(None, None), batch_shape=(None, None), sparse=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1110 16:40:59.516489 140115358799680 deprecation_wrapper.py:119] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_in = Input(shape=(X.shape[1],))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCN (baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1110 16:40:59.522803 140115358799680 deprecation_wrapper.py:119] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W1110 16:40:59.527221 140115358799680 deprecation.py:506] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W1110 16:40:59.535525 140115358799680 deprecation_wrapper.py:119] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define model architecture\n",
    "# NOTE: We pass arguments for graph convolutional layers as a list of tensors.\n",
    "# This is somewhat hacky, more elegant options would require rewriting the Layer base class.\n",
    "H = Dropout(0.5)(X_in)\n",
    "H = GraphConvolution(16, support, activation='relu', kernel_regularizer=l2(5e-4))([H]+G)\n",
    "H = Dropout(0.5)(H)\n",
    "Y = GraphConvolution(y.shape[1], support, activation='softmax')([H]+G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1110 16:40:59.576791 140115358799680 deprecation_wrapper.py:119] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=[X_in]+G, outputs=Y)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# NB_EPOCH = 200\n",
    "# PATIENCE = 10  # early stopping patience\n",
    "# # Helper variables for main training loop\n",
    "# wait = 0\n",
    "# preds = None\n",
    "# best_val_loss = 99999\n",
    "\n",
    "# # Fit\n",
    "# for epoch in range(1, NB_EPOCH+1):\n",
    "\n",
    "#     # Log wall-clock time\n",
    "#     t = time.time()\n",
    "\n",
    "#     # Single training iteration (we mask nodes without labels for loss calculation)\n",
    "#     model.fit(graph, y_train, sample_weight=train_mask,\n",
    "#               batch_size=A.shape[0], epochs=1, shuffle=False, verbose=0)\n",
    "\n",
    "#     # Predict on full dataset\n",
    "#     preds = model.predict(graph, batch_size=A.shape[0])\n",
    "\n",
    "#     # Train / validation scores\n",
    "#     train_val_loss, train_val_acc = evaluate_preds(preds, [y_train, y_val],\n",
    "#                                                    [idx_train, idx_val])\n",
    "#     print(\"Epoch: {:04d}\".format(epoch),\n",
    "#           \"train_loss= {:.4f}\".format(train_val_loss[0]),\n",
    "#           \"train_acc= {:.4f}\".format(train_val_acc[0]),\n",
    "#           \"val_loss= {:.4f}\".format(train_val_loss[1]),\n",
    "#           \"val_acc= {:.4f}\".format(train_val_acc[1]),\n",
    "#           \"time= {:.4f}\".format(time.time() - t))\n",
    "\n",
    "#     # Early stopping\n",
    "#     if train_val_loss[1] < best_val_loss:\n",
    "#         best_val_loss = train_val_loss[1]\n",
    "#         wait = 0\n",
    "#     else:\n",
    "#         if wait >= PATIENCE:\n",
    "#             print('Epoch {}: early stopping'.format(epoch))\n",
    "#             break\n",
    "#         wait += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_loss, test_acc = evaluate_preds(preds, [y_test], [idx_test])\n",
    "# print(f\"\"\"\n",
    "# loss = {test_loss[0]:.4f}\n",
    "# accuracy = {test_acc[0]:.4f}\n",
    "# \"\"\".strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Graph Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1110 16:40:59.633147 140115358799680 deprecation.py:323] From /home/bitcommander/Desktop/robust-graph-convolutional-networks-against-adversarial-attacks-implementation/ggcn/ggcl.py:160: Normal.__init__ (from tensorflow.python.ops.distributions.normal) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
      "W1110 16:40:59.634472 140115358799680 deprecation.py:323] From /home/bitcommander/.local/lib/python3.7/site-packages/tensorflow/python/ops/distributions/normal.py:160: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n"
     ]
    }
   ],
   "source": [
    "H = Dropout(0.5)(X_in)\n",
    "H = GaussianGraphConvolution(16, A.shape[0], \n",
    "    is_first=True, \n",
    "    activation='relu', \n",
    "    kernel_regularizer=l2(5e-4)\n",
    ")([H]+G)\n",
    "Y = GaussianGraphConvolution(y.shape[1], A.shape[0], \n",
    "    is_last=True,\n",
    "    activation='softmax')(H+G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[X_in]+G, outputs=Y)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1110 16:40:59.719927 140115358799680 deprecation.py:323] From /home/bitcommander/.local/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 train_loss= 1.9411 train_acc= 0.2857 val_loss= 1.9415 val_acc= 0.2333 time= 1.0831\n",
      "Epoch: 0002 train_loss= 1.9382 train_acc= 0.2429 val_loss= 1.9357 val_acc= 0.3200 time= 0.0190\n",
      "Epoch: 0003 train_loss= 1.9306 train_acc= 0.3500 val_loss= 1.9323 val_acc= 0.3000 time= 0.0234\n",
      "Epoch: 0004 train_loss= 1.9222 train_acc= 0.3857 val_loss= 1.9236 val_acc= 0.3500 time= 0.0188\n",
      "Epoch: 0005 train_loss= 1.9083 train_acc= 0.5000 val_loss= 1.9159 val_acc= 0.3733 time= 0.0190\n",
      "Epoch: 0006 train_loss= 1.9019 train_acc= 0.4643 val_loss= 1.9080 val_acc= 0.4133 time= 0.0184\n",
      "Epoch: 0007 train_loss= 1.8901 train_acc= 0.4786 val_loss= 1.8988 val_acc= 0.4467 time= 0.0184\n",
      "Epoch: 0008 train_loss= 1.8781 train_acc= 0.5571 val_loss= 1.8912 val_acc= 0.4533 time= 0.0187\n",
      "Epoch: 0009 train_loss= 1.8656 train_acc= 0.6000 val_loss= 1.8801 val_acc= 0.4733 time= 0.0235\n",
      "Epoch: 0010 train_loss= 1.8505 train_acc= 0.6357 val_loss= 1.8697 val_acc= 0.5100 time= 0.0236\n",
      "Epoch: 0011 train_loss= 1.8360 train_acc= 0.6357 val_loss= 1.8579 val_acc= 0.5333 time= 0.0188\n",
      "Epoch: 0012 train_loss= 1.8210 train_acc= 0.6429 val_loss= 1.8464 val_acc= 0.5300 time= 0.0192\n",
      "Epoch: 0013 train_loss= 1.8062 train_acc= 0.6643 val_loss= 1.8353 val_acc= 0.5100 time= 0.0240\n",
      "Epoch: 0014 train_loss= 1.7910 train_acc= 0.6714 val_loss= 1.8225 val_acc= 0.5433 time= 0.0248\n",
      "Epoch: 0015 train_loss= 1.7732 train_acc= 0.7000 val_loss= 1.8102 val_acc= 0.5333 time= 0.0228\n",
      "Epoch: 0016 train_loss= 1.7574 train_acc= 0.6929 val_loss= 1.7970 val_acc= 0.5500 time= 0.0185\n",
      "Epoch: 0017 train_loss= 1.7374 train_acc= 0.6857 val_loss= 1.7829 val_acc= 0.5633 time= 0.0197\n",
      "Epoch: 0018 train_loss= 1.7186 train_acc= 0.7000 val_loss= 1.7676 val_acc= 0.5633 time= 0.0197\n",
      "Epoch: 0019 train_loss= 1.6965 train_acc= 0.7071 val_loss= 1.7531 val_acc= 0.5700 time= 0.0188\n",
      "Epoch: 0020 train_loss= 1.6785 train_acc= 0.7143 val_loss= 1.7372 val_acc= 0.5767 time= 0.0191\n",
      "Epoch: 0021 train_loss= 1.6561 train_acc= 0.7286 val_loss= 1.7215 val_acc= 0.5867 time= 0.0193\n",
      "Epoch: 0022 train_loss= 1.6359 train_acc= 0.7214 val_loss= 1.7053 val_acc= 0.5967 time= 0.0190\n",
      "Epoch: 0023 train_loss= 1.6138 train_acc= 0.7357 val_loss= 1.6884 val_acc= 0.5933 time= 0.0280\n",
      "Epoch: 0024 train_loss= 1.5920 train_acc= 0.7500 val_loss= 1.6719 val_acc= 0.6033 time= 0.0244\n",
      "Epoch: 0025 train_loss= 1.5657 train_acc= 0.7571 val_loss= 1.6546 val_acc= 0.6100 time= 0.0192\n",
      "Epoch: 0026 train_loss= 1.5450 train_acc= 0.7643 val_loss= 1.6370 val_acc= 0.6167 time= 0.0232\n",
      "Epoch: 0027 train_loss= 1.5203 train_acc= 0.7643 val_loss= 1.6195 val_acc= 0.6233 time= 0.0234\n",
      "Epoch: 0028 train_loss= 1.4937 train_acc= 0.7714 val_loss= 1.6008 val_acc= 0.6267 time= 0.0197\n",
      "Epoch: 0029 train_loss= 1.4709 train_acc= 0.7714 val_loss= 1.5831 val_acc= 0.6533 time= 0.0240\n",
      "Epoch: 0030 train_loss= 1.4423 train_acc= 0.7786 val_loss= 1.5640 val_acc= 0.6667 time= 0.0188\n",
      "Epoch: 0031 train_loss= 1.4185 train_acc= 0.8000 val_loss= 1.5442 val_acc= 0.6833 time= 0.0193\n",
      "Epoch: 0032 train_loss= 1.3923 train_acc= 0.8071 val_loss= 1.5252 val_acc= 0.6867 time= 0.0236\n",
      "Epoch: 0033 train_loss= 1.3647 train_acc= 0.8071 val_loss= 1.5055 val_acc= 0.6967 time= 0.0197\n",
      "Epoch: 0034 train_loss= 1.3379 train_acc= 0.8071 val_loss= 1.4863 val_acc= 0.7067 time= 0.0247\n",
      "Epoch: 0035 train_loss= 1.3106 train_acc= 0.8071 val_loss= 1.4663 val_acc= 0.7033 time= 0.0247\n",
      "Epoch: 0036 train_loss= 1.2833 train_acc= 0.8143 val_loss= 1.4469 val_acc= 0.7133 time= 0.0192\n",
      "Epoch: 0037 train_loss= 1.2558 train_acc= 0.8143 val_loss= 1.4258 val_acc= 0.7167 time= 0.0187\n",
      "Epoch: 0038 train_loss= 1.2291 train_acc= 0.8143 val_loss= 1.4057 val_acc= 0.7267 time= 0.0192\n",
      "Epoch: 0039 train_loss= 1.2003 train_acc= 0.8214 val_loss= 1.3857 val_acc= 0.7233 time= 0.0214\n",
      "Epoch: 0040 train_loss= 1.1739 train_acc= 0.8214 val_loss= 1.3650 val_acc= 0.7233 time= 0.0194\n",
      "Epoch: 0041 train_loss= 1.1465 train_acc= 0.8214 val_loss= 1.3451 val_acc= 0.7267 time= 0.0208\n",
      "Epoch: 0042 train_loss= 1.1178 train_acc= 0.8214 val_loss= 1.3248 val_acc= 0.7267 time= 0.0185\n",
      "Epoch: 0043 train_loss= 1.0921 train_acc= 0.8429 val_loss= 1.3049 val_acc= 0.7333 time= 0.0195\n",
      "Epoch: 0044 train_loss= 1.0651 train_acc= 0.8429 val_loss= 1.2849 val_acc= 0.7333 time= 0.0239\n",
      "Epoch: 0045 train_loss= 1.0378 train_acc= 0.8429 val_loss= 1.2650 val_acc= 0.7333 time= 0.0192\n",
      "Epoch: 0046 train_loss= 1.0119 train_acc= 0.8500 val_loss= 1.2458 val_acc= 0.7367 time= 0.0239\n",
      "Epoch: 0047 train_loss= 0.9847 train_acc= 0.8500 val_loss= 1.2268 val_acc= 0.7433 time= 0.0243\n",
      "Epoch: 0048 train_loss= 0.9598 train_acc= 0.8571 val_loss= 1.2072 val_acc= 0.7433 time= 0.0205\n",
      "Epoch: 0049 train_loss= 0.9343 train_acc= 0.8571 val_loss= 1.1880 val_acc= 0.7500 time= 0.0183\n",
      "Epoch: 0050 train_loss= 0.9089 train_acc= 0.8714 val_loss= 1.1700 val_acc= 0.7533 time= 0.0201\n",
      "Epoch: 0051 train_loss= 0.8849 train_acc= 0.8714 val_loss= 1.1517 val_acc= 0.7567 time= 0.0196\n",
      "Epoch: 0052 train_loss= 0.8610 train_acc= 0.8714 val_loss= 1.1341 val_acc= 0.7567 time= 0.0185\n",
      "Epoch: 0053 train_loss= 0.8370 train_acc= 0.8714 val_loss= 1.1160 val_acc= 0.7533 time= 0.0184\n",
      "Epoch: 0054 train_loss= 0.8134 train_acc= 0.8786 val_loss= 1.0988 val_acc= 0.7567 time= 0.0185\n",
      "Epoch: 0055 train_loss= 0.7910 train_acc= 0.8857 val_loss= 1.0819 val_acc= 0.7633 time= 0.0190\n",
      "Epoch: 0056 train_loss= 0.7682 train_acc= 0.9000 val_loss= 1.0656 val_acc= 0.7733 time= 0.0202\n",
      "Epoch: 0057 train_loss= 0.7477 train_acc= 0.9000 val_loss= 1.0496 val_acc= 0.7733 time= 0.0184\n",
      "Epoch: 0058 train_loss= 0.7246 train_acc= 0.9000 val_loss= 1.0337 val_acc= 0.7700 time= 0.0192\n",
      "Epoch: 0059 train_loss= 0.7056 train_acc= 0.9000 val_loss= 1.0185 val_acc= 0.7733 time= 0.0198\n",
      "Epoch: 0060 train_loss= 0.6849 train_acc= 0.9071 val_loss= 1.0037 val_acc= 0.7733 time= 0.0213\n",
      "Epoch: 0061 train_loss= 0.6653 train_acc= 0.9143 val_loss= 0.9894 val_acc= 0.7800 time= 0.0251\n",
      "Epoch: 0062 train_loss= 0.6457 train_acc= 0.9071 val_loss= 0.9757 val_acc= 0.7800 time= 0.0242\n",
      "Epoch: 0063 train_loss= 0.6269 train_acc= 0.9286 val_loss= 0.9620 val_acc= 0.7833 time= 0.0197\n",
      "Epoch: 0064 train_loss= 0.6096 train_acc= 0.9214 val_loss= 0.9479 val_acc= 0.7833 time= 0.0201\n",
      "Epoch: 0065 train_loss= 0.5919 train_acc= 0.9286 val_loss= 0.9351 val_acc= 0.7833 time= 0.0213\n",
      "Epoch: 0066 train_loss= 0.5754 train_acc= 0.9286 val_loss= 0.9226 val_acc= 0.7767 time= 0.0209\n",
      "Epoch: 0067 train_loss= 0.5584 train_acc= 0.9286 val_loss= 0.9105 val_acc= 0.7767 time= 0.0251\n",
      "Epoch: 0068 train_loss= 0.5418 train_acc= 0.9286 val_loss= 0.8981 val_acc= 0.7733 time= 0.0199\n",
      "Epoch: 0069 train_loss= 0.5270 train_acc= 0.9286 val_loss= 0.8864 val_acc= 0.7733 time= 0.0236\n",
      "Epoch: 0070 train_loss= 0.5116 train_acc= 0.9357 val_loss= 0.8752 val_acc= 0.7733 time= 0.0197\n",
      "Epoch: 0071 train_loss= 0.4967 train_acc= 0.9429 val_loss= 0.8642 val_acc= 0.7733 time= 0.0239\n",
      "Epoch: 0072 train_loss= 0.4819 train_acc= 0.9429 val_loss= 0.8538 val_acc= 0.7767 time= 0.0191\n",
      "Epoch: 0073 train_loss= 0.4676 train_acc= 0.9500 val_loss= 0.8429 val_acc= 0.7767 time= 0.0183\n",
      "Epoch: 0074 train_loss= 0.4544 train_acc= 0.9500 val_loss= 0.8325 val_acc= 0.7767 time= 0.0182\n",
      "Epoch: 0075 train_loss= 0.4407 train_acc= 0.9500 val_loss= 0.8228 val_acc= 0.7800 time= 0.0187\n",
      "Epoch: 0076 train_loss= 0.4280 train_acc= 0.9500 val_loss= 0.8133 val_acc= 0.7800 time= 0.0231\n",
      "Epoch: 0077 train_loss= 0.4164 train_acc= 0.9500 val_loss= 0.8040 val_acc= 0.7800 time= 0.0191\n",
      "Epoch: 0078 train_loss= 0.4045 train_acc= 0.9571 val_loss= 0.7954 val_acc= 0.7867 time= 0.0228\n",
      "Epoch: 0079 train_loss= 0.3925 train_acc= 0.9500 val_loss= 0.7868 val_acc= 0.7867 time= 0.0184\n",
      "Epoch: 0080 train_loss= 0.3809 train_acc= 0.9571 val_loss= 0.7782 val_acc= 0.7900 time= 0.0229\n",
      "Epoch: 0081 train_loss= 0.3707 train_acc= 0.9571 val_loss= 0.7701 val_acc= 0.7900 time= 0.0184\n",
      "Epoch: 0082 train_loss= 0.3589 train_acc= 0.9714 val_loss= 0.7620 val_acc= 0.7933 time= 0.0238\n",
      "Epoch: 0083 train_loss= 0.3488 train_acc= 0.9714 val_loss= 0.7543 val_acc= 0.7967 time= 0.0181\n",
      "Epoch: 0084 train_loss= 0.3384 train_acc= 0.9714 val_loss= 0.7474 val_acc= 0.7967 time= 0.0187\n",
      "Epoch: 0085 train_loss= 0.3285 train_acc= 0.9714 val_loss= 0.7393 val_acc= 0.8000 time= 0.0184\n",
      "Epoch: 0086 train_loss= 0.3204 train_acc= 0.9714 val_loss= 0.7329 val_acc= 0.8000 time= 0.0277\n",
      "Epoch: 0087 train_loss= 0.3106 train_acc= 0.9714 val_loss= 0.7266 val_acc= 0.7967 time= 0.0182\n",
      "Epoch: 0088 train_loss= 0.3018 train_acc= 0.9786 val_loss= 0.7194 val_acc= 0.7967 time= 0.0189\n",
      "Epoch: 0089 train_loss= 0.2928 train_acc= 0.9786 val_loss= 0.7133 val_acc= 0.7967 time= 0.0182\n",
      "Epoch: 0090 train_loss= 0.2847 train_acc= 0.9786 val_loss= 0.7075 val_acc= 0.8033 time= 0.0227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0091 train_loss= 0.2762 train_acc= 0.9786 val_loss= 0.7020 val_acc= 0.8033 time= 0.0183\n",
      "Epoch: 0092 train_loss= 0.2689 train_acc= 0.9786 val_loss= 0.6967 val_acc= 0.8067 time= 0.0208\n",
      "Epoch: 0093 train_loss= 0.2615 train_acc= 0.9786 val_loss= 0.6910 val_acc= 0.8100 time= 0.0237\n",
      "Epoch: 0094 train_loss= 0.2544 train_acc= 0.9786 val_loss= 0.6860 val_acc= 0.8100 time= 0.0180\n",
      "Epoch: 0095 train_loss= 0.2471 train_acc= 0.9786 val_loss= 0.6811 val_acc= 0.8100 time= 0.0186\n",
      "Epoch: 0096 train_loss= 0.2407 train_acc= 0.9786 val_loss= 0.6761 val_acc= 0.8100 time= 0.0229\n",
      "Epoch: 0097 train_loss= 0.2343 train_acc= 0.9786 val_loss= 0.6718 val_acc= 0.8100 time= 0.0189\n",
      "Epoch: 0098 train_loss= 0.2276 train_acc= 0.9786 val_loss= 0.6681 val_acc= 0.8133 time= 0.0228\n",
      "Epoch: 0099 train_loss= 0.2215 train_acc= 0.9786 val_loss= 0.6642 val_acc= 0.8167 time= 0.0185\n",
      "Epoch: 0100 train_loss= 0.2158 train_acc= 0.9786 val_loss= 0.6605 val_acc= 0.8200 time= 0.0186\n",
      "Epoch: 0101 train_loss= 0.2095 train_acc= 0.9786 val_loss= 0.6575 val_acc= 0.8233 time= 0.0185\n",
      "Epoch: 0102 train_loss= 0.2042 train_acc= 0.9786 val_loss= 0.6547 val_acc= 0.8233 time= 0.0216\n",
      "Epoch: 0103 train_loss= 0.1986 train_acc= 0.9786 val_loss= 0.6510 val_acc= 0.8233 time= 0.0210\n",
      "Epoch: 0104 train_loss= 0.1935 train_acc= 0.9786 val_loss= 0.6478 val_acc= 0.8233 time= 0.0190\n",
      "Epoch: 0105 train_loss= 0.1882 train_acc= 0.9857 val_loss= 0.6445 val_acc= 0.8233 time= 0.0185\n",
      "Epoch: 0106 train_loss= 0.1836 train_acc= 0.9857 val_loss= 0.6426 val_acc= 0.8300 time= 0.0199\n",
      "Epoch: 0107 train_loss= 0.1787 train_acc= 0.9857 val_loss= 0.6396 val_acc= 0.8333 time= 0.0193\n",
      "Epoch: 0108 train_loss= 0.1744 train_acc= 0.9857 val_loss= 0.6375 val_acc= 0.8300 time= 0.0196\n",
      "Epoch: 0109 train_loss= 0.1698 train_acc= 0.9857 val_loss= 0.6358 val_acc= 0.8300 time= 0.0194\n",
      "Epoch: 0110 train_loss= 0.1652 train_acc= 0.9857 val_loss= 0.6323 val_acc= 0.8300 time= 0.0196\n",
      "Epoch: 0111 train_loss= 0.1616 train_acc= 0.9857 val_loss= 0.6303 val_acc= 0.8300 time= 0.0184\n",
      "Epoch: 0112 train_loss= 0.1573 train_acc= 0.9857 val_loss= 0.6284 val_acc= 0.8233 time= 0.0201\n",
      "Epoch: 0113 train_loss= 0.1538 train_acc= 0.9857 val_loss= 0.6258 val_acc= 0.8300 time= 0.0204\n",
      "Epoch: 0114 train_loss= 0.1496 train_acc= 0.9857 val_loss= 0.6249 val_acc= 0.8233 time= 0.0229\n",
      "Epoch: 0115 train_loss= 0.1462 train_acc= 0.9857 val_loss= 0.6223 val_acc= 0.8233 time= 0.0206\n",
      "Epoch: 0116 train_loss= 0.1430 train_acc= 0.9857 val_loss= 0.6206 val_acc= 0.8233 time= 0.0242\n",
      "Epoch: 0117 train_loss= 0.1395 train_acc= 0.9857 val_loss= 0.6180 val_acc= 0.8200 time= 0.0189\n",
      "Epoch: 0118 train_loss= 0.1358 train_acc= 0.9857 val_loss= 0.6162 val_acc= 0.8200 time= 0.0252\n",
      "Epoch: 0119 train_loss= 0.1329 train_acc= 0.9857 val_loss= 0.6154 val_acc= 0.8200 time= 0.0249\n",
      "Epoch: 0120 train_loss= 0.1300 train_acc= 0.9857 val_loss= 0.6138 val_acc= 0.8233 time= 0.0188\n",
      "Epoch: 0121 train_loss= 0.1265 train_acc= 0.9857 val_loss= 0.6129 val_acc= 0.8233 time= 0.0184\n",
      "Epoch: 0122 train_loss= 0.1242 train_acc= 0.9857 val_loss= 0.6122 val_acc= 0.8233 time= 0.0190\n",
      "Epoch: 0123 train_loss= 0.1211 train_acc= 0.9857 val_loss= 0.6105 val_acc= 0.8233 time= 0.0190\n",
      "Epoch: 0124 train_loss= 0.1190 train_acc= 0.9929 val_loss= 0.6096 val_acc= 0.8233 time= 0.0187\n",
      "Epoch: 0125 train_loss= 0.1163 train_acc= 0.9929 val_loss= 0.6100 val_acc= 0.8233 time= 0.0198\n",
      "Epoch: 0126 train_loss= 0.1131 train_acc= 0.9929 val_loss= 0.6086 val_acc= 0.8233 time= 0.0186\n",
      "Epoch: 0127 train_loss= 0.1108 train_acc= 0.9929 val_loss= 0.6079 val_acc= 0.8233 time= 0.0191\n",
      "Epoch: 0128 train_loss= 0.1082 train_acc= 0.9929 val_loss= 0.6072 val_acc= 0.8233 time= 0.0187\n",
      "Epoch: 0129 train_loss= 0.1068 train_acc= 0.9929 val_loss= 0.6068 val_acc= 0.8233 time= 0.0198\n",
      "Epoch: 0130 train_loss= 0.1042 train_acc= 0.9929 val_loss= 0.6057 val_acc= 0.8233 time= 0.0194\n",
      "Epoch: 0131 train_loss= 0.1012 train_acc= 0.9929 val_loss= 0.6050 val_acc= 0.8233 time= 0.0189\n",
      "Epoch: 0132 train_loss= 0.1001 train_acc= 0.9929 val_loss= 0.6033 val_acc= 0.8233 time= 0.0193\n",
      "Epoch: 0133 train_loss= 0.0976 train_acc= 0.9929 val_loss= 0.6028 val_acc= 0.8233 time= 0.0191\n",
      "Epoch: 0134 train_loss= 0.0962 train_acc= 0.9929 val_loss= 0.6030 val_acc= 0.8233 time= 0.0186\n",
      "Epoch: 0135 train_loss= 0.0933 train_acc= 0.9929 val_loss= 0.6018 val_acc= 0.8233 time= 0.0190\n",
      "Epoch: 0136 train_loss= 0.0921 train_acc= 0.9929 val_loss= 0.6021 val_acc= 0.8233 time= 0.0198\n",
      "Epoch: 0137 train_loss= 0.0900 train_acc= 0.9929 val_loss= 0.6007 val_acc= 0.8233 time= 0.0195\n",
      "Epoch: 0138 train_loss= 0.0881 train_acc= 0.9929 val_loss= 0.5987 val_acc= 0.8233 time= 0.0196\n",
      "Epoch: 0139 train_loss= 0.0868 train_acc= 0.9929 val_loss= 0.5987 val_acc= 0.8200 time= 0.0237\n",
      "Epoch: 0140 train_loss= 0.0855 train_acc= 0.9929 val_loss= 0.5976 val_acc= 0.8300 time= 0.0228\n",
      "Epoch: 0141 train_loss= 0.0834 train_acc= 0.9929 val_loss= 0.5978 val_acc= 0.8233 time= 0.0197\n",
      "Epoch: 0142 train_loss= 0.0818 train_acc= 0.9929 val_loss= 0.5975 val_acc= 0.8233 time= 0.0197\n",
      "Epoch: 0143 train_loss= 0.0805 train_acc= 0.9929 val_loss= 0.5958 val_acc= 0.8233 time= 0.0184\n",
      "Epoch: 0144 train_loss= 0.0782 train_acc= 0.9929 val_loss= 0.5938 val_acc= 0.8267 time= 0.0197\n",
      "Epoch: 0145 train_loss= 0.0767 train_acc= 0.9929 val_loss= 0.5948 val_acc= 0.8233 time= 0.0223\n",
      "Epoch: 0146 train_loss= 0.0757 train_acc= 0.9929 val_loss= 0.5956 val_acc= 0.8267 time= 0.0214\n",
      "Epoch: 0147 train_loss= 0.0741 train_acc= 0.9929 val_loss= 0.5941 val_acc= 0.8267 time= 0.0202\n",
      "Epoch: 0148 train_loss= 0.0728 train_acc= 0.9929 val_loss= 0.5940 val_acc= 0.8267 time= 0.0232\n",
      "Epoch: 0149 train_loss= 0.0723 train_acc= 0.9929 val_loss= 0.5939 val_acc= 0.8233 time= 0.0202\n",
      "Epoch: 0150 train_loss= 0.0703 train_acc= 0.9929 val_loss= 0.5937 val_acc= 0.8233 time= 0.0248\n",
      "Epoch: 0151 train_loss= 0.0688 train_acc= 0.9929 val_loss= 0.5939 val_acc= 0.8233 time= 0.0206\n",
      "Epoch: 0152 train_loss= 0.0679 train_acc= 0.9929 val_loss= 0.5942 val_acc= 0.8233 time= 0.0194\n",
      "Epoch: 0153 train_loss= 0.0672 train_acc= 0.9929 val_loss= 0.5927 val_acc= 0.8233 time= 0.0203\n",
      "Epoch: 0154 train_loss= 0.0653 train_acc= 0.9929 val_loss= 0.5940 val_acc= 0.8233 time= 0.0192\n",
      "Epoch: 0155 train_loss= 0.0644 train_acc= 0.9929 val_loss= 0.5933 val_acc= 0.8233 time= 0.0193\n",
      "Epoch: 0156 train_loss= 0.0631 train_acc= 0.9929 val_loss= 0.5948 val_acc= 0.8267 time= 0.0241\n",
      "Epoch: 0157 train_loss= 0.0623 train_acc= 0.9929 val_loss= 0.5938 val_acc= 0.8233 time= 0.0230\n",
      "Epoch: 0158 train_loss= 0.0614 train_acc= 0.9929 val_loss= 0.5933 val_acc= 0.8233 time= 0.0248\n",
      "Epoch: 0159 train_loss= 0.0598 train_acc= 0.9929 val_loss= 0.5956 val_acc= 0.8233 time= 0.0234\n",
      "Epoch: 0160 train_loss= 0.0594 train_acc= 0.9929 val_loss= 0.5939 val_acc= 0.8233 time= 0.0192\n",
      "Epoch: 0161 train_loss= 0.0581 train_acc= 0.9929 val_loss= 0.5949 val_acc= 0.8233 time= 0.0195\n",
      "Epoch: 0162 train_loss= 0.0572 train_acc= 0.9929 val_loss= 0.5952 val_acc= 0.8267 time= 0.0186\n",
      "Epoch: 0163 train_loss= 0.0562 train_acc= 0.9929 val_loss= 0.5937 val_acc= 0.8233 time= 0.0219\n",
      "Epoch: 0164 train_loss= 0.0549 train_acc= 0.9929 val_loss= 0.5954 val_acc= 0.8267 time= 0.0209\n",
      "Epoch 164: early stopping\n"
     ]
    }
   ],
   "source": [
    "NB_EPOCH = 200\n",
    "PATIENCE = 10  # early stopping patience\n",
    "# Helper variables for main training loop\n",
    "wait = 0\n",
    "preds = None\n",
    "best_val_loss = 99999\n",
    "\n",
    "# Fit\n",
    "for epoch in range(1, NB_EPOCH+1):\n",
    "\n",
    "    # Log wall-clock time\n",
    "    t = time.time()\n",
    "\n",
    "    # Single training iteration (we mask nodes without labels for loss calculation)\n",
    "    model.fit(graph, y_train, sample_weight=train_mask,\n",
    "              batch_size=A.shape[0], epochs=1, shuffle=False, verbose=0)\n",
    "\n",
    "    # Predict on full dataset\n",
    "    preds = model.predict(graph, batch_size=A.shape[0])\n",
    "\n",
    "    # Train / validation scores\n",
    "    train_val_loss, train_val_acc = evaluate_preds(preds, [y_train, y_val],\n",
    "                                                   [idx_train, idx_val])\n",
    "    print(\"Epoch: {:04d}\".format(epoch),\n",
    "          \"train_loss= {:.4f}\".format(train_val_loss[0]),\n",
    "          \"train_acc= {:.4f}\".format(train_val_acc[0]),\n",
    "          \"val_loss= {:.4f}\".format(train_val_loss[1]),\n",
    "          \"val_acc= {:.4f}\".format(train_val_acc[1]),\n",
    "          \"time= {:.4f}\".format(time.time() - t))\n",
    "\n",
    "    # Early stopping\n",
    "    if train_val_loss[1] < best_val_loss:\n",
    "        best_val_loss = train_val_loss[1]\n",
    "        wait = 0\n",
    "    else:\n",
    "        if wait >= PATIENCE:\n",
    "            print('Epoch {}: early stopping'.format(epoch))\n",
    "            break\n",
    "        wait += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.6280\n",
      "accuracy = 0.7990\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate_preds(preds, [y_test], [idx_test])\n",
    "print(f\"\"\"\n",
    "loss = {test_loss[0]:.4f}\n",
    "accuracy = {test_acc[0]:.4f}\n",
    "\"\"\".strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
