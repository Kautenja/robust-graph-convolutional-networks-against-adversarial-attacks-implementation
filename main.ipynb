{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from keras.layers import Input, Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the path of execution\n",
    "EXE_PATH = os.path.abspath(os.path.curdir)\n",
    "# the path of the vendor files\n",
    "VENDOR_PATH = os.path.join(EXE_PATH, 'vendor')\n",
    "# the vendors to include in the system path\n",
    "VENDORS = ['keras-gcn']\n",
    "# create the absolute paths for all vendors\n",
    "VENDORS = list(map(lambda x: os.path.join(VENDOR_PATH, x), VENDORS))\n",
    "# update the Python path to include necessary vendor module\n",
    "sys.path += VENDORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kegra.layers.graph import GraphConvolution\n",
    "from kegra.utils import load_data, preprocess_adj, get_splits, evaluate_preds\n",
    "from ggcn import GaussianGraphConvolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cora dataset...\n",
      "Dataset has 2708 nodes, 5429 edges, 1433 features.\n"
     ]
    }
   ],
   "source": [
    "X, A, y = load_data('data/cora/', dataset='cora')\n",
    "X /= X.sum(1).reshape(-1, 1)\n",
    "A = preprocess_adj(A)\n",
    "y_train, y_val, y_test, idx_train, idx_val, idx_test, train_mask = get_splits(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2708x2708 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 13264 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 1, 0],\n",
       "       ...,\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1110 15:25:38.928311 140593656977216 deprecation_wrapper.py:119] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1110 15:25:38.935813 140593656977216 deprecation_wrapper.py:119] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:515: The name tf.sparse_placeholder is deprecated. Please use tf.compat.v1.sparse_placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "support = 1\n",
    "graph = [X, A]\n",
    "G = [Input(shape=(None, None), batch_shape=(None, None), sparse=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1110 15:25:38.942960 140593656977216 deprecation_wrapper.py:119] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_in = Input(shape=(X.shape[1],))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCN (baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1110 15:25:38.949832 140593656977216 deprecation_wrapper.py:119] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W1110 15:25:38.954389 140593656977216 deprecation.py:506] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W1110 15:25:38.963882 140593656977216 deprecation_wrapper.py:119] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define model architecture\n",
    "# NOTE: We pass arguments for graph convolutional layers as a list of tensors.\n",
    "# This is somewhat hacky, more elegant options would require rewriting the Layer base class.\n",
    "H = Dropout(0.5)(X_in)\n",
    "H = GraphConvolution(16, support, activation='relu', kernel_regularizer=l2(5e-4))([H]+G)\n",
    "H = Dropout(0.5)(H)\n",
    "Y = GraphConvolution(y.shape[1], support, activation='softmax')([H]+G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1110 15:25:39.003683 140593656977216 deprecation_wrapper.py:119] From /home/bitcommander/.local/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=[X_in]+G, outputs=Y)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1110 15:25:39.073235 140593656977216 deprecation.py:323] From /home/bitcommander/.local/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 train_loss= 1.9325 train_acc= 0.3286 val_loss= 1.9331 val_acc= 0.3600 time= 1.0606\n",
      "Epoch: 0002 train_loss= 1.9189 train_acc= 0.2929 val_loss= 1.9200 val_acc= 0.3500 time= 0.0242\n",
      "Epoch: 0003 train_loss= 1.9036 train_acc= 0.2929 val_loss= 1.9057 val_acc= 0.3500 time= 0.0272\n",
      "Epoch: 0004 train_loss= 1.8880 train_acc= 0.2929 val_loss= 1.8912 val_acc= 0.3500 time= 0.0234\n",
      "Epoch: 0005 train_loss= 1.8725 train_acc= 0.2929 val_loss= 1.8769 val_acc= 0.3500 time= 0.0239\n",
      "Epoch: 0006 train_loss= 1.8565 train_acc= 0.2929 val_loss= 1.8627 val_acc= 0.3500 time= 0.0238\n",
      "Epoch: 0007 train_loss= 1.8401 train_acc= 0.2929 val_loss= 1.8484 val_acc= 0.3500 time= 0.0191\n",
      "Epoch: 0008 train_loss= 1.8234 train_acc= 0.2929 val_loss= 1.8340 val_acc= 0.3500 time= 0.0266\n",
      "Epoch: 0009 train_loss= 1.8071 train_acc= 0.2929 val_loss= 1.8203 val_acc= 0.3500 time= 0.0226\n",
      "Epoch: 0010 train_loss= 1.7906 train_acc= 0.2929 val_loss= 1.8068 val_acc= 0.3533 time= 0.0202\n",
      "Epoch: 0011 train_loss= 1.7747 train_acc= 0.3214 val_loss= 1.7939 val_acc= 0.3567 time= 0.0188\n",
      "Epoch: 0012 train_loss= 1.7594 train_acc= 0.3429 val_loss= 1.7820 val_acc= 0.3567 time= 0.0186\n",
      "Epoch: 0013 train_loss= 1.7449 train_acc= 0.3500 val_loss= 1.7710 val_acc= 0.3633 time= 0.0249\n",
      "Epoch: 0014 train_loss= 1.7311 train_acc= 0.3571 val_loss= 1.7609 val_acc= 0.3633 time= 0.0237\n",
      "Epoch: 0015 train_loss= 1.7180 train_acc= 0.3714 val_loss= 1.7520 val_acc= 0.3633 time= 0.0243\n",
      "Epoch: 0016 train_loss= 1.7055 train_acc= 0.3929 val_loss= 1.7439 val_acc= 0.3667 time= 0.0277\n",
      "Epoch: 0017 train_loss= 1.6934 train_acc= 0.4143 val_loss= 1.7365 val_acc= 0.3767 time= 0.0196\n",
      "Epoch: 0018 train_loss= 1.6816 train_acc= 0.4286 val_loss= 1.7292 val_acc= 0.3867 time= 0.0252\n",
      "Epoch: 0019 train_loss= 1.6700 train_acc= 0.4286 val_loss= 1.7221 val_acc= 0.3933 time= 0.0186\n",
      "Epoch: 0020 train_loss= 1.6584 train_acc= 0.4286 val_loss= 1.7149 val_acc= 0.4033 time= 0.0191\n",
      "Epoch: 0021 train_loss= 1.6466 train_acc= 0.4357 val_loss= 1.7075 val_acc= 0.4067 time= 0.0191\n",
      "Epoch: 0022 train_loss= 1.6346 train_acc= 0.4429 val_loss= 1.7000 val_acc= 0.4100 time= 0.0231\n",
      "Epoch: 0023 train_loss= 1.6225 train_acc= 0.4500 val_loss= 1.6923 val_acc= 0.4133 time= 0.0198\n",
      "Epoch: 0024 train_loss= 1.6103 train_acc= 0.4571 val_loss= 1.6845 val_acc= 0.4200 time= 0.0247\n",
      "Epoch: 0025 train_loss= 1.5978 train_acc= 0.4643 val_loss= 1.6768 val_acc= 0.4333 time= 0.0252\n",
      "Epoch: 0026 train_loss= 1.5851 train_acc= 0.4714 val_loss= 1.6691 val_acc= 0.4333 time= 0.0228\n",
      "Epoch: 0027 train_loss= 1.5724 train_acc= 0.4714 val_loss= 1.6614 val_acc= 0.4500 time= 0.0193\n",
      "Epoch: 0028 train_loss= 1.5596 train_acc= 0.4714 val_loss= 1.6535 val_acc= 0.4567 time= 0.0247\n",
      "Epoch: 0029 train_loss= 1.5467 train_acc= 0.4786 val_loss= 1.6453 val_acc= 0.4633 time= 0.0234\n",
      "Epoch: 0030 train_loss= 1.5340 train_acc= 0.5071 val_loss= 1.6373 val_acc= 0.4700 time= 0.0188\n",
      "Epoch: 0031 train_loss= 1.5212 train_acc= 0.5071 val_loss= 1.6291 val_acc= 0.4867 time= 0.0184\n",
      "Epoch: 0032 train_loss= 1.5084 train_acc= 0.5214 val_loss= 1.6210 val_acc= 0.5000 time= 0.0230\n",
      "Epoch: 0033 train_loss= 1.4954 train_acc= 0.5286 val_loss= 1.6123 val_acc= 0.5100 time= 0.0185\n",
      "Epoch: 0034 train_loss= 1.4825 train_acc= 0.5500 val_loss= 1.6037 val_acc= 0.5233 time= 0.0189\n",
      "Epoch: 0035 train_loss= 1.4694 train_acc= 0.5643 val_loss= 1.5946 val_acc= 0.5300 time= 0.0240\n",
      "Epoch: 0036 train_loss= 1.4563 train_acc= 0.5714 val_loss= 1.5853 val_acc= 0.5400 time= 0.0231\n",
      "Epoch: 0037 train_loss= 1.4430 train_acc= 0.5714 val_loss= 1.5754 val_acc= 0.5400 time= 0.0240\n",
      "Epoch: 0038 train_loss= 1.4297 train_acc= 0.5714 val_loss= 1.5655 val_acc= 0.5433 time= 0.0268\n",
      "Epoch: 0039 train_loss= 1.4166 train_acc= 0.5857 val_loss= 1.5557 val_acc= 0.5400 time= 0.0243\n",
      "Epoch: 0040 train_loss= 1.4035 train_acc= 0.5857 val_loss= 1.5460 val_acc= 0.5400 time= 0.0240\n",
      "Epoch: 0041 train_loss= 1.3907 train_acc= 0.6000 val_loss= 1.5369 val_acc= 0.5467 time= 0.0220\n",
      "Epoch: 0042 train_loss= 1.3780 train_acc= 0.6143 val_loss= 1.5279 val_acc= 0.5500 time= 0.0224\n",
      "Epoch: 0043 train_loss= 1.3653 train_acc= 0.6214 val_loss= 1.5188 val_acc= 0.5500 time= 0.0177\n",
      "Epoch: 0044 train_loss= 1.3527 train_acc= 0.6429 val_loss= 1.5094 val_acc= 0.5500 time= 0.0241\n",
      "Epoch: 0045 train_loss= 1.3401 train_acc= 0.6429 val_loss= 1.4994 val_acc= 0.5500 time= 0.0196\n",
      "Epoch: 0046 train_loss= 1.3276 train_acc= 0.6357 val_loss= 1.4891 val_acc= 0.5533 time= 0.0238\n",
      "Epoch: 0047 train_loss= 1.3153 train_acc= 0.6429 val_loss= 1.4793 val_acc= 0.5500 time= 0.0254\n",
      "Epoch: 0048 train_loss= 1.3031 train_acc= 0.6500 val_loss= 1.4700 val_acc= 0.5600 time= 0.0240\n",
      "Epoch: 0049 train_loss= 1.2911 train_acc= 0.6571 val_loss= 1.4611 val_acc= 0.5600 time= 0.0280\n",
      "Epoch: 0050 train_loss= 1.2794 train_acc= 0.6571 val_loss= 1.4523 val_acc= 0.5700 time= 0.0232\n",
      "Epoch: 0051 train_loss= 1.2677 train_acc= 0.6571 val_loss= 1.4438 val_acc= 0.5700 time= 0.0186\n",
      "Epoch: 0052 train_loss= 1.2560 train_acc= 0.6643 val_loss= 1.4355 val_acc= 0.5800 time= 0.0243\n",
      "Epoch: 0053 train_loss= 1.2442 train_acc= 0.6643 val_loss= 1.4278 val_acc= 0.5800 time= 0.0226\n",
      "Epoch: 0054 train_loss= 1.2328 train_acc= 0.6857 val_loss= 1.4203 val_acc= 0.5900 time= 0.0183\n",
      "Epoch: 0055 train_loss= 1.2216 train_acc= 0.7000 val_loss= 1.4130 val_acc= 0.5967 time= 0.0183\n",
      "Epoch: 0056 train_loss= 1.2106 train_acc= 0.7286 val_loss= 1.4056 val_acc= 0.6067 time= 0.0230\n",
      "Epoch: 0057 train_loss= 1.1996 train_acc= 0.7357 val_loss= 1.3978 val_acc= 0.6067 time= 0.0250\n",
      "Epoch: 0058 train_loss= 1.1887 train_acc= 0.7429 val_loss= 1.3897 val_acc= 0.6200 time= 0.0239\n",
      "Epoch: 0059 train_loss= 1.1779 train_acc= 0.7429 val_loss= 1.3809 val_acc= 0.6167 time= 0.0188\n",
      "Epoch: 0060 train_loss= 1.1673 train_acc= 0.7429 val_loss= 1.3719 val_acc= 0.6167 time= 0.0191\n",
      "Epoch: 0061 train_loss= 1.1570 train_acc= 0.7429 val_loss= 1.3631 val_acc= 0.6233 time= 0.0232\n",
      "Epoch: 0062 train_loss= 1.1468 train_acc= 0.7357 val_loss= 1.3544 val_acc= 0.6200 time= 0.0196\n",
      "Epoch: 0063 train_loss= 1.1368 train_acc= 0.7214 val_loss= 1.3459 val_acc= 0.6167 time= 0.0234\n",
      "Epoch: 0064 train_loss= 1.1269 train_acc= 0.7214 val_loss= 1.3376 val_acc= 0.6133 time= 0.0236\n",
      "Epoch: 0065 train_loss= 1.1172 train_acc= 0.7286 val_loss= 1.3295 val_acc= 0.6167 time= 0.0194\n",
      "Epoch: 0066 train_loss= 1.1072 train_acc= 0.7429 val_loss= 1.3221 val_acc= 0.6167 time= 0.0238\n",
      "Epoch: 0067 train_loss= 1.0970 train_acc= 0.7714 val_loss= 1.3153 val_acc= 0.6333 time= 0.0237\n",
      "Epoch: 0068 train_loss= 1.0869 train_acc= 0.7714 val_loss= 1.3092 val_acc= 0.6533 time= 0.0200\n",
      "Epoch: 0069 train_loss= 1.0772 train_acc= 0.7714 val_loss= 1.3041 val_acc= 0.6733 time= 0.0197\n",
      "Epoch: 0070 train_loss= 1.0682 train_acc= 0.7714 val_loss= 1.2991 val_acc= 0.6800 time= 0.0195\n",
      "Epoch: 0071 train_loss= 1.0592 train_acc= 0.7714 val_loss= 1.2931 val_acc= 0.6833 time= 0.0185\n",
      "Epoch: 0072 train_loss= 1.0497 train_acc= 0.7786 val_loss= 1.2857 val_acc= 0.6833 time= 0.0184\n",
      "Epoch: 0073 train_loss= 1.0404 train_acc= 0.7786 val_loss= 1.2778 val_acc= 0.6900 time= 0.0237\n",
      "Epoch: 0074 train_loss= 1.0311 train_acc= 0.7857 val_loss= 1.2692 val_acc= 0.6967 time= 0.0228\n",
      "Epoch: 0075 train_loss= 1.0221 train_acc= 0.7929 val_loss= 1.2603 val_acc= 0.6900 time= 0.0191\n",
      "Epoch: 0076 train_loss= 1.0137 train_acc= 0.7929 val_loss= 1.2522 val_acc= 0.6900 time= 0.0286\n",
      "Epoch: 0077 train_loss= 1.0052 train_acc= 0.7929 val_loss= 1.2447 val_acc= 0.6900 time= 0.0191\n",
      "Epoch: 0078 train_loss= 0.9967 train_acc= 0.7857 val_loss= 1.2372 val_acc= 0.6833 time= 0.0249\n",
      "Epoch: 0079 train_loss= 0.9879 train_acc= 0.8000 val_loss= 1.2302 val_acc= 0.6900 time= 0.0284\n",
      "Epoch: 0080 train_loss= 0.9789 train_acc= 0.8000 val_loss= 1.2237 val_acc= 0.6967 time= 0.0190\n",
      "Epoch: 0081 train_loss= 0.9704 train_acc= 0.8071 val_loss= 1.2173 val_acc= 0.6967 time= 0.0236\n",
      "Epoch: 0082 train_loss= 0.9621 train_acc= 0.8071 val_loss= 1.2118 val_acc= 0.7033 time= 0.0191\n",
      "Epoch: 0083 train_loss= 0.9541 train_acc= 0.8071 val_loss= 1.2068 val_acc= 0.7100 time= 0.0238\n",
      "Epoch: 0084 train_loss= 0.9466 train_acc= 0.8143 val_loss= 1.2023 val_acc= 0.7033 time= 0.0241\n",
      "Epoch: 0085 train_loss= 0.9395 train_acc= 0.8214 val_loss= 1.1979 val_acc= 0.7000 time= 0.0228\n",
      "Epoch: 0086 train_loss= 0.9319 train_acc= 0.8214 val_loss= 1.1923 val_acc= 0.7100 time= 0.0236\n",
      "Epoch: 0087 train_loss= 0.9239 train_acc= 0.8214 val_loss= 1.1850 val_acc= 0.7133 time= 0.0179\n",
      "Epoch: 0088 train_loss= 0.9161 train_acc= 0.8286 val_loss= 1.1772 val_acc= 0.7167 time= 0.0178\n",
      "Epoch: 0089 train_loss= 0.9085 train_acc= 0.8357 val_loss= 1.1698 val_acc= 0.7133 time= 0.0191\n",
      "Epoch: 0090 train_loss= 0.9013 train_acc= 0.8357 val_loss= 1.1634 val_acc= 0.7167 time= 0.0190\n",
      "Epoch: 0091 train_loss= 0.8942 train_acc= 0.8286 val_loss= 1.1574 val_acc= 0.7133 time= 0.0180\n",
      "Epoch: 0092 train_loss= 0.8864 train_acc= 0.8357 val_loss= 1.1523 val_acc= 0.7167 time= 0.0188\n",
      "Epoch: 0093 train_loss= 0.8788 train_acc= 0.8357 val_loss= 1.1473 val_acc= 0.7133 time= 0.0191\n",
      "Epoch: 0094 train_loss= 0.8712 train_acc= 0.8429 val_loss= 1.1418 val_acc= 0.7233 time= 0.0193\n",
      "Epoch: 0095 train_loss= 0.8639 train_acc= 0.8429 val_loss= 1.1367 val_acc= 0.7267 time= 0.0203\n",
      "Epoch: 0096 train_loss= 0.8569 train_acc= 0.8500 val_loss= 1.1316 val_acc= 0.7300 time= 0.0227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0097 train_loss= 0.8502 train_acc= 0.8500 val_loss= 1.1273 val_acc= 0.7267 time= 0.0231\n",
      "Epoch: 0098 train_loss= 0.8437 train_acc= 0.8500 val_loss= 1.1223 val_acc= 0.7367 time= 0.0246\n",
      "Epoch: 0099 train_loss= 0.8372 train_acc= 0.8500 val_loss= 1.1168 val_acc= 0.7367 time= 0.0191\n",
      "Epoch: 0100 train_loss= 0.8309 train_acc= 0.8500 val_loss= 1.1112 val_acc= 0.7333 time= 0.0197\n",
      "Epoch: 0101 train_loss= 0.8243 train_acc= 0.8500 val_loss= 1.1047 val_acc= 0.7333 time= 0.0255\n",
      "Epoch: 0102 train_loss= 0.8179 train_acc= 0.8500 val_loss= 1.0983 val_acc= 0.7333 time= 0.0233\n",
      "Epoch: 0103 train_loss= 0.8116 train_acc= 0.8571 val_loss= 1.0930 val_acc= 0.7367 time= 0.0244\n",
      "Epoch: 0104 train_loss= 0.8053 train_acc= 0.8571 val_loss= 1.0880 val_acc= 0.7433 time= 0.0187\n",
      "Epoch: 0105 train_loss= 0.7990 train_acc= 0.8571 val_loss= 1.0826 val_acc= 0.7433 time= 0.0280\n",
      "Epoch: 0106 train_loss= 0.7927 train_acc= 0.8643 val_loss= 1.0781 val_acc= 0.7433 time= 0.0251\n",
      "Epoch: 0107 train_loss= 0.7869 train_acc= 0.8643 val_loss= 1.0741 val_acc= 0.7433 time= 0.0231\n",
      "Epoch: 0108 train_loss= 0.7812 train_acc= 0.8714 val_loss= 1.0697 val_acc= 0.7467 time= 0.0230\n",
      "Epoch: 0109 train_loss= 0.7755 train_acc= 0.8786 val_loss= 1.0651 val_acc= 0.7500 time= 0.0229\n",
      "Epoch: 0110 train_loss= 0.7701 train_acc= 0.8786 val_loss= 1.0601 val_acc= 0.7467 time= 0.0192\n",
      "Epoch: 0111 train_loss= 0.7647 train_acc= 0.8857 val_loss= 1.0549 val_acc= 0.7533 time= 0.0187\n",
      "Epoch: 0112 train_loss= 0.7593 train_acc= 0.8857 val_loss= 1.0500 val_acc= 0.7500 time= 0.0198\n",
      "Epoch: 0113 train_loss= 0.7539 train_acc= 0.8857 val_loss= 1.0459 val_acc= 0.7533 time= 0.0188\n",
      "Epoch: 0114 train_loss= 0.7484 train_acc= 0.8857 val_loss= 1.0421 val_acc= 0.7567 time= 0.0199\n",
      "Epoch: 0115 train_loss= 0.7426 train_acc= 0.8929 val_loss= 1.0390 val_acc= 0.7567 time= 0.0229\n",
      "Epoch: 0116 train_loss= 0.7370 train_acc= 0.8929 val_loss= 1.0356 val_acc= 0.7567 time= 0.0185\n",
      "Epoch: 0117 train_loss= 0.7315 train_acc= 0.8929 val_loss= 1.0323 val_acc= 0.7567 time= 0.0229\n",
      "Epoch: 0118 train_loss= 0.7258 train_acc= 0.8929 val_loss= 1.0288 val_acc= 0.7567 time= 0.0186\n",
      "Epoch: 0119 train_loss= 0.7203 train_acc= 0.8929 val_loss= 1.0250 val_acc= 0.7567 time= 0.0187\n",
      "Epoch: 0120 train_loss= 0.7151 train_acc= 0.8929 val_loss= 1.0212 val_acc= 0.7567 time= 0.0284\n",
      "Epoch: 0121 train_loss= 0.7103 train_acc= 0.8929 val_loss= 1.0180 val_acc= 0.7600 time= 0.0233\n",
      "Epoch: 0122 train_loss= 0.7061 train_acc= 0.8929 val_loss= 1.0154 val_acc= 0.7600 time= 0.0247\n",
      "Epoch: 0123 train_loss= 0.7018 train_acc= 0.8929 val_loss= 1.0119 val_acc= 0.7600 time= 0.0230\n",
      "Epoch: 0124 train_loss= 0.6968 train_acc= 0.8929 val_loss= 1.0063 val_acc= 0.7633 time= 0.0209\n",
      "Epoch: 0125 train_loss= 0.6916 train_acc= 0.8929 val_loss= 1.0006 val_acc= 0.7633 time= 0.0233\n",
      "Epoch: 0126 train_loss= 0.6862 train_acc= 0.8929 val_loss= 0.9952 val_acc= 0.7667 time= 0.0195\n",
      "Epoch: 0127 train_loss= 0.6809 train_acc= 0.8929 val_loss= 0.9908 val_acc= 0.7667 time= 0.0234\n",
      "Epoch: 0128 train_loss= 0.6759 train_acc= 0.8929 val_loss= 0.9870 val_acc= 0.7700 time= 0.0179\n",
      "Epoch: 0129 train_loss= 0.6709 train_acc= 0.8929 val_loss= 0.9836 val_acc= 0.7733 time= 0.0186\n",
      "Epoch: 0130 train_loss= 0.6660 train_acc= 0.9071 val_loss= 0.9803 val_acc= 0.7767 time= 0.0183\n",
      "Epoch: 0131 train_loss= 0.6615 train_acc= 0.8929 val_loss= 0.9766 val_acc= 0.7767 time= 0.0224\n",
      "Epoch: 0132 train_loss= 0.6571 train_acc= 0.9000 val_loss= 0.9730 val_acc= 0.7800 time= 0.0206\n",
      "Epoch: 0133 train_loss= 0.6530 train_acc= 0.9143 val_loss= 0.9702 val_acc= 0.7833 time= 0.0224\n",
      "Epoch: 0134 train_loss= 0.6489 train_acc= 0.9286 val_loss= 0.9681 val_acc= 0.7900 time= 0.0177\n",
      "Epoch: 0135 train_loss= 0.6448 train_acc= 0.9286 val_loss= 0.9650 val_acc= 0.7900 time= 0.0233\n",
      "Epoch: 0136 train_loss= 0.6407 train_acc= 0.9286 val_loss= 0.9618 val_acc= 0.7900 time= 0.0277\n",
      "Epoch: 0137 train_loss= 0.6368 train_acc= 0.9143 val_loss= 0.9581 val_acc= 0.7867 time= 0.0182\n",
      "Epoch: 0138 train_loss= 0.6331 train_acc= 0.9071 val_loss= 0.9548 val_acc= 0.7833 time= 0.0186\n",
      "Epoch: 0139 train_loss= 0.6295 train_acc= 0.9071 val_loss= 0.9525 val_acc= 0.7800 time= 0.0285\n",
      "Epoch: 0140 train_loss= 0.6263 train_acc= 0.9286 val_loss= 0.9514 val_acc= 0.7867 time= 0.0245\n",
      "Epoch: 0141 train_loss= 0.6232 train_acc= 0.9286 val_loss= 0.9493 val_acc= 0.7867 time= 0.0239\n",
      "Epoch: 0142 train_loss= 0.6198 train_acc= 0.9214 val_loss= 0.9469 val_acc= 0.7833 time= 0.0187\n",
      "Epoch: 0143 train_loss= 0.6163 train_acc= 0.9286 val_loss= 0.9431 val_acc= 0.7800 time= 0.0185\n",
      "Epoch: 0144 train_loss= 0.6129 train_acc= 0.9214 val_loss= 0.9384 val_acc= 0.7900 time= 0.0184\n",
      "Epoch: 0145 train_loss= 0.6093 train_acc= 0.9214 val_loss= 0.9334 val_acc= 0.7933 time= 0.0198\n",
      "Epoch: 0146 train_loss= 0.6061 train_acc= 0.9214 val_loss= 0.9284 val_acc= 0.7967 time= 0.0280\n",
      "Epoch: 0147 train_loss= 0.6022 train_acc= 0.9214 val_loss= 0.9245 val_acc= 0.7967 time= 0.0235\n",
      "Epoch: 0148 train_loss= 0.5987 train_acc= 0.9286 val_loss= 0.9211 val_acc= 0.7967 time= 0.0298\n",
      "Epoch: 0149 train_loss= 0.5950 train_acc= 0.9286 val_loss= 0.9185 val_acc= 0.7967 time= 0.0241\n",
      "Epoch: 0150 train_loss= 0.5908 train_acc= 0.9286 val_loss= 0.9170 val_acc= 0.7967 time= 0.0241\n",
      "Epoch: 0151 train_loss= 0.5872 train_acc= 0.9286 val_loss= 0.9162 val_acc= 0.7933 time= 0.0246\n",
      "Epoch: 0152 train_loss= 0.5838 train_acc= 0.9357 val_loss= 0.9149 val_acc= 0.7933 time= 0.0201\n",
      "Epoch: 0153 train_loss= 0.5803 train_acc= 0.9357 val_loss= 0.9126 val_acc= 0.7933 time= 0.0241\n",
      "Epoch: 0154 train_loss= 0.5769 train_acc= 0.9357 val_loss= 0.9101 val_acc= 0.7933 time= 0.0233\n",
      "Epoch: 0155 train_loss= 0.5735 train_acc= 0.9357 val_loss= 0.9068 val_acc= 0.7900 time= 0.0188\n",
      "Epoch: 0156 train_loss= 0.5706 train_acc= 0.9357 val_loss= 0.9036 val_acc= 0.7900 time= 0.0294\n",
      "Epoch: 0157 train_loss= 0.5681 train_acc= 0.9357 val_loss= 0.9013 val_acc= 0.7933 time= 0.0204\n",
      "Epoch: 0158 train_loss= 0.5650 train_acc= 0.9357 val_loss= 0.8990 val_acc= 0.7933 time= 0.0243\n",
      "Epoch: 0159 train_loss= 0.5617 train_acc= 0.9357 val_loss= 0.8961 val_acc= 0.7967 time= 0.0236\n",
      "Epoch: 0160 train_loss= 0.5582 train_acc= 0.9357 val_loss= 0.8936 val_acc= 0.7967 time= 0.0259\n",
      "Epoch: 0161 train_loss= 0.5549 train_acc= 0.9357 val_loss= 0.8916 val_acc= 0.7967 time= 0.0208\n",
      "Epoch: 0162 train_loss= 0.5519 train_acc= 0.9357 val_loss= 0.8896 val_acc= 0.8000 time= 0.0261\n",
      "Epoch: 0163 train_loss= 0.5490 train_acc= 0.9357 val_loss= 0.8875 val_acc= 0.8000 time= 0.0229\n",
      "Epoch: 0164 train_loss= 0.5456 train_acc= 0.9357 val_loss= 0.8853 val_acc= 0.8000 time= 0.0207\n",
      "Epoch: 0165 train_loss= 0.5424 train_acc= 0.9357 val_loss= 0.8825 val_acc= 0.8000 time= 0.0213\n",
      "Epoch: 0166 train_loss= 0.5391 train_acc= 0.9429 val_loss= 0.8801 val_acc= 0.8033 time= 0.0196\n",
      "Epoch: 0167 train_loss= 0.5362 train_acc= 0.9429 val_loss= 0.8766 val_acc= 0.8033 time= 0.0235\n",
      "Epoch: 0168 train_loss= 0.5339 train_acc= 0.9357 val_loss= 0.8739 val_acc= 0.8000 time= 0.0212\n",
      "Epoch: 0169 train_loss= 0.5321 train_acc= 0.9357 val_loss= 0.8719 val_acc= 0.7967 time= 0.0258\n",
      "Epoch: 0170 train_loss= 0.5298 train_acc= 0.9357 val_loss= 0.8710 val_acc= 0.7967 time= 0.0259\n",
      "Epoch: 0171 train_loss= 0.5275 train_acc= 0.9429 val_loss= 0.8695 val_acc= 0.7967 time= 0.0265\n",
      "Epoch: 0172 train_loss= 0.5251 train_acc= 0.9429 val_loss= 0.8691 val_acc= 0.8000 time= 0.0194\n",
      "Epoch: 0173 train_loss= 0.5227 train_acc= 0.9500 val_loss= 0.8684 val_acc= 0.7900 time= 0.0244\n",
      "Epoch: 0174 train_loss= 0.5203 train_acc= 0.9500 val_loss= 0.8675 val_acc= 0.7867 time= 0.0249\n",
      "Epoch: 0175 train_loss= 0.5174 train_acc= 0.9500 val_loss= 0.8651 val_acc= 0.7900 time= 0.0235\n",
      "Epoch: 0176 train_loss= 0.5146 train_acc= 0.9571 val_loss= 0.8616 val_acc= 0.7967 time= 0.0183\n",
      "Epoch: 0177 train_loss= 0.5122 train_acc= 0.9571 val_loss= 0.8583 val_acc= 0.8033 time= 0.0180\n",
      "Epoch: 0178 train_loss= 0.5099 train_acc= 0.9571 val_loss= 0.8559 val_acc= 0.8133 time= 0.0177\n",
      "Epoch: 0179 train_loss= 0.5076 train_acc= 0.9500 val_loss= 0.8544 val_acc= 0.8133 time= 0.0188\n",
      "Epoch: 0180 train_loss= 0.5054 train_acc= 0.9500 val_loss= 0.8532 val_acc= 0.8133 time= 0.0254\n",
      "Epoch: 0181 train_loss= 0.5033 train_acc= 0.9500 val_loss= 0.8531 val_acc= 0.8133 time= 0.0227\n",
      "Epoch: 0182 train_loss= 0.5011 train_acc= 0.9500 val_loss= 0.8523 val_acc= 0.8067 time= 0.0194\n",
      "Epoch: 0183 train_loss= 0.4987 train_acc= 0.9500 val_loss= 0.8519 val_acc= 0.8067 time= 0.0238\n",
      "Epoch: 0184 train_loss= 0.4962 train_acc= 0.9571 val_loss= 0.8502 val_acc= 0.8033 time= 0.0227\n",
      "Epoch: 0185 train_loss= 0.4935 train_acc= 0.9571 val_loss= 0.8471 val_acc= 0.8033 time= 0.0188\n",
      "Epoch: 0186 train_loss= 0.4907 train_acc= 0.9571 val_loss= 0.8426 val_acc= 0.7967 time= 0.0194\n",
      "Epoch: 0187 train_loss= 0.4885 train_acc= 0.9500 val_loss= 0.8387 val_acc= 0.7967 time= 0.0245\n",
      "Epoch: 0188 train_loss= 0.4868 train_acc= 0.9500 val_loss= 0.8358 val_acc= 0.7967 time= 0.0240\n",
      "Epoch: 0189 train_loss= 0.4857 train_acc= 0.9571 val_loss= 0.8335 val_acc= 0.7900 time= 0.0228\n",
      "Epoch: 0190 train_loss= 0.4835 train_acc= 0.9571 val_loss= 0.8319 val_acc= 0.7933 time= 0.0229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0191 train_loss= 0.4794 train_acc= 0.9571 val_loss= 0.8311 val_acc= 0.7867 time= 0.0201\n",
      "Epoch: 0192 train_loss= 0.4763 train_acc= 0.9571 val_loss= 0.8321 val_acc= 0.7967 time= 0.0234\n",
      "Epoch: 0193 train_loss= 0.4747 train_acc= 0.9643 val_loss= 0.8333 val_acc= 0.7967 time= 0.0231\n",
      "Epoch: 0194 train_loss= 0.4735 train_acc= 0.9571 val_loss= 0.8341 val_acc= 0.8067 time= 0.0235\n",
      "Epoch: 0195 train_loss= 0.4713 train_acc= 0.9571 val_loss= 0.8311 val_acc= 0.8167 time= 0.0245\n",
      "Epoch: 0196 train_loss= 0.4694 train_acc= 0.9643 val_loss= 0.8274 val_acc= 0.8100 time= 0.0234\n",
      "Epoch: 0197 train_loss= 0.4683 train_acc= 0.9643 val_loss= 0.8241 val_acc= 0.8167 time= 0.0254\n",
      "Epoch: 0198 train_loss= 0.4672 train_acc= 0.9643 val_loss= 0.8219 val_acc= 0.8200 time= 0.0190\n",
      "Epoch: 0199 train_loss= 0.4646 train_acc= 0.9643 val_loss= 0.8205 val_acc= 0.8233 time= 0.0234\n",
      "Epoch: 0200 train_loss= 0.4614 train_acc= 0.9643 val_loss= 0.8198 val_acc= 0.8233 time= 0.0245\n"
     ]
    }
   ],
   "source": [
    "NB_EPOCH = 200\n",
    "PATIENCE = 10  # early stopping patience\n",
    "# Helper variables for main training loop\n",
    "wait = 0\n",
    "preds = None\n",
    "best_val_loss = 99999\n",
    "\n",
    "# Fit\n",
    "for epoch in range(1, NB_EPOCH+1):\n",
    "\n",
    "    # Log wall-clock time\n",
    "    t = time.time()\n",
    "\n",
    "    # Single training iteration (we mask nodes without labels for loss calculation)\n",
    "    model.fit(graph, y_train, sample_weight=train_mask,\n",
    "              batch_size=A.shape[0], epochs=1, shuffle=False, verbose=0)\n",
    "\n",
    "    # Predict on full dataset\n",
    "    preds = model.predict(graph, batch_size=A.shape[0])\n",
    "\n",
    "    # Train / validation scores\n",
    "    train_val_loss, train_val_acc = evaluate_preds(preds, [y_train, y_val],\n",
    "                                                   [idx_train, idx_val])\n",
    "    print(\"Epoch: {:04d}\".format(epoch),\n",
    "          \"train_loss= {:.4f}\".format(train_val_loss[0]),\n",
    "          \"train_acc= {:.4f}\".format(train_val_acc[0]),\n",
    "          \"val_loss= {:.4f}\".format(train_val_loss[1]),\n",
    "          \"val_acc= {:.4f}\".format(train_val_acc[1]),\n",
    "          \"time= {:.4f}\".format(time.time() - t))\n",
    "\n",
    "    # Early stopping\n",
    "    if train_val_loss[1] < best_val_loss:\n",
    "        best_val_loss = train_val_loss[1]\n",
    "        wait = 0\n",
    "    else:\n",
    "        if wait >= PATIENCE:\n",
    "            print('Epoch {}: early stopping'.format(epoch))\n",
    "            break\n",
    "        wait += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.8800\n",
      "accuracy = 0.8030\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate_preds(preds, [y_test], [idx_test])\n",
    "print(f\"\"\"\n",
    "loss = {test_loss[0]:.4f}\n",
    "accuracy = {test_acc[0]:.4f}\n",
    "\"\"\".strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Graph Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = Dropout(0.5)(X_in)\n",
    "H = GaussianGraphConvolution(16, A.shape[0], True, support, activation='relu', kernel_regularizer=l2(5e-4))([H]+G)\n",
    "H = Dropout(0.5)(H)\n",
    "Y = GaussianGraphConvolution(y.shape[1], A.shape[0], False, support, activation='softmax')([H]+G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[X_in]+G, outputs=Y)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 train_loss= 1.9439 train_acc= 0.3214 val_loss= 1.9447 val_acc= 0.2933 time= 0.3358\n",
      "Epoch: 0002 train_loss= 1.9411 train_acc= 0.5000 val_loss= 1.9426 val_acc= 0.4400 time= 0.0228\n",
      "Epoch: 0003 train_loss= 1.9373 train_acc= 0.5071 val_loss= 1.9396 val_acc= 0.4400 time= 0.0178\n",
      "Epoch: 0004 train_loss= 1.9323 train_acc= 0.5714 val_loss= 1.9358 val_acc= 0.4767 time= 0.0179\n",
      "Epoch: 0005 train_loss= 1.9262 train_acc= 0.5857 val_loss= 1.9311 val_acc= 0.4933 time= 0.0178\n",
      "Epoch: 0006 train_loss= 1.9193 train_acc= 0.5857 val_loss= 1.9257 val_acc= 0.5167 time= 0.0225\n",
      "Epoch: 0007 train_loss= 1.9120 train_acc= 0.6000 val_loss= 1.9203 val_acc= 0.5267 time= 0.0184\n",
      "Epoch: 0008 train_loss= 1.9043 train_acc= 0.6143 val_loss= 1.9146 val_acc= 0.5267 time= 0.0236\n",
      "Epoch: 0009 train_loss= 1.8963 train_acc= 0.6143 val_loss= 1.9088 val_acc= 0.5267 time= 0.0270\n",
      "Epoch: 0010 train_loss= 1.8878 train_acc= 0.6357 val_loss= 1.9025 val_acc= 0.5333 time= 0.0186\n",
      "Epoch: 0011 train_loss= 1.8786 train_acc= 0.6429 val_loss= 1.8957 val_acc= 0.5500 time= 0.0263\n",
      "Epoch: 0012 train_loss= 1.8691 train_acc= 0.6429 val_loss= 1.8885 val_acc= 0.5567 time= 0.0272\n",
      "Epoch: 0013 train_loss= 1.8591 train_acc= 0.6500 val_loss= 1.8809 val_acc= 0.5467 time= 0.0182\n",
      "Epoch: 0014 train_loss= 1.8486 train_acc= 0.6500 val_loss= 1.8730 val_acc= 0.5433 time= 0.0231\n",
      "Epoch: 0015 train_loss= 1.8378 train_acc= 0.6429 val_loss= 1.8649 val_acc= 0.5533 time= 0.0234\n",
      "Epoch: 0016 train_loss= 1.8266 train_acc= 0.6357 val_loss= 1.8565 val_acc= 0.5600 time= 0.0233\n",
      "Epoch: 0017 train_loss= 1.8150 train_acc= 0.6357 val_loss= 1.8478 val_acc= 0.5533 time= 0.0274\n",
      "Epoch: 0018 train_loss= 1.8029 train_acc= 0.6357 val_loss= 1.8389 val_acc= 0.5533 time= 0.0183\n",
      "Epoch: 0019 train_loss= 1.7905 train_acc= 0.6429 val_loss= 1.8296 val_acc= 0.5500 time= 0.0227\n",
      "Epoch: 0020 train_loss= 1.7776 train_acc= 0.6500 val_loss= 1.8200 val_acc= 0.5467 time= 0.0236\n",
      "Epoch: 0021 train_loss= 1.7643 train_acc= 0.6429 val_loss= 1.8102 val_acc= 0.5400 time= 0.0249\n",
      "Epoch: 0022 train_loss= 1.7507 train_acc= 0.6286 val_loss= 1.8000 val_acc= 0.5400 time= 0.0222\n",
      "Epoch: 0023 train_loss= 1.7367 train_acc= 0.6214 val_loss= 1.7896 val_acc= 0.5333 time= 0.0232\n",
      "Epoch: 0024 train_loss= 1.7224 train_acc= 0.6214 val_loss= 1.7790 val_acc= 0.5333 time= 0.0183\n",
      "Epoch: 0025 train_loss= 1.7078 train_acc= 0.6214 val_loss= 1.7683 val_acc= 0.5333 time= 0.0182\n",
      "Epoch: 0026 train_loss= 1.6927 train_acc= 0.6143 val_loss= 1.7572 val_acc= 0.5333 time= 0.0182\n",
      "Epoch: 0027 train_loss= 1.6775 train_acc= 0.6143 val_loss= 1.7460 val_acc= 0.5333 time= 0.0182\n",
      "Epoch: 0028 train_loss= 1.6619 train_acc= 0.6143 val_loss= 1.7346 val_acc= 0.5367 time= 0.0179\n",
      "Epoch: 0029 train_loss= 1.6461 train_acc= 0.6214 val_loss= 1.7230 val_acc= 0.5333 time= 0.0179\n",
      "Epoch: 0030 train_loss= 1.6300 train_acc= 0.6214 val_loss= 1.7112 val_acc= 0.5333 time= 0.0185\n",
      "Epoch: 0031 train_loss= 1.6138 train_acc= 0.6214 val_loss= 1.6993 val_acc= 0.5333 time= 0.0207\n",
      "Epoch: 0032 train_loss= 1.5973 train_acc= 0.6214 val_loss= 1.6874 val_acc= 0.5367 time= 0.0228\n",
      "Epoch: 0033 train_loss= 1.5807 train_acc= 0.6214 val_loss= 1.6754 val_acc= 0.5467 time= 0.0232\n",
      "Epoch: 0034 train_loss= 1.5640 train_acc= 0.6286 val_loss= 1.6634 val_acc= 0.5467 time= 0.0185\n",
      "Epoch: 0035 train_loss= 1.5470 train_acc= 0.6286 val_loss= 1.6513 val_acc= 0.5500 time= 0.0181\n",
      "Epoch: 0036 train_loss= 1.5300 train_acc= 0.6286 val_loss= 1.6390 val_acc= 0.5533 time= 0.0181\n",
      "Epoch: 0037 train_loss= 1.5128 train_acc= 0.6357 val_loss= 1.6266 val_acc= 0.5533 time= 0.0227\n",
      "Epoch: 0038 train_loss= 1.4955 train_acc= 0.6357 val_loss= 1.6140 val_acc= 0.5567 time= 0.0225\n",
      "Epoch: 0039 train_loss= 1.4781 train_acc= 0.6429 val_loss= 1.6012 val_acc= 0.5600 time= 0.0180\n",
      "Epoch: 0040 train_loss= 1.4608 train_acc= 0.6500 val_loss= 1.5885 val_acc= 0.5600 time= 0.0185\n",
      "Epoch: 0041 train_loss= 1.4434 train_acc= 0.6500 val_loss= 1.5757 val_acc= 0.5600 time= 0.0182\n",
      "Epoch: 0042 train_loss= 1.4260 train_acc= 0.6500 val_loss= 1.5629 val_acc= 0.5733 time= 0.0241\n",
      "Epoch: 0043 train_loss= 1.4087 train_acc= 0.6643 val_loss= 1.5500 val_acc= 0.5800 time= 0.0198\n",
      "Epoch: 0044 train_loss= 1.3916 train_acc= 0.6714 val_loss= 1.5372 val_acc= 0.5933 time= 0.0192\n",
      "Epoch: 0045 train_loss= 1.3745 train_acc= 0.6786 val_loss= 1.5245 val_acc= 0.5967 time= 0.0186\n",
      "Epoch: 0046 train_loss= 1.3575 train_acc= 0.6786 val_loss= 1.5119 val_acc= 0.6100 time= 0.0227\n",
      "Epoch: 0047 train_loss= 1.3406 train_acc= 0.6929 val_loss= 1.4994 val_acc= 0.6167 time= 0.0185\n",
      "Epoch: 0048 train_loss= 1.3240 train_acc= 0.6929 val_loss= 1.4871 val_acc= 0.6233 time= 0.0178\n",
      "Epoch: 0049 train_loss= 1.3074 train_acc= 0.7143 val_loss= 1.4749 val_acc= 0.6267 time= 0.0187\n",
      "Epoch: 0050 train_loss= 1.2909 train_acc= 0.7214 val_loss= 1.4629 val_acc= 0.6300 time= 0.0181\n",
      "Epoch: 0051 train_loss= 1.2746 train_acc= 0.7357 val_loss= 1.4511 val_acc= 0.6467 time= 0.0233\n",
      "Epoch: 0052 train_loss= 1.2586 train_acc= 0.7429 val_loss= 1.4396 val_acc= 0.6533 time= 0.0237\n",
      "Epoch: 0053 train_loss= 1.2429 train_acc= 0.7500 val_loss= 1.4283 val_acc= 0.6700 time= 0.0185\n",
      "Epoch: 0054 train_loss= 1.2274 train_acc= 0.7643 val_loss= 1.4171 val_acc= 0.6767 time= 0.0188\n",
      "Epoch: 0055 train_loss= 1.2122 train_acc= 0.7857 val_loss= 1.4059 val_acc= 0.6800 time= 0.0184\n",
      "Epoch: 0056 train_loss= 1.1971 train_acc= 0.7929 val_loss= 1.3950 val_acc= 0.6800 time= 0.0182\n",
      "Epoch: 0057 train_loss= 1.1824 train_acc= 0.8214 val_loss= 1.3843 val_acc= 0.6833 time= 0.0185\n",
      "Epoch: 0058 train_loss= 1.1680 train_acc= 0.8286 val_loss= 1.3738 val_acc= 0.6867 time= 0.0183\n",
      "Epoch: 0059 train_loss= 1.1540 train_acc= 0.8286 val_loss= 1.3635 val_acc= 0.6900 time= 0.0235\n",
      "Epoch: 0060 train_loss= 1.1401 train_acc= 0.8357 val_loss= 1.3532 val_acc= 0.7000 time= 0.0183\n",
      "Epoch: 0061 train_loss= 1.1266 train_acc= 0.8429 val_loss= 1.3431 val_acc= 0.7067 time= 0.0182\n",
      "Epoch: 0062 train_loss= 1.1134 train_acc= 0.8643 val_loss= 1.3332 val_acc= 0.7200 time= 0.0224\n",
      "Epoch: 0063 train_loss= 1.1005 train_acc= 0.8643 val_loss= 1.3234 val_acc= 0.7267 time= 0.0233\n",
      "Epoch: 0064 train_loss= 1.0878 train_acc= 0.8643 val_loss= 1.3135 val_acc= 0.7300 time= 0.0184\n",
      "Epoch: 0065 train_loss= 1.0752 train_acc= 0.8643 val_loss= 1.3037 val_acc= 0.7433 time= 0.0224\n",
      "Epoch: 0066 train_loss= 1.0628 train_acc= 0.8714 val_loss= 1.2941 val_acc= 0.7433 time= 0.0185\n",
      "Epoch: 0067 train_loss= 1.0508 train_acc= 0.8714 val_loss= 1.2846 val_acc= 0.7467 time= 0.0180\n",
      "Epoch: 0068 train_loss= 1.0389 train_acc= 0.8714 val_loss= 1.2752 val_acc= 0.7467 time= 0.0226\n",
      "Epoch: 0069 train_loss= 1.0274 train_acc= 0.8714 val_loss= 1.2661 val_acc= 0.7467 time= 0.0194\n",
      "Epoch: 0070 train_loss= 1.0161 train_acc= 0.8857 val_loss= 1.2572 val_acc= 0.7500 time= 0.0235\n",
      "Epoch: 0071 train_loss= 1.0050 train_acc= 0.8857 val_loss= 1.2483 val_acc= 0.7500 time= 0.0226\n",
      "Epoch: 0072 train_loss= 0.9941 train_acc= 0.8857 val_loss= 1.2398 val_acc= 0.7500 time= 0.0228\n",
      "Epoch: 0073 train_loss= 0.9833 train_acc= 0.8857 val_loss= 1.2314 val_acc= 0.7500 time= 0.0231\n",
      "Epoch: 0074 train_loss= 0.9729 train_acc= 0.8857 val_loss= 1.2231 val_acc= 0.7500 time= 0.0181\n",
      "Epoch: 0075 train_loss= 0.9625 train_acc= 0.9000 val_loss= 1.2148 val_acc= 0.7533 time= 0.0232\n",
      "Epoch: 0076 train_loss= 0.9522 train_acc= 0.9000 val_loss= 1.2063 val_acc= 0.7533 time= 0.0189\n",
      "Epoch: 0077 train_loss= 0.9422 train_acc= 0.9000 val_loss= 1.1980 val_acc= 0.7533 time= 0.0180\n",
      "Epoch: 0078 train_loss= 0.9323 train_acc= 0.9000 val_loss= 1.1899 val_acc= 0.7533 time= 0.0185\n",
      "Epoch: 0079 train_loss= 0.9225 train_acc= 0.9000 val_loss= 1.1819 val_acc= 0.7533 time= 0.0229\n",
      "Epoch: 0080 train_loss= 0.9130 train_acc= 0.9000 val_loss= 1.1741 val_acc= 0.7533 time= 0.0228\n",
      "Epoch: 0081 train_loss= 0.9036 train_acc= 0.9000 val_loss= 1.1665 val_acc= 0.7533 time= 0.0194\n",
      "Epoch: 0082 train_loss= 0.8943 train_acc= 0.9000 val_loss= 1.1589 val_acc= 0.7533 time= 0.0211\n",
      "Epoch: 0083 train_loss= 0.8854 train_acc= 0.9000 val_loss= 1.1517 val_acc= 0.7533 time= 0.0273\n",
      "Epoch: 0084 train_loss= 0.8766 train_acc= 0.9000 val_loss= 1.1446 val_acc= 0.7567 time= 0.0277\n",
      "Epoch: 0085 train_loss= 0.8682 train_acc= 0.9000 val_loss= 1.1377 val_acc= 0.7600 time= 0.0183\n",
      "Epoch: 0086 train_loss= 0.8597 train_acc= 0.9000 val_loss= 1.1308 val_acc= 0.7600 time= 0.0181\n",
      "Epoch: 0087 train_loss= 0.8514 train_acc= 0.9000 val_loss= 1.1238 val_acc= 0.7633 time= 0.0193\n",
      "Epoch: 0088 train_loss= 0.8432 train_acc= 0.9000 val_loss= 1.1171 val_acc= 0.7667 time= 0.0271\n",
      "Epoch: 0089 train_loss= 0.8351 train_acc= 0.9000 val_loss= 1.1106 val_acc= 0.7700 time= 0.0228\n",
      "Epoch: 0090 train_loss= 0.8272 train_acc= 0.9000 val_loss= 1.1042 val_acc= 0.7700 time= 0.0189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0091 train_loss= 0.8194 train_acc= 0.9071 val_loss= 1.0980 val_acc= 0.7700 time= 0.0269\n",
      "Epoch: 0092 train_loss= 0.8118 train_acc= 0.9071 val_loss= 1.0919 val_acc= 0.7700 time= 0.0259\n",
      "Epoch: 0093 train_loss= 0.8044 train_acc= 0.9071 val_loss= 1.0861 val_acc= 0.7733 time= 0.0187\n",
      "Epoch: 0094 train_loss= 0.7971 train_acc= 0.9071 val_loss= 1.0802 val_acc= 0.7700 time= 0.0188\n",
      "Epoch: 0095 train_loss= 0.7899 train_acc= 0.9071 val_loss= 1.0746 val_acc= 0.7700 time= 0.0177\n",
      "Epoch: 0096 train_loss= 0.7830 train_acc= 0.9071 val_loss= 1.0691 val_acc= 0.7700 time= 0.0184\n",
      "Epoch: 0097 train_loss= 0.7761 train_acc= 0.9071 val_loss= 1.0637 val_acc= 0.7733 time= 0.0208\n",
      "Epoch: 0098 train_loss= 0.7695 train_acc= 0.9000 val_loss= 1.0586 val_acc= 0.7733 time= 0.0199\n",
      "Epoch: 0099 train_loss= 0.7631 train_acc= 0.9071 val_loss= 1.0538 val_acc= 0.7767 time= 0.0195\n",
      "Epoch: 0100 train_loss= 0.7567 train_acc= 0.9071 val_loss= 1.0489 val_acc= 0.7767 time= 0.0235\n",
      "Epoch: 0101 train_loss= 0.7507 train_acc= 0.9071 val_loss= 1.0442 val_acc= 0.7767 time= 0.0195\n",
      "Epoch: 0102 train_loss= 0.7446 train_acc= 0.9071 val_loss= 1.0394 val_acc= 0.7800 time= 0.0195\n",
      "Epoch: 0103 train_loss= 0.7387 train_acc= 0.9286 val_loss= 1.0349 val_acc= 0.7833 time= 0.0242\n",
      "Epoch: 0104 train_loss= 0.7328 train_acc= 0.9286 val_loss= 1.0304 val_acc= 0.7800 time= 0.0246\n",
      "Epoch: 0105 train_loss= 0.7271 train_acc= 0.9286 val_loss= 1.0260 val_acc= 0.7833 time= 0.0190\n",
      "Epoch: 0106 train_loss= 0.7214 train_acc= 0.9286 val_loss= 1.0216 val_acc= 0.7833 time= 0.0186\n",
      "Epoch: 0107 train_loss= 0.7159 train_acc= 0.9286 val_loss= 1.0173 val_acc= 0.7833 time= 0.0186\n",
      "Epoch: 0108 train_loss= 0.7105 train_acc= 0.9286 val_loss= 1.0130 val_acc= 0.7833 time= 0.0186\n",
      "Epoch: 0109 train_loss= 0.7050 train_acc= 0.9286 val_loss= 1.0088 val_acc= 0.7833 time= 0.0190\n",
      "Epoch: 0110 train_loss= 0.6995 train_acc= 0.9286 val_loss= 1.0044 val_acc= 0.7833 time= 0.0276\n",
      "Epoch: 0111 train_loss= 0.6943 train_acc= 0.9357 val_loss= 1.0003 val_acc= 0.7833 time= 0.0189\n",
      "Epoch: 0112 train_loss= 0.6891 train_acc= 0.9357 val_loss= 0.9961 val_acc= 0.7833 time= 0.0203\n",
      "Epoch: 0113 train_loss= 0.6841 train_acc= 0.9357 val_loss= 0.9918 val_acc= 0.7833 time= 0.0190\n",
      "Epoch: 0114 train_loss= 0.6791 train_acc= 0.9357 val_loss= 0.9876 val_acc= 0.7833 time= 0.0183\n",
      "Epoch: 0115 train_loss= 0.6740 train_acc= 0.9357 val_loss= 0.9836 val_acc= 0.7833 time= 0.0231\n",
      "Epoch: 0116 train_loss= 0.6691 train_acc= 0.9357 val_loss= 0.9794 val_acc= 0.7833 time= 0.0195\n",
      "Epoch: 0117 train_loss= 0.6642 train_acc= 0.9357 val_loss= 0.9755 val_acc= 0.7833 time= 0.0183\n",
      "Epoch: 0118 train_loss= 0.6594 train_acc= 0.9357 val_loss= 0.9716 val_acc= 0.7833 time= 0.0194\n",
      "Epoch: 0119 train_loss= 0.6547 train_acc= 0.9357 val_loss= 0.9677 val_acc= 0.7833 time= 0.0188\n",
      "Epoch: 0120 train_loss= 0.6499 train_acc= 0.9357 val_loss= 0.9638 val_acc= 0.7833 time= 0.0182\n",
      "Epoch: 0121 train_loss= 0.6453 train_acc= 0.9357 val_loss= 0.9597 val_acc= 0.7833 time= 0.0187\n",
      "Epoch: 0122 train_loss= 0.6407 train_acc= 0.9357 val_loss= 0.9560 val_acc= 0.7833 time= 0.0187\n",
      "Epoch: 0123 train_loss= 0.6362 train_acc= 0.9357 val_loss= 0.9527 val_acc= 0.7833 time= 0.0196\n",
      "Epoch: 0124 train_loss= 0.6318 train_acc= 0.9357 val_loss= 0.9494 val_acc= 0.7833 time= 0.0183\n",
      "Epoch: 0125 train_loss= 0.6274 train_acc= 0.9357 val_loss= 0.9462 val_acc= 0.7833 time= 0.0183\n",
      "Epoch: 0126 train_loss= 0.6231 train_acc= 0.9357 val_loss= 0.9431 val_acc= 0.7833 time= 0.0189\n",
      "Epoch: 0127 train_loss= 0.6190 train_acc= 0.9357 val_loss= 0.9402 val_acc= 0.7833 time= 0.0227\n",
      "Epoch: 0128 train_loss= 0.6150 train_acc= 0.9357 val_loss= 0.9378 val_acc= 0.7833 time= 0.0194\n",
      "Epoch: 0129 train_loss= 0.6111 train_acc= 0.9357 val_loss= 0.9356 val_acc= 0.7867 time= 0.0194\n",
      "Epoch: 0130 train_loss= 0.6075 train_acc= 0.9357 val_loss= 0.9335 val_acc= 0.7900 time= 0.0184\n",
      "Epoch: 0131 train_loss= 0.6039 train_acc= 0.9357 val_loss= 0.9310 val_acc= 0.7900 time= 0.0190\n",
      "Epoch: 0132 train_loss= 0.6004 train_acc= 0.9500 val_loss= 0.9281 val_acc= 0.7867 time= 0.0192\n",
      "Epoch: 0133 train_loss= 0.5969 train_acc= 0.9429 val_loss= 0.9251 val_acc= 0.7867 time= 0.0235\n",
      "Epoch: 0134 train_loss= 0.5934 train_acc= 0.9429 val_loss= 0.9221 val_acc= 0.7900 time= 0.0194\n",
      "Epoch: 0135 train_loss= 0.5898 train_acc= 0.9429 val_loss= 0.9193 val_acc= 0.7900 time= 0.0186\n",
      "Epoch: 0136 train_loss= 0.5862 train_acc= 0.9500 val_loss= 0.9161 val_acc= 0.7900 time= 0.0188\n",
      "Epoch: 0137 train_loss= 0.5825 train_acc= 0.9500 val_loss= 0.9129 val_acc= 0.7933 time= 0.0192\n",
      "Epoch: 0138 train_loss= 0.5790 train_acc= 0.9500 val_loss= 0.9100 val_acc= 0.7933 time= 0.0191\n",
      "Epoch: 0139 train_loss= 0.5757 train_acc= 0.9500 val_loss= 0.9068 val_acc= 0.7967 time= 0.0189\n",
      "Epoch: 0140 train_loss= 0.5722 train_acc= 0.9500 val_loss= 0.9034 val_acc= 0.7967 time= 0.0187\n",
      "Epoch: 0141 train_loss= 0.5690 train_acc= 0.9500 val_loss= 0.9000 val_acc= 0.8067 time= 0.0193\n",
      "Epoch: 0142 train_loss= 0.5656 train_acc= 0.9500 val_loss= 0.8968 val_acc= 0.8067 time= 0.0187\n",
      "Epoch: 0143 train_loss= 0.5624 train_acc= 0.9500 val_loss= 0.8939 val_acc= 0.8033 time= 0.0204\n",
      "Epoch: 0144 train_loss= 0.5593 train_acc= 0.9500 val_loss= 0.8913 val_acc= 0.8067 time= 0.0199\n",
      "Epoch: 0145 train_loss= 0.5563 train_acc= 0.9500 val_loss= 0.8885 val_acc= 0.8133 time= 0.0224\n",
      "Epoch: 0146 train_loss= 0.5533 train_acc= 0.9500 val_loss= 0.8856 val_acc= 0.8133 time= 0.0203\n",
      "Epoch: 0147 train_loss= 0.5503 train_acc= 0.9500 val_loss= 0.8825 val_acc= 0.8133 time= 0.0195\n",
      "Epoch: 0148 train_loss= 0.5473 train_acc= 0.9500 val_loss= 0.8794 val_acc= 0.8100 time= 0.0204\n",
      "Epoch: 0149 train_loss= 0.5443 train_acc= 0.9500 val_loss= 0.8769 val_acc= 0.8133 time= 0.0195\n",
      "Epoch: 0150 train_loss= 0.5415 train_acc= 0.9571 val_loss= 0.8745 val_acc= 0.8133 time= 0.0178\n",
      "Epoch: 0151 train_loss= 0.5388 train_acc= 0.9571 val_loss= 0.8722 val_acc= 0.8133 time= 0.0191\n",
      "Epoch: 0152 train_loss= 0.5361 train_acc= 0.9571 val_loss= 0.8704 val_acc= 0.8167 time= 0.0201\n",
      "Epoch: 0153 train_loss= 0.5335 train_acc= 0.9571 val_loss= 0.8685 val_acc= 0.8200 time= 0.0179\n",
      "Epoch: 0154 train_loss= 0.5310 train_acc= 0.9571 val_loss= 0.8669 val_acc= 0.8133 time= 0.0182\n",
      "Epoch: 0155 train_loss= 0.5284 train_acc= 0.9571 val_loss= 0.8656 val_acc= 0.8133 time= 0.0197\n",
      "Epoch: 0156 train_loss= 0.5259 train_acc= 0.9571 val_loss= 0.8646 val_acc= 0.8167 time= 0.0185\n",
      "Epoch: 0157 train_loss= 0.5234 train_acc= 0.9571 val_loss= 0.8636 val_acc= 0.8167 time= 0.0187\n",
      "Epoch: 0158 train_loss= 0.5208 train_acc= 0.9571 val_loss= 0.8623 val_acc= 0.8167 time= 0.0185\n",
      "Epoch: 0159 train_loss= 0.5182 train_acc= 0.9571 val_loss= 0.8608 val_acc= 0.8167 time= 0.0185\n",
      "Epoch: 0160 train_loss= 0.5155 train_acc= 0.9571 val_loss= 0.8593 val_acc= 0.8167 time= 0.0190\n",
      "Epoch: 0161 train_loss= 0.5128 train_acc= 0.9571 val_loss= 0.8578 val_acc= 0.8167 time= 0.0185\n",
      "Epoch: 0162 train_loss= 0.5102 train_acc= 0.9571 val_loss= 0.8560 val_acc= 0.8167 time= 0.0185\n",
      "Epoch: 0163 train_loss= 0.5075 train_acc= 0.9571 val_loss= 0.8540 val_acc= 0.8167 time= 0.0189\n",
      "Epoch: 0164 train_loss= 0.5048 train_acc= 0.9571 val_loss= 0.8521 val_acc= 0.8133 time= 0.0193\n",
      "Epoch: 0165 train_loss= 0.5022 train_acc= 0.9571 val_loss= 0.8499 val_acc= 0.8133 time= 0.0183\n",
      "Epoch: 0166 train_loss= 0.4996 train_acc= 0.9571 val_loss= 0.8480 val_acc= 0.8133 time= 0.0190\n",
      "Epoch: 0167 train_loss= 0.4971 train_acc= 0.9571 val_loss= 0.8462 val_acc= 0.8133 time= 0.0182\n",
      "Epoch: 0168 train_loss= 0.4947 train_acc= 0.9571 val_loss= 0.8443 val_acc= 0.8133 time= 0.0194\n",
      "Epoch: 0169 train_loss= 0.4922 train_acc= 0.9571 val_loss= 0.8424 val_acc= 0.8200 time= 0.0185\n",
      "Epoch: 0170 train_loss= 0.4897 train_acc= 0.9643 val_loss= 0.8407 val_acc= 0.8200 time= 0.0184\n",
      "Epoch: 0171 train_loss= 0.4873 train_acc= 0.9643 val_loss= 0.8392 val_acc= 0.8200 time= 0.0183\n",
      "Epoch: 0172 train_loss= 0.4850 train_acc= 0.9643 val_loss= 0.8377 val_acc= 0.8233 time= 0.0192\n",
      "Epoch: 0173 train_loss= 0.4828 train_acc= 0.9714 val_loss= 0.8360 val_acc= 0.8233 time= 0.0189\n",
      "Epoch: 0174 train_loss= 0.4807 train_acc= 0.9714 val_loss= 0.8342 val_acc= 0.8233 time= 0.0184\n",
      "Epoch: 0175 train_loss= 0.4785 train_acc= 0.9714 val_loss= 0.8323 val_acc= 0.8233 time= 0.0192\n",
      "Epoch: 0176 train_loss= 0.4763 train_acc= 0.9714 val_loss= 0.8303 val_acc= 0.8233 time= 0.0188\n",
      "Epoch: 0177 train_loss= 0.4740 train_acc= 0.9714 val_loss= 0.8281 val_acc= 0.8233 time= 0.0183\n",
      "Epoch: 0178 train_loss= 0.4718 train_acc= 0.9714 val_loss= 0.8260 val_acc= 0.8233 time= 0.0192\n",
      "Epoch: 0179 train_loss= 0.4698 train_acc= 0.9714 val_loss= 0.8239 val_acc= 0.8233 time= 0.0185\n",
      "Epoch: 0180 train_loss= 0.4675 train_acc= 0.9714 val_loss= 0.8216 val_acc= 0.8233 time= 0.0183\n",
      "Epoch: 0181 train_loss= 0.4654 train_acc= 0.9714 val_loss= 0.8197 val_acc= 0.8233 time= 0.0184\n",
      "Epoch: 0182 train_loss= 0.4632 train_acc= 0.9714 val_loss= 0.8178 val_acc= 0.8233 time= 0.0180\n",
      "Epoch: 0183 train_loss= 0.4610 train_acc= 0.9714 val_loss= 0.8162 val_acc= 0.8233 time= 0.0192\n",
      "Epoch: 0184 train_loss= 0.4589 train_acc= 0.9714 val_loss= 0.8146 val_acc= 0.8233 time= 0.0189\n",
      "Epoch: 0185 train_loss= 0.4568 train_acc= 0.9714 val_loss= 0.8129 val_acc= 0.8233 time= 0.0179\n",
      "Epoch: 0186 train_loss= 0.4547 train_acc= 0.9714 val_loss= 0.8120 val_acc= 0.8233 time= 0.0181\n",
      "Epoch: 0187 train_loss= 0.4525 train_acc= 0.9714 val_loss= 0.8108 val_acc= 0.8233 time= 0.0182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0188 train_loss= 0.4503 train_acc= 0.9714 val_loss= 0.8098 val_acc= 0.8233 time= 0.0191\n",
      "Epoch: 0189 train_loss= 0.4482 train_acc= 0.9714 val_loss= 0.8089 val_acc= 0.8233 time= 0.0249\n",
      "Epoch: 0190 train_loss= 0.4461 train_acc= 0.9714 val_loss= 0.8079 val_acc= 0.8200 time= 0.0216\n",
      "Epoch: 0191 train_loss= 0.4440 train_acc= 0.9714 val_loss= 0.8069 val_acc= 0.8233 time= 0.0202\n",
      "Epoch: 0192 train_loss= 0.4420 train_acc= 0.9714 val_loss= 0.8062 val_acc= 0.8233 time= 0.0199\n",
      "Epoch: 0193 train_loss= 0.4400 train_acc= 0.9714 val_loss= 0.8052 val_acc= 0.8233 time= 0.0222\n",
      "Epoch: 0194 train_loss= 0.4379 train_acc= 0.9714 val_loss= 0.8040 val_acc= 0.8233 time= 0.0187\n",
      "Epoch: 0195 train_loss= 0.4360 train_acc= 0.9714 val_loss= 0.8029 val_acc= 0.8233 time= 0.0197\n",
      "Epoch: 0196 train_loss= 0.4339 train_acc= 0.9714 val_loss= 0.8013 val_acc= 0.8233 time= 0.0256\n",
      "Epoch: 0197 train_loss= 0.4319 train_acc= 0.9714 val_loss= 0.7994 val_acc= 0.8267 time= 0.0226\n",
      "Epoch: 0198 train_loss= 0.4300 train_acc= 0.9714 val_loss= 0.7974 val_acc= 0.8267 time= 0.0186\n",
      "Epoch: 0199 train_loss= 0.4282 train_acc= 0.9714 val_loss= 0.7955 val_acc= 0.8267 time= 0.0195\n",
      "Epoch: 0200 train_loss= 0.4263 train_acc= 0.9714 val_loss= 0.7934 val_acc= 0.8267 time= 0.0178\n"
     ]
    }
   ],
   "source": [
    "NB_EPOCH = 200\n",
    "PATIENCE = 10  # early stopping patience\n",
    "# Helper variables for main training loop\n",
    "wait = 0\n",
    "preds = None\n",
    "best_val_loss = 99999\n",
    "\n",
    "# Fit\n",
    "for epoch in range(1, NB_EPOCH+1):\n",
    "\n",
    "    # Log wall-clock time\n",
    "    t = time.time()\n",
    "\n",
    "    # Single training iteration (we mask nodes without labels for loss calculation)\n",
    "    model.fit(graph, y_train, sample_weight=train_mask,\n",
    "              batch_size=A.shape[0], epochs=1, shuffle=False, verbose=0)\n",
    "\n",
    "    # Predict on full dataset\n",
    "    preds = model.predict(graph, batch_size=A.shape[0])\n",
    "\n",
    "    # Train / validation scores\n",
    "    train_val_loss, train_val_acc = evaluate_preds(preds, [y_train, y_val],\n",
    "                                                   [idx_train, idx_val])\n",
    "    print(\"Epoch: {:04d}\".format(epoch),\n",
    "          \"train_loss= {:.4f}\".format(train_val_loss[0]),\n",
    "          \"train_acc= {:.4f}\".format(train_val_acc[0]),\n",
    "          \"val_loss= {:.4f}\".format(train_val_loss[1]),\n",
    "          \"val_acc= {:.4f}\".format(train_val_acc[1]),\n",
    "          \"time= {:.4f}\".format(time.time() - t))\n",
    "\n",
    "    # Early stopping\n",
    "    if train_val_loss[1] < best_val_loss:\n",
    "        best_val_loss = train_val_loss[1]\n",
    "        wait = 0\n",
    "    else:\n",
    "        if wait >= PATIENCE:\n",
    "            print('Epoch {}: early stopping'.format(epoch))\n",
    "            break\n",
    "        wait += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.8440\n",
      "accuracy = 0.8210\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate_preds(preds, [y_test], [idx_test])\n",
    "print(f\"\"\"\n",
    "loss = {test_loss[0]:.4f}\n",
    "accuracy = {test_acc[0]:.4f}\n",
    "\"\"\".strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
